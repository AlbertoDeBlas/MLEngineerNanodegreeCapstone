{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  # Autoreload all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "import mxnet as mx\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#Import custom libraries\n",
    "from data_loading import list_csv_files, load_dataframe_from_s3\n",
    "from data_cleaning import (dropMissingColumns, dropLowVarianceCols, \n",
    "dropColumnsWithUniqueValues, replaceForNan, timestampToFloat, to_category, to_int, impute_mode_categorical,\n",
    "impute_median_numerical, encodeColumnByLabel, timestampToInt)\n",
    "from memory_dataframe import memory_usage\n",
    "from feature_selection import unzipModel, explained_variance\n",
    "from data_visualization import display_component\n",
    "from csv_transformation import csvToDataFrame, readKmeanResultToDF\n",
    "from model_selection import loadModelByGroupNumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3 client to get S3 data\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name='sagemaker-eu-west-1-848439228145'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list withe files in the bucket and print the file names to be sure that we will be retrieving from the correct location and obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Capstone/Udacity_AZDIAS_052018.csv', 'Capstone/Udacity_CUSTOMERS_052018.csv', 'Capstone/Udacity_MAILOUT_052018_TEST.csv', 'Capstone/Udacity_MAILOUT_052018_TRAIN.csv', 'arvato/azdias.csv', 'arvato/customers.csv', 'arvato/transform/pca/transform/test/azdias.csv.out', 'arvato/transform/pca/transform/test/customers.csv.out', 'mailout-xgboost/mailout_test.csv', 'mailout-xgboost/mailout_train.csv', 'mailout-xgboost/mailout_validation.csv', 'mailout/transform/test/mailout_test.csv.out', 'test/customers.csv.out', 'xgboost-200512-2100-006-5d9003f4-2020-05-12-21-13-29-318/mailout_test.csv.out', 'xgboost-200513-1550-009-510b69c6-2020-05-13-16-00-48-200/mailout_test.csv.out', 'xgboost-200513-2107-008-571099bb-2020-05-13-21-17-53-739/mailout_test.csv.out', 'xgboost-200513-2210-004-d4b243f8-2020-05-13-22-22-41-620/mailout_test.csv.out']\n"
     ]
    }
   ],
   "source": [
    "# get a list of objects in the bucket\n",
    "obj_list=s3_client.list_objects(Bucket=bucket_name)\n",
    "#filter the list with to get only csv\n",
    "filtered_list = list_csv_files(obj_list)\n",
    "# print csv objects in in S3 bucket  \n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9628</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0    9626         2         1.0      10.0          NaN   \n",
       "1           1    9628        -1         9.0      11.0          NaN   \n",
       "2           2  143872        -1         1.0       6.0          NaN   \n",
       "3           3  143873         1         1.0       8.0          NaN   \n",
       "4           4  143874        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VK_ZG11  \\\n",
       "0          NaN          NaN          NaN                  10.0  ...      2.0   \n",
       "1          NaN          NaN          NaN                   NaN  ...      3.0   \n",
       "2          NaN          NaN          NaN                   0.0  ...     11.0   \n",
       "3          NaN          NaN          NaN                   8.0  ...      2.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...      4.0   \n",
       "\n",
       "   W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0             6.0             9.0       7.0         3  COSMETIC_AND_FOOD   \n",
       "1             0.0             9.0       NaN         3               FOOD   \n",
       "2             6.0             9.0       2.0         3  COSMETIC_AND_FOOD   \n",
       "3             NaN             9.0       7.0         1           COSMETIC   \n",
       "4             2.0             9.0       3.0         1               FOOD   \n",
       "\n",
       "   CUSTOMER_GROUP  ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0     MULTI_BUYER                0         1                    4  \n",
       "1    SINGLE_BUYER                0         1                    4  \n",
       "2     MULTI_BUYER                0         2                    4  \n",
       "3     MULTI_BUYER                0         1                    4  \n",
       "4     MULTI_BUYER                0         1                    3  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df = None\n",
    "customers_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[1])\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0  910215        -1         NaN       NaN          NaN   \n",
       "1           1  910220        -1         9.0       0.0          NaN   \n",
       "2           2  910225        -1         9.0      17.0          NaN   \n",
       "3           3  910226         2         1.0      13.0          NaN   \n",
       "4           4  910241        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VHN  \\\n",
       "0          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "1          NaN          NaN          NaN                  21.0  ...  4.0   \n",
       "2          NaN          NaN          NaN                  17.0  ...  2.0   \n",
       "3          NaN          NaN          NaN                  13.0  ...  0.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...  2.0   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1       8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2       9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3       7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4       3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3         1                    2  \n",
       "1         5         2                    1  \n",
       "2         5         2                    3  \n",
       "3         3         2                    4  \n",
       "4         4         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df = None\n",
    "azdias_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[0])\n",
    "azdias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>11766.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>139810.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>137910.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>141725.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>1.747525</td>\n",
       "      <td>11.352009</td>\n",
       "      <td>12.337243</td>\n",
       "      <td>13.672353</td>\n",
       "      <td>14.647059</td>\n",
       "      <td>15.377119</td>\n",
       "      <td>10.331579</td>\n",
       "      <td>...</td>\n",
       "      <td>4.374417</td>\n",
       "      <td>4.564769</td>\n",
       "      <td>3.168868</td>\n",
       "      <td>4.152716</td>\n",
       "      <td>8.646371</td>\n",
       "      <td>3.723133</td>\n",
       "      <td>2.576806</td>\n",
       "      <td>0.090247</td>\n",
       "      <td>1.376432</td>\n",
       "      <td>3.060907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55325.311233</td>\n",
       "      <td>55325.311233</td>\n",
       "      <td>1.391672</td>\n",
       "      <td>1.966334</td>\n",
       "      <td>6.275026</td>\n",
       "      <td>4.006050</td>\n",
       "      <td>3.243335</td>\n",
       "      <td>2.753787</td>\n",
       "      <td>2.307653</td>\n",
       "      <td>4.134828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.924355</td>\n",
       "      <td>2.887035</td>\n",
       "      <td>2.233516</td>\n",
       "      <td>1.974375</td>\n",
       "      <td>1.154001</td>\n",
       "      <td>2.095540</td>\n",
       "      <td>1.168486</td>\n",
       "      <td>0.286536</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>1.086254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47912.750000</td>\n",
       "      <td>47913.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>143738.250000</td>\n",
       "      <td>143739.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191651.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0            LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  191652.000000  191652.000000  191652.000000  145056.000000   \n",
       "mean    95825.500000   95826.500000       0.344359       1.747525   \n",
       "std     55325.311233   55325.311233       1.391672       1.966334   \n",
       "min         0.000000       1.000000      -1.000000       1.000000   \n",
       "25%     47912.750000   47913.750000      -1.000000       1.000000   \n",
       "50%     95825.500000   95826.500000       0.000000       1.000000   \n",
       "75%    143738.250000  143739.250000       2.000000       1.000000   \n",
       "max    191651.000000  191652.000000       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  145056.000000  11766.000000  5100.000000  1275.000000   236.000000   \n",
       "mean       11.352009     12.337243    13.672353    14.647059    15.377119   \n",
       "std         6.275026      4.006050     3.243335     2.753787     2.307653   \n",
       "min         0.000000      2.000000     2.000000     5.000000     8.000000   \n",
       "25%         8.000000      9.000000    11.000000    13.000000    14.000000   \n",
       "50%        11.000000     13.000000    14.000000    15.000000    16.000000   \n",
       "75%        16.000000     16.000000    16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000    18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...       VK_DHT4A     VK_DISTANZ        VK_ZG11  \\\n",
       "count         139810.000000  ...  143781.000000  143781.000000  143781.000000   \n",
       "mean              10.331579  ...       4.374417       4.564769       3.168868   \n",
       "std                4.134828  ...       2.924355       2.887035       2.233516   \n",
       "min                0.000000  ...       1.000000       1.000000       1.000000   \n",
       "25%                9.000000  ...       2.000000       2.000000       1.000000   \n",
       "50%               10.000000  ...       4.000000       4.000000       3.000000   \n",
       "75%               13.000000  ...       7.000000       7.000000       4.000000   \n",
       "max               25.000000  ...      11.000000      13.000000      11.000000   \n",
       "\n",
       "       W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE       ZABEOTYP  \\\n",
       "count   137910.000000   145056.000000  141725.000000  191652.000000   \n",
       "mean         4.152716        8.646371       3.723133       2.576806   \n",
       "std          1.974375        1.154001       2.095540       1.168486   \n",
       "min          0.000000        1.000000       0.000000       1.000000   \n",
       "25%          2.000000        9.000000       2.000000       1.000000   \n",
       "50%          5.000000        9.000000       3.000000       3.000000   \n",
       "75%          6.000000        9.000000       5.000000       3.000000   \n",
       "max          6.000000        9.000000       8.000000       6.000000   \n",
       "\n",
       "       ONLINE_PURCHASE      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count    191652.000000  191652.000000         191652.000000  \n",
       "mean          0.090247       1.376432              3.060907  \n",
       "std           0.286536       0.484492              1.086254  \n",
       "min           0.000000       1.000000              1.000000  \n",
       "25%           0.000000       1.000000              3.000000  \n",
       "50%           0.000000       1.000000              3.000000  \n",
       "75%           0.000000       2.000000              4.000000  \n",
       "max           1.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(customers_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891221.000000</td>\n",
       "      <td>8.912210e+05</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>81058.000000</td>\n",
       "      <td>29499.000000</td>\n",
       "      <td>6170.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>628274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>770025.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>783619.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>798073.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-0.358435</td>\n",
       "      <td>4.421928</td>\n",
       "      <td>10.864126</td>\n",
       "      <td>11.745392</td>\n",
       "      <td>13.402658</td>\n",
       "      <td>14.476013</td>\n",
       "      <td>15.089627</td>\n",
       "      <td>13.700717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417322</td>\n",
       "      <td>6.001214</td>\n",
       "      <td>7.532130</td>\n",
       "      <td>5.945972</td>\n",
       "      <td>3.933406</td>\n",
       "      <td>7.908791</td>\n",
       "      <td>4.052836</td>\n",
       "      <td>3.362438</td>\n",
       "      <td>1.522098</td>\n",
       "      <td>2.777398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257273.486465</td>\n",
       "      <td>2.572735e+05</td>\n",
       "      <td>1.198724</td>\n",
       "      <td>3.638805</td>\n",
       "      <td>7.639683</td>\n",
       "      <td>4.097660</td>\n",
       "      <td>3.243300</td>\n",
       "      <td>2.712427</td>\n",
       "      <td>2.452932</td>\n",
       "      <td>5.079849</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166572</td>\n",
       "      <td>2.856091</td>\n",
       "      <td>3.247789</td>\n",
       "      <td>2.771464</td>\n",
       "      <td>1.964701</td>\n",
       "      <td>1.923137</td>\n",
       "      <td>1.949539</td>\n",
       "      <td>1.352704</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>1.068775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916530e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222805.000000</td>\n",
       "      <td>4.144580e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668415.000000</td>\n",
       "      <td>8.600680e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891220.000000</td>\n",
       "      <td>1.082873e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0           LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  891221.000000  8.912210e+05  891221.000000  817722.000000   \n",
       "mean   445610.000000  6.372630e+05      -0.358435       4.421928   \n",
       "std    257273.486465  2.572735e+05       1.198724       3.638805   \n",
       "min         0.000000  1.916530e+05      -1.000000       1.000000   \n",
       "25%    222805.000000  4.144580e+05      -1.000000       1.000000   \n",
       "50%    445610.000000  6.372630e+05      -1.000000       3.000000   \n",
       "75%    668415.000000  8.600680e+05      -1.000000       9.000000   \n",
       "max    891220.000000  1.082873e+06       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  817722.000000  81058.000000  29499.000000  6170.000000  1205.000000   \n",
       "mean       10.864126     11.745392     13.402658    14.476013    15.089627   \n",
       "std         7.639683      4.097660      3.243300     2.712427     2.452932   \n",
       "min         0.000000      2.000000      2.000000     4.000000     7.000000   \n",
       "25%         0.000000      8.000000     11.000000    13.000000    14.000000   \n",
       "50%        13.000000     12.000000     14.000000    15.000000    15.000000   \n",
       "75%        17.000000     15.000000     16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000     18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...            VHN       VK_DHT4A     VK_DISTANZ  \\\n",
       "count         628274.000000  ...  770025.000000  815304.000000  815304.000000   \n",
       "mean              13.700717  ...       2.417322       6.001214       7.532130   \n",
       "std                5.079849  ...       1.166572       2.856091       3.247789   \n",
       "min                0.000000  ...       0.000000       1.000000       1.000000   \n",
       "25%               11.000000  ...       2.000000       3.000000       5.000000   \n",
       "50%               14.000000  ...       2.000000       6.000000       8.000000   \n",
       "75%               17.000000  ...       3.000000       9.000000      10.000000   \n",
       "max               25.000000  ...       4.000000      11.000000      13.000000   \n",
       "\n",
       "             VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE  \\\n",
       "count  815304.000000   783619.000000   817722.000000  798073.000000   \n",
       "mean        5.945972        3.933406        7.908791       4.052836   \n",
       "std         2.771464        1.964701        1.923137       1.949539   \n",
       "min         1.000000        0.000000        1.000000       0.000000   \n",
       "25%         4.000000        2.000000        8.000000       3.000000   \n",
       "50%         6.000000        4.000000        9.000000       3.000000   \n",
       "75%         8.000000        6.000000        9.000000       5.000000   \n",
       "max        11.000000        6.000000        9.000000       8.000000   \n",
       "\n",
       "            ZABEOTYP      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count  891221.000000  891221.000000         891221.000000  \n",
       "mean        3.362438       1.522098              2.777398  \n",
       "std         1.352704       0.499512              1.068775  \n",
       "min         1.000000       1.000000              1.000000  \n",
       "25%         3.000000       1.000000              2.000000  \n",
       "50%         3.000000       2.000000              3.000000  \n",
       "75%         4.000000       2.000000              4.000000  \n",
       "max         6.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 361 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(azdias_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTER_KIND4                    99.864792\n",
       "ALTER_KIND3                    99.307691\n",
       "ALTER_KIND2                    96.690047\n",
       "ALTER_KIND1                    90.904837\n",
       "EXTSEL992                      73.399639\n",
       "KK_KUNDENTYP                   65.596749\n",
       "ALTERSKATEGORIE_FEIN           29.504130\n",
       "D19_VERSI_ONLINE_QUOTE_12      28.849522\n",
       "D19_LETZTER_KAUF_BRANCHE       28.849522\n",
       "D19_BANKEN_ONLINE_QUOTE_12     28.849522\n",
       "D19_TELKO_ONLINE_QUOTE_12      28.849522\n",
       "D19_VERSAND_ONLINE_QUOTE_12    28.849522\n",
       "D19_KONSUMTYP                  28.849522\n",
       "D19_SOZIALES                   28.849522\n",
       "D19_GESAMT_ONLINE_QUOTE_12     28.849522\n",
       "D19_LOTTO                      28.849522\n",
       "KBA05_SEG8                     14.959701\n",
       "KBA05_SEG7                     14.959701\n",
       "KBA05_KW2                      14.959701\n",
       "KBA05_KW3                      14.959701\n",
       "KBA05_MAXAH                    14.959701\n",
       "KBA05_MAXBJ                    14.959701\n",
       "KBA05_MAXHERST                 14.959701\n",
       "KBA05_MAXSEG                   14.959701\n",
       "KBA05_MAXVORB                  14.959701\n",
       "KBA05_MOD1                     14.959701\n",
       "KBA05_MOD2                     14.959701\n",
       "KBA05_MOD3                     14.959701\n",
       "KBA05_MOD4                     14.959701\n",
       "KBA05_MOD8                     14.959701\n",
       "                                 ...    \n",
       "D19_RATGEBER                    0.000000\n",
       "FINANZ_ANLEGER                  0.000000\n",
       "D19_REISEN                      0.000000\n",
       "D19_SAMMELARTIKEL               0.000000\n",
       "D19_SCHUHE                      0.000000\n",
       "D19_SONSTIGE                    0.000000\n",
       "D19_TECHNIK                     0.000000\n",
       "D19_TELKO_ANZ_12                0.000000\n",
       "D19_TELKO_ANZ_24                0.000000\n",
       "D19_TELKO_DATUM                 0.000000\n",
       "D19_TELKO_MOBILE                0.000000\n",
       "D19_TELKO_OFFLINE_DATUM         0.000000\n",
       "D19_TELKO_ONLINE_DATUM          0.000000\n",
       "D19_TELKO_REST                  0.000000\n",
       "D19_TIERARTIKEL                 0.000000\n",
       "D19_VERSAND_ANZ_12              0.000000\n",
       "D19_VERSAND_ANZ_24              0.000000\n",
       "D19_VERSAND_DATUM               0.000000\n",
       "D19_VERSAND_OFFLINE_DATUM       0.000000\n",
       "D19_VERSAND_ONLINE_DATUM        0.000000\n",
       "D19_VERSAND_REST                0.000000\n",
       "D19_VERSI_ANZ_12                0.000000\n",
       "D19_VERSI_ANZ_24                0.000000\n",
       "D19_VERSI_DATUM                 0.000000\n",
       "D19_VERSI_OFFLINE_DATUM         0.000000\n",
       "D19_VERSI_ONLINE_DATUM          0.000000\n",
       "D19_VERSICHERUNGEN              0.000000\n",
       "D19_VOLLSORTIMENT               0.000000\n",
       "D19_WEIN_FEINKOST               0.000000\n",
       "Unnamed: 0                      0.000000\n",
       "Length: 367, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = azdias_df.shape[0]\n",
    "missing_values_azdias = azdias_df.isnull().sum().sort_values(ascending = False).divide(other = (rows/100))\n",
    "\n",
    "display(missing_values_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have more than 28% of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 351)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a dict with the names of the columns and then drop this columns from dataframe\n",
    "drop_columns = missing_values_azdias[missing_values_azdias > 28]\n",
    "\n",
    "azdias_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)\n",
    "\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have less than 0.5 variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_description = azdias_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns:  ANZ_HH_TITEL              0.324028\n",
      "ANZ_TITEL                 0.068855\n",
      "D19_TELKO_ANZ_12          0.277552\n",
      "D19_TELKO_ANZ_24          0.393587\n",
      "D19_TELKO_ONLINE_DATUM    0.241035\n",
      "D19_VERSI_ANZ_12          0.434877\n",
      "D19_VERSI_ONLINE_DATUM    0.311191\n",
      "DSL_FLAG                  0.176488\n",
      "GREEN_AVANTGARDE          0.397437\n",
      "HH_DELTA_FLAG             0.290075\n",
      "KBA13_KRSSEG_KLEIN        0.292661\n",
      "KONSUMZELLE               0.424725\n",
      "SOHO_KZ                   0.091392\n",
      "TITEL_KZ                  0.084957\n",
      "UNGLEICHENN_FLAG          0.286278\n",
      "ANREDE_KZ                 0.499512\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ANZ_HH_TITEL', 'ANZ_TITEL', 'D19_TELKO_ANZ_12', 'D19_TELKO_ANZ_24',\n",
       "       'D19_TELKO_ONLINE_DATUM', 'D19_VERSI_ANZ_12', 'D19_VERSI_ONLINE_DATUM',\n",
       "       'DSL_FLAG', 'GREEN_AVANTGARDE', 'HH_DELTA_FLAG', 'KBA13_KRSSEG_KLEIN',\n",
       "       'KONSUMZELLE', 'SOHO_KZ', 'TITEL_KZ', 'UNGLEICHENN_FLAG', 'ANREDE_KZ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropLowVarianceCols(azdias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 335)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 2486.31 Mb\n"
     ]
    }
   ],
   "source": [
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'LNR', 'AGER_TYP', 'AKT_DAT_KL', 'ALTER_HH', 'ANZ_HAUSHALTE_AKTIV', 'ANZ_KINDER', 'ANZ_PERSONEN', 'ANZ_STATISTISCHE_HAUSHALTE', 'ARBEIT', 'BALLRAUM', 'CAMEO_DEU_2015', 'CAMEO_DEUG_2015', 'CAMEO_INTL_2015', 'CJT_GESAMTTYP', 'CJT_KATALOGNUTZER', 'CJT_TYP_1', 'CJT_TYP_2', 'CJT_TYP_3', 'CJT_TYP_4', 'CJT_TYP_5', 'CJT_TYP_6', 'D19_BANKEN_ANZ_12', 'D19_BANKEN_ANZ_24', 'D19_BANKEN_DATUM', 'D19_BANKEN_DIREKT', 'D19_BANKEN_GROSS', 'D19_BANKEN_LOKAL', 'D19_BANKEN_OFFLINE_DATUM', 'D19_BANKEN_ONLINE_DATUM', 'D19_BANKEN_REST', 'D19_BEKLEIDUNG_GEH', 'D19_BEKLEIDUNG_REST', 'D19_BILDUNG', 'D19_BIO_OEKO', 'D19_BUCH_CD', 'D19_DIGIT_SERV', 'D19_DROGERIEARTIKEL', 'D19_ENERGIE', 'D19_FREIZEIT', 'D19_GARTEN', 'D19_GESAMT_ANZ_12', 'D19_GESAMT_ANZ_24', 'D19_GESAMT_DATUM', 'D19_GESAMT_OFFLINE_DATUM', 'D19_GESAMT_ONLINE_DATUM', 'D19_HANDWERK', 'D19_HAUS_DEKO', 'D19_KINDERARTIKEL', 'D19_KONSUMTYP_MAX', 'D19_KOSMETIK', 'D19_LEBENSMITTEL', 'D19_NAHRUNGSERGAENZUNG', 'D19_RATGEBER', 'D19_REISEN', 'D19_SAMMELARTIKEL', 'D19_SCHUHE', 'D19_SONSTIGE', 'D19_TECHNIK', 'D19_TELKO_DATUM', 'D19_TELKO_MOBILE', 'D19_TELKO_OFFLINE_DATUM', 'D19_TELKO_REST', 'D19_TIERARTIKEL', 'D19_VERSAND_ANZ_12', 'D19_VERSAND_ANZ_24', 'D19_VERSAND_DATUM', 'D19_VERSAND_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM', 'D19_VERSAND_REST', 'D19_VERSI_ANZ_24', 'D19_VERSI_DATUM', 'D19_VERSI_OFFLINE_DATUM', 'D19_VERSICHERUNGEN', 'D19_VOLLSORTIMENT', 'D19_WEIN_FEINKOST', 'EINGEFUEGT_AM', 'EINGEZOGENAM_HH_JAHR', 'EWDICHTE', 'FINANZ_ANLEGER', 'FINANZ_HAUSBAUER', 'FINANZ_MINIMALIST', 'FINANZ_SPARER', 'FINANZ_UNAUFFAELLIGER', 'FINANZ_VORSORGER', 'FINANZTYP', 'FIRMENDICHTE', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GEBURTSJAHR', 'GEMEINDETYP', 'GFK_URLAUBERTYP', 'HEALTH_TYP', 'HH_EINKOMMEN_SCORE', 'INNENSTADT', 'KBA05_ALTER1', 'KBA05_ALTER2', 'KBA05_ALTER3', 'KBA05_ALTER4', 'KBA05_ANHANG', 'KBA05_ANTG1', 'KBA05_ANTG2', 'KBA05_ANTG3', 'KBA05_ANTG4', 'KBA05_AUTOQUOT', 'KBA05_BAUMAX', 'KBA05_CCM1', 'KBA05_CCM2', 'KBA05_CCM3', 'KBA05_CCM4', 'KBA05_DIESEL', 'KBA05_FRAU', 'KBA05_GBZ', 'KBA05_HERST1', 'KBA05_HERST2', 'KBA05_HERST3', 'KBA05_HERST4', 'KBA05_HERST5', 'KBA05_HERSTTEMP', 'KBA05_KRSAQUOT', 'KBA05_KRSHERST1', 'KBA05_KRSHERST2', 'KBA05_KRSHERST3', 'KBA05_KRSKLEIN', 'KBA05_KRSOBER', 'KBA05_KRSVAN', 'KBA05_KRSZUL', 'KBA05_KW1', 'KBA05_KW2', 'KBA05_KW3', 'KBA05_MAXAH', 'KBA05_MAXBJ', 'KBA05_MAXHERST', 'KBA05_MAXSEG', 'KBA05_MAXVORB', 'KBA05_MOD1', 'KBA05_MOD2', 'KBA05_MOD3', 'KBA05_MOD4', 'KBA05_MOD8', 'KBA05_MODTEMP', 'KBA05_MOTOR', 'KBA05_MOTRAD', 'KBA05_SEG1', 'KBA05_SEG10', 'KBA05_SEG2', 'KBA05_SEG3', 'KBA05_SEG4', 'KBA05_SEG5', 'KBA05_SEG6', 'KBA05_SEG7', 'KBA05_SEG8', 'KBA05_SEG9', 'KBA05_VORB0', 'KBA05_VORB1', 'KBA05_VORB2', 'KBA05_ZUL1', 'KBA05_ZUL2', 'KBA05_ZUL3', 'KBA05_ZUL4', 'KBA13_ALTERHALTER_30', 'KBA13_ALTERHALTER_45', 'KBA13_ALTERHALTER_60', 'KBA13_ALTERHALTER_61', 'KBA13_ANTG1', 'KBA13_ANTG2', 'KBA13_ANTG3', 'KBA13_ANTG4', 'KBA13_ANZAHL_PKW', 'KBA13_AUDI', 'KBA13_AUTOQUOTE', 'KBA13_BAUMAX', 'KBA13_BJ_1999', 'KBA13_BJ_2000', 'KBA13_BJ_2004', 'KBA13_BJ_2006', 'KBA13_BJ_2008', 'KBA13_BJ_2009', 'KBA13_BMW', 'KBA13_CCM_0_1400', 'KBA13_CCM_1000', 'KBA13_CCM_1200', 'KBA13_CCM_1400', 'KBA13_CCM_1401_2500', 'KBA13_CCM_1500', 'KBA13_CCM_1600', 'KBA13_CCM_1800', 'KBA13_CCM_2000', 'KBA13_CCM_2500', 'KBA13_CCM_2501', 'KBA13_CCM_3000', 'KBA13_CCM_3001', 'KBA13_FAB_ASIEN', 'KBA13_FAB_SONSTIGE', 'KBA13_FIAT', 'KBA13_FORD', 'KBA13_GBZ', 'KBA13_HALTER_20', 'KBA13_HALTER_25', 'KBA13_HALTER_30', 'KBA13_HALTER_35', 'KBA13_HALTER_40', 'KBA13_HALTER_45', 'KBA13_HALTER_50', 'KBA13_HALTER_55', 'KBA13_HALTER_60', 'KBA13_HALTER_65', 'KBA13_HALTER_66', 'KBA13_HERST_ASIEN', 'KBA13_HERST_AUDI_VW', 'KBA13_HERST_BMW_BENZ', 'KBA13_HERST_EUROPA', 'KBA13_HERST_FORD_OPEL', 'KBA13_HERST_SONST', 'KBA13_HHZ', 'KBA13_KMH_0_140', 'KBA13_KMH_110', 'KBA13_KMH_140', 'KBA13_KMH_140_210', 'KBA13_KMH_180', 'KBA13_KMH_210', 'KBA13_KMH_211', 'KBA13_KMH_250', 'KBA13_KMH_251', 'KBA13_KRSAQUOT', 'KBA13_KRSHERST_AUDI_VW', 'KBA13_KRSHERST_BMW_BENZ', 'KBA13_KRSHERST_FORD_OPEL', 'KBA13_KRSSEG_OBER', 'KBA13_KRSSEG_VAN', 'KBA13_KRSZUL_NEU', 'KBA13_KW_0_60', 'KBA13_KW_110', 'KBA13_KW_120', 'KBA13_KW_121', 'KBA13_KW_30', 'KBA13_KW_40', 'KBA13_KW_50', 'KBA13_KW_60', 'KBA13_KW_61_120', 'KBA13_KW_70', 'KBA13_KW_80', 'KBA13_KW_90', 'KBA13_MAZDA', 'KBA13_MERCEDES', 'KBA13_MOTOR', 'KBA13_NISSAN', 'KBA13_OPEL', 'KBA13_PEUGEOT', 'KBA13_RENAULT', 'KBA13_SEG_GELAENDEWAGEN', 'KBA13_SEG_GROSSRAUMVANS', 'KBA13_SEG_KLEINST', 'KBA13_SEG_KLEINWAGEN', 'KBA13_SEG_KOMPAKTKLASSE', 'KBA13_SEG_MINIVANS', 'KBA13_SEG_MINIWAGEN', 'KBA13_SEG_MITTELKLASSE', 'KBA13_SEG_OBEREMITTELKLASSE', 'KBA13_SEG_OBERKLASSE', 'KBA13_SEG_SONSTIGE', 'KBA13_SEG_SPORTWAGEN', 'KBA13_SEG_UTILITIES', 'KBA13_SEG_VAN', 'KBA13_SEG_WOHNMOBILE', 'KBA13_SITZE_4', 'KBA13_SITZE_5', 'KBA13_SITZE_6', 'KBA13_TOYOTA', 'KBA13_VORB_0', 'KBA13_VORB_1', 'KBA13_VORB_1_2', 'KBA13_VORB_2', 'KBA13_VORB_3', 'KBA13_VW', 'KKK', 'KOMBIALTER', 'KONSUMNAEHE', 'LP_FAMILIE_FEIN', 'LP_FAMILIE_GROB', 'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'LP_STATUS_FEIN', 'LP_STATUS_GROB', 'MIN_GEBAEUDEJAHR', 'MOBI_RASTER', 'MOBI_REGIO', 'NATIONALITAET_KZ', 'ONLINE_AFFINITAET', 'ORTSGR_KLS9', 'OST_WEST_KZ', 'PLZ8_ANTG1', 'PLZ8_ANTG2', 'PLZ8_ANTG3', 'PLZ8_ANTG4', 'PLZ8_BAUMAX', 'PLZ8_GBZ', 'PLZ8_HHZ', 'PRAEGENDE_JUGENDJAHRE', 'REGIOTYP', 'RELAT_AB', 'RETOURTYP_BK_S', 'RT_KEIN_ANREIZ', 'RT_SCHNAEPPCHEN', 'RT_UEBERGROESSE', 'SEMIO_DOM', 'SEMIO_ERL', 'SEMIO_FAM', 'SEMIO_KAEM', 'SEMIO_KRIT', 'SEMIO_KULT', 'SEMIO_LUST', 'SEMIO_MAT', 'SEMIO_PFLICHT', 'SEMIO_RAT', 'SEMIO_REL', 'SEMIO_SOZ', 'SEMIO_TRADV', 'SEMIO_VERT', 'SHOPPER_TYP', 'STRUKTURTYP', 'UMFELD_ALT', 'UMFELD_JUNG', 'VERDICHTUNGSRAUM', 'VERS_TYP', 'VHA', 'VHN', 'VK_DHT4A', 'VK_DISTANZ', 'VK_ZG11', 'W_KEIT_KIND_HH', 'WOHNDAUER_2008', 'WOHNLAGE', 'ZABEOTYP', 'ALTERSKATEGORIE_GROB']\n"
     ]
    }
   ],
   "source": [
    "print(list(azdias_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceForNan(azdias_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to reduce the size of the dataframe in order to optimize the memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 650.54 Mb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "categorical_columns = [\n",
    "                        'ALTERSKATEGORIE_GROB','AGER_TYP','ALTER_HH',\n",
    "                      'BALLRAUM','CAMEO_DEUG_2015','CAMEO_DEU_2015','D19_BANKEN_ANZ_24',\n",
    "                      'CJT_GESAMTTYP','D19_BANKEN_ANZ_12','D19_BANKEN_DATUM',\n",
    "                      'D19_BANKEN_OFFLINE_DATUM',\n",
    "                      'D19_BANKEN_ONLINE_DATUM','D19_BANKEN_DIREKT','D19_BANKEN_GROSS',\n",
    "                      'D19_BANKEN_LOKAL','D19_BANKEN_REST',\n",
    "                      'D19_BEKLEIDUNG_GEH','D19_BEKLEIDUNG_REST','D19_BILDUNG',\n",
    "                      'D19_BIO_OEKO','D19_BUCH_CD','D19_DIGIT_SERV','D19_DROGERIEARTIKEL',\n",
    "                      'D19_ENERGIE','D19_FREIZEIT','D19_GARTEN','D19_GESAMT_ANZ_12',\n",
    "                      'D19_GESAMT_ANZ_24','D19_GESAMT_DATUM','D19_GESAMT_OFFLINE_DATUM','D19_GESAMT_ONLINE_DATUM',\n",
    "                      'D19_HANDWERK','D19_HAUS_DEKO','D19_KINDERARTIKEL',\n",
    "                      'D19_KONSUMTYP_MAX','D19_KOSMETIK','D19_LEBENSMITTEL','D19_NAHRUNGSERGAENZUNG',\n",
    "                      'D19_RATGEBER','D19_REISEN','D19_SAMMELARTIKEL','D19_SCHUHE','D19_SONSTIGE',\n",
    "                      'D19_TECHNIK','D19_TELKO_DATUM',\n",
    "                      'D19_TELKO_MOBILE','D19_TELKO_OFFLINE_DATUM',\n",
    "                       'D19_TELKO_REST','D19_TIERARTIKEL','D19_VERSAND_ANZ_12',\n",
    "                      'D19_VERSAND_ANZ_24','D19_VERSAND_DATUM','D19_VERSAND_DATUM',\n",
    "                      'D19_VERSAND_ONLINE_DATUM','D19_VERSAND_REST','D19_VERSICHERUNGEN',\n",
    "                      'D19_VERSI_ANZ_24','D19_VOLLSORTIMENT','D19_WEIN_FEINKOST','EWDICHTE',\n",
    "                      'FINANZTYP','FINANZ_ANLEGER','FINANZ_HAUSBAUER','FINANZ_MINIMALIST',\n",
    "                      'FINANZ_SPARER','FINANZ_UNAUFFAELLIGER','FINANZ_VORSORGER',\n",
    "                      'GEBAEUDETYP','GEBAEUDETYP_RASTER','GFK_URLAUBERTYP',\n",
    "                      'STRUKTURTYP','HEALTH_TYP',\n",
    "                      'HH_EINKOMMEN_SCORE','INNENSTADT','KBA05_ALTER1','KBA05_ALTER2',\n",
    "                      'KBA05_ALTER3','KBA05_ALTER4','KBA05_ANHANG','KBA05_ANTG1','KBA05_ANTG2',\n",
    "                      'KBA05_ANTG3','KBA05_ANTG4','KBA05_AUTOQUOT','KBA05_BAUMAX','KBA05_CCM1',\n",
    "                    'KBA05_CCM2','KBA05_CCM3','KBA05_CCM4','KBA05_DIESEL','KBA05_FRAU','KBA05_GBZ',\n",
    "                    'KBA05_HERST1','KBA05_HERST2','KBA05_HERST3','KBA05_HERST4','KBA05_HERST5',\n",
    "                    'KBA05_HERSTTEMP','KBA05_KRSAQUOT','KBA05_KRSHERST1','KBA05_KRSHERST2',\n",
    "                    'KBA05_KRSHERST3','KBA05_KRSKLEIN','KBA05_KRSOBER','KBA05_KRSVAN',\n",
    "                    'KBA05_KRSZUL','KBA05_KW1','KBA05_KW2','KBA05_KW3','KBA05_MAXAH','KBA05_MAXBJ',\n",
    "                    'KBA05_MAXHERST','KBA05_MAXSEG','KBA05_MAXVORB','KBA05_MOD1','KBA05_MOD2',\n",
    "                    'KBA05_MOD3','KBA05_MOD4','KBA05_MOD8','KBA05_MODTEMP','KBA05_MOTOR',\n",
    "                    'KBA05_MOTRAD','KBA05_SEG1','KBA05_SEG10','KBA05_SEG2','KBA05_SEG3',\n",
    "                    'KBA05_SEG4','KBA05_SEG5','KBA05_SEG6','KBA05_SEG7','KBA05_SEG8','KBA05_SEG9',\n",
    "                    'KBA05_VORB0','KBA05_VORB1','KBA05_VORB2','KBA05_ZUL1','KBA05_ZUL2',\n",
    "                    'KBA05_ZUL3','KBA05_ZUL4','KBA13_ALTERHALTER_30','KBA13_ALTERHALTER_45',\n",
    "                    'KBA13_ALTERHALTER_60','KBA13_ALTERHALTER_61','KBA13_AUDI','KBA13_AUTOQUOTE',\n",
    "                    'KBA13_BJ_1999','KBA13_BJ_2000','KBA13_BJ_2004','KBA13_BJ_2006',\n",
    "                    'KBA13_BJ_2008','KBA13_BJ_2009','KBA13_BMW','KBA13_CCM_1000','KBA13_CCM_1200',\n",
    "                    'KBA13_CCM_1400','KBA13_CCM_0_1400','KBA13_CCM_1500','KBA13_CCM_1401_2500',\n",
    "                    'KBA13_CCM_1600','KBA13_CCM_1800','KBA13_CCM_2000','KBA13_CCM_2500',\n",
    "                    'KBA13_CCM_2501','KBA13_CCM_3000','KBA13_CCM_3001','KBA13_FAB_ASIEN',\n",
    "                    'KBA13_FAB_SONSTIGE','KBA13_FIAT','KBA13_FORD','KBA13_HALTER_20',\n",
    "                    'KBA13_HALTER_25','KBA13_HALTER_30','KBA13_HALTER_35','KBA13_HALTER_40',\n",
    "                    'KBA13_HALTER_45','KBA13_HALTER_50','KBA13_HALTER_55','KBA13_HALTER_60',\n",
    "                    'KBA13_HALTER_65','KBA13_HALTER_66','KBA13_HERST_ASIEN','KBA13_HERST_AUDI_VW',\n",
    "                    'KBA13_HERST_BMW_BENZ','KBA13_HERST_EUROPA','KBA13_HERST_FORD_OPEL',\n",
    "                    'KBA13_HERST_SONST','KBA13_KMH_110','KBA13_KMH_140','KBA13_KMH_180',\n",
    "                    'KBA13_KMH_0_140','KBA13_KMH_140_210','KBA13_KMH_211','KBA13_KMH_250',\n",
    "                    'KBA13_KMH_251','KBA13_KRSAQUOT','KBA13_KRSHERST_AUDI_VW',\n",
    "                    'KBA13_KRSHERST_BMW_BENZ','KBA13_KRSHERST_FORD_OPEL',\n",
    "                    'KBA13_KRSSEG_OBER','KBA13_KRSSEG_VAN','KBA13_KRSZUL_NEU','KBA13_KW_30',\n",
    "                    'KBA13_KW_40','KBA13_KW_50','KBA13_KW_60','KBA13_KW_0_60','KBA13_KW_70',\n",
    "                    'KBA13_KW_61_120','KBA13_KW_80','KBA13_KW_90','KBA13_KW_110','KBA13_KW_120',\n",
    "                    'KBA13_KW_121','KBA13_MAZDA','KBA13_MERCEDES','KBA13_MOTOR','KBA13_NISSAN',\n",
    "                    'KBA13_OPEL','KBA13_PEUGEOT','KBA13_RENAULT','KBA13_SEG_GELAENDEWAGEN',\n",
    "                    'KBA13_SEG_GROSSRAUMVANS','KBA13_SEG_KLEINST','KBA13_SEG_KLEINWAGEN',\n",
    "                    'KBA13_SEG_KOMPAKTKLASSE','KBA13_SEG_MINIVANS','KBA13_SEG_MINIWAGEN',\n",
    "                    'KBA13_SEG_MITTELKLASSE','KBA13_SEG_OBEREMITTELKLASSE','KBA13_SEG_OBERKLASSE',\n",
    "                    'KBA13_SEG_SONSTIGE','KBA13_SEG_SPORTWAGEN','KBA13_SEG_UTILITIES',\n",
    "                    'KBA13_SEG_VAN','KBA13_SEG_WOHNMOBILE','KBA13_SITZE_4','KBA13_SITZE_5',\n",
    "                    'KBA13_SITZE_6','KBA13_TOYOTA','KBA13_VORB_0','KBA13_VORB_1','KBA13_VORB_1_2',\n",
    "                    'KBA13_VORB_2','KBA13_VORB_3','KBA13_VW','KKK','KONSUMNAEHE','LP_FAMILIE_FEIN',\n",
    "                    'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','LP_LEBENSPHASE_GROB','LP_STATUS_FEIN',\n",
    "                    'LP_STATUS_GROB','MOBI_REGIO','NATIONALITAET_KZ','ONLINE_AFFINITAET','ORTSGR_KLS9',\n",
    "                    'OST_WEST_KZ','PLZ8_ANTG1','PLZ8_ANTG2','PLZ8_ANTG3','PLZ8_ANTG4','PLZ8_BAUMAX',\n",
    "                    'PLZ8_GBZ','PLZ8_HHZ','PRAEGENDE_JUGENDJAHRE','REGIOTYP','RELAT_AB',\n",
    "                    'RETOURTYP_BK_S','SEMIO_DOM','SEMIO_ERL','SEMIO_FAM','SEMIO_KAEM','SEMIO_KRIT',\n",
    "                    'SEMIO_KULT','SEMIO_LUST','SEMIO_MAT','SEMIO_PFLICHT','SEMIO_RAT','SEMIO_REL',\n",
    "                    'SEMIO_SOZ','SEMIO_TRADV','SEMIO_VERT','SHOPPER_TYP',\n",
    "                    'VERS_TYP','WOHNDAUER_2008','WOHNLAGE','W_KEIT_KIND_HH','ZABEOTYP']\n",
    "\n",
    "#GEBURTSJAHR year of birth, to int or to date\n",
    "#GREEN_AVANTGARDE maybe can be a bool\n",
    "azdias_df = to_category(azdias_df, categorical_columns)\n",
    "#azdias_df = to_int(azdias_df, categorical_columns)\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging for more space it can be seen that there are columns that are not listed in the csv description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EINGEFUEGT_AM                 60.686382\n",
       "CAMEO_INTL_2015               39.016406\n",
       "ANZ_STATISTISCHE_HAUSHALTE     6.799477\n",
       "KBA13_GBZ                      6.799477\n",
       "CJT_KATALOGNUTZER              6.799477\n",
       "RT_SCHNAEPPCHEN                6.799477\n",
       "RT_KEIN_ANREIZ                 6.799477\n",
       "AKT_DAT_KL                     6.799477\n",
       "KBA13_HHZ                      6.799477\n",
       "ANZ_HAUSHALTE_AKTIV            6.799477\n",
       "ANZ_KINDER                     6.799477\n",
       "ANZ_PERSONEN                   6.799477\n",
       "ARBEIT                         6.799477\n",
       "D19_VERSI_OFFLINE_DATUM        6.799477\n",
       "D19_VERSAND_OFFLINE_DATUM      6.799477\n",
       "CJT_TYP_6                      6.799477\n",
       "CJT_TYP_5                      6.799477\n",
       "CJT_TYP_4                      6.799477\n",
       "MOBI_RASTER                    6.799477\n",
       "MIN_GEBAEUDEJAHR               6.799477\n",
       "CJT_TYP_3                      6.799477\n",
       "CJT_TYP_2                      6.799477\n",
       "CJT_TYP_1                      6.799477\n",
       "KOMBIALTER                     6.799477\n",
       "D19_VERSI_DATUM                6.799477\n",
       "KBA13_ANTG3                    6.799477\n",
       "VERDICHTUNGSRAUM               6.799477\n",
       "LNR                            6.799477\n",
       "FIRMENDICHTE                   6.799477\n",
       "KBA13_ANTG1                    6.799477\n",
       "                                ...    \n",
       "KBA13_CCM_3001                 0.850125\n",
       "KBA13_HALTER_35                0.850125\n",
       "KBA13_HALTER_30                0.850125\n",
       "KBA13_FIAT                     0.850125\n",
       "KBA13_HALTER_20                0.850125\n",
       "KBA13_FAB_ASIEN                0.850125\n",
       "KBA13_FORD                     0.850125\n",
       "KBA13_FAB_SONSTIGE             0.850125\n",
       "KBA13_KRSZUL_NEU               0.850118\n",
       "KBA05_KRSVAN                   0.850118\n",
       "PLZ8_ANTG3                     0.850118\n",
       "KBA13_MOTOR                    0.850118\n",
       "NATIONALITAET_KZ               0.850118\n",
       "KBA05_MAXVORB                  0.850118\n",
       "KBA05_KRSKLEIN                 0.850118\n",
       "KBA13_KRSSEG_VAN               0.850118\n",
       "KBA05_KRSOBER                  0.850118\n",
       "HEALTH_TYP                     0.850118\n",
       "KBA05_KRSZUL                   0.850118\n",
       "KBA13_KRSSEG_OBER              0.850118\n",
       "KBA05_ANTG3                    0.850118\n",
       "VERS_TYP                       0.850034\n",
       "STRUKTURTYP                    0.850034\n",
       "KBA13_KMH_110                  0.850034\n",
       "KBA05_ANTG4                    0.850034\n",
       "PLZ8_ANTG4                     0.850034\n",
       "KBA05_SEG6                     0.850034\n",
       "KBA13_KMH_251                  0.850034\n",
       "KBA13_KW_30                    0.850034\n",
       "Index                          0.000076\n",
       "Length: 336, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(azdias_df.memory_usage(deep=True) / 1024 ** 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 364.24 Mb\n"
     ]
    }
   ],
   "source": [
    "categorical_columns2 = ['CAMEO_INTL_2015','KBA13_ANTG1','KBA13_GBZ','D19_VERSI_DATUM','RT_UEBERGROESSE',\n",
    "                       'RT_SCHNAEPPCHEN','RT_KEIN_ANREIZ','ANZ_HAUSHALTE_AKTIV','ANZ_KINDER',\n",
    "                       'ANZ_PERSONEN','ANZ_STATISTISCHE_HAUSHALTE','ARBEIT','MOBI_RASTER',\n",
    "                       'D19_VERSI_OFFLINE_DATUM','MIN_GEBAEUDEJAHR','KOMBIALTER',\n",
    "                       'CJT_KATALOGNUTZER','CJT_TYP_1','CJT_TYP_2','CJT_TYP_3','CJT_TYP_4','CJT_TYP_5',\n",
    "                        'CJT_TYP_6','KBA13_HHZ','KBA13_KMH_210','KBA13_BAUMAX',\n",
    "                       'UMFELD_JUNG','EINGEZOGENAM_HH_JAHR','GEMEINDETYP',\n",
    "                       'GEBURTSJAHR','AKT_DAT_KL','KBA13_ANTG2','D19_VERSAND_OFFLINE_DATUM','UMFELD_ALT',\n",
    "                       'KBA13_ANTG3','VK_DISTANZ','FIRMENDICHTE','VERDICHTUNGSRAUM',\n",
    "                       'VK_ZG11','KBA13_ANTG4','VK_DHT4A','VHN','VHA']\n",
    "\n",
    "azdias_df = to_category(azdias_df, categorical_columns2)\n",
    "#KBA13_ANZAHL_PKW to int\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows that not have at least 270 (80%) non null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 316.11 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_df.dropna(thresh=290, inplace = True)\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace nulls and unknown (-1) values with mode or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 335)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of the non ordinal categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 435.76 Mb\n"
     ]
    }
   ],
   "source": [
    "one_hot_list = ['WOHNLAGE','VERS_TYP','SHOPPER_TYP','RETOURTYP_BK_S','PLZ8_BAUMAX','NATIONALITAET_KZ',\n",
    "                'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','KBA05_MODTEMP','KBA05_MAXHERST','KBA05_HERSTTEMP',\n",
    "                'HEALTH_TYP','GFK_URLAUBERTYP','GEBAEUDETYP','FINANZTYP','D19_KONSUMTYP_MAX',\n",
    "                'CJT_GESAMTTYP','CAMEO_DEU_2015','AGER_TYP']\n",
    "azdias_df = pd.get_dummies(azdias_df, columns =one_hot_list)\n",
    "\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once performed one hot encoded, drop low variance resulting columns that are result of having previous columns with a value that appears few times and it is not statistically relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns:  WOHNLAGE_0.0          0.005159\n",
      "WOHNLAGE_1.0          0.229614\n",
      "WOHNLAGE_2.0          0.333616\n",
      "WOHNLAGE_3.0          0.466133\n",
      "WOHNLAGE_4.0          0.379090\n",
      "WOHNLAGE_5.0          0.291100\n",
      "WOHNLAGE_7.0          0.412624\n",
      "WOHNLAGE_8.0          0.110560\n",
      "VERS_TYP_-1           0.000000\n",
      "VERS_TYP_1            0.497406\n",
      "VERS_TYP_2            0.497406\n",
      "SHOPPER_TYP_-1        0.000000\n",
      "SHOPPER_TYP_0         0.371447\n",
      "SHOPPER_TYP_1         0.477413\n",
      "SHOPPER_TYP_2         0.441425\n",
      "SHOPPER_TYP_3         0.412968\n",
      "RETOURTYP_BK_S_1.0    0.362170\n",
      "RETOURTYP_BK_S_2.0    0.318464\n",
      "RETOURTYP_BK_S_3.0    0.411980\n",
      "RETOURTYP_BK_S_4.0    0.357871\n",
      "RETOURTYP_BK_S_5.0    0.480777\n",
      "PLZ8_BAUMAX_1.0       0.480413\n",
      "PLZ8_BAUMAX_2.0       0.289192\n",
      "PLZ8_BAUMAX_3.0       0.249646\n",
      "PLZ8_BAUMAX_4.0       0.262719\n",
      "PLZ8_BAUMAX_5.0       0.334023\n",
      "NATIONALITAET_KZ_0    0.202955\n",
      "NATIONALITAET_KZ_1    0.370452\n",
      "NATIONALITAET_KZ_2    0.272115\n",
      "NATIONALITAET_KZ_3    0.197405\n",
      "                        ...   \n",
      "CAMEO_DEU_2015_5C     0.109338\n",
      "CAMEO_DEU_2015_5D     0.136477\n",
      "CAMEO_DEU_2015_5E     0.067265\n",
      "CAMEO_DEU_2015_5F     0.073580\n",
      "CAMEO_DEU_2015_6A     0.092616\n",
      "CAMEO_DEU_2015_6B     0.266235\n",
      "CAMEO_DEU_2015_6C     0.136199\n",
      "CAMEO_DEU_2015_6D     0.087903\n",
      "CAMEO_DEU_2015_6E     0.143131\n",
      "CAMEO_DEU_2015_6F     0.082317\n",
      "CAMEO_DEU_2015_7A     0.204741\n",
      "CAMEO_DEU_2015_7B     0.174186\n",
      "CAMEO_DEU_2015_7C     0.107359\n",
      "CAMEO_DEU_2015_7D     0.082141\n",
      "CAMEO_DEU_2015_7E     0.076569\n",
      "CAMEO_DEU_2015_8A     0.252718\n",
      "CAMEO_DEU_2015_8B     0.202616\n",
      "CAMEO_DEU_2015_8C     0.197117\n",
      "CAMEO_DEU_2015_8D     0.149646\n",
      "CAMEO_DEU_2015_9A     0.161761\n",
      "CAMEO_DEU_2015_9B     0.186370\n",
      "CAMEO_DEU_2015_9C     0.177323\n",
      "CAMEO_DEU_2015_9D     0.189152\n",
      "CAMEO_DEU_2015_9E     0.086232\n",
      "CAMEO_DEU_2015_XX     0.019609\n",
      "AGER_TYP_-1           0.000000\n",
      "AGER_TYP_0            0.101431\n",
      "AGER_TYP_1            0.305503\n",
      "AGER_TYP_2            0.354423\n",
      "AGER_TYP_3            0.177943\n",
      "Length: 186, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(751331, 316)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropLowVarianceCols(azdias_df)\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode into numerical values binary feature OST_WEST_KZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['OST_WEST_KZ'] = encodeColumnByLabel(azdias_df, 'OST_WEST_KZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp into an integer formed by year month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['EINGEFUEGT_AM'] = timestampToInt(azdias_df, 'EINGEFUEGT_AM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize values before aplying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "np_azdias = azdias_df.values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np_azdias)\n",
    "np_azdias = scaler.transform(np_azdias)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in the dataframe the normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df = pd.DataFrame(data=np_azdias,\n",
    "          index=azdias_df.index,\n",
    "          columns=azdias_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "# get IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'arvato'\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix+\"/train\")\n",
    "#num_components = 400\n",
    "#since removing columns with low variance after performing one hot encoding the remaining number of columns is\n",
    "#less than the previously specified number of components (316) so I set a new number of components\n",
    "num_components = 300\n",
    "\n",
    "\n",
    "\n",
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to recordset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_azdias_data = pca.record_set(np_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit data to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 20:54:33 Starting - Starting the training job...\n",
      "2020-05-15 20:54:35 Starting - Launching requested ML instances......\n",
      "2020-05-15 20:55:34 Starting - Preparing the instances for training...\n",
      "2020-05-15 20:56:08 Downloading - Downloading input data...\n",
      "2020-05-15 20:57:00 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'316', u'mini_batch_size': u'500', u'num_components': u'300'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Final configuration: {u'num_components': u'300', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'316', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 WARNING 139992559576896] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/99e881c0-e606-496b-8217-ba8c54a37f36', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-54-33-473', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-244-0.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ce557f25-bda1-46d6-9e32-84abf94427a8', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-54-33-473', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/99e881c0-e606-496b-8217-ba8c54a37f36', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.244.0', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-54-33-473', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-244-0.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ce557f25-bda1-46d6-9e32-84abf94427a8', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-54-33-473', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/99e881c0-e606-496b-8217-ba8c54a37f36', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-54-33-473', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-244-0.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ce557f25-bda1-46d6-9e32-84abf94427a8', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-54-33-473', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/99e881c0-e606-496b-8217-ba8c54a37f36', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.244.0', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-54-33-473', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-244-0.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ce557f25-bda1-46d6-9e32-84abf94427a8', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-54-33-473', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/99e881c0-e606-496b-8217-ba8c54a37f36', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.244.0', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-54-33-473', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-244-0.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ce557f25-bda1-46d6-9e32-84abf94427a8', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-54-33-473', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 60 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 69 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:15 INFO 139992559576896] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:16 INFO 139992559576896] nvidia-smi took: 0.0251560211182 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:16 INFO 139992559576896] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:16 INFO 139992559576896] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:16 INFO 139992559576896] 316 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:16 INFO 139992559576896] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1346.2471961975098, \"sum\": 1346.2471961975098, \"min\": 1346.2471961975098}}, \"EndTime\": 1589576236.647398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576235.283606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589576236.647786, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576236.647725}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 20:57:16.654] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1369, \"num_examples\": 1, \"num_bytes\": 1278000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 20:57:29 Uploading - Uploading generated training model\u001b[34m[2020-05-15 20:57:26.718] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 10058, \"num_examples\": 1503, \"num_bytes\": 1920402036}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 10064.547061920166, \"sum\": 10064.547061920166, \"min\": 10064.547061920166}}, \"EndTime\": 1589576246.719022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576236.6475}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:26 INFO 139992559576896] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576246.720286, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1589576236.654233}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:26 INFO 139992559576896] #throughput_metric: host=algo-1, train throughput=74637.9449816 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 30.521869659423828, \"sum\": 30.521869659423828, \"min\": 30.521869659423828}}, \"EndTime\": 1589576246.751498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576246.719168}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 20:57:26 INFO 139992559576896] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 11628.683090209961, \"sum\": 11628.683090209961, \"min\": 11628.683090209961}, \"setuptime\": {\"count\": 1, \"max\": 37.86897659301758, \"sum\": 37.86897659301758, \"min\": 37.86897659301758}}, \"EndTime\": 1589576246.767952, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576246.751556}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-15 20:57:35 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 87\n"
     ]
    }
   ],
   "source": [
    "#train_inputs = sagemaker.s3_input(train_s3, content_type='text/csv;label_size=0')\n",
    "\n",
    "pca.fit(formatted_azdias_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arvato/train/pca-2020-05-15-20-54-33-473/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "unzipModel(pca._current_job_name,bucket_name, prefix+\"/train\",'model.tar.gz','model_pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model to find the features weights in each component and the optimal number of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the unzipped artifacts\n",
    "pca_model_params = mx.ndarray.load('model_pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selected params\n",
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())\n",
    "v=pd.DataFrame(pca_model_params['v'].asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the features weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "295   711.394958\n",
      "296   911.158386\n",
      "297   931.638672\n",
      "298  1067.674438\n",
      "299  1331.909790\n"
     ]
    }
   ],
   "source": [
    "N_COMPONENTS = 300\n",
    "\n",
    "# looking at top 5 components\n",
    "n_principal_components = 5\n",
    "\n",
    "start_idx = N_COMPONENTS - n_principal_components  # 33-n\n",
    "\n",
    "# print a selection of s\n",
    "print(s.iloc[start_idx:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv4AAAGDCAYAAABTMRQ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xu85mO9//HXe5xzSDEqhQnlFA2tyJmMHBoZWw6zRZKt2tmVfkmp9lZKOk4kSkpll0NJDpFdgwjRwjJDxmyzDTk2OU80Bu/fH9/rzndua637njHLmlnf9/PxWA/3fV3X97qu73fd+Hyv+3N9l2wTEREREREj26jhnkBERERERAy9BP4REREREQ2QwD8iIiIiogES+EdERERENEAC/4iIiIiIBkjgHxERERHRAAn8IyIihpAkS1p3uOcREZHAPyJiESBppqSnJM2W9KCkH0laoVa/i6QrJT0haZak30t6V1sfO5Qg86guxltJ0rck3V3GnFHerzoU57eokXSwpD90aHNFuZ5vbis/r5TvMKSTHGLdfKZGsvLv3Lgu224o6Zry+guSPtJW1yvpkfLzO0kbDtW8I16MBP4REYuOPWyvAGwG9ACfBZD0buDnwE+A1wGvAv4T2KPt+PcCDwMHDTaIpKWBycBGwK7ASsCWwEPA5gvpXEaK6dSup6RVqK7VrGGb0UIwH5+pqLwF6K29vrFWdx/wbuCVwKrABcBZL+nsIrqUwD8iYhFj+17gEuBNkgR8EzjW9mm2H7P9nO3f2/631jGSlqcKPj4MvEFSzyBDHASsCexl+8+lv7/aPtb2xaW/DcqK96OSbq2vBJdvI06WdEn5tuBqSa8u3xg8ImmapE1r7WdK+rSkP5f60yUtW6v/N0l3SHpY0gWSVq/VWdIHJf1vmct3yjVp1R8i6bbS76WS1up0rKQNgO8CW5b5PzrItfopsJ+kJcr7icB5wNO1cTaXdG0Z435JJ5WbqxeQtI2kv7S+LZC0vqTflnO/XdK+tbZXSDq09n6ebynK+X1E0v9J+pukr0nq+P/1bj5TkkZJ+qykuyT9VdJPJL281I0pY7+vnMsj5Tq/VdKUch1Oapv31eW6PFY+HzvV6lcvv/eHy+eg/rk+RtI5Zfwnymexp+3Yc1V9Y3Gn5l2JH/BYSWdQ/TtwYfkMfLLDZesBbiivNwX6WhW2H7U907YBAc8CSe2KRVIC/4iIRYykNYDdgZuA9YA1gF90OOxfgNlUq7iXUq3+D2Qc8BvbswcYfyngQuB/gNWA/wB+Kmm9WrN9qb6RWBWYA1xLtQq6apnrN9u6PQDYBVgHeCPPf5vxduDLpb/XAHfxwtXS8cBbgU1Ku13KsXsCR5dzHw1cBZzZ6VjbtwEfBK61vYLtlfu/TEC1mvtn4B3l/UFUq+R1zwJHlHPfEtgJ+Pf2jiTtWua3t+0rVN2s/Rb4GdV13h84WfOXJrIXVVC6GbAncEgXx3TzmTq4/OwIrA2sAJzU1mYL4A3AfsC3gM9QfbY2AvaVtH1b2xlU1+i/gF9KemWpOwu4B1id6ub1uPK5aHlXabMy1Wr6SVDdnFB9Tm8GXkt13T8maZdOx9o+ELib8i2b7a/2dxHKTdmjVDfU35b0ONW3I/dIuqSt7aPAP4BvA8f111/EcEvgHxGx6PhVCR7+APyeKnhYpdTd3+HY9wJn236WKpDcvwTw/VmlQ39vowr0jrf9tO3LgIuoVrtbzrN9g+1/UK2A/8P2T8r4Z1OtitadZPsvth8GvlTr6wDgh7ZvtD0H+DTVSvyY2rHHl1XVu4HLgbGl/IPAl23fZvsZqus1tr7qP8ix8+MnwEGS1gdWtn1tvbJchz/afsb2TOB7wPZtfexTynezfX0pGw/MtH16OfYm4NzStltfsf1wOb9vMe/vaCDdfKYOAL5p+//KDeKnqT5TS9baHGv7H7b/B/g7cGb55uheqpuw+mfgr8C3bM+1fTZwO/DOcpO7NXBU6asPOI1509X+YPvi8tk6A2jtuXgrMNr2F8rn9P+A71PdQHU6tiu2d6ZKf+uzvRJwPPAp2yvb3q2t7crAy4HDqW7aIxY5CfwjIhYdE0pAsZbtf7f9FFXePVSr4f0qwdOOVGkpAOcDywLvHOCQhwbrj2rl9S+2n6uV3UW1qtryYO31U/28X4F5/aWtr1Y6z+rlPQAlyHyobawHaq+frPW9FnBCSS15lGp/g7o8dn78Eng7VUB3RnulpDdKukjSA2VF+Diqle26jwHn2L6lVrYWsEVr/uUcDgBePR9zG+i6DqbjZ4q230t5vSTVanfL/HwG7i2pMO1zXR142PYTbXWD/Q6XLTcgawGrt12/o9vmONCxHUk6vPR5M7BReX0s8Nky3mrtx9j+O1Ua2U/6q48Ybgn8IyIWbbdTBXd7D9LmQKr/nl8o6QHg/6gC/4HSfX4H7FJSTfpzH7BGW774msC98zPxNmu09XVfbax6Xv7yVCvS3Yz1F+AD5Wap9bOc7Wu6ONadm5SG9pNUey4+RD+BP3AKMA14Q1kVPprqBqRuH2CCpI+2zf/3bfNfwfaHSv3fgZfV2vd3QzDQdR1MN5+peX4vpe9nmDe4nx+vLXsL6v3dV35eKWnFtrpuf/93tl2/FW3v3uWcBv0M2D6prOL/nurGby2qG5iXl7H+OsCho6h+b68doD5i2CTwj4hYhJVV0o8DnyubKVcqGy+3kXRqafZe4PNUaSytn72B3VU9habdGVRB07llc+koSatIOlrS7sB1VKujn5S0lKqNqHvw4p5U8mFJryt53Z+hSgeCKuf9fZLGSlqGarX8upIy08l3gU9L2ghA0ssldZsm8yDwOg2wCbcfRwPbDzCvFYHHgdklHehD/bS5jyoH/aOSWvUXAW+UdGC5zkuVDbIblPo+4F8kvUzV3wF4fz/9HinpFeVbn49Srque34A7pv2ALj9TZwJHSHq9qsfKHkeVSvbMoFdpYKsBHynnuA+wAXCx7b8A1wBflrSspE3Kef53F31eDzwh6ShJy0laQtKbJL21yzk9SLV/oZOxVKv+mzHv03wAkLSzpE3L+CtR7W95BLity3lEvGQS+EdELOJs/4JqA+UhVAHkg8AXgfMlvY1qJfI7th+o/VwA3EE/Od8ll34c1Sr1b6mC1uup0lOus/00VaC/G/A34GTgINvTXsRp/Ixqs/D/UW3y/GKZy++Az1Hltt9Ptfl3/wH6aD+P84CvAGeVFJtbypy7cRlwK/CApL91MdZ9tgd67v8ngH8FnqDKMT+7v0YlD38n4FOSDi3pLe+gOt/7qNJSvgIsUw6ZRPX0oAeBH/N8Klfd+VRPm+kDfg38oJSvQZUy0+/K+WCfqdLkh1Q3iFcCd1JtWv2PAc6/G9dRbQT+G9Uej3fbbqUcTQTGlHmcB/xX+VwMquTtj6cKzO8sfZ9GlWffjS/zfNrOJ/prIGlN4KHyrc9mPP9kn7qVqW6UHqP6bK8D7Fr2v0QsUjRvyl1ERMTCJWkmcGg3wVx0T5Kp0ovu6Kfus8As29976Wf2grkcTPX732a45xLRdF1tcImIiIjFh+0vDvccImLRk1SfiIiIiIgGSKpPREREREQDZMU/IiIiIqIBEvhHRERERDRANvdG9GPVVVf1mDFjhnsaERERER3dcMMNf7M9ulO7BP4R/RgzZgy9vb3DPY2IiIiIjiTd1U27pPpERERERDRAVvwjhtHbdtp9uKcQEQ3xx8kXD/cUImKYZcU/IiIiIqIBEvhHRERERDRAAv+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCBf0REREREAyTwj4iIiIhogAT+ERERERENkMA/IiIiIqIB8pd7G0DS64DvABtS3exdBBxJ9fv/PrAJIOBR4ADg/HLoq4FngVnl/ea2n27rexJwl+1vlfeXAn+xfWh5/w3gXuCXwG3A7bXDv2n7J5IOAY4AXOb3GeAdwNbA0sDra8d90fYv+jnHHwEX2f6FpFcCk4ETgZcB/1ZruiSwEbCh7ds6XbuIiIiIkSKB/wgnSVRB9ym295S0BHAq8CXgYeBB2xuXtusBD9geW94fA8y2/fVBhrga2Bf4lqRRwKrASrX6raiCeoAZrb5r83sdVaC/me3HJK0AjLZ9fqkfQxXQz3PcIOf7cuBS4FTbp5fi79TqjwP6EvRHRERE0yTVZ+R7O/CPVhBs+1mqQPwQqpX0e1sNbd9ue8589n8NsGV5vRFwC/CEpFdIWgbYALhxkONXA54AZpc5zLZ953zOoWUF4BLgZ7ZPaa+UtB3VTcq/L2D/EREREYutBP4j30bADfUC248DdwP/DRwl6VpJX5T0hvnt3PZ9wDOS1qRa3b8WuI7qZqAHmFpLD1pHUl/tZ1vgZuBB4E5Jp0vaYwHPE+CbwB9sT2qvkLQy8CPgveX8X0DSYZJ6JfXOmjWrvyYRERERi60E/s32KLA28DXglcCfJG2wAP1cQxX0twL/a2vvr661m2F7bO3nqvINxK7Au4HpwKSSYrQgLgP2lLRaP3XfBc6wfXU/dQDYPtV2j+2e0aNHL+AUIiIiIhZNCfxHvj8Db6kXSFoJWBO4o6TW/NL2v1N9A7D7AoxxNVWQvzFVqs8fqVb8t6K6KRiUK9fb/jKwP7D3AswB4CyqAP9iSSu2CiW9F1gLOHYB+42IiIhY7CXwH/kmAy+TdBBA2dz7Daq0l00lvaKUL0311J+7FmCMa4DxwMO2n7X9MLAyVfA/aOAvaXVJm9WKxi7gHAAoaT6TgV9KWlrS2sBxwAG2n1nQfiMiIiIWd3mqzwhn25L2Ak6W9Dmqm72LgaOB/YBTypN/RgG/Bs5dgGGmUj3N52dtZSvY/lutbB1JfbX3P6R6dOjXJa0O/IPq0aEfXIA5/JPtoySdDpwBPE71SM9fVqf5T/9h+6oXM05ERETE4kS2h3sOEYucnp4e9/b2Dvk4b9tpQTKrIiLm3x8nXzzcU4iIISLpBts9ndol1SciIiIiogGS6hNdkbQKVe58u51sP/QSzuM7VH/Rt+6E2h/rioiIiIh+JPCPrpTgvqu/njvE8/jwcM8hIiIiYnGUVJ+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCBf0REREREA2Rzb8QwynO1IyIi4qWSFf+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCBf0REREREAyTwj4iIiIhogAT+ERERERENkMd5RgQA2+z1vuGeQkQMoT+cd/pwTyEihllW/CMiIiIiGiCBf0REREREAyTwj4iIiIhogAT+ERERERENkMA/IiIiIqIBEvhHRERERDRAAv+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGqBRgb+k2bXXu0uaLmktScdIuldSn6Rpkk6RNKrWdklJsyQd39bf4ZLukGRJq9bK95Q0pfTXK2mbQeY0RtItbWXHSPpEef0jSXeWvvokXVPKDy5zas35iNrx60m6otTdJulUSbvU+pgt6fby+icDzGsHSY+VNlMk/U7SarWxLWlcrf2EUvbucv6/qtV9WtIdtfd7SLpgkGsyU9LUMvZUSXvW6p6tnUefpE+V8isk9dba9Ui6orz+Utsx00s/Kww0h4iIiIiRplGBf4uknYATgd1s31WKJ9keC2wIbAxsXztkZ2A6sI8k1cqvBsYBdzGvycCbS3+HAKe9yCkfaXts+dmqVn52GWNr4DOS1ijlJ7bOx/YGwLdtX9rqA+gFDijvDxpk3KtKm02APwEfrtVNBfavvZ8I3FxeXwO8rVa3JfB468YB2Kq0GcyOZa7vLufT8lTtWoy1Xb8ZW03Sbu0d2f5M/ZhyLl+2Pbu9bURERMRI1bjAX9J2wPeB8bZn9NNkaWBZ4JFa2UTgBOBuqiAWANs32Z7Z3oHt2bZd3i4PuL3NwmT7IeAO4DWl6DXAPbX6qS+m/3KzsyLzXpOrgM0lLVVWztcF+sp4s6gC/XVL29cC51IF/JR/Xt3l8Cu1jTuYrwGfGayBpPeUuR7TZZ8RERERI0LTAv9lgF8BE2xPa6s7QlIfcD8w3XYfgKRlqVb1LwTOpLoJ6EjSXpKmAb+mWvUfzDr1VBTgg231X6vV/7SfsdakulmZUoomAZdJukTSEZJW7mbO/di2zOduqmvww1qdgd8BuwB7Au2pO1cDW0laD/hf4I/l/ZLAm6lW3QdzeUmB+j3w2Vr5cm1pO/vV6q4Fnpa0Y38dShoDHE/1bccz/dQfVlKzemfNmtVhehERERGLl6YF/nOpUkze309dK9VnNWB5Sa00lvHA5bafolq1niBpiU4D2T7P9vrABODYDs1ntKWifLetvp7qc0CtfD9JU6hW+0+2/Y8y9unABsDPgR2AP0paptOc+9FK9VkDOB34alv9WVTpPvtT3RTVXUO1sr8VVUB+PbAFsCkwrTXXQexo+01UaVcn1fLx21N9zm477ovMe6MAQPmd/TfwOdt3tNcD2D7Vdo/tntGjR3eYXkRERMTipWmB/3PAvlQpKkf318D2XOA3wHalaCIwTtJM4AZgFeDt3Q5o+0pg7frm34Xo7JJ/vxVwvKRX18a9z/YPbe8JPAO86UWOdQHPX5PWGNdTBear2p7e1v5qaoG/7SeovpXYgc75/fUxZgAPUu296Kb9ZcByzLvHAKqbgfvLTVFERERE4zQt8Mf2k8A7gQMkvWDlv+Szbw3MkLQSsC2wpu0xtsdQbXAdNN1H0rqtTcCSNqNKMXpooZ5Ije1e4Azgo2XMXSUtVV6/mupm5d4XOcw2QH97Ij4F9HcTdRuwejnuplLWSmPqNr+fsiH49bxwA/Vgvgh8stbH24CDgcPmo4+IiIiIEWXJ4Z7AcLD9sKRdgSsltZK5jygbP5eiypU/merbgctsz6kdfj7w1ZI68wGqAPPVwBRJF9s+FNgbOEjSXOApYL/aZt8F8TVJ9fSVzftp8xXgRknHAe8ATpDUSqc50vYDCzBuK8dfwGPAoe0NbF/S34G2Lek64OXlWxSoUn4Oo7sV/8slPUv1+/iU7QdL+XJlTi2/sf2ptrEvrv1eAT4PvKz0WW+69wAbvCMiIiJGHL24eDRiZOrp6XFvb2/nhiPINnu9b7inEBFD6A/nJdMxYqSSdIPtnk7tGpfqExERERHRRI1M9RkOkjamysOvm2N7i+GYT4ukXajShOrutL3XSzD2dVT7H+oOfLF/dyAiIiIiXiiB/0ukBLNjh3se7WxfClw6TGMP601PRERERJMk1SciIiIiogES+EdERERENEAC/4iIiIiIBkjgHxERERHRANncGxFAnvEdEREx0mXFPyIiIiKiARL4R0REREQ0QAL/iIiIiIgGSOAfEREREdEACfwjIiIiIhogT/WJiEFtf/BRwz2FiFgIfv+jrwz3FCJimGXFPyIiIiKiARL4R0REREQ0QAL/iIiIiIgGSOAfEREREdEACfwjIiIiIhoggX9ERERERAMk8I+IiIiIaIAE/hERERERDZDAPyIiIiKiARL4R0REREQ0QAL/RZSk2bXXu0uaLmktScdIuldSn6Rpkk6RNKrWdklJsyQd39bf4ZLukGRJq9bK95Q0pfTXK2mbDvN6o6SLJf2vpBslnSPpVaVuc0lXSrpd0k2STpP0MkkHl3HH1fqZUMrePchYP5B0c5nfLyStUMqXkXR2OZ/rJI2pHfPpUn67pF1q5T+U9FdJtwx+5SMiIiJGpgT+izhJOwEnArvZvqsUT7I9FtgQ2BjYvnbIzsB0YB9JqpVfDYwD7mJek4E3l/4OAU4bZC7LAr8GTrH9BtubAScDo0vw/3PgKNvr2d4U+A2wYjl8KrB/rbuJwM0dTv8I22+2vQlwN3B4KX8/8IjtdYFJwFfK/DYsY2wE7AqcLGmJcsyPSllEREREIyXwX4RJ2g74PjDe9ox+miwNLAs8UiubCJxAFShv2Sq0fZPtme0d2J5t2+Xt8oDb29T8K3Ct7Qtrx19h+xbgw8CPbV9bq/uF7QfL26uAzSUtVVbu1wX6BhkL248DlBuY5Wpz2xP4cXn9C2Cn0mZP4Czbc2zfCdwBbF76uhJ4eLDxJB1WvvXonTVr1mBNIyIiIhY7CfwXXcsAvwIm2J7WVneEpD7gfmC67T7454r8OOBC4Eyqm4COJO0laRrVav4hgzR9E3DDAtRBFbT/DtiFKkC/oMu5nQ48AKwPfLsUvxb4C4DtZ4DHgFXq5cU9pawrtk+13WO7Z/To0d0eFhEREbFYSOC/6JoLXEOV1tKuleqzGrC8pFYKzXjgcttPAecCE2qpLgOyfZ7t9YEJwLELZfb9O4sqFWd/qhuTjmy/D1gduA3Yb+imFhERETGyJfBfdD0H7EuVHnN0fw1sz6XKo9+uFE0ExkmaSbX6vgrw9m4HLOkwa9c3/7a5FXjLAtS1+r+eak/Cqranz8e8nqW6adi7FN0LrAHVZmbg5cBD9fLidaUsIiIiovES+C/CbD8JvBM4QNILVv5LXvvWwAxJKwHbAmvaHmN7DFXe/aDpPpLWbW0ClrQZVYrRQwM0/xmwlaR31o7fTtKbgJOA90raolb3L60n/tR8Cuj3Rqb93CStWzvPdwGtlKcLgPeW1+8GLiv7FC4A9i9P/Xk98Abg+k5jRURERDTBksM9gRic7Ycl7QpcKam14/QISe8BlgKmUD1ZZ1+qAHhO7fDzga9KWgb4APBJ4NXAFEkX2z6UahX9IElzgaeA/Wqbfdvn8pSk8cC3JH2LKh1pCvBR2w+WlKOvS1qN6huLK6m+kaj3cUmXpy7gx+WGRlRPAPpQqfsBcIakO6g27O5f+r5V0jnAn4FngA+XbwuQdCawA7CqpHuA/7L9gy7nEhEREbHY0wAxXkSj9fT0uLe3d7insUjY/uCjhnsKEbEQ/P5HXxnuKUTEEJF0g+2eTu2S6hMRERER0QBJ9YkXkLQxcEZb8RzbW/TXfiGMdx7w+rbio2xfOhTjRURERDRRAv94AdtTgbEv4Xh7vVRjRURERDRVUn0iIiIiIhoggX9ERERERAMk8I+IiIiIaIDk+EfEoPIIwIiIiJEhK/4REREREQ2QwD8iIiIiogES+EdERERENEAC/4iIiIiIBkjgHxERERHRAAn8IyIiIiIaII/zjIiIaICdPjppuKcQ0UiTTzhiuKfwT1nxj4iIiIhogAT+ERERERENkMA/IiIiIqIBEvhHRERERDRAAv+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCBf0REREREAyTwj4iIiIhogAT+I4ik2bXXu0uaLmktScdIuldSn6Rpkk6RNKrWdklJsyQd39bf4ZLukGRJq9bK95Q0pfTXK2mbQeY0StKJkm6RNFXSnyS9vtTNlPSq0k+fpAdq8+yTtF/tdevnOUm7SRoj6am2uoMGmccVkm6vtV1tQa9zRERExOJoyeGeQCx8knYCTgR2sX2XJIBJtr9eAv4rge2By8shOwPTgX0kfdq2S/nVwEXAFW1DTAYusG1JmwDnAOsPMJ39gNWBTWw/J+l1wN9r9c/aHlvmfQww2/bXa/Vn187rMOAA4FJgTWBG69guHWC7dz7aR0RERIwYWfEfYSRtB3wfGG97Rj9NlgaWBR6plU0ETgDuBrZsFdq+yfbM9g5sz67dHCwPuL1NzWuA+20/V469x/Yjg7Tvl6Q3Av8JHNjqKyIiIiK6l8B/ZFkG+BUwwfa0trojJPUB9wPTbfcBSFoWGAdcCJxJdRPQkaS9JE0Dfg0cMkjTc4A9SnrNNyRtOl9nVI21FPAz4P/ZvrtWtU5bqs+2Hbo6vbT7nMrXIG3jHFZSl3pnzZo1v9OMiIiIWKQl8B9Z5gLXAO/vp25SSYtZDVhe0v6lfDxwue2ngHOBCZKW6DSQ7fNsrw9MAI4dpN09wHrAp4HngMklFWl+HAvcavvstvIZtsfWfq4apI8DbG8MbFt+Duxnrqfa7rHdM3r06PmcYkRERMSiLYH/yPIcsC+wuaSj+2tgey7wG2C7UjQRGCdpJnADsArw9m4HtH0lsHZ9828/bebYvsT2kcBxVDcLXZG0A7A3cHi3xwwwh3vLP5+g+vZg8xfTX0RERMTiJoH/CGP7SeCdwAGSXrDyX1JctgZmSFqJavV7TdtjbI8BPkyHdB9J67ZSZSRtRpVi9NAAbTeTtHp5PQrYBLirm3OR9ArgdOCgErAvkPLUolXL66WovuW4ZUH7i4iIiFgc5ak+I5DthyXtClwpqZWsfoSk9wBLAVOAk6m+HbjM9pza4ecDX5W0DPAB4JPAq4Epki62fSjVCvxBkuYCTwH71Tb7tlsN+H7pD+B64KQuT+WD5fhT2lLyvwxcR8nxr5X/0PaJ/fSzDHBpCfqXAH5HtQE6IiIiojE0cLwW0Vw9PT3u7c2TPyNi5Njpo5OGewoRjTT5hCOGfAxJN9ju6dQuqT4REREREQ2QVJ9YKCRtDJzRVjzH9hYv8Tyuo0rtqTvQ9tSXch4RERERi5oE/rFQlMB6fv6K7lDN4yW90YiIiIhYXCTVJyIiIiKiARL4R0REREQ0QAL/iIiIiIgGSOAfEREREdEA2dwbERHRAC/Fs8QjYtGWFf+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCBf0REREREAyTwj4iIiIhogDzVJyKGzS7/+dPhnkJEY1z6hQOGewoRMcyy4h8RERER0QAJ/CMiIiIiGiCBf0REREREAyTwj4iIiIhogAT+ERERERENkMA/IiIiIqIBEvhHRERERDRAAv+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGmC+An9JoyStNFSTGUqSZtde7y5puqS1JB0j6V5JfZKmSTpF0qha2yUlzZJ0fFt/h0u6Q5IlrVor31PSlNJfr6RtBpnTKEknSrpF0lRJf5L0+lI3s5T1lZ8Ta8d9vMx1qqSbJX1T0lKDjHNIaTuljLVnKf+RpDtL/zdK2rKUS9JnJf1vuU6XS9qo1t/MWn+/L9dxldpcH6hd0z5JkyR9rHb8pZJOq73/hqSP195/TNI/JL287Tw2l3RFmdeNkn4taeNSd0zbmH2SVpa0Q/kd7VHr5yJJOwx0vSIiIiJGoo6Bv6SfSVpJ0vLALcCfJR059FMbGpJ2Ak4EdrN9VymeZHtYTN0IAAAgAElEQVQssCGwMbB97ZCdgenAPpJUK78aGAfcxbwmA28u/R0CnMbA9gNWBzaxvTGwF/BorX5H22PLz0fK/D8IvAN4WznmrcBfgeUGON/XAZ8BtrG9CfA2YEqtyZFlrp8CvlfKPgxsVc7jjcCXgQskLds2t02AK4DP2n6oNVfgu5RrWt5fXfqj3FStCmxU62sr4Jra+4nAn4B/qZ3Hq4BzgKNtv8H2ZmVe69SOm1S7XmNtt67lPeUaRERERDRWNyv+G9p+HJgAXAK8HjhwSGc1RCRtB3wfGG97Rj9NlgaWBR6plU0ETgDuBrZsFdq+yfbM9g5sz7bt8nZ5wO1tal4D3G/7uXLsPbYfGaQ9VAHsh1pBre2nbR9ffkf9WQ14Aphdm9+d/bS7Eli3vD4KONz2k+WY/6EKzA/o57hrgdd2mPM1PH/tNqK6gXxC0iskLQNsANwIIGkdYAXgs1TXvuVw4Me2/3mDYPsPtn/VYWyAm4HHJO08WCNJh5VvaXpnzZrVRbcRERERi49uAv+lShrJBOAC23MZPJhdVC0D/AqYYHtaW90RkvqA+4HptvsAygr3OOBC4EzmDUQHJGkvSdOAX1Ot+g/kHGCPkpbyDUmbttVfXktbOUJVmtUKAwTuA7kZeBC4U9Lp9ZSXNnsAU8sYy9v+v7b6XuZdpW/Zleq6Dsj2fcAzktakWt2/FriO6magB5hq++nSfH/gLOAqYL2y0k8Z+8bBxqH8HsvP5W11X6K6mRhsnqfa7rHdM3r06A5DRURERCxeugn8vwfMpFq9vlLSWsBAq8uLsrlUK8/v76euleqzGrC8pP1L+XjgcttPAecCEyQt0Wkg2+fZXp/qZunYQdrdA6wHfBp4DphcUpFa6qk+k9qPl7RLCXJnStpqgDGepQrO302VsjRJ0jG1Jl8rNz2H0f+1Gcjlku4FdqO6KerkGqqgvxX4X1t7f3Wt3UTgrPItyLnAPv11Juk6SbdJOqFWXE/12bHe3vaV5bgB91xEREREjGQdA3/bJ9p+re3dXbkL2LHTcYug54B9gc0lHd1fg/Jtxm+A7UrRRGCcpJnADcAqwNu7HbAEm2urtvm3nzZzbF9i+0jgOKqbhYHaPg7Mbm0Atn1puWG5hSpNaaDjbPt621+mWlHfu1Z9ZAmUd7Z9Sxnj75LWbuvmLcCttfc7AmsBfcDnBxq7ppXnv3GZ7x+pVvz/md9fNuq+Afhtueb78/y3LLcCm9XOaQvgc8A8G4A76LjqHxERETFSdbO591WSfiDpkvJ+Q+C9Qz6zIVBy1t8JHCDpBavbZfPu1sCMkvKyLbCm7TG2x1Bteh003UfSuq1NwJI2o0oxemiAtptJWr28HgVswgs3C7f7MnCKpJVrc152oMaSVi/zaBnbxRhfA06UtFzpYxywDfCzeiPbzwAfAw6S9MoOfV5D9Q3Kw7aftf0wsDJV8N/K258IHNO63rZXB1Yv3zJ9Bzi47ZuNl3UYcx5lr8IrqK5zRERERKMs2UWbHwGn8/xTUaYDZwM/GKI5DSnbD0valSptqbWD8whJ7wGWonrizclU3w5cZntO7fDzga+WDakfAD4JvBqYIuli24dSraYfJGku8BSwX22zb7vVgO+X/gCuB06q1V8u6dnyeortg4BTqNKurpM0h2rT7tXATQOMsRTw9XKD8Q9gFvDBwa4R8G2qAHlqGf8BYM+S8jQP2/dLOpPqpmjAtCZgKtXTfH7WVraC7b+V9/sDu7cddx6wv+2vSNoP+Iqk11I9yehvwBdqbVu/x5b+vj35EtXvMSIiIqJRNHBMWhpIf7L9Vkk32d60lPWVFJOIEamnp8e9vb3DPY0Rb5f//OlwTyGiMS79Qn8PZouIkUDSDbZ7OrXrZnPv3yWtQnmSj6S3AY+9yPlFRERERMRLqJtUn48DFwDrSLoaGE31hJjoUtm0ekZb8ZyyQXVhjnMd1Z6CugNtT12Y40RERETE4mfQwL9sOF2W6i/ZrgcIuL08/Sa6VALvIU+NWtg3EhERERExcgwa+Nt+TtJ3Sm7/rYO1jYiIiIiIRVc3Of6TJe3dekRlREREREQsfroJ/D8A/ByYI+lxSU9IWhz/cm9ERERERGN13Nxre8WXYiIR0Tx5vGBERMRLp2PgL2m7/sptX7nwpxMREREREUOhm8d5Hll7vSywOXAD8PYhmVFERERERCx03aT67FF/L2kN4FtDNqOIiIiIiFjoutnc2+4eYIOFPZGIiIiIiBg63eT4fxtweTuK6g9R3TiUk4qIiIiIiIWrmxz/3trrZ4AzbV89RPOJiIiIiIgh0E3gv7LtE+oFkj7aXhYR8WLs/fWLhnsKESPauZ8YP9xTiIhh1k2O/3v7KTt4Ic8jIiIiIiKG0IAr/pImAv8KvF7SBbWqFYGHh3piERERERGx8AyW6nMNcD+wKvCNWvkTwJShnFRERERERCxcAwb+tu8C7gK2fOmmExERERERQ6Fjjr+kt0n6k6TZkp6W9Kykx1+KyUVERERExMLRzebek4CJwP8CywGHAt8ZyklFRERERMTC1dVf7rV9B7CE7Wdtnw7sOrTTioiIiIiIhamb5/g/KWlpoE/SV6k2/HZ1wxAREREREYuGbgL4A0u7w4G/A2sAew/lpCIiIiIiYuHqGPiXp/sIeI3tz9v+eEn9iYVM0uza690lTZe0lqRjJN0rqU/SNEmnSBpVa7ukpFmSjm/r73BJd0iypFVr5XtKmlL665W0zSBzGlOO/2KtbFVJcyWdVN7X59f6WVnSDpIeq837621971bG/7OkmyR9o8v+bpJ0u6QrJY2v9TfQcS+T9FNJUyXdIukPklZYsN9SRERExOKpm6f67AH0Ab8p78e2/UGvWMgk7QScCOxWbrwAJtkeC2wIbAxsXztkZ2A6sI8k1cqvBsZRPZa1bjLw5tLfIcBpHaZ0J/DO2vt9gFvb2kyyPbb282gpv6qMsykwXtLW5RzfRLVx/D22NwR6gDu67G9T2+sBHwFOKtdrsOM+Cjxoe2PbbwLeD8ztcM4RERERI0o3qT7HAJsDjwLY7gNeP4RzajRJ2wHfB8bbntFPk6WBZYFHamUTgROAu6n93QXbN9me2d6B7dm2Xd4uD7i9TZsngdsk9ZT3+wHndD6becZ8iuoG8rWl6JPAl2xPK/XP2j5lPvvsA75AlYY2mNcA99aOu932nPkZKyIiImJx103gP9f2Y21lnQLFWDDLAL8CJrQC4pojJPVRba6eXoJeJC1Ltap/IXAm1U1AR5L2kjQN+DXVqn8nZwH7S1oDeBa4r7/5lZ/L+xnvFcAbgCtL0ZuAGwYZb9D+am4E1u9w3A+BoyRdK+mLkt7QX0eSDiupR72zZs0aZMiIiIiIxU83gf+tkv4VWELSGyR9G7hmiOfVVHOpru37+6lrpfqsBiwvaf9SPh64vKyonwtMkLREp4Fsn2d7fWACcGwXc/sNVUrR/sDZA82v/OxYK99W0s1UK+6X2n6gi7EG66+d2t6/4Lhyk7Q28DXglcCfJG3Q3pHtU2332O4ZPXp0l9OMiIiIWDwMGPhLOqO8nAFsBMyhWlF+HPjY0E+tkZ4D9gU2l3R0fw1sz6UKwrcrRROBcZJmUq2grwK8vdsBbV8JrF3f/DtAu6dL//8P+EW3/VPl5L+Z6jP0fkljS/mtwFvmo5+BbArc1qlRSW/6pe1/B/4b2H0hjB0RERGx2Bhsxf8tklanyuf+BrAL8I7y+mUvwdwayfaTVBtpD5D0gpX/snl3a2CGpJWAbYE1bY+xPQb4MB3SfSSt29oELGkzqhSjh7qY3jeAo2w/PB+nBIDtO4HjgaNK0deAoyW9scxjlKQPzk+fkjYBPkeHvyQtaeuSaoSqv0mxIS/c8BwRERExog32B7y+S/X0l7WB3lq5qHL81x7CeTWa7Ycl7QpcKamVbH6EpPcASwFTgJOpvh24rG2j6vnAVyUtA3yAahPtq4Epki62fSjV32E4SNJc4Clgv9pm38HmdSsvfJpPS2t+LRP6afNd4BOSxtieIuljwJmSXkb1mbqoi/62lXQT1c3nX4GP2J7c4bh1gFPKzc4oqn0N5w56shEREREjjDrFe5JOsf2hl2g+EYuEnp4e9/b2dm4YC83eX7+oc6OIWGDnfmJ850YRsViSdIPtnk7tuvkDXgn6IyIiIiIWc4Ol+kSDSNoYOKOteI7tLYZjPhERERGxcCXwDwBsTwXGdmwYEREREYulbp7jHxERERERi7kE/hERERERDZDAPyIiIiKiARL4R0REREQ0QDb3RsQiIc8Yj4iIGFpZ8Y+IiIiIaIAE/hERERERDZDAPyIiIiKiARL4R0REREQ0QAL/iIiIiIgGSOAfEREREdEAeZxnRCySDvve5OGeQsSIcuoHdhruKUTEMMuKf0REREREAyTwj4iIiIhogAT+ERERERENkMA/IiIiIqIBEvhHRERERDRAAv+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCBf0REREREAyTwX8xIml17vbuk6ZLWknSMpHsl9UmaJukUSaNqbZeUNEvS8W39HS7pDkmWtGqtfE9JU0p/vZK2GWROYyTdUnv/b5JukPQKST+S9KSkFWv136qPVz+n8v5gSScNMt7HJf25zG+ypLVqdb+R9Kiki7o5z4iIiIimSOC/mJK0E3AisJvtu0rxJNtjgQ2BjYHta4fsDEwH9pGkWvnVwDjgLuY1GXhz6e8Q4LQu53Ug8B/ALrYfKcV3AHuW+lHA24F7u+lvADcBPbY3AX4BfLVW9zXgwH6OGeg8IyIiIhohgf9iSNJ2wPeB8bZn9NNkaWBZ4JFa2UTgBOBuYMtWoe2bbM9s78D2bNsub5cH3N6mn3ntC3wKeIftv9WqzgL2K693oArCn+nU30BsX277yfL2j8DranWTgSf6Oabf84yIiIhoigT+i59lgF8BE2xPa6s7QlIfcD8w3XYfgKRlqVa7LwTOpLoJ6EjSXpKmAb+mWvUfzFrASVRB/wNtddOB0ZJeUcY+q61+uZJS1Ffm/4Vu5le8H7hkPtoPSNJhJa2pd9asWQujy4iIiIhFRgL/xc9c4BqqgLddK9VnNWB5SfuX8vHA5bafAs4FJkhaotNAts+zvT4wATi2Q/NZVN8m7DtA/S+B/YEtgKva6p6yPbb1A/xnp7kBSHoP0EOV3vOi2T7Vdo/tntGjRy+MLiMiIiIWGQn8Fz/PUQXXm0s6ur8GtucCvwG2K0UTgXGSZgI3AKtQ5dl3xfaVwNodNsU+CewOfFDSAf3Un0118/Bb2891O/ZAJI0DPgO8y/acF9tfRERExEi35HBPIOaf7SclvRO4StKDtn9Qry+bd7cGbpK0ErAtsEYrQJb0Pqqbgd8ONIakdYEZti1pM6oUo4c6zOuvknYFrpD0N9uX1urukvQZ4HcLcs5tc9sU+B6wq+2/vtj+IiIiIpogK/6LKdsPA7sCn5X0rlLcyvG/BVgCOBnYC7isbVX8fGAPSctI+oike6g2yE6R1Hp6z97ALaW/7wD71Tb7DjavO4F3AT+UtHlb3fcG2Iw8v74GrAD8vOwLuKBVIekq4OfATpLukbRLKR/oPCMiIiIaQV3EchGN09PT497e3uGeRqMd9r3Jwz2FiBHl1A/sNNxTiIghIukG2z2d2mXFPyIiIiKiAZLjH12TtDFwRlvxHNtbDNF4nwH2aSv+ue0vDcV4ERERESNZAv/omu2pwNiXcLwvAQnyIyIiIhaCpPpERERERDRAAv+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCbeyNikZRnjkdERCxcWfGPiIiIiGiABP4REREREQ2QwD8iIiIiogES+EdERERENEAC/4iIiIiIBshTfSJikXb0mdcM9xQiRoTjJm413FOIiGGWFf+IiIiIiAZI4B8RERER0QAJ/CMiIiIiGiCBf0REREREAyTwj4iIiIhogAT+ERERERENkMA/IiIiIqIBEvhHRERERDRAAv+IiIiIiAZI4B8RERER0QBDFvhLml17vbuk6ZLWknSMpHsl9UmaJukUSaNqbZeUNEvS8W39HS7pDkmWtGqtfE9JU0p/vZK2GWROoySdKOkWSVMl/UnS60vdzFLWV35OrB338TLXqZJulvRNSUsNMs7LJf2kzHdGef3yUjdG0lNljJslXSNpvVK3g6THanPokzSu1D1b3t8i6UJJK/fTX+vnoNo5XdU2tz5Jt9TGu0jS+2rHPl27Dg8OUH68pIPL76k+7oZlPrf0c01+JOnd5fUrJd1Uxu23fYfPwvhy/M2S/izpA6V8PUlXlLncJunUTtc1IiIioimWHOoBJO0EnAjsYvsuSQCTbH+9BPxXAtsDl5dDdgamA/tI+rRtl/KrgYuAK9qGmAxcYNuSNgHOAdYfYDr7AasDm9h+TtLrgL/X6ne0/be2+X8QeAfwNtuPSloa+DiwHDB3gHF+ANxiuxWAfx44Ddin1M+wPbbUfQA4GnhvqbvK9vh++nyqdsyPgQ8DX2rvrx8rSlrD9l8kbdBfA9unA6eXvmcOcB3mKZd0MHC27cPb2o0ZYB6t+pcDlwKn2j69Q/sXfBbKDdepwOa275G0DNDq40Sqz9b5ZayNa30NdF0jIiIiGmFIU30kbQd8Hxhve0Y/TZYGlgUeqZVNBE4A7ga2bBXavsn2zPYObM+u3RwsD7i9Tc1rgPttP1eOvcf2I4O0B/gM8CHbj5ZjnrZ9vO3H+2ssaV3gLcCxteIvAD2S1unnkJWY9/y7cS3w2i7bnkN1wwPVtT1zPsdamFYALgF+ZvuULtr391lYkeqG9SEA23Ns317qXgPc0zrY9tT5mZykw1R9a9Q7a9as+Tk0IiIiYpE3lIH/MsCvgAm2p7XVHSGpD7gfmG67D0DSssA44EKqAHViNwNJ2kvSNODXwCGDND0H2KOkenxD0qZt9ZfXUkGOkLQSsILtO7uZR7Eh0Gf72VZBed0HbFSK1iljzKD69uCbteO3bUtJmedmQdISwE7ABbXiddqO2bZWdy7wL+X1HlTXdmHZr23c5Tq0/ybwB9uTOnU80GfB9sNU536XpDMlHaDnU8UmAZdJuqT8/laudTnodS19n2q7x3bP6NGjO558RERExOJkKAP/ucA1wPv7qZtUUlNWA5aXtH8pHw9cbvspqoB1Qgl0B2X7PNvrAxOYd6W9vd09wHrAp4HngMklFallR9tjy88LglNJu5SgcaakrTrNaxAzyhjrAB+jSl1puao2h7G1b0qWKzdLDwCvAn7bT3+tn3pe/0PAI+Ua3wY8+SLm3e7stnGf6tD+MmBPSat10feAnwXbh1Ld/FwPfAL4YSk/HdgA+DmwA/DHkgoEA1/XiIiIiEYYysD/OWBfYHNJR/fXwPZc4DfAdqVoIjCu5JPfAKwCvL3bAW1fCayt2ubfftrMsX2J7SOB46huFgZq+zgwW2UDsO1Lyw3LLVRpSv35MzBW825YHgWMLXXtLuD58x9MK8d/LUBUOf7dOhv4DsOb5gNwFvBd4GJJK3ZoO+hnwfbUcnO2M7B3rfw+2z+0vSfwDPCmhXsKEREREYunIc3xt/0k8E7gAEkvWPlXtdN3a2BGSavZFljT9hjbY6iC20HTfSStW/pB0mZUKUYPDdB2M0mrl9ejgE2AuzqcxpeBU/T8U3REtS+hX7bvAG4CPlsr/ixwY6lrtw3Q9epzuaYfAf6fpG43Z58HfJVqU+2wKsH6ZOCXZaP0Cwz2WZC0gqQdas3HUn6HknYtm3+R9Gqqm4V7h+pcIiIiIhYnQ/4c/5KTvSvwWUnvKsWtHP9bgCWAk4G9gMtsz6kdfj5VTv4ykj4i6R7gdcAUSaeVNnsDt5T+vgPsV9vs22414EJVj4+cQrUifFKtvp7j/5NSdgpVoHqdpClUTxe6qfwM5P3AG1U9ynMG8EbmTXlq5eTfTPWtw6G1uvZc9He3d277pjL/iW39tX4+0tb+Cdtfsf30IHNeEO05/q30p/Uk3VP72ad+kO2jqDbhnkH1GZynPYN8Fqg+L5+UdHv5nX8eOLi0eQfVZ+FmqpucI20/UOo6XteIiIiIkUwDx8gRzdXT0+Pe3t7hnkYAR595zXBPIWJEOG7ii9maFhGLMkk32O7p1C5/uTciIiIiogGG/A94DQdVf7jpjLbiOba3WMjjXEe1p6DuwPl9fnxERERExFAbkYF/CbwH+ku2C3OchXojERERERExVJLqExERERHRAAn8IyIiIiIaIIF/xP9v786DLSnLO45/fzAypEAjyrgSGRAIYiQj3mAMggZRXBAwooCoEDGGKo1VaEw0ZLE0GhO1UMolLlHUBEFQEPdCFiEK6ADXAQkOMyyGCeoEMZFAJug8+aP7VrXHu83c5cy5/f1UnZo+7/t299NPnzvznL5v90iSJPXAkpzjL2np8BGEkiTND6/4S5IkST1g4S9JkiT1gIW/JEmS1AMW/pIkSVIPWPhLkiRJPWDhL0mSJPWAj/OUtE179xevHXYI0pLw+iMOGHYIkobMK/6SJElSD1j4S5IkST1g4S9JkiT1gIW/JEmS1AMW/pIkSVIPWPhLkiRJPWDhL0mSJPWAhb8kSZLUAxb+kiRJUg9Y+C8hSe7pLD83ydokuyd5c5INScaT3JTkg0m264xdlmRjkncMbO81SdYlqSS7dtqPSrKm3d7qJE+dJqbtkpyR5IYk1yf5TpI92r7bkjy83c54kh924hxPcmxneeK1OclzkqxMct9A38tnkaMLk9ywpbmVJEkadcuGHYDmX5JnAGcAh1fV7UkATq+qd7UF/+XA04BL21WeCawFXpTkTVVVbfs3gS8Clw3s4mLgwqqqJPsDnwH2nSKcY4FHAftX1eYkuwH/0+n/RVWtauN+M3BPVb2r039O57heBZwAfA14DLB+Yt3ZSPIHwD0zDpQkSVqCvOK/xCQ5BPgIcERVrZ9kyA7AjsDdnbbjgfcCPwCeMtFYVddV1W2DG6iqezpfDnYCanBMxyOBO6tqc7vuHVV19zTjJ5VkH+CvgZdNbGsL198ZeB3wt1u6riRJ0lJg4b+0LAcuAI6uqpsG+k5NMg7cCaytqnGAJDsChwFfAD5N8yVgRklekOQm4EvAK6YZ+hng+e1UnHcneeIWHVGzrwcAZwGvr6ofdLoeOzDV5+BpNvNW4N3AvdPs51Xt1KXVGzdu3NIwJUmStmkW/kvL/cC3gJMn6Tu9nRbzMGCnJMe17UcAl1bVfcBngaOTbD/Tjqrq/KraFziapqieatwdwG8CbwI2Axe3U5G2xFuB71XVOQPt66tqVed1xWQrJ1kFPLaqzp9uJ1X14aoaq6qxFStWbGGIkiRJ2zYL/6VlM/Bi4MAkfzHZgKq6H/gqcEjbdDxwWJLbgGuAhwKHznaHVXU5sGf35t9Jxmyqqq9U1RuAt9N8WZiVJE8HXgi8ZrbrTOIpwFh7jP8K7JPksjlsT5IkaeRY+C8xVXUv8DzghCS/cuU/zZ2+BwHrkzwIOBh4TFWtrKqVwKuZYbpPkr3a7ZDkAJopRndNMfaAJI9ql7cD9gdun82xJNkF+Djw8qr62WzWmUxVfbCqHtUe31Nppjo9fWu3J0mSNIp8qs8SVFU/SfJs4PIkE5PVT03yUuABwBrgAzS/HbikqjZ1Vv888A9JlgN/DPwZ8AhgTZIvV9Uraa7AvzzJ/cB9wLGdm30HPQz4SLs9gG8D75vloZzSrv/B9nvGhL8Drqad499p/1hVnTHLbUuSJPVKpq7XpP4aGxur1atXDzsMAe/+4rXDDkFaEl5/xAHDDkHSAklyTVWNzTTOqT6SJElSDzjVR/MiyROATw00b6qqJy9yHFfT3HPQ9bKqun4x45AkSdrWWPhrXrSF9az/F90FjGNRv2hIkiSNCqf6SJIkST1g4S9JkiT1gIW/JEmS1AMW/pIkSVIPeHOvpG2azx6XJGl+eMVfkiRJ6gELf0mSJKkHLPwlSZKkHrDwlyRJknrAwl+SJEnqAZ/qI2kknHn5vw07BGmknXTI44YdgqQh84q/JEmS1AMW/pIkSVIPWPhLkiRJPWDhL0mSJPWAhb8kSZLUAxb+kiRJUg9Y+EuSJEk9YOEvSZIk9YCFvyRJktQDFv6SJElSD1j4j5gk93SWn5tkbZLdk7w5yYYk40luSvLBJNt1xi5LsjHJOwa295ok65JUkl077UclWdNub3WSp04T08okN3Te/1GSa5LskuTMJPcmeWCn/z3d/XWPqX1/UpL3TbO/1yW5sY3v4iS7d/p+0cY8nuTCTvseSa5uj/WcJDtMtX1JkqSlyMJ/RCV5BnAG8Jyqur1tPr2qVgH7AU8AntZZ5ZnAWuBFSdJp/yZwGHA7v+xi4Lfb7b0C+Ogs43oZ8CfA4VV1d9u8Djiq7d8OOBTYMJvtTeE6YKyq9gfOA/6h03dfVa1qX0d22v+eJj97AXcDJ89h/5IkSSPHwn8EJTkE+AhwRFWtn2TIDsCONAXuhOOB9wI/AJ4y0VhV11XVbYMbqKp7qqratzsBNThmkrheDLwReFZV/Wen62zg2Hb56TRfNn4+0/amUlWXVtW97durgN1miCs0XzbOa5s+ARw9ybhXtb/dWL1x48atDU+SJGmbZOE/epYDFwBHV9VNA32nJhkH7gTWVtU4QJIdaa7qfwH4NM2XgBkleUGSm4Av0Vz1n87uwPtoiv4fDvStBVYk2aXd99kD/b/WmZ4zDrxlNvG1Tga+0nm/Y1u8X5Vkorh/KPDTqpr4snEH8OjBDVXVh6tqrKrGVqxYsQUhSJIkbfss/EfP/cC3mHyqysRUn4cBOyU5rm0/Ari0qu4DPgscnWT7mXZUVedX1b40V8ffOsPwjTS/TXjxFP2fA44DngxcMdDXnZ6zCvjrmWIDSPJSYAx4Z6d596oaA14CvCfJY2ezLUmSpKXOwn/0bKYprg9M8heTDQZMDRIAAAnnSURBVKiq+4GvAoe0TccDhyW5DbiG5gr4obPdYVVdDuzZvfl3EvcCzwVOSXLCJP3n0Hx5uKiqNs9231NJchhwGnBkVW3qxLqh/fMW4DLgicBdwIOTLGuH7cbc7jGQJEkaORb+I6id3/484IQkv3Llv53TfhCwPsmDgIOBx1TVyqpaCbyaGab7JNlr4ibgJAfQTDG6a4a4fgw8G3h7ksMH+m6nKdQ/MKuDnD62JwIfoin6f9xp3yXJ8nZ5V5oc3Njeq3ApcEw79ETg83ONQ5IkaZRY+I+oqvoJTZH9l0kmnl4zMcf/BmB7miL7BcAl3aviNEXv85MsT/LaJHfQXAVfk2Ti6T0vBG5ot/d+4NjOzb7TxXUrcCTwsSQHDvR9aIqbkbfUO4GdgXMHHtv5OGB1ku/SFPrvqKob274/B16XZB3Nbzz+aR7ikCRJGhmZRS0n9c7Y2FitXr162GGo48zL/23YIUgj7aRDHjfsECQtkCTXtPc4Tssr/pIkSVIPLJt5iNRI8gTgUwPNm6rqyQu0v9OAFw00n1tVb1uI/UmSJC1lFv6ataq6Hli1iPt7G2CRL0mSNA+c6iNJkiT1gIW/JEmS1AMW/pIkSVIPWPhLkiRJPeDNvZJGgs8glyRpbrziL0mSJPWAhb8kSZLUA6mqYccgbXOSbARuH3YcW2lX4D+HHcQ2wDw0zIM5mGAeGuahYR6WVg52r6oVMw2y8JeWmCSrq2ps2HEMm3lomAdzMME8NMxDwzz0MwdO9ZEkSZJ6wMJfkiRJ6gELf2np+fCwA9hGmIeGeTAHE8xDwzw0zEMPc+Acf0mSJKkHvOIvSZIk9YCFvzSCkjwkyUVJbm7/3GWSMauSXJnke0nWJDm207dHkquTrEtyTpIdFvcI5sds8tCO+2qSnyb54kD7mUluTTLevlYtTuTzZx5y0LfPwontmJuTnNhpvyzJ9zufhYctXvRzl+TZbfzrkrxxkv7l7fld157vlZ2+N7Xt309y+GLGPZ+2NgdJVia5r3Pu/3GxY59Ps8jDIUmuTfLzJMcM9E368zGK5piHX3Q+DxcuXtQLz8JfGk1vBC6uqr2Bi9v3g+4FXl5VjweeDbwnyYPbvr8HTq+qvYC7gZMXIeaFMJs8ALwTeNkUfW+oqlXta3whglxgc81Bbz4LSR4C/A3wZOBA4G8GviCc0Pks/Hgxgp4PSbYH3g88B9gPOD7JfgPDTgbubs/z6TTnnXbcccDE3xMfaLc3UuaSg9b6zrk/ZVGCXgCzzMMPgJOAswbWnennY2TMJQ+t+zqfhyMXNNhFZuEvjaajgE+0y58Ajh4cUFVrq+rmdvk/gB8DK5IEOBQ4b7r1R8SMeQCoqouBny1WUItsq3PQw8/C4cBFVfWTqrobuIim2B11BwLrquqWqvo/4GyafHR183Me8Iz2/B8FnF1Vm6rqVmBdu71RM5ccLCUz5qGqbquqNcDmgXWX0s/HXPKwpFn4S6Pp4VV1Z7v8Q+Dh0w1OciCwA7AeeCjw06r6edt9B/DohQp0gW1RHqbwtnYq1OlJls9jbItlLjno22fh0cC/d94PHu/H21/t/9WIFYQzHdcvjWnP93/RnP/ZrDsK5pIDgD2SXJfkG0kOXuhgF9BczudS+SzA3I9lxySrk1yVZFQvhkxq2bADkDS5JF8HHjFJ12ndN1VVSaZ8PFeSRwKfAk6sqs2jVc/MXx6m8CaaInEHmse6/Tnwlq2JcyEtcA5GxgLn4YSq2pDkgcBnaaZFfXLrItWIuRN4TFXdleRJwAVJHl9V/z3swDQ0u7d/H+wJXJLk+qpaP+yg5oOFv7SNqqrDpupL8qMkj6yqO9vCftL5yEkeBHwJOK2qrmqb7wIenGRZe9VrN2DDPIc/b+YjD9Nse+IK8aYkHwf+dA6hLpgFzEHfPgsbgKd33u8GXNZue0P758+SnEUzVWBUCv8NwG903k92HifG3JFkGfDrNOd/NuuOgq3OQTXPNd8EUFXXJFkP7AOsXvCo599czueUPx8jaE6f687fB7ckuQx4Is1vzEeeU32k0XQhMPHEhROBzw8OSPN0lvOBT1bVxBxu2n/kLgWOmW79ETFjHqbTFogTc92PBm6Y1+gWx1bnoIefha8Bz0qyS3vT4rOAryVZlmRXgCQPAI5gtD4L3wH2TvOEph1obtYdfBJJNz/HAJe05/9C4Lj2iTd7AHsD316kuOfTVucgyYqJG5rbK7x7A7csUtzzbTZ5mMqkPx8LFOdC2+o8tMe/vF3eFTgIuHHBIl1sVeXLl68Re9HMS70YuBn4OvCQtn0M+Gi7/FLgfmC881rV9u1J84/7OuBcYPmwj2mh8tC+vwLYCNxHM9fz8Lb9EuB6miLvn4Gdh31MQ8hB3z4Lr2iPdR3wh23bTsA1wBrge8B7ge2HfUxbePzPBdbSXJU8rW17C3Bku7xje37Xted7z866p7XrfR94zrCPZbFzALywPe/jwLXA84d9LAuch99p/w74H5rf+nyvs+6v/HyM6mtr8wD8XvvvwnfbP08e9rHM58v/uVeSJEnqAaf6SJIkST1g4S9JkiT1gIW/JEmS1AMW/pIkSVIPWPhLkiRJPWDhL0nSAkjy0ST7zTDmzCTHTNK+MslLFi46SX1k4S9J0gKoqldW1db+xz8rAQt/SfPKwl+SpGkkeUOS17bLpye5pF0+NMm/JHlWkiuTXJvk3CQ7t/2XJRlrl09OsjbJt5N8JMn7Ors4JMm3ktzSufr/DuDgJONJTk3y+Hbd8SRrkuy9iCmQtERY+EuSNL0rgIPb5TFg5yQPaNvWAH8JHFZVBwCrgdd1V07yKOCvgN8FDgL2Hdj+I4GnAkfQFPwAbwSuqKpVVXU6cArw3qpa1cZwx7weoaReWDbsACRJ2sZdAzwpyYOATcC1NMX3wcCFwH7AN5MA7ABcObD+gcA3quonAEnOBfbp9F9QVZuBG5M8fIoYrgROS7Ib8LmqunlejkxSr1j4S5I0jaq6P8mtwEnAt2iu8v8+sBdwK3BRVR0/h11s6ixnihjOSnI18Dzgy0n+uKoumcM+JfWQU30kSZrZFcCfApe3y6cA1wFXAQcl2QsgyU5J9hlY9zvA05LskmQZ8MJZ7O9nwAMn3iTZE7ilqs4APg/sP8fjkdRDFv6SJM3sCpq5+FdW1Y+A/6WZg7+R5jcBn06yhmZKzi/N4a+qDcDbgW8D3wRuA/5rhv2tAX6R5LtJTgVeDNyQZBz4LeCT83RcknokVTXsGCRJWtKS7FxV97RX/M8HPlZV5w87Lkn94hV/SZIW3pvbq/U30NwXcMGQ45HUQ17xlyRJknrAK/6SJElSD1j4S5IkST1g4S9JkiT1gIW/JEmS1AMW/pIkSVIPWPhLkiRJPfD/CLpmGwBip4wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display makeup of first component\n",
    "for num in range(1,5):\n",
    "    display_component(v, azdias_df.columns.values, component_num=num, n_components = N_COMPONENTS, n_weights=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the explained variance vs number of components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0    0.980038\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "n_top_components = 220 # select a value for the number of top components\n",
    "\n",
    "# calculate the explained variance\n",
    "exp_variance = explained_variance(s, n_top_components)\n",
    "print('Explained variance: ', exp_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for x in range(num_components):\n",
    "    y.append(explained_variance(s, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y)\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how many components are needed for 90% of explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "#convert list of series to list of floats\n",
    "floats_y = [float(i) for i in y]\n",
    "#construct an comprehension to locate the index of the first element with more than 0.9 explained variance\n",
    "components = (i for i,v in enumerate(floats_y) if (v > 0.9))\n",
    "num_components = next(components)\n",
    "print(num_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-fit PCA with the number of components obtained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 20:58:19 Starting - Starting the training job...\n",
      "2020-05-15 20:58:22 Starting - Launching requested ML instances......\n",
      "2020-05-15 20:59:22 Starting - Preparing the instances for training...\n",
      "2020-05-15 21:00:12 Downloading - Downloading input data......\n",
      "2020-05-15 21:01:19 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'316', u'mini_batch_size': u'500', u'num_components': u'134'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Final configuration: {u'num_components': u'134', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'316', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 WARNING 140676506498880] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/53cd306c-48ed-45e3-bf8c-5da9936b45e0', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-58-18-831', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-53.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/625505a9-141e-4fdc-a89f-5f48b9f6d2ea', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-58-18-831', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/53cd306c-48ed-45e3-bf8c-5da9936b45e0', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.156.53', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-58-18-831', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-53.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/625505a9-141e-4fdc-a89f-5f48b9f6d2ea', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-58-18-831', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/53cd306c-48ed-45e3-bf8c-5da9936b45e0', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-58-18-831', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-53.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/625505a9-141e-4fdc-a89f-5f48b9f6d2ea', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-58-18-831', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/53cd306c-48ed-45e3-bf8c-5da9936b45e0', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.156.53', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-58-18-831', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-53.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/625505a9-141e-4fdc-a89f-5f48b9f6d2ea', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-58-18-831', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/53cd306c-48ed-45e3-bf8c-5da9936b45e0', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.156.53', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-15-20-58-18-831', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-53.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/625505a9-141e-4fdc-a89f-5f48b9f6d2ea', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-15-20-58-18-831', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 60 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 69 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:22 INFO 140676506498880] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:23 INFO 140676506498880] nvidia-smi took: 0.0251610279083 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:23 INFO 140676506498880] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:23 INFO 140676506498880] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:23 INFO 140676506498880] 316 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:23 INFO 140676506498880] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1140.0790214538574, \"sum\": 1140.0790214538574, \"min\": 1140.0790214538574}}, \"EndTime\": 1589576483.684672, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576482.519829}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589576483.685038, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576483.68498}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:01:23.691] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1168, \"num_examples\": 1, \"num_bytes\": 1278000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:01:41 Uploading - Uploading generated training model\n",
      "2020-05-15 21:01:41 Completed - Training job completed\n",
      "\u001b[34m[2020-05-15 21:01:34.352] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 10651, \"num_examples\": 1503, \"num_bytes\": 1920402036}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 10664.386987686157, \"sum\": 10664.386987686157, \"min\": 10664.386987686157}}, \"EndTime\": 1589576494.356025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576483.684772}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:34 INFO 140676506498880] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576494.356627, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1589576483.691428}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:34 INFO 140676506498880] #throughput_metric: host=algo-1, train throughput=70445.3693257 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 40.85087776184082, \"sum\": 40.85087776184082, \"min\": 40.85087776184082}}, \"EndTime\": 1589576494.397941, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576494.356121}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:01:34 INFO 140676506498880] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 12040.560960769653, \"sum\": 12040.560960769653, \"min\": 12040.560960769653}, \"setuptime\": {\"count\": 1, \"max\": 42.5410270690918, \"sum\": 42.5410270690918, \"min\": 42.5410270690918}}, \"EndTime\": 1589576494.417806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1589576494.397995}\n",
      "\u001b[0m\n",
      "Training seconds: 89\n",
      "Billable seconds: 89\n"
     ]
    }
   ],
   "source": [
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)\n",
    "\n",
    "pca.fit(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 ms, sys: 540 µs, total: 23 ms\n",
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pca_transformer = pca.transformer(instance_count = 1, \n",
    "                                  instance_type = 'ml.m5.large',\n",
    "                                  output_path='s3://{}/{}/pca/transform/test'.format(bucket_name, prefix+\"/transform\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'azdias.csv'\n",
    "\n",
    "\n",
    "u = azdias_df.select_dtypes(object)\n",
    "azdias_df[u.columns] = u.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into local notebook storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df.to_csv(filename,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "np_azdias_location = session.upload_data(os.path.join(filename), key_prefix=prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print dataset location in order to avoid previous computation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-848439228145/arvato/azdias.csv\n"
     ]
    }
   ],
   "source": [
    "print(np_azdias_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete temp file from sagemaker notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] nvidia-smi took: 0.0253269672394 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loading entry points\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:09:06 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:09:06 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:09:06 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:09:06 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loading model...\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:09:06 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] loading model...\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:06 INFO 140368757495616] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576961.408901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576946.277658}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576961.408901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576946.277658}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[32m2020-05-15T21:09:21.422:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576964.793795, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576961.408988}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576964.793795, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576961.408988}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576965.923637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576946.365847}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576965.923637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576946.365847}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576968.102427, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576966.605747}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576968.102427, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576966.605747}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576968.578716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576967.287402}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576968.578716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576967.287402}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576969.519398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576968.102759}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576969.519398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576968.102759}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576970.086277, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576968.57884}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576971.004277, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576969.51947}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576970.086277, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576968.57884}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576971.004277, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576969.51947}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576971.554071, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576970.086712}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:31 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:31 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:31 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:31 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576971.554071, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576970.086712}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:31 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:31 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:31 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:31 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576972.299547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576971.004358}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576972.918743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576971.554401}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576972.299547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576971.004358}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576972.918743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576971.554401}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576973.659269, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576972.299625}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576973.659269, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576972.299625}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576974.383134, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576972.919353}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576974.383134, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576972.919353}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576975.150461, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576973.659352}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576975.150461, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576973.659352}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576975.737757, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576974.383506}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576975.737757, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576974.383506}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576977.087757, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576975.738106}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576977.858216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576976.438913}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576977.087757, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576975.738106}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576977.858216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576976.438913}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576978.484201, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576977.087983}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576978.484201, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576977.087983}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576979.26406, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576977.858598}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576979.775843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576978.484529}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576979.26406, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576977.858598}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576979.775843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576978.484529}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576980.650388, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576979.264137}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576980.650388, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576979.264137}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:41 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:41 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:41 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:41 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576981.380489, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576979.776144}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576981.960768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576980.650893}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:41 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:41 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:41 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:41 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576981.380489, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576979.776144}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576981.960768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576980.650893}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576982.875204, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576981.380797}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576982.875204, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576981.380797}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576983.53975, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576981.961332}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576983.53975, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576981.961332}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576984.314841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576982.875431}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576984.996619, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576983.539831}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576984.314841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576982.875431}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576984.996619, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576983.539831}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576985.651922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576984.315633}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576985.651922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576984.315633}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576987.15842, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576985.652559}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576987.15842, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576985.652559}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576988.077473, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576986.384313}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576988.60053, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576987.15925}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576988.077473, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576986.384313}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576988.60053, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576987.15925}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576989.429861, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576988.077554}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576989.98958, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576988.600914}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576989.429861, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576988.077554}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576989.98958, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576988.600914}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576990.790268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576989.42994}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576990.790268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576989.42994}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576991.375709, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576989.990324}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:51 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:51 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:51 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:51 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576991.375709, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576989.990324}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:51 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:51 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:51 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:51 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576992.173806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576990.790346}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576992.860185, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576991.375977}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576992.173806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576990.790346}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576992.860185, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576991.375977}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576993.469571, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576992.174292}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576993.469571, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576992.174292}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576994.204307, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576992.86053}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576994.204307, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576992.86053}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576994.886369, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576993.470117}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576994.886369, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576993.470117}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576995.554932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576994.204555}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576995.554932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576994.204555}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:09:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576997.462239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576995.55539}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576997.846726, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576996.253968}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576997.462239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576995.55539}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576997.846726, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576996.253968}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:58 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576998.815138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576997.462985}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:58 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576998.815138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576997.462985}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576999.205875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576997.846809}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589576999.205875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576997.846809}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:09:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:09:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577000.232462, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576998.815894}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577000.646535, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576999.205956}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577000.232462, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576998.815894}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577000.646535, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589576999.205956}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:01 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577001.700585, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577000.233161}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:01 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577001.700585, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577000.233161}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577002.147345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577000.646615}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577002.147345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577000.646615}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577003.255883, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577001.702763}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577003.519992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577002.147539}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577003.255883, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577001.702763}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577003.519992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577002.147539}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:04 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:04 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:04 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:04 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577004.693908, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577003.256614}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:04 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:04 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:04 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:04 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577004.693908, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577003.256614}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577005.094811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577003.520078}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577005.094811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577003.520078}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577006.075839, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577004.694639}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577006.552151, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577005.094893}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577006.075839, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577004.694639}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577006.552151, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577005.094893}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2460.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2460.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577007.540139, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577006.076618}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577007.897527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577006.552236}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577007.540139, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577006.076618}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577007.897527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577006.552236}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577008.98043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577007.540832}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577008.98043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577007.540832}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577009.189356, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577007.89761}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577009.189356, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577007.89761}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577010.277323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577008.981119}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577010.688987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577009.189437}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577010.277323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577008.981119}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577010.688987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577009.189437}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:10:11 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:11 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577011.605819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577010.277581}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:11 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:11 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577011.605819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577010.277581}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577012.111065, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577010.689371}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577012.111065, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577010.689371}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577013.125797, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577011.606101}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577013.590836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577012.111401}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:13 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:13 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:13 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:13 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577013.125797, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577011.606101}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577013.590836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577012.111401}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:13 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:13 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:13 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:13 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:14 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:14 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:14 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:14 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577014.485491, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577013.126012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577015.000595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577013.590986}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:14 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:14 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:14 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:14 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577014.485491, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577013.126012}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577015.000595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577013.590986}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:16 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:16 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:16 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:16 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:16 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:16 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:10:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:17 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:17 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:17 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:17 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577017.490331, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577016.091166}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:17 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:17 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:17 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:17 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577017.490331, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577016.091166}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577018.181115, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577016.747249}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577018.181115, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577016.747249}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577018.962408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577017.491057}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577018.962408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577017.491057}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577019.517522, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577018.1812}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:19 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:19 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:19 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:19 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577019.517522, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577018.1812}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:19 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:19 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:19 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:19 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577020.247033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577018.963161}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577020.247033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577018.963161}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577020.966338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577019.517605}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577020.966338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577019.517605}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577021.577794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577020.247754}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:21 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:21 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:21 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:21 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577021.577794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577020.247754}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:21 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:21 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:21 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:21 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:22 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:22 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:22 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:22 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577022.487107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577020.966416}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577022.945504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577021.578509}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:22 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:22 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:22 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:22 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577022.487107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577020.966416}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577022.945504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577021.578509}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577024.048164, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577022.487191}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577024.048164, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577022.487191}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577024.296196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577022.946582}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577024.296196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577022.946582}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577025.387994, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577024.048242}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577025.682846, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577024.296526}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577025.387994, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577024.048242}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577025.682846, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577024.296526}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:10:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577026.777259, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577025.388135}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577026.777259, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577025.388135}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577027.141755, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577025.683635}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577027.141755, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577025.683635}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577028.25314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577026.777337}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577028.532611, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577027.142472}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577028.25314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577026.777337}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577028.532611, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577027.142472}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577029.649767, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577028.253218}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577029.649767, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577028.253218}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577030.013227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577028.533327}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577030.013227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577028.533327}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577031.126937, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577029.649841}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577031.126937, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577029.649841}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577031.417052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577030.014036}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:31 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:31 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:31 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:31 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577031.417052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577030.014036}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:31 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:31 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:31 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:31 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577032.570469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577031.12701}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577032.753984, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577031.417411}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577032.570469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577031.12701}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577032.753984, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577031.417411}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577034.039148, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577032.570994}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577034.062107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577032.75427}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577034.039148, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577032.570994}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577034.062107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577032.75427}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577035.419651, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577034.040033}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577035.626235, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577034.062503}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577035.419651, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577034.040033}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577035.626235, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577034.062503}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577036.882118, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577035.419726}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577036.882118, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577035.419726}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577036.886475, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577035.627124}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577036.886475, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577035.627124}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577038.192182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577036.887208}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577038.192182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577036.887208}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577038.196778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577036.8822}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577038.196778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577036.8822}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577039.431343, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577038.193042}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577039.769072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577038.196888}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577039.431343, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577038.193042}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577039.769072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577038.196888}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577040.773942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577039.432306}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577040.773942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577039.432306}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577042.135471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577040.77465}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577042.770333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577041.219533}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577042.135471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577040.77465}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577042.770333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577041.219533}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577043.698239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577042.135847}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577043.698239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577042.135847}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577044.20216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577042.770442}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577044.20216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577042.770442}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577044.995652, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577043.698523}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577044.995652, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577043.698523}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577045.685204, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577044.20235}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577045.685204, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577044.20235}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577046.356257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577044.995891}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577046.356257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577044.995891}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577047.116417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577045.685696}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577047.68341, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577046.356509}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577047.116417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577045.685696}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577047.68341, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577046.356509}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577048.623407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577047.11693}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577048.623407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577047.11693}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577049.147408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577047.683655}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577049.147408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577047.683655}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577050.040924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577048.623481}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577050.040924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577048.623481}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577050.536636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577049.14749}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577050.536636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577049.14749}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577051.832283, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577050.536872}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577051.832283, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577050.536872}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577053.001814, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577051.832604}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577053.001814, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577051.832604}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577053.169304, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577051.577344}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577053.169304, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577051.577344}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577054.377048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577053.169387}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577054.465912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577053.002243}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577054.377048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577053.169387}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577054.465912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577053.002243}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577055.73999, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577054.466237}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577055.883694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577054.377213}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577055.73999, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577054.466237}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577055.883694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577054.377213}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577057.109896, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577055.883849}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577057.109896, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577055.883849}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577057.199129, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577055.740227}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577057.199129, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577055.740227}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577058.451517, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577057.110056}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577058.661994, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577057.199487}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577058.451517, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577057.110056}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577058.661994, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577057.199487}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:10:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2494.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577059.895955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577058.45159}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577060.074732, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577058.662246}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:10:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2494.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577059.895955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577058.45159}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577060.074732, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577058.662246}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2500.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2492.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2500.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2492.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:11:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577062.635355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577061.212927}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577062.955313, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577061.514325}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577062.635355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577061.212927}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577062.955313, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577061.514325}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577063.964104, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577062.635627}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577063.964104, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577062.635627}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577064.557859, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577062.955849}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:04 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577064.557859, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577062.955849}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:04 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:04 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:04 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:04 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:04 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:04 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:04 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577065.408763, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577063.964337}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577066.083428, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577064.558403}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577065.408763, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577063.964337}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577066.083428, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577064.558403}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577066.72251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577065.409013}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577066.72251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577065.409013}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577067.592968, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577066.084029}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577067.592968, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577066.084029}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577068.145456, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577066.722726}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577069.064063, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577067.593044}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577068.145456, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577066.722726}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577069.064063, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577067.593044}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577069.643356, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577068.146129}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577069.643356, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577068.146129}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577070.399225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577069.064142}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577070.870121, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577069.643668}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577070.399225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577069.064142}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577070.870121, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577069.643668}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:11:11 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:11 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577071.896978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577070.399763}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:11 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:11 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577071.896978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577070.399763}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577072.176986, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577070.870401}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577072.176986, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577070.870401}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577073.268439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577071.897493}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577073.656492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577072.177204}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:13 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:13 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:13 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:13 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577073.268439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577071.897493}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577073.656492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577072.177204}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:13 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:13 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:13 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:13 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:14 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:14 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:14 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:14 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577074.620578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577073.268515}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577075.054021, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577073.669762}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:14 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:14 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:14 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:14 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577074.620578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577073.268515}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577075.054021, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577073.669762}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577076.056847, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577074.620654}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577076.056847, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577074.620654}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577076.4856, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577075.054681}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:16 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:16 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:16 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577076.4856, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577075.054681}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:16 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:16 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:16 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:17 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:17 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:17 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:17 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577077.418551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577076.056924}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577077.97038, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577076.486319}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:17 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:17 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:17 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:17 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577077.418551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577076.056924}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577077.97038, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577076.486319}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577078.846479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577077.418626}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577078.846479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577077.418626}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577079.488637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577077.970941}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:19 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:19 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:19 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:19 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577079.488637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577077.970941}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:19 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:19 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:19 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:19 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577080.407105, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577078.846556}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577080.901113, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577079.488847}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:21 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:21 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:21 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:21 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577080.407105, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577078.846556}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577080.901113, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577079.488847}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:21 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:21 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:21 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:21 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:11:22 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:22 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:22 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:22 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:22 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:22 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:22 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:22 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577083.214706, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577081.827786}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577083.57433, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577082.280162}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577083.214706, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577081.827786}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577083.57433, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577082.280162}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577084.660516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577083.215215}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577084.969924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577083.574556}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577084.660516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577083.215215}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577084.969924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577083.574556}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577086.091451, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577084.661028}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577086.091451, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577084.661028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577086.386155, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577084.970162}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577086.386155, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577084.970162}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577087.518006, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577086.091973}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577087.518006, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577086.091973}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577087.696606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577086.386381}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577087.696606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577086.386381}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577088.822849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577087.518507}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577088.822849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577087.518507}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577089.22027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577087.696918}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577089.22027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577087.696918}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577090.3875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577088.82334}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577090.841009, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577089.220786}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577090.3875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577088.82334}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577090.841009, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577089.220786}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:11:31 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:31 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577091.955551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577090.388009}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:31 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:31 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577091.955551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577090.388009}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577092.318691, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577090.841355}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577092.318691, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577090.841355}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577093.449786, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577091.956081}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577093.728836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577092.318926}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577093.449786, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577091.956081}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577093.728836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577092.318926}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577094.826781, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577093.450322}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577095.054338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577093.728921}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577094.826781, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577093.450322}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577095.054338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577093.728921}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577096.194321, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577094.826856}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577096.451419, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577095.054979}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577096.194321, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577094.826856}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577096.451419, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577095.054979}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577097.554441, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577096.194399}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577097.93944, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577096.451957}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577097.554441, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577096.194399}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577097.93944, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577096.451957}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577098.827052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577097.554517}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577098.827052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577097.554517}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577099.280655, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577097.939618}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577099.280655, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577097.939618}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577100.170708, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577098.827133}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577100.706816, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577099.281194}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577100.170708, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577098.827133}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577100.706816, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577099.281194}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:11:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577102.904933, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577101.55887}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577102.904933, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577101.55887}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577103.434178, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577102.082501}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577103.434178, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577102.082501}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577104.204072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577102.905011}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577104.783514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577103.434696}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577104.204072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577102.905011}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577104.783514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577103.434696}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577105.591435, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577104.20415}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577105.591435, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577104.20415}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577106.196975, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577104.784056}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577106.991578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577105.591513}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577106.196975, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577104.784056}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577106.991578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577105.591513}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577107.691823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577106.197485}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:47 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:47 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:47 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:47 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577107.691823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577106.197485}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577108.434885, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577106.991653}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577108.434885, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577106.991653}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577109.290365, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577107.692309}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577109.290365, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577107.692309}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577110.056024, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577108.43541}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577110.056024, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577108.43541}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577110.707153, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577109.290638}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577110.707153, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577109.290638}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577112.18557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577110.707337}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577113.041809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577111.555222}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577112.18557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577110.707337}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577113.041809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577111.555222}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577113.50171, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577112.186186}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577113.50171, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577112.186186}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577114.492703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577113.041888}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577114.869864, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577113.502362}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577114.492703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577113.041888}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577114.869864, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577113.502362}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577115.85955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577114.492778}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577115.85955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577114.492778}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577116.138758, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577114.870163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2497.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577116.138758, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577114.870163}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2497.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577117.228475, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577115.860056}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577117.550575, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577116.138958}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577117.228475, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577115.860056}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577117.550575, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577116.138958}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:58 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:58 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:58 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:58 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577118.739133, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577117.22895}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577119.059671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577117.55079}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:58 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:58 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:58 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:58 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577118.739133, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577117.22895}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577119.059671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577117.55079}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:11:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577120.064819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577118.739628}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:11:59 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577120.064819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577118.739628}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577120.418432, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577119.059874}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577120.418432, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577119.059874}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:00 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:12:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577122.853232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577121.52882}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:02 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:02 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:02 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:02 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577122.853232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577121.52882}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577123.165257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577121.641559}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577123.165257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577121.641559}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:03 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577124.213918, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577122.853309}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577124.447408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577123.165536}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577124.213918, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577122.853309}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577124.447408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577123.165536}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:04 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:04 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:04 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:04 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:04 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:04 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:04 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:04 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:05 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:05 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:05 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:05 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577125.704199, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577124.214425}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577125.739872, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577124.447495}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577125.704199, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577124.214425}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577125.739872, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577124.447495}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577126.900563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577125.740155}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:06 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577126.900563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577125.740155}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577127.218037, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577125.704702}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577127.218037, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577125.704702}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:07 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577128.227124, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577126.900639}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577128.744367, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577127.218572}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577128.227124, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577126.900639}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577128.744367, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577127.218572}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:08 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:08 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:08 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:08 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577129.539711, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577128.227399}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:09 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:09 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:09 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:09 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577129.539711, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577128.227399}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577130.206043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577128.74485}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577130.206043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577128.74485}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577131.069658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577129.53994}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:10 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577131.069658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577129.53994}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:12:11 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:11 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577132.37932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577131.070293}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577132.98413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577131.597612}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577132.37932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577131.070293}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577132.98413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577131.597612}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:12 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:13 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:13 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:13 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:13 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:13 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:13 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577133.837107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577132.37998}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:13 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:13 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577133.837107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577132.37998}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:14 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:14 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:14 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:14 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577134.446518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577132.984224}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:14 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:14 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:14 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:14 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577134.446518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577132.984224}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577135.146563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577133.837717}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577135.749834, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577134.446597}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577135.146563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577133.837717}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577135.749834, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577134.446597}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:15 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:16 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:16 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:16 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577136.529889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577135.147151}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:16 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:16 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:16 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:16 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577136.529889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577135.147151}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577137.110998, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577135.749914}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577137.110998, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577135.749914}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:17 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:17 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:17 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:17 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577137.977686, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577136.530517}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:17 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:17 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:17 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:17 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577137.977686, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577136.530517}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577138.870001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577137.111079}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:18 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577138.870001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577137.111079}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:19 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:19 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:19 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:19 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577139.589384, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577137.97789}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:19 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:19 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:19 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:19 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577139.589384, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577137.97789}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577140.148615, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577138.870084}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577140.953208, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577139.589462}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577140.148615, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577138.870084}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:20 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577140.953208, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577139.589462}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577142.970263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577141.617963}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577142.970263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577141.617963}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577143.862804, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577142.471879}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:23 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577143.862804, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577142.471879}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577144.354977, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577142.970341}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577144.354977, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577142.970341}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:24 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:24 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:24 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:24 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577145.145544, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577143.863586}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577145.90754, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577144.355066}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577145.145544, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577143.863586}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:25 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577145.90754, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577144.355066}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577146.457504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577145.145625}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577146.457504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577145.145625}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:26 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:26 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:26 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:26 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577147.311723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577145.908027}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577147.79613, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577146.457584}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577147.311723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577145.908027}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577147.79613, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577146.457584}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:27 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577148.749392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577147.312204}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:28 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:28 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:28 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:28 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577148.749392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577147.312204}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577149.30238, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577147.796213}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2496.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577149.30238, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577147.796213}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2496.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:29 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577150.105934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577148.749467}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577150.105934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577148.749467}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577150.638663, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577149.30286}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577150.638663, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577149.30286}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:30 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:30 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:30 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:30 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577152.148832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577150.63883}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577153.053737, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577151.550271}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577152.148832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577150.63883}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:32 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577153.053737, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577151.550271}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577153.466136, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577152.149611}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577153.466136, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577152.149611}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:33 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:33 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:33 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:33 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:34 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:34 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:34 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:34 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577154.38118, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577153.053813}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577154.882915, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577153.466643}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577154.38118, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577153.053813}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577154.882915, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577153.466643}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577155.739017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577154.381257}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:35 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577155.739017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577154.381257}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577156.270647, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577154.883768}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577157.028382, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577155.739135}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577156.270647, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577154.883768}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:36 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577157.028382, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577155.739135}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:37 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577157.612921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577156.271292}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:37 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:37 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:37 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577157.612921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577156.271292}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577158.290182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577157.028457}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577158.290182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577157.028457}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:38 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577158.924572, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577157.613746}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577158.924572, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577157.613746}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577159.627742, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577158.290259}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:39 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:39 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:39 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:39 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577159.627742, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577158.290259}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577160.286516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577158.925416}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577160.874974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577159.627817}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577160.286516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577158.925416}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577160.874974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577159.627817}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:40 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:12:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577162.2894, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577160.875049}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577162.980942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577161.673329}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:42 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577162.2894, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577160.875049}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577162.980942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577161.673329}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577163.719135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577162.289475}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:43 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577163.719135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577162.289475}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577164.347529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577162.981665}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577165.062398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577163.719214}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577164.347529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577162.981665}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:44 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577165.062398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577163.719214}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577165.661484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577164.348272}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:45 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:45 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:45 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:45 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577165.661484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577164.348272}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577166.338455, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577165.062475}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577166.338455, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577165.062475}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:46 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577167.200085, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577165.661875}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577167.728601, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577166.338941}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577167.200085, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577165.661875}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577167.728601, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577166.338941}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577168.801637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577167.200412}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577169.051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577167.728685}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:48 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577168.801637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577167.200412}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577169.051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577167.728685}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577170.101383, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577168.802377}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:49 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577170.101383, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577168.802377}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577170.301346, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577169.051081}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577170.301346, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577169.051081}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:50 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:12:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577172.676946, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577171.392673}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:52 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577172.676946, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577171.392673}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577172.981565, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577171.642827}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577172.981565, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577171.642827}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577174.006854, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577172.67768}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:53 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577174.006854, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577172.67768}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577174.330056, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577172.982211}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577174.330056, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577172.982211}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:54 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:54 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:54 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:54 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577175.348642, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577174.007318}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577175.787676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577174.330138}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577175.348642, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577174.007318}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577175.787676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577174.330138}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:55 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577176.67138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577175.349054}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577177.062068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577175.787757}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:12:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:56 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:56 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:56 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:56 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577176.67138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577175.349054}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577177.062068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577175.787757}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:57 WARNING 140368757495616] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:57 INFO 140368757495616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:57 INFO 140368757495616] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:12:57 INFO 140368757495616] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577177.547524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577176.67175}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577177.547524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577176.67175}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1.57 s, sys: 87.6 ms, total: 1.66 s\n",
      "Wall time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "pca_transformer.transform(np_azdias_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/azdias.csv.out to ./azdias.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/azdias.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 384.06 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_sub_pca = pd.DataFrame()\n",
    "\n",
    "azdias_sub_pca = csvToDataFrame('azdias.csv.out')\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 134)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_sub_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data visualization azdias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.4 Apply same transformations done on azdias to customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.dropna(thresh=290, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceForNan(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = to_category(customers_df, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 93.49 Mb\n"
     ]
    }
   ],
   "source": [
    "customers_df = to_category(customers_df, categorical_columns2)\n",
    "\n",
    "print('Memory used:', memory_usage(customers_df), 'Mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "0           0    9626        2        1.0     10.0                 1.0   \n",
       "2           2  143872        2        1.0      6.0                 1.0   \n",
       "3           3  143873        1        1.0      8.0                 0.0   \n",
       "4           4  143874        2        1.0     20.0                 7.0   \n",
       "5           5  143888        1        1.0     11.0                 1.0   \n",
       "\n",
       "   ANZ_HH_TITEL ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ...  \\\n",
       "0           0.0        0.0          2.0                        1.0  ...   \n",
       "2           0.0        0.0          1.0                        1.0  ...   \n",
       "3           NaN        0.0          0.0                        1.0  ...   \n",
       "4           0.0        0.0          4.0                        7.0  ...   \n",
       "5           0.0        0.0          2.0                        1.0  ...   \n",
       "\n",
       "   VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0      2.0            6.0            9.0      7.0        3  COSMETIC_AND_FOOD   \n",
       "2     11.0            6.0            9.0      2.0        3  COSMETIC_AND_FOOD   \n",
       "3      2.0            6.0            9.0      7.0        1           COSMETIC   \n",
       "4      4.0            2.0            9.0      3.0        1               FOOD   \n",
       "5      1.0            6.0            9.0      1.0        2  COSMETIC_AND_FOOD   \n",
       "\n",
       "  CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0    MULTI_BUYER               0         1                    4  \n",
       "2    MULTI_BUYER               0         2                    4  \n",
       "3    MULTI_BUYER               0         1                    4  \n",
       "4    MULTI_BUYER               0         1                    3  \n",
       "5    MULTI_BUYER               0         1                    3  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(customers_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "0           0    9626        2        1.0     10.0                 1.0   \n",
       "2           2  143872        2        1.0      6.0                 1.0   \n",
       "3           3  143873        1        1.0      8.0                 0.0   \n",
       "4           4  143874        2        1.0     20.0                 7.0   \n",
       "5           5  143888        1        1.0     11.0                 1.0   \n",
       "\n",
       "   ANZ_HH_TITEL ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ...  \\\n",
       "0           0.0        0.0          2.0                        1.0  ...   \n",
       "2           0.0        0.0          1.0                        1.0  ...   \n",
       "3           0.0        0.0          0.0                        1.0  ...   \n",
       "4           0.0        0.0          4.0                        7.0  ...   \n",
       "5           0.0        0.0          2.0                        1.0  ...   \n",
       "\n",
       "   VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0      2.0            6.0            9.0      7.0        3  COSMETIC_AND_FOOD   \n",
       "2     11.0            6.0            9.0      2.0        3  COSMETIC_AND_FOOD   \n",
       "3      2.0            6.0            9.0      7.0        1           COSMETIC   \n",
       "4      4.0            2.0            9.0      3.0        1               FOOD   \n",
       "5      1.0            6.0            9.0      1.0        2  COSMETIC_AND_FOOD   \n",
       "\n",
       "  CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0    MULTI_BUYER               0         1                    4  \n",
       "2    MULTI_BUYER               0         2                    4  \n",
       "3    MULTI_BUYER               0         1                    4  \n",
       "4    MULTI_BUYER               0         1                    3  \n",
       "5    MULTI_BUYER               0         1                    3  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(customers_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = pd.get_dummies(customers_df, columns =one_hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>CAMEO_DEU_2015_9B</th>\n",
       "      <th>CAMEO_DEU_2015_9C</th>\n",
       "      <th>CAMEO_DEU_2015_9D</th>\n",
       "      <th>CAMEO_DEU_2015_9E</th>\n",
       "      <th>CAMEO_DEU_2015_XX</th>\n",
       "      <th>AGER_TYP_-1</th>\n",
       "      <th>AGER_TYP_0</th>\n",
       "      <th>AGER_TYP_1</th>\n",
       "      <th>AGER_TYP_2</th>\n",
       "      <th>AGER_TYP_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\n",
       "0           0    9626        1.0     10.0                 1.0           0.0   \n",
       "2           2  143872        1.0      6.0                 1.0           0.0   \n",
       "3           3  143873        1.0      8.0                 0.0           0.0   \n",
       "4           4  143874        1.0     20.0                 7.0           0.0   \n",
       "5           5  143888        1.0     11.0                 1.0           0.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ...  \\\n",
       "0        0.0          2.0                        1.0        0.0  ...   \n",
       "2        0.0          1.0                        1.0        0.0  ...   \n",
       "3        0.0          0.0                        1.0        0.0  ...   \n",
       "4        0.0          4.0                        7.0        0.0  ...   \n",
       "5        0.0          2.0                        1.0        0.0  ...   \n",
       "\n",
       "  CAMEO_DEU_2015_9B CAMEO_DEU_2015_9C CAMEO_DEU_2015_9D CAMEO_DEU_2015_9E  \\\n",
       "0                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "5                 0                 0                 0                 0   \n",
       "\n",
       "  CAMEO_DEU_2015_XX AGER_TYP_-1 AGER_TYP_0 AGER_TYP_1 AGER_TYP_2 AGER_TYP_3  \n",
       "0                 0           0          0          0          1          0  \n",
       "2                 0           0          0          0          1          0  \n",
       "3                 0           0          0          1          0          0  \n",
       "4                 0           0          0          0          1          0  \n",
       "5                 0           0          0          1          0          0  \n",
       "\n",
       "[5 rows x 520 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_median_numerical(customers_df).head()\n",
    "impute_mode_categorical(customers_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df['OST_WEST_KZ'] = encodeColumnByLabel(customers_df, 'OST_WEST_KZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df['EINGEFUEGT_AM'] = timestampToInt(customers_df, 'EINGEFUEGT_AM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137087, 520)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that come from one hot encoding that do not exist in azdias and add with zeros the ones that exists in azdias but not in customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to add []\n",
      "Columns to drop ['AGER_TYP_-1' 'AGER_TYP_0' 'AGER_TYP_1' 'AGER_TYP_2' 'AGER_TYP_3'\n",
      " 'ANREDE_KZ' 'ANZ_HH_TITEL' 'ANZ_TITEL' 'CAMEO_DEU_2015_1A'\n",
      " 'CAMEO_DEU_2015_1B' 'CAMEO_DEU_2015_1C' 'CAMEO_DEU_2015_1D'\n",
      " 'CAMEO_DEU_2015_1E' 'CAMEO_DEU_2015_2A' 'CAMEO_DEU_2015_2B'\n",
      " 'CAMEO_DEU_2015_2C' 'CAMEO_DEU_2015_2D' 'CAMEO_DEU_2015_3A'\n",
      " 'CAMEO_DEU_2015_3B' 'CAMEO_DEU_2015_3C' 'CAMEO_DEU_2015_3D'\n",
      " 'CAMEO_DEU_2015_4A' 'CAMEO_DEU_2015_4B' 'CAMEO_DEU_2015_4C'\n",
      " 'CAMEO_DEU_2015_4D' 'CAMEO_DEU_2015_4E' 'CAMEO_DEU_2015_5A'\n",
      " 'CAMEO_DEU_2015_5B' 'CAMEO_DEU_2015_5C' 'CAMEO_DEU_2015_5D'\n",
      " 'CAMEO_DEU_2015_5E' 'CAMEO_DEU_2015_5F' 'CAMEO_DEU_2015_6A'\n",
      " 'CAMEO_DEU_2015_6B' 'CAMEO_DEU_2015_6C' 'CAMEO_DEU_2015_6D'\n",
      " 'CAMEO_DEU_2015_6E' 'CAMEO_DEU_2015_6F' 'CAMEO_DEU_2015_7A'\n",
      " 'CAMEO_DEU_2015_7B' 'CAMEO_DEU_2015_7C' 'CAMEO_DEU_2015_7D'\n",
      " 'CAMEO_DEU_2015_7E' 'CAMEO_DEU_2015_8A' 'CAMEO_DEU_2015_8B'\n",
      " 'CAMEO_DEU_2015_8C' 'CAMEO_DEU_2015_8D' 'CAMEO_DEU_2015_9A'\n",
      " 'CAMEO_DEU_2015_9B' 'CAMEO_DEU_2015_9C' 'CAMEO_DEU_2015_9D'\n",
      " 'CAMEO_DEU_2015_9E' 'CAMEO_DEU_2015_XX' 'CJT_GESAMTTYP_1.0'\n",
      " 'CJT_GESAMTTYP_2.0' 'CJT_GESAMTTYP_3.0' 'CJT_GESAMTTYP_4.0'\n",
      " 'CJT_GESAMTTYP_5.0' 'CJT_GESAMTTYP_6.0' 'CUSTOMER_GROUP'\n",
      " 'D19_KONSUMTYP_MAX_1' 'D19_KONSUMTYP_MAX_2' 'D19_KONSUMTYP_MAX_3'\n",
      " 'D19_KONSUMTYP_MAX_4' 'D19_KONSUMTYP_MAX_8' 'D19_KONSUMTYP_MAX_9'\n",
      " 'D19_TELKO_ANZ_12' 'D19_TELKO_ANZ_24' 'D19_TELKO_ONLINE_DATUM'\n",
      " 'D19_VERSI_ANZ_12' 'D19_VERSI_ONLINE_DATUM' 'DSL_FLAG' 'FINANZTYP_1'\n",
      " 'FINANZTYP_2' 'FINANZTYP_3' 'FINANZTYP_4' 'FINANZTYP_5' 'FINANZTYP_6'\n",
      " 'GEBAEUDETYP_1.0' 'GEBAEUDETYP_2.0' 'GEBAEUDETYP_3.0' 'GEBAEUDETYP_4.0'\n",
      " 'GEBAEUDETYP_6.0' 'GEBAEUDETYP_8.0' 'GFK_URLAUBERTYP_1.0'\n",
      " 'GFK_URLAUBERTYP_10.0' 'GFK_URLAUBERTYP_11.0' 'GFK_URLAUBERTYP_12.0'\n",
      " 'GFK_URLAUBERTYP_2.0' 'GFK_URLAUBERTYP_3.0' 'GFK_URLAUBERTYP_4.0'\n",
      " 'GFK_URLAUBERTYP_5.0' 'GFK_URLAUBERTYP_6.0' 'GFK_URLAUBERTYP_7.0'\n",
      " 'GFK_URLAUBERTYP_8.0' 'GFK_URLAUBERTYP_9.0' 'GREEN_AVANTGARDE'\n",
      " 'HEALTH_TYP_-1' 'HEALTH_TYP_1' 'HEALTH_TYP_2' 'HEALTH_TYP_3'\n",
      " 'HH_DELTA_FLAG' 'KBA05_HERSTTEMP_1.0' 'KBA05_HERSTTEMP_2.0'\n",
      " 'KBA05_HERSTTEMP_3.0' 'KBA05_HERSTTEMP_4.0' 'KBA05_HERSTTEMP_5.0'\n",
      " 'KBA05_HERSTTEMP_9.0' 'KBA05_MAXHERST_1.0' 'KBA05_MAXHERST_2.0'\n",
      " 'KBA05_MAXHERST_3.0' 'KBA05_MAXHERST_4.0' 'KBA05_MAXHERST_5.0'\n",
      " 'KBA05_MAXHERST_9.0' 'KBA05_MODTEMP_1.0' 'KBA05_MODTEMP_2.0'\n",
      " 'KBA05_MODTEMP_3.0' 'KBA05_MODTEMP_4.0' 'KBA05_MODTEMP_5.0'\n",
      " 'KBA05_MODTEMP_6.0' 'KBA13_KRSSEG_KLEIN' 'KONSUMZELLE'\n",
      " 'LP_FAMILIE_GROB_0.0' 'LP_FAMILIE_GROB_1.0' 'LP_FAMILIE_GROB_2.0'\n",
      " 'LP_FAMILIE_GROB_3.0' 'LP_FAMILIE_GROB_4.0' 'LP_FAMILIE_GROB_5.0'\n",
      " 'LP_LEBENSPHASE_FEIN_0.0' 'LP_LEBENSPHASE_FEIN_1.0'\n",
      " 'LP_LEBENSPHASE_FEIN_10.0' 'LP_LEBENSPHASE_FEIN_11.0'\n",
      " 'LP_LEBENSPHASE_FEIN_12.0' 'LP_LEBENSPHASE_FEIN_13.0'\n",
      " 'LP_LEBENSPHASE_FEIN_14.0' 'LP_LEBENSPHASE_FEIN_15.0'\n",
      " 'LP_LEBENSPHASE_FEIN_16.0' 'LP_LEBENSPHASE_FEIN_17.0'\n",
      " 'LP_LEBENSPHASE_FEIN_18.0' 'LP_LEBENSPHASE_FEIN_19.0'\n",
      " 'LP_LEBENSPHASE_FEIN_2.0' 'LP_LEBENSPHASE_FEIN_20.0'\n",
      " 'LP_LEBENSPHASE_FEIN_21.0' 'LP_LEBENSPHASE_FEIN_22.0'\n",
      " 'LP_LEBENSPHASE_FEIN_23.0' 'LP_LEBENSPHASE_FEIN_24.0'\n",
      " 'LP_LEBENSPHASE_FEIN_25.0' 'LP_LEBENSPHASE_FEIN_26.0'\n",
      " 'LP_LEBENSPHASE_FEIN_27.0' 'LP_LEBENSPHASE_FEIN_28.0'\n",
      " 'LP_LEBENSPHASE_FEIN_29.0' 'LP_LEBENSPHASE_FEIN_3.0'\n",
      " 'LP_LEBENSPHASE_FEIN_30.0' 'LP_LEBENSPHASE_FEIN_31.0'\n",
      " 'LP_LEBENSPHASE_FEIN_32.0' 'LP_LEBENSPHASE_FEIN_33.0'\n",
      " 'LP_LEBENSPHASE_FEIN_34.0' 'LP_LEBENSPHASE_FEIN_35.0'\n",
      " 'LP_LEBENSPHASE_FEIN_36.0' 'LP_LEBENSPHASE_FEIN_37.0'\n",
      " 'LP_LEBENSPHASE_FEIN_38.0' 'LP_LEBENSPHASE_FEIN_39.0'\n",
      " 'LP_LEBENSPHASE_FEIN_4.0' 'LP_LEBENSPHASE_FEIN_40.0'\n",
      " 'LP_LEBENSPHASE_FEIN_5.0' 'LP_LEBENSPHASE_FEIN_6.0'\n",
      " 'LP_LEBENSPHASE_FEIN_7.0' 'LP_LEBENSPHASE_FEIN_8.0'\n",
      " 'LP_LEBENSPHASE_FEIN_9.0' 'NATIONALITAET_KZ_0' 'NATIONALITAET_KZ_1'\n",
      " 'NATIONALITAET_KZ_2' 'NATIONALITAET_KZ_3' 'ONLINE_PURCHASE'\n",
      " 'PLZ8_BAUMAX_1.0' 'PLZ8_BAUMAX_2.0' 'PLZ8_BAUMAX_3.0' 'PLZ8_BAUMAX_4.0'\n",
      " 'PLZ8_BAUMAX_5.0' 'PRODUCT_GROUP' 'RETOURTYP_BK_S_1.0'\n",
      " 'RETOURTYP_BK_S_2.0' 'RETOURTYP_BK_S_3.0' 'RETOURTYP_BK_S_4.0'\n",
      " 'RETOURTYP_BK_S_5.0' 'SHOPPER_TYP_-1' 'SHOPPER_TYP_0' 'SHOPPER_TYP_1'\n",
      " 'SHOPPER_TYP_2' 'SHOPPER_TYP_3' 'SOHO_KZ' 'TITEL_KZ' 'UNGLEICHENN_FLAG'\n",
      " 'VERS_TYP_-1' 'VERS_TYP_1' 'VERS_TYP_2' 'WOHNLAGE_0.0' 'WOHNLAGE_1.0'\n",
      " 'WOHNLAGE_2.0' 'WOHNLAGE_3.0' 'WOHNLAGE_4.0' 'WOHNLAGE_5.0'\n",
      " 'WOHNLAGE_7.0' 'WOHNLAGE_8.0']\n"
     ]
    }
   ],
   "source": [
    "#Drop and add columns\n",
    "\n",
    "addColumnList = np.setdiff1d(azdias_df.columns,customers_df.columns)\n",
    "print(\"Columns to add\", addColumnList)\n",
    "\n",
    "dropColumnList = np.setdiff1d(customers_df.columns, azdias_df.columns)\n",
    "print(\"Columns to drop\", dropColumnList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.drop(list(dropColumnList), axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_customers = customers_df.values\n",
    "np_customers = scaler.transform(np_customers)\n",
    "\n",
    "customers_df = pd.DataFrame(data=np_customers,\n",
    "          index=customers_df.index,\n",
    "          columns=customers_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA transformation on customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_file = 'customers.csv'\n",
    "\n",
    "customers_dtypes = customers_df.select_dtypes(object)\n",
    "customers_df[u.columns] = customers_dtypes.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n",
    "customers_df.to_csv(customers_file,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "customers_location = session.upload_data(os.path.join(customers_file), key_prefix=prefix)\n",
    "\n",
    "os.remove(customers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] nvidia-smi took: 0.0251400470734 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loading entry points\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:18:28 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:18:28 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:18:28 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:18:28 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loading model...\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] ...model loaded.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] loading model...\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:18:28 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:28 INFO 140046617249600] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577523.35503, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577508.924575}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577523.35503, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577508.924575}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-05-15T21:18:43.366:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:48 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:48 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577528.932082, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577508.96248}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577529.136123, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577523.355152}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577528.932082, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577508.96248}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577529.136123, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577523.355152}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:49 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2390.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577530.431681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577528.932178}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:49 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2390.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577530.431681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577528.932178}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577530.538763, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577529.136484}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2387.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:51 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577530.538763, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577529.136484}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2387.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:51 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577531.779316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577530.53936}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577531.865424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577530.43176}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:52 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:52 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:52 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:52 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577531.779316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577530.53936}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577531.865424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577530.43176}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:52 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:52 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:52 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:52 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:18:53 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:53 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:53 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:53 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:54 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:54 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:54 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:54 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577534.477597, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577533.095488}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:53 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:53 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:53 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:53 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:54 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:54 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:54 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:54 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577534.477597, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577533.095488}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577534.886584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577533.347644}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577534.886584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577533.347644}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:55 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:55 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577535.742115, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577534.478299}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577536.143572, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577534.886666}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577535.742115, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577534.478299}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577536.143572, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577534.886666}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:56 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577537.048221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577535.742781}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577537.439041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577536.14365}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:56 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577537.048221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577535.742781}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577537.439041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577536.14365}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:57 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:57 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:57 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:57 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2388.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577538.337324, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577537.04894}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:57 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:57 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:57 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:57 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2388.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577538.337324, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577537.04894}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577538.784335, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577537.43922}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:58 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2391.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:59 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:59 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:59 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:18:59 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577538.784335, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577537.43922}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:58 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2391.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:59 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:59 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:59 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:18:59 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577539.557699, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577538.337919}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577539.557699, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577538.337919}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577540.021496, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577538.784415}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577540.021496, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577538.784415}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:00 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577540.758692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577539.558368}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577541.2391, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577540.02158}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2391.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:00 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577540.758692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577539.558368}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577541.2391, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577540.02158}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2391.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:01 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2400.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577542.100239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577540.759391}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577542.450504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577541.23918}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:01 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2400.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577542.100239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577540.759391}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577542.450504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577541.23918}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:19:02 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:02 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577543.296743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577542.101036}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:02 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:02 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577543.296743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577542.101036}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577543.618598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577542.450583}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:04 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577543.618598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577542.450583}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:04 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577544.889294, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577543.297396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577544.931085, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577543.619122}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577544.889294, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577543.297396}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577544.931085, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577543.619122}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:05 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577546.185673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577544.890017}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577546.350131, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577544.93117}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:05 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577546.185673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577544.890017}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577546.350131, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577544.93117}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:06 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577547.406174, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577546.186331}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:06 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577547.406174, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577546.186331}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577547.692894, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577546.350206}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:08 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577547.692894, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577546.350206}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:08 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577548.807119, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577547.40683}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577549.105997, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577547.692973}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577548.807119, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577547.40683}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577549.105997, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577547.692973}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:09 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577550.095841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577548.807845}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:09 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577550.095841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577548.807845}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577550.590039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577549.106074}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:10 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:10 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577550.590039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577549.106074}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:10 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:10 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:10 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:10 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2400.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577551.332947, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577550.096572}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:10 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:10 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2400.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577551.332947, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577550.096572}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:11 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577551.97034, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577550.590118}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:11 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577551.97034, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577550.590118}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:19:13 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:13 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:13 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:13 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577553.482939, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577551.970419}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:13 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:13 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:13 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:13 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577553.482939, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577551.970419}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577553.888376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577552.634036}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577553.888376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577552.634036}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2389.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:14 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2389.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:14 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2393.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577554.87051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577553.483012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577555.165416, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577553.88911}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577554.87051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577553.483012}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577555.165416, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577553.88911}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2397.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:15 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577556.141809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577554.870586}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577556.431502, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577555.16627}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:15 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577556.141809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577554.870586}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577556.431502, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577555.16627}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:16 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:16 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:16 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:16 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2390.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:17 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:17 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:17 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:17 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577557.537392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577556.141886}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:16 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:16 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:16 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:16 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2390.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:17 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:17 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:17 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:17 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577557.537392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577556.141886}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577557.757901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577556.432214}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577557.757901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577556.432214}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:18 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2398.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:18 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577558.884836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577557.537471}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577558.993221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577557.758625}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2391.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:19 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577558.884836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577557.537471}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577558.993221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577557.758625}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2391.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:19 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577560.148924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577558.884916}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577560.214187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577558.993952}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577560.148924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577558.884916}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577560.214187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577558.993952}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:20 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2399.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:20 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577561.430831, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577560.214873}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577561.545933, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577560.149005}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577561.430831, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577560.214873}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577561.545933, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577560.149005}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:22 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:22 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/15/2020 21:19:23 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:23 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:23 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:23 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2395.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577564.082742, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577562.723223}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577564.250547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577562.878408}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577564.082742, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577562.723223}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577564.250547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577562.878408}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:24 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577565.421135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577564.083658}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577565.512765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577564.250626}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2396.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:24 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2392.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577565.421135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577564.083658}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577565.512765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577564.250626}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:25 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:25 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:25 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:19:25 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 528.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577565.867046, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577565.421465}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:25 WARNING 140046617249600] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:25 INFO 140046617249600] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:25 INFO 140046617249600] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/15/2020 21:19:25 INFO 140046617249600] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 528.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577565.867046, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1589577565.421465}\n",
      "\u001b[0m\n",
      "\n",
      "CPU times: user 628 ms, sys: 39.9 ms, total: 668 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "pca_transformer.transform(customers_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the transformed data to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/customers.csv.out to ./customers.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/customers.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 70.07 Mb\n"
     ]
    }
   ],
   "source": [
    "customers_sub_pca = csvToDataFrame('customers.csv.out')\n",
    "\n",
    "print('Memory used:', memory_usage(customers_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137087, 134)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_sub_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data visualization PCA Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_formatted_azdias_data = pca.record_set(azdias_sub_pca.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch jobs from 2 to 12 groups to determine how many groups form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 21:20:54 Starting - Starting the training job......\n",
      "2020-05-15 21:21:25 Starting - Launching requested ML instances...\n",
      "2020-05-15 21:22:23 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:23:11 Downloading - Downloading input data...\n",
      "2020-05-15 21:23:50 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'2', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'2', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 WARNING 140522877904704] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] nvidia-smi took: 0.0251560211182 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'2', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:09 INFO 140522877904704] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589577849.721492, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589577849.721442}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:24:09.725] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 47, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:10 INFO 140522877904704] Iter 10: Short term msd 15.276083. Long term msd 16.062163\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:10 INFO 140522877904704] Iter 20: Short term msd 14.610439. Long term msd 14.936972\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:10 INFO 140522877904704] Iter 30: Short term msd 14.472712. Long term msd 14.625623\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:10 INFO 140522877904704] Iter 40: Short term msd 14.462789. Long term msd 14.512720\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:11 INFO 140522877904704] Iter 50: Short term msd 14.288671. Long term msd 14.361561\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:11 INFO 140522877904704] Iter 60: Short term msd 14.351392. Long term msd 14.362653\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:11 INFO 140522877904704] Iter 70: Short term msd 14.376098. Long term msd 14.372071\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:11 INFO 140522877904704] Iter 80: Short term msd 14.318702. Long term msd 14.345262\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:11 INFO 140522877904704] Iter 90: Short term msd 14.295315. Long term msd 14.304252\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:11 INFO 140522877904704] Iter 100: Short term msd 14.282901. Long term msd 14.287425\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] Iter 110: Short term msd 14.227086. Long term msd 14.258188\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] Iter 120: Short term msd 14.287544. Long term msd 14.279524\u001b[0m\n",
      "\n",
      "2020-05-15 21:24:24 Uploading - Uploading generated training model\n",
      "2020-05-15 21:24:24 Completed - Training job completed\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] Iter 130: Short term msd 14.362521. Long term msd 14.337475\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] Iter 140: Short term msd 14.342387. Long term msd 14.345019\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] Iter 150: Short term msd 14.331437. Long term msd 14.332839\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:24:12.659] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 2933, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589577852.660348, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589577849.726124}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] #throughput_metric: host=algo-1, train throughput=256045.075955 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 WARNING 140522877904704] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] shrinking 20 centers into 2\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #0. Current mean square distance 3.651826\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #1. Current mean square distance 3.890799\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #2. Current mean square distance 3.651826\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #3. Current mean square distance 3.890799\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #4. Current mean square distance 3.651826\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #5. Current mean square distance 3.866159\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #6. Current mean square distance 3.789321\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #7. Current mean square distance 3.789321\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #8. Current mean square distance 3.651826\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] local kmeans attempt #9. Current mean square distance 3.890799\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] finished shrinking process. Mean Square Distance = 4\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] #quality_metric: host=algo-1, train msd <loss>=3.65182614326\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] compute all data-center distances: point norm took: 46.2183%, (1.350662 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] predict compute msd took: 14.6275%, (0.427468 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] compute all data-center distances: inner product took: 12.0498%, (0.352138 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] gradient: cluster size  took: 7.0372%, (0.205651 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] gradient: cluster center took: 6.3726%, (0.186230 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] batch data loading with context took: 5.7883%, (0.169155 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] update state and report convergance took: 2.6460%, (0.077326 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] collect from kv store took: 1.9341%, (0.056520 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] compute all data-center distances: center norm took: 1.3531%, (0.039542 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] splitting centers key-value pair took: 1.1056%, (0.032310 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] gradient: one_hot took: 0.7522%, (0.021981 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] predict minus dist took: 0.1080%, (0.003155 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] update set-up time took: 0.0073%, (0.000213 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] TOTAL took: 2.922352314\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 137.47692108154297, \"sum\": 137.47692108154297, \"min\": 137.47692108154297}, \"initialize.time\": {\"count\": 1, \"max\": 25.70199966430664, \"sum\": 25.70199966430664, \"min\": 25.70199966430664}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.15211105346679688, \"sum\": 0.15211105346679688, \"min\": 0.15211105346679688}, \"update.time\": {\"count\": 1, \"max\": 2934.033155441284, \"sum\": 2934.033155441284, \"min\": 2934.033155441284}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.6809234619140625, \"sum\": 0.6809234619140625, \"min\": 0.6809234619140625}, \"_shrink.time\": {\"count\": 1, \"max\": 134.0048313140869, \"sum\": 134.0048313140869, \"min\": 134.0048313140869}}, \"EndTime\": 1589577852.799223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589577849.677123}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:24:12 INFO 140522877904704] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 3209.582805633545, \"sum\": 3209.582805633545, \"min\": 3209.582805633545}, \"setuptime\": {\"count\": 1, \"max\": 12.122869491577148, \"sum\": 12.122869491577148, \"min\": 12.122869491577148}}, \"EndTime\": 1589577852.822977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589577852.799378}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 73\n",
      "Billable seconds: 73\n",
      "2020-05-15 21:24:36 Starting - Starting the training job...\n",
      "2020-05-15 21:24:38 Starting - Launching requested ML instances......\n",
      "2020-05-15 21:25:38 Starting - Preparing the instances for training...\n",
      "2020-05-15 21:26:17 Downloading - Downloading input data...\n",
      "2020-05-15 21:26:55 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'3', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'3', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 WARNING 140668135569216] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] nvidia-smi took: 0.0251269340515 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'3', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:10 INFO 140668135569216] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589578030.601166, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578030.601115}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:27:10.617] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 57, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:11 INFO 140668135569216] Iter 10: Short term msd 14.402571. Long term msd 15.148621\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:11 INFO 140668135569216] Iter 20: Short term msd 13.767793. Long term msd 14.077388\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:11 INFO 140668135569216] Iter 30: Short term msd 13.626822. Long term msd 13.765345\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:11 INFO 140668135569216] Iter 40: Short term msd 13.635061. Long term msd 13.676580\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:11 INFO 140668135569216] Iter 50: Short term msd 13.588028. Long term msd 13.620050\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:12 INFO 140668135569216] Iter 60: Short term msd 13.652259. Long term msd 13.646841\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:12 INFO 140668135569216] Iter 70: Short term msd 13.712165. Long term msd 13.691969\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:12 INFO 140668135569216] Iter 80: Short term msd 13.687088. Long term msd 13.693889\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:12 INFO 140668135569216] Iter 90: Short term msd 13.679909. Long term msd 13.679264\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:12 INFO 140668135569216] Iter 100: Short term msd 13.705536. Long term msd 13.698060\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:12 INFO 140668135569216] Iter 110: Short term msd 13.682110. Long term msd 13.694382\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] Iter 120: Short term msd 13.741096. Long term msd 13.727567\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] Iter 130: Short term msd 13.829207. Long term msd 13.796307\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] Iter 140: Short term msd 13.828261. Long term msd 13.820557\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] Iter 150: Short term msd 13.819851. Long term msd 13.817752\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:27:13.646] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3028, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589578033.646787, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589578030.617446}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] #throughput_metric: host=algo-1, train throughput=248005.516703 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 WARNING 140668135569216] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] shrinking 30 centers into 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #0. Current mean square distance 3.965041\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #1. Current mean square distance 3.867440\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #2. Current mean square distance 4.004922\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #3. Current mean square distance 3.856014\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #4. Current mean square distance 3.949392\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #5. Current mean square distance 3.861562\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #6. Current mean square distance 3.811244\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #7. Current mean square distance 3.779712\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #8. Current mean square distance 4.041368\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] local kmeans attempt #9. Current mean square distance 3.853357\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] finished shrinking process. Mean Square Distance = 4\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] #quality_metric: host=algo-1, train msd <loss>=3.77971220016\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] compute all data-center distances: point norm took: 40.6287%, (1.225682 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] predict compute msd took: 17.7302%, (0.534882 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] compute all data-center distances: inner product took: 12.6680%, (0.382168 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] gradient: cluster size  took: 9.1334%, (0.275534 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] gradient: cluster center took: 7.2176%, (0.217739 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] batch data loading with context took: 5.1215%, (0.154504 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] update state and report convergance took: 2.2906%, (0.069103 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] collect from kv store took: 1.4676%, (0.044276 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] gradient: one_hot took: 1.3766%, (0.041528 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] compute all data-center distances: center norm took: 1.2494%, (0.037692 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] splitting centers key-value pair took: 1.0095%, (0.030455 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] predict minus dist took: 0.0967%, (0.002917 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] update set-up time took: 0.0101%, (0.000306 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] TOTAL took: 3.01678562164\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 120.6200122833252, \"sum\": 120.6200122833252, \"min\": 120.6200122833252}, \"initialize.time\": {\"count\": 1, \"max\": 24.85513687133789, \"sum\": 24.85513687133789, \"min\": 24.85513687133789}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.14591217041015625, \"sum\": 0.14591217041015625, \"min\": 0.14591217041015625}, \"update.time\": {\"count\": 1, \"max\": 3029.1318893432617, \"sum\": 3029.1318893432617, \"min\": 3029.1318893432617}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7600784301757812, \"sum\": 0.7600784301757812, \"min\": 0.7600784301757812}, \"_shrink.time\": {\"count\": 1, \"max\": 119.13418769836426, \"sum\": 119.13418769836426, \"min\": 119.13418769836426}}, \"EndTime\": 1589578033.768875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578030.558721}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:27:13 INFO 140668135569216] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 3290.158987045288, \"sum\": 3290.158987045288, \"min\": 3290.158987045288}, \"setuptime\": {\"count\": 1, \"max\": 11.636018753051758, \"sum\": 11.636018753051758, \"min\": 11.636018753051758}}, \"EndTime\": 1589578033.788922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578033.768978}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:27:25 Uploading - Uploading generated training model\n",
      "2020-05-15 21:27:25 Completed - Training job completed\n",
      "Training seconds: 68\n",
      "Billable seconds: 68\n",
      "2020-05-15 21:27:48 Starting - Starting the training job...\n",
      "2020-05-15 21:27:49 Starting - Launching requested ML instances......\n",
      "2020-05-15 21:28:49 Starting - Preparing the instances for training...\n",
      "2020-05-15 21:29:48 Downloading - Downloading input data......\n",
      "2020-05-15 21:30:37 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'4', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'4', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 WARNING 140117882976064] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] nvidia-smi took: 0.0251450538635 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'4', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:30:59 INFO 140117882976064] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589578259.538733, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578259.538684}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:30:59.543] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 60, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:00 INFO 140117882976064] Iter 10: Short term msd 13.979082. Long term msd 14.675941\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:00 INFO 140117882976064] Iter 20: Short term msd 13.417125. Long term msd 13.698970\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:00 INFO 140117882976064] Iter 30: Short term msd 13.309800. Long term msd 13.431029\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:00 INFO 140117882976064] Iter 40: Short term msd 13.335532. Long term msd 13.366114\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:00 INFO 140117882976064] Iter 50: Short term msd 13.276307. Long term msd 13.308825\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:01 INFO 140117882976064] Iter 60: Short term msd 13.355727. Long term msd 13.344782\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:01 INFO 140117882976064] Iter 70: Short term msd 13.390545. Long term msd 13.376337\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:01 INFO 140117882976064] Iter 80: Short term msd 13.373095. Long term msd 13.381994\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:01 INFO 140117882976064] Iter 90: Short term msd 13.381312. Long term msd 13.375494\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:01 INFO 140117882976064] Iter 100: Short term msd 13.406560. Long term msd 13.396723\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] Iter 110: Short term msd 13.380724. Long term msd 13.392075\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] Iter 120: Short term msd 13.442134. Long term msd 13.428145\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] Iter 130: Short term msd 13.524268. Long term msd 13.492857\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] Iter 140: Short term msd 13.525776. Long term msd 13.517306\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] Iter 150: Short term msd 13.524617. Long term msd 13.518233\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:31:02.894] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3350, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589578262.89515, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589578259.544053}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] #throughput_metric: host=algo-1, train throughput=224189.77851 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 WARNING 140117882976064] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] shrinking 40 centers into 4\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] local kmeans attempt #0. Current mean square distance 3.712803\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] local kmeans attempt #1. Current mean square distance 3.823373\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] local kmeans attempt #2. Current mean square distance 3.770026\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] local kmeans attempt #3. Current mean square distance 3.677347\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] local kmeans attempt #4. Current mean square distance 3.565296\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:02 INFO 140117882976064] local kmeans attempt #5. Current mean square distance 3.905693\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] local kmeans attempt #6. Current mean square distance 3.788346\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] local kmeans attempt #7. Current mean square distance 3.809155\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] local kmeans attempt #8. Current mean square distance 3.472564\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] local kmeans attempt #9. Current mean square distance 3.421829\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] #quality_metric: host=algo-1, train msd <loss>=3.4218287468\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] compute all data-center distances: point norm took: 36.0012%, (1.202376 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] predict compute msd took: 19.2882%, (0.644191 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] compute all data-center distances: inner product took: 14.9512%, (0.499344 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] gradient: cluster size  took: 10.5480%, (0.352284 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] gradient: cluster center took: 7.4887%, (0.250110 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] batch data loading with context took: 4.9374%, (0.164901 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] update state and report convergance took: 1.9939%, (0.066592 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] compute all data-center distances: center norm took: 1.6846%, (0.056261 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] collect from kv store took: 1.3648%, (0.045583 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] splitting centers key-value pair took: 0.8732%, (0.029165 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] gradient: one_hot took: 0.7679%, (0.025646 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] predict minus dist took: 0.0945%, (0.003156 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] update set-up time took: 0.0063%, (0.000210 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] TOTAL took: 3.3398194313\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 152.87518501281738, \"sum\": 152.87518501281738, \"min\": 152.87518501281738}, \"initialize.time\": {\"count\": 1, \"max\": 34.687042236328125, \"sum\": 34.687042236328125, \"min\": 34.687042236328125}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.13709068298339844, \"sum\": 0.13709068298339844, \"min\": 0.13709068298339844}, \"update.time\": {\"count\": 1, \"max\": 3350.893974304199, \"sum\": 3350.893974304199, \"min\": 3350.893974304199}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 1.516103744506836, \"sum\": 1.516103744506836, \"min\": 1.516103744506836}, \"_shrink.time\": {\"count\": 1, \"max\": 150.21800994873047, \"sum\": 150.21800994873047, \"min\": 150.21800994873047}}, \"EndTime\": 1589578263.050284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578259.479928}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:31:03 INFO 140117882976064] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 3654.5419692993164, \"sum\": 3654.5419692993164, \"min\": 3654.5419692993164}, \"setuptime\": {\"count\": 1, \"max\": 12.05301284790039, \"sum\": 12.05301284790039, \"min\": 12.05301284790039}}, \"EndTime\": 1589578263.067666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578263.050382}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:31:14 Uploading - Uploading generated training model\n",
      "2020-05-15 21:31:14 Completed - Training job completed\n",
      "Training seconds: 86\n",
      "Billable seconds: 86\n",
      "2020-05-15 21:31:30 Starting - Starting the training job...\n",
      "2020-05-15 21:31:31 Starting - Launching requested ML instances...\n",
      "2020-05-15 21:32:30 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:33:20 Downloading - Downloading input data......\n",
      "2020-05-15 21:34:28 Training - Training image download completed. Training in progress.\n",
      "2020-05-15 21:34:28 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'5', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 WARNING 140308858853184] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] nvidia-smi took: 0.0251398086548 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:19 INFO 140308858853184] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589578459.831096, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578459.831042}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:34:19.838] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 86, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:20 INFO 140308858853184] Iter 10: Short term msd 14.054120. Long term msd 14.795948\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:20 INFO 140308858853184] Iter 20: Short term msd 13.311121. Long term msd 13.640714\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:20 INFO 140308858853184] Iter 30: Short term msd 13.167398. Long term msd 13.314900\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:21 INFO 140308858853184] Iter 40: Short term msd 13.171838. Long term msd 13.217542\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:21 INFO 140308858853184] Iter 50: Short term msd 13.101355. Long term msd 13.141567\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:21 INFO 140308858853184] Iter 60: Short term msd 13.176724. Long term msd 13.170443\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:21 INFO 140308858853184] Iter 70: Short term msd 13.210510. Long term msd 13.198662\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:22 INFO 140308858853184] Iter 80: Short term msd 13.193607. Long term msd 13.203372\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:22 INFO 140308858853184] Iter 90: Short term msd 13.202824. Long term msd 13.197687\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:22 INFO 140308858853184] Iter 100: Short term msd 13.229255. Long term msd 13.219362\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:22 INFO 140308858853184] Iter 110: Short term msd 13.206203. Long term msd 13.217726\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:22 INFO 140308858853184] Iter 120: Short term msd 13.259788. Long term msd 13.248207\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] Iter 130: Short term msd 13.340859. Long term msd 13.310819\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] Iter 140: Short term msd 13.338618. Long term msd 13.331900\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] Iter 150: Short term msd 13.342143. Long term msd 13.337081\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:34:23.532] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3693, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589578463.532923, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589578459.838692}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] #throughput_metric: host=algo-1, train throughput=203367.095351 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 WARNING 140308858853184] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] shrinking 50 centers into 5\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #0. Current mean square distance 3.395568\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #1. Current mean square distance 3.516501\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #2. Current mean square distance 3.688786\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #3. Current mean square distance 3.482605\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #4. Current mean square distance 3.253096\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #5. Current mean square distance 3.448856\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #6. Current mean square distance 3.317786\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #7. Current mean square distance 3.558059\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #8. Current mean square distance 3.199340\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] local kmeans attempt #9. Current mean square distance 3.621375\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] #quality_metric: host=algo-1, train msd <loss>=3.19933986664\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] compute all data-center distances: point norm took: 34.3251%, (1.262656 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] predict compute msd took: 20.1695%, (0.741940 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] compute all data-center distances: inner product took: 15.9737%, (0.587595 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] gradient: cluster size  took: 11.7382%, (0.431791 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] gradient: cluster center took: 7.4179%, (0.272869 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] batch data loading with context took: 4.3998%, (0.161847 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] update state and report convergance took: 1.9214%, (0.070678 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] compute all data-center distances: center norm took: 1.3384%, (0.049233 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] collect from kv store took: 1.1110%, (0.040870 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] gradient: one_hot took: 0.8335%, (0.030661 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] splitting centers key-value pair took: 0.6863%, (0.025245 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] predict minus dist took: 0.0789%, (0.002902 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] update set-up time took: 0.0064%, (0.000234 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] TOTAL took: 3.67852282524\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 173.58684539794922, \"sum\": 173.58684539794922, \"min\": 173.58684539794922}, \"initialize.time\": {\"count\": 1, \"max\": 62.2861385345459, \"sum\": 62.2861385345459, \"min\": 62.2861385345459}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.1938343048095703, \"sum\": 0.1938343048095703, \"min\": 0.1938343048095703}, \"update.time\": {\"count\": 1, \"max\": 3694.042921066284, \"sum\": 3694.042921066284, \"min\": 3694.042921066284}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 1.1539459228515625, \"sum\": 1.1539459228515625, \"min\": 1.1539459228515625}, \"_shrink.time\": {\"count\": 1, \"max\": 171.53215408325195, \"sum\": 171.53215408325195, \"min\": 171.53215408325195}}, \"EndTime\": 1589578463.708438, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578459.751516}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:34:23 INFO 140308858853184] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4041.232109069824, \"sum\": 4041.232109069824, \"min\": 4041.232109069824}, \"setuptime\": {\"count\": 1, \"max\": 12.594938278198242, \"sum\": 12.594938278198242, \"min\": 12.594938278198242}}, \"EndTime\": 1589578463.728541, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578463.708605}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:34:34 Completed - Training job completed\n",
      "Training seconds: 74\n",
      "Billable seconds: 74\n",
      "2020-05-15 21:35:12 Starting - Starting the training job...\n",
      "2020-05-15 21:35:14 Starting - Launching requested ML instances...\n",
      "2020-05-15 21:36:12 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:37:05 Downloading - Downloading input data......\n",
      "2020-05-15 21:38:08 Training - Training image download completed. Training in progress.\n",
      "2020-05-15 21:38:08 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'6', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'6', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 WARNING 140144092653376] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] nvidia-smi took: 0.0251281261444 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'6', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:37:59 INFO 140144092653376] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589578679.973026, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578679.972977}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:37:59.986] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 84, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:00 INFO 140144092653376] Iter 10: Short term msd 13.635503. Long term msd 14.311111\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:00 INFO 140144092653376] Iter 20: Short term msd 13.051767. Long term msd 13.333033\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:01 INFO 140144092653376] Iter 30: Short term msd 12.943553. Long term msd 13.063188\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:01 INFO 140144092653376] Iter 40: Short term msd 12.962014. Long term msd 12.994485\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:01 INFO 140144092653376] Iter 50: Short term msd 12.898977. Long term msd 12.931488\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:01 INFO 140144092653376] Iter 60: Short term msd 12.972860. Long term msd 12.964486\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:01 INFO 140144092653376] Iter 70: Short term msd 13.011636. Long term msd 12.997621\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:02 INFO 140144092653376] Iter 80: Short term msd 12.996168. Long term msd 13.004147\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:02 INFO 140144092653376] Iter 90: Short term msd 13.014256. Long term msd 13.005033\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:02 INFO 140144092653376] Iter 100: Short term msd 13.028033. Long term msd 13.020732\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:02 INFO 140144092653376] Iter 110: Short term msd 13.006056. Long term msd 13.018090\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] Iter 120: Short term msd 13.066644. Long term msd 13.052330\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] Iter 130: Short term msd 13.144009. Long term msd 13.114584\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] Iter 140: Short term msd 13.148357. Long term msd 13.138454\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] Iter 150: Short term msd 13.145542. Long term msd 13.140549\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:38:03.830] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3843, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589578683.831566, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589578679.986798}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] #throughput_metric: host=algo-1, train throughput=195410.023492 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 WARNING 140144092653376] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] shrinking 60 centers into 6\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #0. Current mean square distance 3.462343\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #1. Current mean square distance 3.512551\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #2. Current mean square distance 3.167550\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #3. Current mean square distance 2.960751\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #4. Current mean square distance 3.555717\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #5. Current mean square distance 3.369354\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #6. Current mean square distance 3.494841\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #7. Current mean square distance 2.972711\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #8. Current mean square distance 3.397340\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] local kmeans attempt #9. Current mean square distance 3.060443\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] #quality_metric: host=algo-1, train msd <loss>=2.96075057983\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] compute all data-center distances: point norm took: 30.2238%, (1.157812 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] predict compute msd took: 22.1968%, (0.850314 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] compute all data-center distances: inner product took: 16.8264%, (0.644585 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] gradient: cluster size  took: 13.1929%, (0.505392 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] gradient: cluster center took: 7.4488%, (0.285348 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] batch data loading with context took: 4.3964%, (0.168417 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] update state and report convergance took: 1.8755%, (0.071847 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] collect from kv store took: 1.3006%, (0.049824 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] compute all data-center distances: center norm took: 0.9371%, (0.035898 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] gradient: one_hot took: 0.7842%, (0.030043 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] splitting centers key-value pair took: 0.7334%, (0.028093 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] predict minus dist took: 0.0775%, (0.002967 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:03 INFO 140144092653376] update set-up time took: 0.0065%, (0.000250 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:04 INFO 140144092653376] TOTAL took: 3.83078980446\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:04 INFO 140144092653376] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 167.49191284179688, \"sum\": 167.49191284179688, \"min\": 167.49191284179688}, \"initialize.time\": {\"count\": 1, \"max\": 48.475027084350586, \"sum\": 48.475027084350586, \"min\": 48.475027084350586}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.14901161193847656, \"sum\": 0.14901161193847656, \"min\": 0.14901161193847656}, \"update.time\": {\"count\": 1, \"max\": 3844.4690704345703, \"sum\": 3844.4690704345703, \"min\": 3844.4690704345703}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.6940364837646484, \"sum\": 0.6940364837646484, \"min\": 0.6940364837646484}, \"_shrink.time\": {\"count\": 1, \"max\": 166.0921573638916, \"sum\": 166.0921573638916, \"min\": 166.0921573638916}}, \"EndTime\": 1589578684.000412, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578679.901759}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:38:04 INFO 140144092653376] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4176.789999008179, \"sum\": 4176.789999008179, \"min\": 4176.789999008179}, \"setuptime\": {\"count\": 1, \"max\": 12.052059173583984, \"sum\": 12.052059173583984, \"min\": 12.052059173583984}}, \"EndTime\": 1589578684.018436, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578684.000501}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:38:15 Completed - Training job completed\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n",
      "2020-05-15 21:38:55 Starting - Starting the training job...\n",
      "2020-05-15 21:38:57 Starting - Launching requested ML instances......\n",
      "2020-05-15 21:40:23 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:40:56 Downloading - Downloading input data...\n",
      "2020-05-15 21:41:49 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'7', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 WARNING 139729414391616] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] nvidia-smi took: 0.0251231193542 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:50 INFO 139729414391616] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589578911.048749, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578911.048694}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:41:51.054] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 85, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:51 INFO 139729414391616] Iter 10: Short term msd 13.471082. Long term msd 14.149974\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:51 INFO 139729414391616] Iter 20: Short term msd 12.914384. Long term msd 13.189491\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:52 INFO 139729414391616] Iter 30: Short term msd 12.804704. Long term msd 12.922958\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:52 INFO 139729414391616] Iter 40: Short term msd 12.838966. Long term msd 12.865962\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:52 INFO 139729414391616] Iter 50: Short term msd 12.785233. Long term msd 12.812343\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:52 INFO 139729414391616] Iter 60: Short term msd 12.854112. Long term msd 12.845567\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:53 INFO 139729414391616] Iter 70: Short term msd 12.892983. Long term msd 12.878507\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:53 INFO 139729414391616] Iter 80: Short term msd 12.877591. Long term msd 12.885334\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:53 INFO 139729414391616] Iter 90: Short term msd 12.889996. Long term msd 12.883716\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:53 INFO 139729414391616] Iter 100: Short term msd 12.909034. Long term msd 12.901194\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:54 INFO 139729414391616] Iter 110: Short term msd 12.891732. Long term msd 12.901492\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:54 INFO 139729414391616] Iter 120: Short term msd 12.955954. Long term msd 12.939717\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:54 INFO 139729414391616] Iter 130: Short term msd 13.027256. Long term msd 12.999065\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:54 INFO 139729414391616] Iter 140: Short term msd 13.021346. Long term msd 13.016172\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] Iter 150: Short term msd 13.038572. Long term msd 13.028976\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:41:55.067] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4012, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589578915.067867, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589578911.054567}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] #throughput_metric: host=algo-1, train throughput=187202.816226 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 WARNING 139729414391616] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] shrinking 70 centers into 7\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #0. Current mean square distance 3.371287\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #1. Current mean square distance 2.921468\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #2. Current mean square distance 3.036589\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #3. Current mean square distance 3.325972\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #4. Current mean square distance 3.118817\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #5. Current mean square distance 3.030715\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #6. Current mean square distance 2.894596\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #7. Current mean square distance 3.072027\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #8. Current mean square distance 2.873699\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] local kmeans attempt #9. Current mean square distance 2.876161\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] #quality_metric: host=algo-1, train msd <loss>=2.87369942665\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] compute all data-center distances: point norm took: 28.6487%, (1.144959 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] predict compute msd took: 23.9155%, (0.955794 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] compute all data-center distances: inner product took: 16.6957%, (0.667252 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] gradient: cluster size  took: 14.5855%, (0.582917 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] gradient: cluster center took: 7.4493%, (0.297714 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] batch data loading with context took: 3.4663%, (0.138533 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] update state and report convergance took: 1.6124%, (0.064441 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] compute all data-center distances: center norm took: 1.2654%, (0.050571 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] collect from kv store took: 0.9198%, (0.036760 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] gradient: one_hot took: 0.7826%, (0.031278 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] splitting centers key-value pair took: 0.5902%, (0.023587 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] predict minus dist took: 0.0635%, (0.002537 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] update set-up time took: 0.0053%, (0.000210 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] TOTAL took: 3.99655199051\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 220.19004821777344, \"sum\": 220.19004821777344, \"min\": 220.19004821777344}, \"initialize.time\": {\"count\": 1, \"max\": 62.64805793762207, \"sum\": 62.64805793762207, \"min\": 62.64805793762207}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.12302398681640625, \"sum\": 0.12302398681640625, \"min\": 0.12302398681640625}, \"update.time\": {\"count\": 1, \"max\": 4013.0560398101807, \"sum\": 4013.0560398101807, \"min\": 4013.0560398101807}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7500648498535156, \"sum\": 0.7500648498535156, \"min\": 0.7500648498535156}, \"_shrink.time\": {\"count\": 1, \"max\": 218.10007095336914, \"sum\": 218.10007095336914, \"min\": 218.10007095336914}}, \"EndTime\": 1589578915.289517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578910.968613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:41:55 INFO 139729414391616] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4405.002117156982, \"sum\": 4405.002117156982, \"min\": 4405.002117156982}, \"setuptime\": {\"count\": 1, \"max\": 14.753103256225586, \"sum\": 14.753103256225586, \"min\": 14.753103256225586}}, \"EndTime\": 1589578915.305867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589578915.289606}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:42:06 Uploading - Uploading generated training model\n",
      "2020-05-15 21:42:06 Completed - Training job completed\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n",
      "2020-05-15 21:42:36 Starting - Starting the training job...\n",
      "2020-05-15 21:42:38 Starting - Launching requested ML instances...\n",
      "2020-05-15 21:43:36 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:44:12 Downloading - Downloading input data...\n",
      "2020-05-15 21:44:55 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'8', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'8', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 WARNING 140390821410624] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] nvidia-smi took: 0.0251498222351 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'8', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589579111.38873, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579111.387624}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:45:11.400] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 81, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:11 INFO 140390821410624] Iter 10: Short term msd 13.410860. Long term msd 14.077800\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:12 INFO 140390821410624] Iter 20: Short term msd 12.843996. Long term msd 13.120192\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:12 INFO 140390821410624] Iter 30: Short term msd 12.747081. Long term msd 12.863983\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:12 INFO 140390821410624] Iter 40: Short term msd 12.769953. Long term msd 12.800342\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:13 INFO 140390821410624] Iter 50: Short term msd 12.712005. Long term msd 12.742869\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:13 INFO 140390821410624] Iter 60: Short term msd 12.779856. Long term msd 12.770641\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:13 INFO 140390821410624] Iter 70: Short term msd 12.802361. Long term msd 12.791908\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:13 INFO 140390821410624] Iter 80: Short term msd 12.783750. Long term msd 12.793326\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:14 INFO 140390821410624] Iter 90: Short term msd 12.804300. Long term msd 12.796435\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:14 INFO 140390821410624] Iter 100: Short term msd 12.824678. Long term msd 12.816265\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:14 INFO 140390821410624] Iter 110: Short term msd 12.806128. Long term msd 12.815330\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] Iter 120: Short term msd 12.853987. Long term msd 12.845476\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] Iter 130: Short term msd 12.928113. Long term msd 12.902249\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] Iter 140: Short term msd 12.920779. Long term msd 12.916924\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] Iter 150: Short term msd 12.935528. Long term msd 12.927705\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:45:15.783] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4381, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589579115.783906, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589579111.400953}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] #throughput_metric: host=algo-1, train throughput=171414.689352 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 WARNING 140390821410624] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] shrinking 80 centers into 8\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #0. Current mean square distance 2.761860\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #1. Current mean square distance 2.849787\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #2. Current mean square distance 2.907931\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #3. Current mean square distance 2.822395\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #4. Current mean square distance 2.864640\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #5. Current mean square distance 2.967150\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #6. Current mean square distance 2.879608\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #7. Current mean square distance 2.822093\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:15 INFO 140390821410624] local kmeans attempt #8. Current mean square distance 2.840135\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] local kmeans attempt #9. Current mean square distance 2.912319\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] #quality_metric: host=algo-1, train msd <loss>=2.76185965538\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] compute all data-center distances: point norm took: 26.3343%, (1.157378 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] predict compute msd took: 24.6062%, (1.081429 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] compute all data-center distances: inner product took: 17.1038%, (0.751701 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] gradient: cluster size  took: 14.4518%, (0.635147 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] gradient: cluster center took: 7.9289%, (0.348471 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] batch data loading with context took: 3.8775%, (0.170413 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] update state and report convergance took: 1.6584%, (0.072886 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] compute all data-center distances: center norm took: 1.3553%, (0.059563 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] collect from kv store took: 1.1342%, (0.049846 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] gradient: one_hot took: 0.8075%, (0.035490 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] splitting centers key-value pair took: 0.6668%, (0.029304 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] predict minus dist took: 0.0674%, (0.002961 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] update set-up time took: 0.0080%, (0.000353 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] TOTAL took: 4.39494299889\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 220.5970287322998, \"sum\": 220.5970287322998, \"min\": 220.5970287322998}, \"initialize.time\": {\"count\": 1, \"max\": 43.80297660827637, \"sum\": 43.80297660827637, \"min\": 43.80297660827637}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.14209747314453125, \"sum\": 0.14209747314453125, \"min\": 0.14209747314453125}, \"update.time\": {\"count\": 1, \"max\": 4382.756948471069, \"sum\": 4382.756948471069, \"min\": 4382.756948471069}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.8609294891357422, \"sum\": 0.8609294891357422, \"min\": 0.8609294891357422}, \"_shrink.time\": {\"count\": 1, \"max\": 218.2631492614746, \"sum\": 218.2631492614746, \"min\": 218.2631492614746}}, \"EndTime\": 1589579116.006054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579111.318152}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:45:16 INFO 140390821410624] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4769.9830532073975, \"sum\": 4769.9830532073975, \"min\": 4769.9830532073975}, \"setuptime\": {\"count\": 1, \"max\": 13.062000274658203, \"sum\": 13.062000274658203, \"min\": 13.062000274658203}}, \"EndTime\": 1589579116.022196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579116.006151}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:45:26 Uploading - Uploading generated training model\n",
      "2020-05-15 21:45:26 Completed - Training job completed\n",
      "Training seconds: 74\n",
      "Billable seconds: 74\n",
      "2020-05-15 21:45:48 Starting - Starting the training job...\n",
      "2020-05-15 21:45:51 Starting - Launching requested ML instances...\n",
      "2020-05-15 21:46:49 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:47:40 Downloading - Downloading input data......\n",
      "2020-05-15 21:48:47 Training - Training image download completed. Training in progress.\n",
      "2020-05-15 21:48:47 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'9', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'9', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 WARNING 139756009088832] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] nvidia-smi took: 0.0251331329346 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'9', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:38 INFO 139756009088832] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589579319.075915, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579319.075865}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:48:39.084] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 122, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:39 INFO 139756009088832] Iter 10: Short term msd 13.304010. Long term msd 13.969335\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:39 INFO 139756009088832] Iter 20: Short term msd 12.731383. Long term msd 13.007619\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:40 INFO 139756009088832] Iter 30: Short term msd 12.612949. Long term msd 12.734131\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:40 INFO 139756009088832] Iter 40: Short term msd 12.634090. Long term msd 12.666211\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:40 INFO 139756009088832] Iter 50: Short term msd 12.578456. Long term msd 12.607406\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:41 INFO 139756009088832] Iter 60: Short term msd 12.649185. Long term msd 12.640426\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:41 INFO 139756009088832] Iter 70: Short term msd 12.698256. Long term msd 12.681002\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:41 INFO 139756009088832] Iter 80: Short term msd 12.674485. Long term msd 12.683043\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:42 INFO 139756009088832] Iter 90: Short term msd 12.669781. Long term msd 12.670309\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:42 INFO 139756009088832] Iter 100: Short term msd 12.697221. Long term msd 12.689626\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:42 INFO 139756009088832] Iter 110: Short term msd 12.679224. Long term msd 12.689325\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:42 INFO 139756009088832] Iter 120: Short term msd 12.740034. Long term msd 12.725723\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] Iter 130: Short term msd 12.818076. Long term msd 12.788548\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] Iter 140: Short term msd 12.818786. Long term msd 12.811370\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] Iter 150: Short term msd 12.817004. Long term msd 12.811764\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:48:43.724] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4639, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589579323.724723, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589579319.084407}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] #throughput_metric: host=algo-1, train throughput=161907.618003 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 WARNING 139756009088832] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] shrinking 90 centers into 9\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] local kmeans attempt #0. Current mean square distance 2.834308\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] local kmeans attempt #1. Current mean square distance 2.739924\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] local kmeans attempt #2. Current mean square distance 2.755120\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] local kmeans attempt #3. Current mean square distance 2.758784\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:43 INFO 139756009088832] local kmeans attempt #4. Current mean square distance 2.806450\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] local kmeans attempt #5. Current mean square distance 2.798108\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] local kmeans attempt #6. Current mean square distance 2.833015\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] local kmeans attempt #7. Current mean square distance 2.857247\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] local kmeans attempt #8. Current mean square distance 2.821211\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] local kmeans attempt #9. Current mean square distance 2.838216\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] #quality_metric: host=algo-1, train msd <loss>=2.73992371559\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] predict compute msd took: 25.1800%, (1.169155 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] compute all data-center distances: point norm took: 24.5367%, (1.139287 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] compute all data-center distances: inner product took: 17.4454%, (0.810021 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] gradient: cluster size  took: 15.7376%, (0.730725 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] gradient: cluster center took: 7.9772%, (0.370396 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] batch data loading with context took: 3.5805%, (0.166250 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] update state and report convergance took: 1.5119%, (0.070201 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] collect from kv store took: 1.1667%, (0.054173 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] gradient: one_hot took: 1.0413%, (0.048348 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] compute all data-center distances: center norm took: 0.9987%, (0.046369 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] splitting centers key-value pair took: 0.7555%, (0.035081 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] predict minus dist took: 0.0632%, (0.002935 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] update set-up time took: 0.0053%, (0.000246 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] TOTAL took: 4.64318585396\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 390.8510208129883, \"sum\": 390.8510208129883, \"min\": 390.8510208129883}, \"initialize.time\": {\"count\": 1, \"max\": 97.23591804504395, \"sum\": 97.23591804504395, \"min\": 97.23591804504395}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.13494491577148438, \"sum\": 0.13494491577148438, \"min\": 0.13494491577148438}, \"update.time\": {\"count\": 1, \"max\": 4640.033960342407, \"sum\": 4640.033960342407, \"min\": 4640.033960342407}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7851123809814453, \"sum\": 0.7851123809814453, \"min\": 0.7851123809814453}, \"_shrink.time\": {\"count\": 1, \"max\": 388.14377784729004, \"sum\": 388.14377784729004, \"min\": 388.14377784729004}}, \"EndTime\": 1589579324.117172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579318.960902}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:48:44 INFO 139756009088832] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5222.6879596710205, \"sum\": 5222.6879596710205, \"min\": 5222.6879596710205}, \"setuptime\": {\"count\": 1, \"max\": 12.119054794311523, \"sum\": 12.119054794311523, \"min\": 12.119054794311523}}, \"EndTime\": 1589579324.123071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579324.117272}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:48:54 Completed - Training job completed\n",
      "Training seconds: 74\n",
      "Billable seconds: 74\n",
      "2020-05-15 21:49:30 Starting - Starting the training job...\n",
      "2020-05-15 21:49:32 Starting - Launching requested ML instances......\n",
      "2020-05-15 21:50:32 Starting - Preparing the instances for training...\n",
      "2020-05-15 21:51:20 Downloading - Downloading input data......\n",
      "2020-05-15 21:52:29 Training - Training image download completed. Training in progress.\n",
      "2020-05-15 21:52:29 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'10', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 WARNING 140577827186496] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] nvidia-smi took: 0.0251541137695 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:20 INFO 140577827186496] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589579540.571907, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579540.571875}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:52:20.584] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 146, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:21 INFO 140577827186496] Iter 10: Short term msd 13.215795. Long term msd 13.864407\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:21 INFO 140577827186496] Iter 20: Short term msd 12.654817. Long term msd 12.923354\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:21 INFO 140577827186496] Iter 30: Short term msd 12.531460. Long term msd 12.651927\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:22 INFO 140577827186496] Iter 40: Short term msd 12.551585. Long term msd 12.583757\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:22 INFO 140577827186496] Iter 50: Short term msd 12.497504. Long term msd 12.525550\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:22 INFO 140577827186496] Iter 60: Short term msd 12.548282. Long term msd 12.544846\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:23 INFO 140577827186496] Iter 70: Short term msd 12.586866. Long term msd 12.574433\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:23 INFO 140577827186496] Iter 80: Short term msd 12.566583. Long term msd 12.574279\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:23 INFO 140577827186496] Iter 90: Short term msd 12.575056. Long term msd 12.571154\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:24 INFO 140577827186496] Iter 100: Short term msd 12.590555. Long term msd 12.585262\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:24 INFO 140577827186496] Iter 110: Short term msd 12.581114. Long term msd 12.588383\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:24 INFO 140577827186496] Iter 120: Short term msd 12.634670. Long term msd 12.622858\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:24 INFO 140577827186496] Iter 130: Short term msd 12.709035. Long term msd 12.681090\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] Iter 140: Short term msd 12.710303. Long term msd 12.702608\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] Iter 150: Short term msd 12.720213. Long term msd 12.712168\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:52:25.489] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4903, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589579545.489711, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589579540.584868}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] #throughput_metric: host=algo-1, train throughput=153176.525648 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 WARNING 140577827186496] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] shrinking 100 centers into 10\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #0. Current mean square distance 2.705697\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #1. Current mean square distance 2.764196\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #2. Current mean square distance 2.821779\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #3. Current mean square distance 2.706154\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #4. Current mean square distance 2.791428\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #5. Current mean square distance 2.792034\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #6. Current mean square distance 2.677397\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #7. Current mean square distance 2.858112\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #8. Current mean square distance 2.769696\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] local kmeans attempt #9. Current mean square distance 2.711703\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] #quality_metric: host=algo-1, train msd <loss>=2.67739725113\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] predict compute msd took: 25.7831%, (1.261150 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] compute all data-center distances: point norm took: 22.2239%, (1.087055 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] compute all data-center distances: inner product took: 18.4616%, (0.903026 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] gradient: cluster size  took: 16.3971%, (0.802042 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] gradient: cluster center took: 8.4963%, (0.415586 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] batch data loading with context took: 3.7067%, (0.181307 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] update state and report convergance took: 1.5519%, (0.075911 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] compute all data-center distances: center norm took: 1.0865%, (0.053147 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] collect from kv store took: 0.8963%, (0.043839 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] gradient: one_hot took: 0.7726%, (0.037790 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] splitting centers key-value pair took: 0.5573%, (0.027261 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] predict minus dist took: 0.0621%, (0.003037 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] update set-up time took: 0.0046%, (0.000223 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] TOTAL took: 4.89137554169\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 302.7968406677246, \"sum\": 302.7968406677246, \"min\": 302.7968406677246}, \"initialize.time\": {\"count\": 1, \"max\": 116.74094200134277, \"sum\": 116.74094200134277, \"min\": 116.74094200134277}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.12993812561035156, \"sum\": 0.12993812561035156, \"min\": 0.12993812561035156}, \"update.time\": {\"count\": 1, \"max\": 4904.623985290527, \"sum\": 4904.623985290527, \"min\": 4904.623985290527}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.6890296936035156, \"sum\": 0.6890296936035156, \"min\": 0.6890296936035156}, \"_shrink.time\": {\"count\": 1, \"max\": 300.51708221435547, \"sum\": 300.51708221435547, \"min\": 300.51708221435547}}, \"EndTime\": 1589579545.793902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579540.437545}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:52:25 INFO 140577827186496] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5477.528095245361, \"sum\": 5477.528095245361, \"min\": 5477.528095245361}, \"setuptime\": {\"count\": 1, \"max\": 12.107133865356445, \"sum\": 12.107133865356445, \"min\": 12.107133865356445}}, \"EndTime\": 1589579545.818541, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579545.794007}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:52:35 Completed - Training job completed\n",
      "Training seconds: 75\n",
      "Billable seconds: 75\n",
      "2020-05-15 21:53:12 Starting - Starting the training job...\n",
      "2020-05-15 21:53:14 Starting - Launching requested ML instances......\n",
      "2020-05-15 21:54:39 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:55:14 Downloading - Downloading input data...\n",
      "2020-05-15 21:55:56 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'11', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'11', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 WARNING 140119970854720] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] nvidia-smi took: 0.0251219272614 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'11', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:11 INFO 140119970854720] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589579772.030149, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579772.030094}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:56:12.040] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 141, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:12 INFO 140119970854720] Iter 10: Short term msd 13.136279. Long term msd 13.778395\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:13 INFO 140119970854720] Iter 20: Short term msd 12.584063. Long term msd 12.850975\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:13 INFO 140119970854720] Iter 30: Short term msd 12.471065. Long term msd 12.587808\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:13 INFO 140119970854720] Iter 40: Short term msd 12.498531. Long term msd 12.526713\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:13 INFO 140119970854720] Iter 50: Short term msd 12.434449. Long term msd 12.466825\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:14 INFO 140119970854720] Iter 60: Short term msd 12.510370. Long term msd 12.501061\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:14 INFO 140119970854720] Iter 70: Short term msd 12.543936. Long term msd 12.530409\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:14 INFO 140119970854720] Iter 80: Short term msd 12.520589. Long term msd 12.530718\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:15 INFO 140119970854720] Iter 90: Short term msd 12.527874. Long term msd 12.525132\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:15 INFO 140119970854720] Iter 100: Short term msd 12.551028. Long term msd 12.543094\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:15 INFO 140119970854720] Iter 110: Short term msd 12.537984. Long term msd 12.545435\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:16 INFO 140119970854720] Iter 120: Short term msd 12.592664. Long term msd 12.579229\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:16 INFO 140119970854720] Iter 130: Short term msd 12.668437. Long term msd 12.640290\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:16 INFO 140119970854720] Iter 140: Short term msd 12.669513. Long term msd 12.662671\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] Iter 150: Short term msd 12.667586. Long term msd 12.664307\u001b[0m\n",
      "\u001b[34m[2020-05-15 21:56:17.029] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4988, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589579777.029784, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589579772.040465}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] #throughput_metric: host=algo-1, train throughput=150582.666352 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 WARNING 140119970854720] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] shrinking 110 centers into 11\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #0. Current mean square distance 2.667068\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #1. Current mean square distance 2.702462\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #2. Current mean square distance 2.620492\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #3. Current mean square distance 2.789051\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #4. Current mean square distance 2.762373\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #5. Current mean square distance 2.696150\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #6. Current mean square distance 2.582986\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #7. Current mean square distance 2.618596\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #8. Current mean square distance 2.716014\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] local kmeans attempt #9. Current mean square distance 2.711646\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] #quality_metric: host=algo-1, train msd <loss>=2.58298563957\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] predict compute msd took: 26.6767%, (1.326084 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] compute all data-center distances: point norm took: 21.5187%, (1.069685 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] compute all data-center distances: inner product took: 18.5538%, (0.922299 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] gradient: cluster size  took: 17.3453%, (0.862227 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] gradient: cluster center took: 8.0503%, (0.400179 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] batch data loading with context took: 3.1888%, (0.158516 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] update state and report convergance took: 1.4306%, (0.071113 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] compute all data-center distances: center norm took: 1.0312%, (0.051259 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] collect from kv store took: 0.8204%, (0.040781 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] gradient: one_hot took: 0.8096%, (0.040245 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] splitting centers key-value pair took: 0.5110%, (0.025402 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] predict minus dist took: 0.0587%, (0.002918 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] update set-up time took: 0.0049%, (0.000245 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] TOTAL took: 4.9709546566\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 284.44910049438477, \"sum\": 284.44910049438477, \"min\": 284.44910049438477}, \"initialize.time\": {\"count\": 1, \"max\": 113.65985870361328, \"sum\": 113.65985870361328, \"min\": 113.65985870361328}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.16999244689941406, \"sum\": 0.16999244689941406, \"min\": 0.16999244689941406}, \"update.time\": {\"count\": 1, \"max\": 4989.104986190796, \"sum\": 4989.104986190796, \"min\": 4989.104986190796}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7889270782470703, \"sum\": 0.7889270782470703, \"min\": 0.7889270782470703}, \"_shrink.time\": {\"count\": 1, \"max\": 282.95397758483887, \"sum\": 282.95397758483887, \"min\": 282.95397758483887}}, \"EndTime\": 1589579777.315779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579771.897896}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 21:56:17 INFO 140119970854720] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5504.769086837769, \"sum\": 5504.769086837769, \"min\": 5504.769086837769}, \"setuptime\": {\"count\": 1, \"max\": 14.72616195678711, \"sum\": 14.72616195678711, \"min\": 14.72616195678711}}, \"EndTime\": 1589579777.337815, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589579777.31588}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 21:56:40 Uploading - Uploading generated training model\n",
      "2020-05-15 21:56:46 Completed - Training job completed\n",
      "Training seconds: 92\n",
      "Billable seconds: 92\n"
     ]
    }
   ],
   "source": [
    "##Launch different jobs\n",
    "K = range(2, 12) # change the range to be used for k\n",
    "\n",
    "output_path = 's3://{}/kmeans/output/'.format(bucket_name)\n",
    "job_names = {}\n",
    "# launching jobs for all k\n",
    "for k in K:\n",
    "    k_estimator = sagemaker.KMeans(role,\n",
    "                               train_instance_count = 1,\n",
    "                               train_instance_type = 'ml.m5.large',\n",
    "                               k = k,\n",
    "                               output_path = output_path\n",
    "                              )\n",
    "\n",
    "    k_estimator.fit(k_formatted_azdias_data)\n",
    "    job_names[k] = k_estimator._current_job_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'kmeans-2020-05-15-21-20-54-724', 3: 'kmeans-2020-05-15-21-24-36-594', 4: 'kmeans-2020-05-15-21-27-48-491', 5: 'kmeans-2020-05-15-21-31-30-519', 6: 'kmeans-2020-05-15-21-35-12-570', 7: 'kmeans-2020-05-15-21-38-54-858', 8: 'kmeans-2020-05-15-21-42-36-757', 9: 'kmeans-2020-05-15-21-45-48-517', 10: 'kmeans-2020-05-15-21-49-30-653', 11: 'kmeans-2020-05-15-21-53-12-573'}\n"
     ]
    }
   ],
   "source": [
    "print(job_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names = {2: 'kmeans-2020-05-15-17-50-43-572', 3: 'kmeans-2020-05-15-17-54-25-717', 4: 'kmeans-2020-05-15-17-58-07-694', 5: 'kmeans-2020-05-15-18-01-51-353', 6: 'kmeans-2020-05-15-18-05-03-070', 7: 'kmeans-2020-05-15-18-08-45-222', 8: 'kmeans-2020-05-15-18-11-56-941', 9: 'kmeans-2020-05-15-18-15-38-922', 10: 'kmeans-2020-05-15-18-19-20-867', 11: 'kmeans-2020-05-15-18-22-32-629'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the most appropiate number of groups using the elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_selection import loadModelByGroupNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#chunk based on https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "K = range(2, 12) # change the range to be used for k\n",
    "\n",
    "plt.plot()\n",
    "colors = ['b', 'g', 'r']\n",
    "markers = ['o', 'v', 's']\n",
    "models = {}\n",
    "distortions = []\n",
    "for k in K:\n",
    "    kmeans_model = loadModelByGroupNumber(k,'model.tar.gz', job_names, bucket_name)\n",
    "    kmeans_numpy = kmeans_model[0].asnumpy()\n",
    "    distortions.append(sum(np.min(cdist(azdias_sub_pca.values, kmeans_numpy, 'euclidean'), axis=1)) / azdias_sub_pca.values.shape[0])\n",
    "    models[k] = kmeans_numpy\n",
    " \n",
    "#plot\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('distortion')\n",
    "plt.title('Elbow graph')\n",
    "plt.show()\n",
    "\n",
    "#s3://sagemaker-eu-west-1-848439228145/kmeans/output/kmeans-2020-05-06-16-55-36-157/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the elbow graph it seems that 7 groups are the best option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_7 = loadModelByGroupNumber(7,'model.tar.gz',job_names, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit with 7 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_formatted_customers_data = pca.record_set(customers_sub_pca.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 21:57:51 Starting - Starting the training job...\n",
      "2020-05-15 21:57:52 Starting - Launching requested ML instances......\n",
      "2020-05-15 21:59:18 Starting - Preparing the instances for training......\n",
      "2020-05-15 21:59:54 Downloading - Downloading input data...\n",
      "2020-05-15 22:00:51 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'7', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 WARNING 140297671714624] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] nvidia-smi took: 0.0251529216766 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:53 INFO 140297671714624] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589580053.719899, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589580053.719839}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:00:53.732] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 98, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:54 INFO 140297671714624] Iter 10: Short term msd 13.611931. Long term msd 14.328001\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:54 INFO 140297671714624] Iter 20: Short term msd 12.962278. Long term msd 13.266002\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:54 INFO 140297671714624] Iter 30: Short term msd 12.846951. Long term msd 12.978021\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:55 INFO 140297671714624] Iter 40: Short term msd 12.865990. Long term msd 12.902227\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:55 INFO 140297671714624] Iter 50: Short term msd 12.807250. Long term msd 12.840477\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:55 INFO 140297671714624] Iter 60: Short term msd 12.880397. Long term msd 12.872437\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:55 INFO 140297671714624] Iter 70: Short term msd 12.921420. Long term msd 12.906027\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:56 INFO 140297671714624] Iter 80: Short term msd 12.905592. Long term msd 12.913356\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:56 INFO 140297671714624] Iter 90: Short term msd 12.917942. Long term msd 12.910749\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:56 INFO 140297671714624] Iter 100: Short term msd 12.933797. Long term msd 12.925467\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:56 INFO 140297671714624] Iter 110: Short term msd 12.913888. Long term msd 12.924986\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] Iter 120: Short term msd 12.976296. Long term msd 12.960872\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] Iter 130: Short term msd 13.056430. Long term msd 13.025188\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] Iter 140: Short term msd 13.045386. Long term msd 13.041704\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] Iter 150: Short term msd 13.053395. Long term msd 13.047149\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:00:57.873] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4140, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580057.874184, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1589580053.732884}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] #throughput_metric: host=algo-1, train throughput=181416.2845 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 WARNING 140297671714624] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] shrinking 70 centers into 7\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] local kmeans attempt #0. Current mean square distance 3.098012\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] local kmeans attempt #1. Current mean square distance 3.041445\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] local kmeans attempt #2. Current mean square distance 3.116595\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] local kmeans attempt #3. Current mean square distance 2.997060\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:57 INFO 140297671714624] local kmeans attempt #4. Current mean square distance 3.031366\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] local kmeans attempt #5. Current mean square distance 2.923617\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] local kmeans attempt #6. Current mean square distance 2.955143\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] local kmeans attempt #7. Current mean square distance 3.396478\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] local kmeans attempt #8. Current mean square distance 3.507104\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] local kmeans attempt #9. Current mean square distance 2.947281\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] #quality_metric: host=algo-1, train msd <loss>=2.92361688614\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] compute all data-center distances: point norm took: 27.3147%, (1.127957 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] predict compute msd took: 22.9242%, (0.946649 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] compute all data-center distances: inner product took: 17.3749%, (0.717494 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] gradient: cluster size  took: 15.2906%, (0.631421 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] gradient: cluster center took: 7.6164%, (0.314517 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] batch data loading with context took: 4.1786%, (0.172553 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] update state and report convergance took: 1.7790%, (0.073464 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] collect from kv store took: 1.0539%, (0.043521 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] compute all data-center distances: center norm took: 0.9260%, (0.038239 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] gradient: one_hot took: 0.7828%, (0.032327 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] splitting centers key-value pair took: 0.6773%, (0.027970 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] predict minus dist took: 0.0726%, (0.002998 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] update set-up time took: 0.0091%, (0.000374 secs)\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] TOTAL took: 4.12948226929\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 204.40316200256348, \"sum\": 204.40316200256348, \"min\": 204.40316200256348}, \"initialize.time\": {\"count\": 1, \"max\": 68.07899475097656, \"sum\": 68.07899475097656, \"min\": 68.07899475097656}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.15687942504882812, \"sum\": 0.15687942504882812, \"min\": 0.15687942504882812}, \"update.time\": {\"count\": 1, \"max\": 4141.119003295898, \"sum\": 4141.119003295898, \"min\": 4141.119003295898}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7369518280029297, \"sum\": 0.7369518280029297, \"min\": 0.7369518280029297}, \"_shrink.time\": {\"count\": 1, \"max\": 202.19111442565918, \"sum\": 202.19111442565918, \"min\": 202.19111442565918}}, \"EndTime\": 1589580058.08004, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589580053.633676}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:00:58 INFO 140297671714624] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4523.537158966064, \"sum\": 4523.537158966064, \"min\": 4523.537158966064}, \"setuptime\": {\"count\": 1, \"max\": 12.637138366699219, \"sum\": 12.637138366699219, \"min\": 12.637138366699219}}, \"EndTime\": 1589580058.096134, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1589580058.080141}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-15 22:01:09 Uploading - Uploading generated training model\n",
      "2020-05-15 22:01:09 Completed - Training job completed\n",
      "Training seconds: 75\n",
      "Billable seconds: 75\n"
     ]
    }
   ],
   "source": [
    "kmeans_prefix = 'kmeans/output/'\n",
    "output_path = ('s3://{}/'+kmeans_prefix).format(bucket_name)\n",
    "\n",
    "k_estimator = sagemaker.KMeans(role,\n",
    "                               train_instance_count = 1,\n",
    "                               train_instance_type = 'ml.m5.large',\n",
    "                               output_path = output_path,\n",
    "                               k = 7                           \n",
    "                              )\n",
    "\n",
    "k_estimator.fit(k_formatted_azdias_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model to analize the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans/output/kmeans-2020-05-15-21-57-51-499/output/model.tar.gz\n",
      "[\n",
      "[[-8.35158397e-03 -1.41447745e-02 -2.47396668e-03  7.38216739e-04\n",
      "   2.03210674e-02  5.98512311e-03 -1.82825774e-02  1.90150924e-02\n",
      "  -6.09522918e-03 -1.08582024e-02  3.83973029e-03  1.26171543e-03\n",
      "   1.34394942e-02 -2.94209830e-03  1.23238959e-03 -9.78444703e-03\n",
      "  -6.09766180e-03  7.54301809e-03  1.49492372e-03  1.70726757e-02\n",
      "  -6.20652456e-03  8.17815866e-03 -1.52562244e-03  1.28471712e-02\n",
      "  -8.17914587e-03  5.30655123e-03  3.83036025e-03 -5.01284329e-03\n",
      "   1.76844303e-03 -4.35261009e-03 -3.18039255e-03  1.26548037e-02\n",
      "   1.37021849e-02 -6.83827745e-03 -1.37920799e-02  7.35755684e-03\n",
      "   2.85751466e-03 -4.74866573e-03  1.59141384e-02  1.48633672e-02\n",
      "  -8.45605973e-03  7.26141455e-03  2.86001945e-03  1.00948298e-02\n",
      "  -1.06343962e-02  1.85853057e-02 -5.06150210e-03  3.13918618e-03\n",
      "   7.93128181e-03  1.04692846e-03  7.63502496e-04  2.20881477e-02\n",
      "   1.13262050e-02  5.28404256e-04  1.20783867e-02  1.34829851e-02\n",
      "  -7.63205253e-03 -1.53258778e-02  2.48364545e-02  6.91839755e-02\n",
      "   2.22210842e-03  1.56087615e-02  2.38311924e-02 -4.78812633e-03\n",
      "   3.35513474e-03 -1.21228592e-02 -1.80097260e-02  4.99971816e-03\n",
      "   3.71217553e-04 -1.30342469e-02 -6.84660068e-03 -5.93050756e-03\n",
      "  -5.21003408e-03 -1.65097993e-02 -7.68883247e-03 -3.10052615e-02\n",
      "   2.88640540e-02  3.62423472e-02 -1.91432498e-02 -1.17431590e-02\n",
      "   3.18807759e-03  1.05304075e-02 -1.09413452e-02 -1.21258907e-02\n",
      "   1.86430663e-03  2.58333534e-02  5.62545750e-03  2.47476399e-02\n",
      "  -4.57854243e-03 -3.21017951e-03  1.40004407e-03 -1.11707468e-02\n",
      "   7.06098136e-03 -3.68362963e-02  3.61233251e-03 -4.99049900e-03\n",
      "  -2.52218135e-02 -7.35160755e-03  1.63108371e-02  1.42183024e-02\n",
      "   1.70775242e-02  5.84610924e-03 -8.97067320e-03  1.62647031e-02\n",
      "  -1.00664273e-02  3.57610509e-02  5.68932621e-03  1.35208899e-03\n",
      "   8.42757151e-03  5.79102896e-03 -6.69020638e-02  9.59945619e-02\n",
      "   1.01900089e-03 -2.16874760e-04  1.65052172e-02  4.93004993e-02\n",
      "   2.14861557e-02 -3.11800502e-02 -2.22959995e-01  3.64648812e-02\n",
      "  -4.75208946e-02  1.81436792e-01 -1.07455269e-01  6.76497594e-02\n",
      "  -3.51789504e-01 -5.14499068e-01 -2.14743271e-01  8.58189911e-03\n",
      "  -1.98050141e-01 -1.37003765e-01 -5.23703933e-01 -3.62903386e-01\n",
      "   5.26896358e-01 -2.22942805e+00]\n",
      " [ 1.25590537e-04  1.87559228e-03  6.12990838e-03  1.27251446e-03\n",
      "  -3.06226593e-03 -2.25945405e-04  9.72399395e-03 -1.41906273e-03\n",
      "   2.42789928e-03  8.05350428e-05 -1.30973494e-04 -9.88765823e-05\n",
      "  -6.55257981e-03 -1.96578726e-03  4.27025836e-03  1.55087234e-03\n",
      "  -2.36910814e-03 -2.98427371e-03  3.41854547e-03  5.01691597e-03\n",
      "  -1.34517532e-03  8.06734897e-03 -5.00868366e-04 -4.92889085e-04\n",
      "   4.02974850e-03 -1.14859631e-02 -2.80816667e-03 -7.18516530e-03\n",
      "  -1.37541373e-03  7.31664302e-04 -3.07921949e-03 -5.89228643e-04\n",
      "   1.16014970e-04  2.98625929e-03  5.71769988e-03  3.86301801e-03\n",
      "   7.11798295e-03 -9.11046402e-04 -4.83324472e-03  6.38604350e-03\n",
      "  -5.60831884e-03 -2.92249955e-03  3.70960170e-03 -2.25881720e-03\n",
      "   2.76633212e-03  4.30190470e-03  3.31723783e-03  7.61420047e-03\n",
      "  -2.63734953e-03 -2.70709791e-03  1.91659364e-03  7.54107907e-03\n",
      "  -5.92133729e-03 -8.30281712e-03 -5.71841665e-04 -1.47910527e-04\n",
      "  -7.35934451e-03  6.83359336e-03 -1.10032288e-02 -9.31732706e-04\n",
      "  -1.21420238e-03  3.64507362e-03 -4.67387214e-03  7.21893273e-04\n",
      "  -3.68287507e-03  2.43629585e-03  1.84704852e-03 -6.96597155e-03\n",
      "   2.61623226e-03  5.00643486e-03 -9.68614221e-03 -4.22226638e-03\n",
      "  -6.15389086e-03 -6.01239922e-03 -5.78333391e-03 -1.00021474e-02\n",
      "  -1.00601986e-02 -6.37650304e-03  8.99148453e-03  5.08981338e-03\n",
      "  -2.40204134e-03  3.59456451e-03  8.96610320e-03 -1.07365819e-02\n",
      "  -1.91550720e-02 -7.88901560e-03 -2.56680930e-03  7.86366686e-03\n",
      "   8.99827760e-03 -1.25455745e-02  9.04017501e-03 -4.26507602e-03\n",
      "  -7.86773395e-03 -9.32215061e-03  1.49866240e-02  1.44149261e-02\n",
      "   2.21517980e-02  3.31145921e-03  3.18436557e-03 -1.28198415e-04\n",
      "   1.11255306e-03  1.05221523e-04 -2.29560956e-03  2.48903409e-03\n",
      "   7.00561050e-03  5.87884570e-04  5.19796973e-03 -3.42192426e-02\n",
      "   1.71071477e-02 -9.42872837e-03  2.27457397e-02  5.58960112e-03\n",
      "  -4.77517676e-03 -1.95862353e-02 -5.36164828e-03  5.43697588e-02\n",
      "  -2.94267349e-02  2.37839278e-02  1.90124623e-02  5.53329475e-02\n",
      "  -2.47527063e-02 -2.96113957e-02 -4.36774679e-02  1.18661728e-02\n",
      "  -1.06363051e-01  2.53234189e-02 -2.55242810e-02  5.90516478e-02\n",
      "  -5.66126630e-02 -1.22309491e-01 -4.04419526e-02 -7.49221295e-02\n",
      "  -9.10048306e-01  1.11670089e+00]\n",
      " [-3.77139542e-04  1.43221568e-03  8.05207354e-04  3.10826756e-04\n",
      "   1.00878836e-03  4.21949057e-03  8.00615293e-04 -2.84193410e-03\n",
      "  -6.12168945e-03 -2.15518591e-03 -3.17139225e-03 -7.24300975e-04\n",
      "  -2.11397116e-03 -4.41944459e-04  6.60542725e-03 -1.12626515e-03\n",
      "   5.25294570e-03 -8.34888895e-04 -1.52698066e-03 -5.25698485e-03\n",
      "   3.15939588e-03 -6.24884432e-03  7.07879849e-03 -7.32428161e-03\n",
      "  -9.46065318e-03 -7.07662664e-03 -5.11045149e-03  7.19781872e-03\n",
      "   2.50383839e-03 -2.78567662e-03 -9.37642530e-03  2.93624261e-03\n",
      "  -1.87200890e-03  4.17660410e-03 -2.37187161e-03 -4.83553857e-03\n",
      "  -4.73474618e-03 -1.50160808e-02  7.24897720e-03  3.28905415e-04\n",
      "  -7.39989616e-03 -3.74686043e-03 -7.18249055e-03 -1.03562337e-03\n",
      "  -4.48961800e-04 -8.18928983e-03  4.80232807e-03  5.31460764e-03\n",
      "  -8.01040139e-03 -2.25158734e-03  7.04434095e-03  2.39519449e-03\n",
      "  -1.10158296e-02 -6.53107651e-03  8.29979219e-03  5.36882412e-03\n",
      "  -5.20225905e-04 -1.98717415e-03 -9.15786903e-03  2.86344462e-03\n",
      "   2.91158631e-03 -1.55588361e-02 -1.40054466e-03 -9.63649945e-04\n",
      "  -1.32639753e-02  6.23983471e-03 -1.13661671e-02  1.26652177e-02\n",
      "   1.85560144e-03 -1.41285476e-03  6.91527454e-03 -5.97448228e-03\n",
      "   1.60680898e-02  6.62634987e-03  1.91821679e-02  7.16550741e-03\n",
      "   7.11054495e-03  6.60556322e-03 -5.07052196e-03  1.84536597e-03\n",
      "   3.83117725e-03 -2.46145157e-03 -1.19907772e-02  7.47683039e-03\n",
      "  -5.03983628e-03  7.24872202e-03  1.37493890e-02  1.97082036e-03\n",
      "  -4.87452745e-03  2.34043528e-03  1.88020198e-03  1.50866935e-03\n",
      "  -2.33720765e-02  6.06888020e-03  1.37999775e-02  1.03846332e-02\n",
      "  -8.08588695e-04  4.70405584e-03 -1.94722451e-02  6.45253621e-03\n",
      "   1.00147389e-02  1.43755050e-02  1.76495174e-04  8.08839279e-04\n",
      "   1.48740935e-03  8.59793462e-03  1.49784293e-02 -1.00464318e-02\n",
      "   2.19778456e-02  3.21974349e-03 -3.21280397e-02 -2.64216885e-02\n",
      "  -5.52626187e-03  2.38844529e-02  1.61979150e-03  1.77476485e-03\n",
      "  -2.44200733e-02  2.82494463e-02 -3.52100329e-03 -9.00483504e-03\n",
      "   2.47049592e-02  1.88085716e-02  2.26073619e-03 -5.32474667e-02\n",
      "  -7.93768466e-03  2.73284819e-02  1.93557739e-02  9.39623415e-02\n",
      "   3.24780308e-02 -4.61663529e-02  1.20862520e+00 -2.13800251e-01\n",
      "   4.21009868e-01  2.34764576e-01]\n",
      " [ 2.56990339e-03  6.72605494e-03 -2.60888878e-03 -4.64444747e-06\n",
      "  -1.37268761e-02 -3.52119328e-03  6.25894405e-03 -4.94559063e-03\n",
      "   4.50163521e-03  6.87502883e-03  2.17467104e-03  1.75563572e-03\n",
      "  -5.32721914e-03 -1.29312000e-04 -6.94816059e-04  5.86371683e-03\n",
      "  -2.11249513e-04  7.32514018e-05 -2.10861606e-03 -3.59654101e-03\n",
      "   6.82301004e-04  2.20263842e-03 -3.96965351e-03 -1.83285156e-03\n",
      "   5.71044162e-03  7.49758910e-05 -3.31593840e-03 -6.95292745e-03\n",
      "  -6.20303152e-04  6.46876916e-03  3.54567077e-04 -6.71849260e-03\n",
      "  -2.67843972e-03  4.32202825e-03  1.19916471e-02  2.40420923e-05\n",
      "   7.34793581e-03  1.29094487e-02 -1.07008321e-02 -9.02688131e-04\n",
      "  -1.60808663e-03 -1.95102405e-03  7.22840475e-03 -4.25248966e-03\n",
      "   6.04115892e-03 -9.58080962e-03  1.94612716e-04  3.13651492e-03\n",
      "  -9.10725357e-05 -5.82429208e-03  2.91091361e-04 -1.27062919e-02\n",
      "  -1.14377530e-04 -3.90832638e-03 -6.25293422e-03  3.57527309e-03\n",
      "  -6.16140757e-03  5.89985820e-03 -1.52873239e-02 -2.24718377e-02\n",
      "  -6.40134700e-03 -8.54543177e-05 -7.38472212e-03  3.98930977e-04\n",
      "  -1.52580533e-03  5.44809178e-03  1.60510298e-02 -1.04276612e-02\n",
      "  -3.17372289e-03  8.69537704e-03 -7.64228124e-03 -2.85183801e-03\n",
      "  -1.83833595e-02  3.10428703e-04 -9.21476725e-03 -9.32664145e-03\n",
      "  -1.51787214e-02 -2.51952335e-02  7.18542468e-03  7.97617063e-03\n",
      "   3.34724248e-03 -9.29341943e-04  1.53568862e-02 -1.02484906e-02\n",
      "  -5.55140944e-03 -3.37720774e-02 -1.83827318e-02 -9.15840361e-03\n",
      "   2.13249568e-02 -3.89056723e-03  3.13508394e-03  1.30333193e-03\n",
      "   2.95938496e-02  1.66061670e-02 -7.23488769e-03  1.41095165e-02\n",
      "   1.19411098e-02  3.15567222e-03  9.86815803e-03  4.33331588e-03\n",
      "  -3.80166178e-03 -1.11447321e-02  2.81366124e-03 -2.47861305e-03\n",
      "   8.54833517e-03 -9.66145657e-03 -5.09403925e-03 -2.31691934e-02\n",
      "  -4.45115659e-03 -1.40286265e-02  2.19046436e-02 -2.98444871e-02\n",
      "   2.56654737e-03 -3.04158088e-02 -6.25012023e-03 -9.00647044e-03\n",
      "  -1.85335241e-03 -2.89151352e-03  1.09823354e-01 -1.26173887e-02\n",
      "   8.59896839e-03 -9.09130797e-02  4.31546494e-02  2.36501005e-02\n",
      "   1.63863584e-01  2.21320242e-01  6.44481704e-02  2.49048881e-03\n",
      "  -2.95093888e-03 -1.24933533e-01  1.16541281e-01  8.68136063e-02\n",
      "   1.04958975e+00 -1.21995544e+00]\n",
      " [-8.09663092e-04 -3.09875607e-03  3.40284291e-03 -2.75990833e-03\n",
      "   3.80732794e-03 -1.81131950e-03 -5.77717274e-03  1.01902764e-02\n",
      "   8.40197690e-03 -1.00739226e-02 -3.36710946e-06 -4.87359799e-03\n",
      "  -4.20706812e-03 -3.60026956e-03  1.28119253e-03 -8.34643934e-03\n",
      "  -1.37292659e-02 -1.58112515e-02  8.19486380e-03 -2.40542111e-03\n",
      "   5.74928848e-03 -8.13102722e-03 -6.92789326e-05  1.51567589e-02\n",
      "   7.06138462e-03  6.96577411e-03  1.94731019e-02 -5.09655196e-03\n",
      "  -3.40560335e-03 -2.16613300e-02 -8.55250936e-03 -2.60723308e-02\n",
      "   3.08228517e-03 -1.96143910e-02 -2.77342997e-03  2.85172486e-03\n",
      "  -3.13477451e-03 -3.47621646e-03  1.73807535e-02  2.31565675e-04\n",
      "  -1.39366579e-03 -2.14300957e-02  5.51760290e-03 -1.76286057e-03\n",
      "  -7.33128749e-03 -4.09831246e-03  5.55824954e-03  4.06358438e-03\n",
      "  -2.73198122e-04  2.91676400e-03 -4.04989766e-03 -4.25302144e-03\n",
      "  -2.78343745e-02 -5.34031866e-03 -1.83386053e-03 -2.51919236e-02\n",
      "   2.89736483e-02  2.83545628e-02 -2.73500364e-02  3.89580019e-02\n",
      "  -1.48838898e-02 -8.35313741e-03  1.45494249e-02 -1.09953471e-02\n",
      "   3.14404592e-02 -2.26564566e-03  3.35425325e-03 -1.69546958e-02\n",
      "  -1.22395223e-02 -2.16411054e-02 -3.18698585e-02 -1.01103848e-02\n",
      "  -2.67371833e-02 -2.56153825e-03 -5.23767248e-02 -2.30157524e-02\n",
      "  -1.69011299e-02 -2.42033862e-02  3.12120630e-03  6.95256051e-04\n",
      "   3.69366095e-03 -5.96090872e-03  2.69755796e-02  2.12972984e-02\n",
      "  -3.44796218e-02  5.41329905e-02  2.14296672e-03  3.01415287e-02\n",
      "  -2.74002198e-02 -5.38938586e-03  1.74656361e-02  9.93869267e-03\n",
      "   7.05038458e-02  3.46732959e-02 -9.70565341e-03  1.74281411e-02\n",
      "  -5.10446616e-02  3.34976688e-02  7.06799980e-03  1.17932996e-02\n",
      "  -5.13426727e-04 -3.68131660e-02 -1.05873188e-02  3.00200703e-03\n",
      "   4.34279116e-03 -8.28372464e-02 -8.54633469e-03  2.51863897e-02\n",
      "  -4.80674431e-02 -1.82851888e-02  1.28240183e-01  3.54181342e-02\n",
      "  -1.27673559e-02  3.91982272e-02 -3.28171812e-03 -1.01202633e-02\n",
      "   6.02264330e-03  2.64542196e-02  9.27995890e-02  6.52590916e-02\n",
      "   8.83199051e-02 -1.36975855e-01  7.22302869e-02 -2.27733385e-02\n",
      "   2.34957218e-01  1.53868943e-01  8.07719305e-02 -9.55534637e-01\n",
      "   5.54099903e-02  5.55180693e+00  5.41910529e-03 -5.37496269e-01\n",
      "  -1.24151373e+00 -1.24958265e+00]\n",
      " [ 1.81521149e-03 -3.80892860e-04 -4.90600988e-03 -4.04341659e-03\n",
      "   3.39770340e-03 -3.38580081e-04 -4.41898918e-03  1.16493116e-04\n",
      "   1.33571180e-03  1.22975698e-03 -4.04515816e-03 -5.17266453e-04\n",
      "   3.90431494e-03  2.23362260e-03 -6.34528417e-03 -2.71036988e-03\n",
      "   2.95860460e-03  1.90549728e-03 -2.73649837e-03 -6.78945100e-03\n",
      "  -6.29561197e-04 -1.02579426e-02  1.74294983e-04  1.37729524e-03\n",
      "   1.50810683e-03  1.01613812e-02  9.81829129e-04  9.82326269e-03\n",
      "   1.48733729e-04  1.66756869e-03  5.13491966e-03  5.08905505e-04\n",
      "  -5.32638375e-03  1.07631111e-03 -7.96029158e-03 -3.76699260e-03\n",
      "  -7.62986997e-03 -7.07278773e-03 -7.70006143e-03 -1.03717670e-02\n",
      "   8.45427811e-03  1.17696170e-03 -7.54021015e-03 -1.23933691e-03\n",
      "   2.69339839e-03 -2.58046784e-04 -8.59849621e-04 -1.26202302e-02\n",
      "  -2.44225957e-03  6.73443917e-03 -4.62017301e-03 -1.07764853e-02\n",
      "   1.31809274e-02  9.26556811e-03  6.93837530e-04 -6.83222618e-03\n",
      "   6.65534195e-03  1.87679019e-04  1.12648858e-02 -1.34303020e-02\n",
      "   3.55842290e-03  1.69144175e-03 -2.09374493e-03  8.77851271e-04\n",
      "   4.55365889e-03 -3.47684743e-03 -4.07345314e-03  1.78385375e-03\n",
      "   4.09617787e-03  3.25050065e-03  1.94480140e-02  2.08031759e-02\n",
      "   1.31124733e-02  7.95987621e-03  9.96238273e-03  2.45648045e-02\n",
      "   3.98174510e-04  5.91530045e-03  4.92649199e-03 -3.54808290e-03\n",
      "   1.13511924e-04 -2.46127765e-03 -1.38267996e-02  6.47669844e-03\n",
      "   1.40766352e-02  5.06884884e-03  1.38073731e-02 -2.07383726e-02\n",
      "  -1.46859009e-02  1.53120626e-02 -4.19649482e-03  1.19141908e-02\n",
      "  -3.03917676e-02  6.65108161e-03 -1.55526469e-03 -9.59633756e-03\n",
      "   7.92045239e-03 -4.47353022e-03 -1.01170000e-02 -1.96566954e-02\n",
      "  -1.74816623e-02 -6.39107078e-03  5.40201738e-03 -6.13304414e-03\n",
      "  -7.23105483e-03 -2.11711768e-02 -1.36438408e-03  1.06723653e-02\n",
      "  -1.14543429e-02  3.05673270e-03  2.39991993e-02 -3.75719517e-02\n",
      "   5.59838768e-03  1.33817736e-02 -6.71879528e-03 -5.42400070e-02\n",
      "   2.93514021e-02 -1.72629002e-02 -1.06233899e-02  3.56314257e-02\n",
      "   2.52080522e-02  8.50271806e-03  4.37401868e-02 -5.53205013e-02\n",
      "   2.05314681e-01  6.17736615e-02  7.99764842e-02 -3.69918197e-02\n",
      "   1.14459999e-01 -2.93048024e-01 -5.73723495e-01  3.06148440e-01\n",
      "  -1.06536889e+00 -1.02921116e+00]\n",
      " [ 3.04406247e-04 -3.25358566e-03 -1.42508652e-03  2.28199456e-03\n",
      "   2.83990987e-03 -3.80039285e-03 -7.62565993e-03 -1.56005751e-03\n",
      "  -8.85257730e-04  1.06028758e-03  4.19094227e-03 -4.83052921e-04\n",
      "   7.64267286e-03  3.67693603e-03 -7.92573765e-03  2.37060525e-03\n",
      "  -1.78290938e-04  1.21121074e-03 -1.81709009e-04  9.56468866e-05\n",
      "   1.49555726e-03 -1.96697365e-04 -2.52770912e-03  3.61910526e-04\n",
      "   3.51672817e-04  1.18696308e-02  8.94626230e-03  3.45987221e-03\n",
      "  -8.35919578e-04 -1.90235977e-03  1.33864172e-02  2.36735214e-04\n",
      "   2.89418967e-03 -9.92878340e-03 -2.30551953e-03 -1.07685907e-03\n",
      "  -7.10525317e-03  1.72293819e-02  9.22871102e-03 -6.95257355e-03\n",
      "   1.58825647e-02  8.92666169e-03  7.15337228e-04  5.68854669e-03\n",
      "  -7.04877591e-03  3.24756582e-03 -8.51031765e-03 -1.04959803e-02\n",
      "   1.27555039e-02  5.02927136e-03 -6.68032048e-03 -1.02601643e-03\n",
      "   4.53146035e-03  1.61133986e-02 -1.01258717e-02 -7.25232344e-03\n",
      "   1.33725991e-02 -1.07702622e-02  2.27573253e-02 -7.34976912e-03\n",
      "   2.25345534e-03  2.40444904e-03  4.32525156e-03  2.84482911e-03\n",
      "   1.27616338e-02 -6.25051046e-03  7.81968236e-03  5.59904380e-03\n",
      "  -6.74207183e-03 -1.01683857e-02  1.79887889e-03 -2.47340836e-03\n",
      "   3.05357901e-03  2.66400818e-03 -3.40150623e-03  1.16738612e-02\n",
      "   1.02519840e-02  5.91029599e-03 -1.23381214e-02 -8.91074073e-03\n",
      "  -6.89355470e-03 -4.85846214e-03  1.47955562e-03  1.81638598e-02\n",
      "   3.21775600e-02  1.48665337e-02 -1.17872218e-02  7.45947473e-04\n",
      "  -1.00745605e-02  7.31138978e-03 -1.97613928e-02 -5.05155930e-03\n",
      "   3.14057432e-02 -7.73207750e-04 -3.37132253e-02 -4.19572406e-02\n",
      "  -3.87008786e-02 -9.72913112e-03  8.39983765e-03  7.78363436e-04\n",
      "   1.04825408e-03  4.21867706e-03  8.11622362e-04 -5.43884654e-03\n",
      "  -9.46971029e-03  1.45246089e-02 -2.23773289e-02  8.18998292e-02\n",
      "  -3.64992321e-02  2.40137912e-02 -3.03534046e-02  3.99345756e-02\n",
      "   6.36395812e-03  1.85897648e-02  1.31329307e-02 -4.85149883e-02\n",
      "   3.32238562e-02 -3.58081087e-02 -1.81556530e-02 -1.45403773e-01\n",
      "  -1.11732706e-02  2.97731645e-02  2.56568454e-02  4.67113405e-02\n",
      "  -6.36250228e-02 -1.14304349e-01 -3.10625788e-02 -5.39012179e-02\n",
      "   3.66955735e-02  1.19153999e-01 -5.37299216e-01  2.15301335e-01\n",
      "   9.67579722e-01  2.04137421e+00]]\n",
      "<NDArray 7x134 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "# get the trained kmeans params using mxnet\n",
    "kmeans_prefix = 'kmeans/output'\n",
    "\n",
    "unzipModel(k_estimator._current_job_name,bucket_name,kmeans_prefix,'model.tar.gz','model_kmeans')\n",
    "kmeans_model_params = mx.ndarray.load('model_kmeans')\n",
    "\n",
    "print(kmeans_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008352</td>\n",
       "      <td>-0.014145</td>\n",
       "      <td>-0.002474</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>-0.018283</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351790</td>\n",
       "      <td>-0.514499</td>\n",
       "      <td>-0.214743</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>-0.198050</td>\n",
       "      <td>-0.137004</td>\n",
       "      <td>-0.523704</td>\n",
       "      <td>-0.362903</td>\n",
       "      <td>0.526896</td>\n",
       "      <td>-2.229428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>-0.003062</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>-0.001419</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>-0.025524</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>-0.056613</td>\n",
       "      <td>-0.122309</td>\n",
       "      <td>-0.040442</td>\n",
       "      <td>-0.074922</td>\n",
       "      <td>-0.910048</td>\n",
       "      <td>1.116701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000377</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>-0.002842</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007938</td>\n",
       "      <td>0.027328</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.093962</td>\n",
       "      <td>0.032478</td>\n",
       "      <td>-0.046166</td>\n",
       "      <td>1.208625</td>\n",
       "      <td>-0.213800</td>\n",
       "      <td>0.421010</td>\n",
       "      <td>0.234765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>-0.002609</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.013727</td>\n",
       "      <td>-0.003521</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>-0.004946</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163864</td>\n",
       "      <td>0.221320</td>\n",
       "      <td>0.064448</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>-0.002951</td>\n",
       "      <td>-0.124934</td>\n",
       "      <td>0.116541</td>\n",
       "      <td>0.086814</td>\n",
       "      <td>1.049590</td>\n",
       "      <td>-1.219955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000810</td>\n",
       "      <td>-0.003099</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234957</td>\n",
       "      <td>0.153869</td>\n",
       "      <td>0.080772</td>\n",
       "      <td>-0.955535</td>\n",
       "      <td>0.055410</td>\n",
       "      <td>5.551807</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>-0.537496</td>\n",
       "      <td>-1.241514</td>\n",
       "      <td>-1.249583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001815</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>-0.004419</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205315</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>-0.036992</td>\n",
       "      <td>0.114460</td>\n",
       "      <td>-0.293048</td>\n",
       "      <td>-0.573723</td>\n",
       "      <td>0.306148</td>\n",
       "      <td>-1.065369</td>\n",
       "      <td>-1.029211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.003254</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>-0.003800</td>\n",
       "      <td>-0.007626</td>\n",
       "      <td>-0.001560</td>\n",
       "      <td>-0.000885</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063625</td>\n",
       "      <td>-0.114304</td>\n",
       "      <td>-0.031063</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>0.036696</td>\n",
       "      <td>0.119154</td>\n",
       "      <td>-0.537299</td>\n",
       "      <td>0.215301</td>\n",
       "      <td>0.967580</td>\n",
       "      <td>2.041374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.008352 -0.014145 -0.002474  0.000738  0.020321  0.005985 -0.018283   \n",
       "1  0.000126  0.001876  0.006130  0.001273 -0.003062 -0.000226  0.009724   \n",
       "2 -0.000377  0.001432  0.000805  0.000311  0.001009  0.004219  0.000801   \n",
       "3  0.002570  0.006726 -0.002609 -0.000005 -0.013727 -0.003521  0.006259   \n",
       "4 -0.000810 -0.003099  0.003403 -0.002760  0.003807 -0.001811 -0.005777   \n",
       "5  0.001815 -0.000381 -0.004906 -0.004043  0.003398 -0.000339 -0.004419   \n",
       "6  0.000304 -0.003254 -0.001425  0.002282  0.002840 -0.003800 -0.007626   \n",
       "\n",
       "        7         8         9    ...       124       125       126       127  \\\n",
       "0  0.019015 -0.006095 -0.010858  ... -0.351790 -0.514499 -0.214743  0.008582   \n",
       "1 -0.001419  0.002428  0.000081  ... -0.106363  0.025323 -0.025524  0.059052   \n",
       "2 -0.002842 -0.006122 -0.002155  ... -0.007938  0.027328  0.019356  0.093962   \n",
       "3 -0.004946  0.004502  0.006875  ...  0.163864  0.221320  0.064448  0.002490   \n",
       "4  0.010190  0.008402 -0.010074  ...  0.234957  0.153869  0.080772 -0.955535   \n",
       "5  0.000116  0.001336  0.001230  ...  0.205315  0.061774  0.079976 -0.036992   \n",
       "6 -0.001560 -0.000885  0.001060  ... -0.063625 -0.114304 -0.031063 -0.053901   \n",
       "\n",
       "        128       129       130       131       132       133  \n",
       "0 -0.198050 -0.137004 -0.523704 -0.362903  0.526896 -2.229428  \n",
       "1 -0.056613 -0.122309 -0.040442 -0.074922 -0.910048  1.116701  \n",
       "2  0.032478 -0.046166  1.208625 -0.213800  0.421010  0.234765  \n",
       "3 -0.002951 -0.124934  0.116541  0.086814  1.049590 -1.219955  \n",
       "4  0.055410  5.551807  0.005419 -0.537496 -1.241514 -1.249583  \n",
       "5  0.114460 -0.293048 -0.573723  0.306148 -1.065369 -1.029211  \n",
       "6  0.036696  0.119154 -0.537299  0.215301  0.967580  2.041374  \n",
       "\n",
       "[7 rows x 134 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get all the centroids\n",
    "cluster_centroids=pd.DataFrame(kmeans_model_params[0].asnumpy())\n",
    "cluster_centroids.columns=azdias_sub_pca.columns\n",
    "\n",
    "display(cluster_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select most relevant components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cluster_centroids = cluster_centroids[range(124,len(azdias_sub_pca.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApUAAAIrCAYAAAC+kWKiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XmcJXV97//Xe0YWNxZhAgoiGKMiRjQSo1cFJIkgbpigQXBLjBNzk58huVFwR4RgvDEqgSijqOACGhBBNjdEiAnqjIIXJCSoMDKCgyCIiiLD5/fHOaNN09NdPafO9Kmp19NHPaZP1bfrfE7R037m891SVUiSJEmjWLTQAUiSJKn7TColSZI0MpNKSZIkjcykUpIkSSMzqZQkSdLITColSZI0MpNKqWOS7JTkJ0kWD19fmOTPFzqu9TGu2JMckeQjbd93EiV5XZL3z3L9miR/sCFjktRPJpXSmA0Tpx8l2Wza+Q8lOWrauTkTgKpaWVX3q6o1LcS23slXkoOG8Wba+XslWZ3kWaPGNymSHJxk+TCZvz7JeUme0sJ9R05+q+ofqqqT/6iQtHExqZTGKMnOwFOBAp7Twv3uNeo9WvQpYCtgr2nn92Pwec/f4BGNQZK/A94F/AOwHbAT8K/AczfAeyeJv6cldYK/rKTxeglwCfAh4KVrTyZZChwCvGZY/fp0kg8zSFg+PTz3miQ7J6kkL0+yErhgyrmpCeZvJvlqkh8nOTPJA4bvs3eS66YGtLYammQ/4HXAnwzf77Lh9S2TnDisyK1KctTarvapqurnwCeGn3H6Z/5YVd2ZZOskZye5cVitPTvJjjM9qOlVu+mfs2lcU2ye5ONJbkvy9SS7D+/z6iSnT3vvY5O8e4aYtgSOBP6qqj5ZVT+tql9W1aer6tXDNouSHJ7k20luSvKJKc9/7Wd4aZKVSX6Y5PXDa+t6/hcmOTrJl4GfAQ9N8qAkZyW5OcnVSV4xy3N7cZJrh7G8fpbnI0mtMqmUxuslwEeHx75JtgOoqmXDc28fdmU/u6peDKwEnj089/Yp99kL2BXYd5b3+TPggcCdwLFzBVZV5zOovn18+H67Dy99aHiPhwGPA54OrKt79STgwCT3hl8lYc8enofB75gPAg9hkDDfDhw3V2zrMJ+4YFBJ/DfgAcDHgE8l2QT4CLBfkq2GMd8LOAg4eYZ7PAnYHDhjlvf5/4ADGPw3ehDwI+D4aW2eAjwC+H3gTUl2neX5A7wYWArcH7gWOBW4bnj/A4F/SLLP9ECSPAp4z/D7HwRsA8yYxEtS20wqpTEZjrl7CPCJqloBfBs4eD1vd8SwSnb7Oq5/uKour6qfAm8EXjBHFW9dMW8H7A8cOny/1cA7GSRd91BVXwZ+ADxveOoFwH9X1aXD6zdV1elV9bOqug04mnt2l7ce19CKqjqtqn4J/DOD5PCJVXU9cBHw/GG7/YAfDv8bTbfN8Nqds7zPK4HXV9V1VfUL4AgGifbUSvJbqur2qroMuAzYfYb7TPWhqrpi+L7bA08GDquqnw+f7fu5Z4UYBgnn2VV10TCWNwJ3zfFektQKk0ppfF4KfLaqfjh8/TGmdIHP0/fmcf1aYBNg2/V4n4cMv/f6JLckuQU4AfiNWb7nZH6d4LyYKRW/JPdJcsKwO/bHDJK5rdYj4V2fuH71TKrqLn5d6YNBJfVFw69fBHx4Hfe4Cdh2jrGsDwHOmBLXlcAaBuMv17phytc/A+43y/3uFvsw5puHSfla1wI7zPB9D+Lun/unw88gSWM3SYP+pY3GsDv4BcDiJGsTis0YJFS7DytWNcO3znRutvNrPXjK1zsBvwR+CPwUuM+UuBYDS2a57/eAXwDbzlGdm+rDDLp0nwQ8kcHnXuv/MOj2/b2quiHJY4FvALnnbe4eK4MK3Shx/eqZDCe77Ah8f3jqU8B7kjwaeBbwmnXc4z+H73sAcNo62nwP+LNh1fZuMpioNZsm/72/Dzwgyf2nJJY7Aatm+L7rGQyTWPv+92FQbZWksbNSKY3HAQyqVY8CHjs8dgUu5tdVvR8AD532fTOda+JFSR41TCKOBE4bLjn03wwmrDxzOJ7wDQyS26nvt/Mw6WLYNfxZ4B1JthhOQvnNJOvssq6qa4B/B04BPldVU6ty92cwjvKW4eSVN8/yGS4F9sxgHc4tgddOeY95xwU8PskfDauMhzJIDi8Z3u/nDJLEjwFfraqV6/hstwJvAo5PcsCw8rpJkmckWTvm9b3A0UkeApBkSZKmM8Pv9vzXEcP3gP8AjkmyeZLHAC9nMDZ0utOAZyV5SpJNGfws+Hte0gbhLxtpPF4KfHC4puQNaw8Gk1QOGSY6JwKPGnabfmr4fccAbxie+/t5vN+HGUxkuYHB2MFXwa+Sov/NYAzeKgbVwKmzwf9t+OdNSb4+/PolwKbAtxhMOjmNwQSg2ZzEoBt4+mSXdwH3ZlA1vYRZlhmqqs8BHwe+CawAzp7WZL5xnQn8ybDti4E/Go6vnBrzb7Puru+1cb0D+DsGCfmNDCqTf82g2gnwbuAs4LNJbht+zt+b7Z5TzPT8Z/JCYGcGVcszgDdX1edniPUK4K8YJMvXM/js101vJ0njkKq5etUkaeOTZCfgv4Dtq+rHCx2PJHWdlUpJvTPsbv474FQTSklqhxN1JPVKkvsyGMt4LYPlhCRJLbD7W5IkSSOz+1uSJEkjM6mUJEnSyBZkTOXXbjzHPvd5uPWOmdaJ1mxuX+Mzm4+f/tLnNV+/uMtnNh+LfFzztmRzd9icr/12fMaC/6Tde6cXjj3HuX3lKQv+OWdipVKSJEkjc/a3JElSS2bZIGuj199PLkmSpNZYqZQkSWpJelyv6+8nlyRJUmusVEqSJLXEMZWSJEnSCKxUSpIktcRKpSRJkjQCK5WSJEktSSZys5sNwkqlJEmSRmalUpIkqTX9rdeZVEqSJLXEiTqSJEnSCKxUSpIktcRKpSRJkjQCK5WSJEktSY/rdf395JIkSWqNlUpJkqSWOKZSkiRJGoGVSkmSpJZYqVxPSTZP8s9JHtpWQJIkSeqeUSuVmwF/A5wBfGf0cCRJkrrLSuUskqxc1wFcDgQ4bXju2lnuszTJ8iTLzzj5/BY/giRJkhZak0rljsD1wGdnuLYp8ELg68ANs92kqpYBywC+duM5Nb8wJUmSJl/IQoewYJoklQcD7wS2B/6qqn7VzZ1kKwZJ5TFVddF4QpQkSdKkm7P7u6pOBR4JfA/4ZpI3Jdl07eVxBidJktQlyaKxH5OqUWRVdWtVLQX2BV4AXJ7kD8camSRJkjpjXrO/q+rLSR4LHA6cCXwBq5WSJEmAs7/nparurKqjgMcAi4GVwM/bDkySJEndsd7rVFbV1cD+LcYiSZLUaVYqJUmSpBE0qlQm2QF4BbAD8C3gA1V167Q2uwLHV9U+rUcpSZLUCf2t182ZVCbZGVgObA3cCLwcOCzJIVX1hSlNtwD2GkOMkiRJnWD39+yOAlYDu1TV9sBuwFXAuUkOHmdwkiRJ6oYm3d9PBQ6rqpUAVXVlkn2A44GTk2xZVe8ZZ5CSJEld0OdKZZOkcltg1dQTVbUGeGWSW4DjkmwBXNh+eJIkSeqCJknlSgZd3hdPv1BVhye5DTgGOK/l2CRJkjolPZ6o0+STXwQcsq6LVXU0cCiwX1tBSZIkqVuaVCqXAQcl2aaqbpqpQVUdm2Q1g73BJUmSeskxlbOoqhXAigbtTgVObSMoSZIkdUtr6XSSPZNc0Nb9JEmSuibJ2I9J1WaNdgkufi5JktRLTXbU2anhvZaMGIskSVKnOaZydtcA1aBdGraTJEnSRqZJUnk7g2WFTpuj3R7A0pEjkiRJ6qg+r1PZJKm8DFhTVSfO1mi4u45JpSRJUg81SSpXAAc2vF+jKUmbLraXfD5+emd//9WjDeOXNbmzCSfVZov8PTYfm/l7f97uFZ9ZFzmmcnZvY+6ub6rqdNqdTS5JkqSOaLL4+Spg1QaIRZIkqdP6XKns7yeXJElSa5p0f0uSJKmBPs/+7u8nlyRJUmusVEqSJLWlx2MqTSolSZJa4kQdSZIkaQRWKiVJklqS9HczCSuVkiRJGpmVSkmSpJa4pJAkSZI0AiuVkiRJLXH2tyRJkjYaSRYn+UaSs2e49rIkNya5dHj8eRvvaaVSkiSpLZMz+/tvgCuBLdZx/eNV9ddtvqGVSkmSpI1Ikh2BZwLv35Dva1IpSZLUlkUb4Jjbu4DXAHfN0uaPk3wzyWlJHjyfj7guJpWSJEkdkmRpkuVTjqVTrj0LWF1VK2a5xaeBnavqMcDngJPaiMsxlZIkSW3ZAGMqq2oZsGwdl58MPCfJ/sDmwBZJPlJVL5ry/TdNaf9+4O1txGWlUpIkaSNRVa+tqh2ramfgIOCCqQklQJIHTnn5HAYTekZmpVKSJKktkzP7+26SHAksr6qzgFcleQ5wJ3Az8LI23sOkUpIkaSNUVRcCFw6/ftOU868FXtv2+42UVCbZDqiqWt1SPJIkSd3V44GFc370JM9JsuW0cwcnuRb4PnB9ku8mef64gpQkSdJka5JPnwE8Yu2LJM8FPgL8ADh8eNwMnJrkD9Z1k6nT30876fzRopYkSZpAlYz9mFRNur+nR384g/75P6iquwCS/PPw3GuAz890k6nT3y+7+exav3AlSZI0idan5/9xwHFrE0qAqloDHA/s0VZgkiRJnZMNcEyo9Ukq1zDo+p7uBuC+o4UjSZKkLmo6+/uIJD8cfn0HsAvw5WltHsxgbKUkSVI/LZrgUuKYNUkqVwK7Tnl9C/C7DCbrTLU/cEVLcUmSJHXPBE+kGbc5k8rhNj9NnAl8d6RoJEmS1Emt7ahTVae2dS9JkqRO6m+hss/rvkuSJKktjSqVSXYAXgHsAHwL+EBV3Tqtza7A8VW1T+tRSpIkdYETddYtyc7AcmBr4Ebg5cBhSQ6pqi9MaboFsNcYYpQkSdKEa9L9fRSwGtilqrYHdgOuAs5NcvA4g5MkSeqUZPzHhGqSVD4VOLKqVgJU1ZXAPsAHgZOT/OUY45MkSVIHNBlTuS2wauqJ4baMr0xyC3Bcki0Y7P0tSZLUX5NbSBy7pouf7wZcPP1CVR2e5DbgGOC8lmOTJElSRzRJKi8CDgHeO9PFqjp6mFi+s83AJEmSOsfZ37NaBhyUZJuqummmBlV1bJLVwL6tRidJkqROaLJN4wpgRYN2pwLuqiNJkvqrv4XK9nbUSbJnkgvaup8kSZK6o7W9v4EluPi5JEnqsZrgdSTHrcmOOjs1vNeSEWORJElSRzWpVF4DVIN2adhOkiRp4+Ts71ndzmBZodPmaLcHsHTkiCRJktQ5TZLKy4A1VXXibI2Gu+uYVEqSpP7qb6GyUVK5Ajiw4f0aPcof39HjJ74e7tXaHP3+uMuBGPNyv3vdtdAhdM6a8veYxusXd/kzpm5pklS+jbm7vqmq02lxiSJJkqTOcfb3ulXVKmDVBohFkiSp23o8UcfKoiRJkkbW5uLnkiRJ/dbfQqWVSkmSJI3OSqUkSVJbejxRx0qlJEmSRmalUpIkqS1WKiVJkqT1Z6VSkiSpLT0u1/X4o0uSJKktViolSZLa4phKSZIkaf1ZqZQkSWpLfwuVViolSZI0OiuVkiRJLalF/S1VWqmUJEnSyKxUSpIktcXZ35IkSdL6s1IpSZLUlv4WKq1USpIkaXRWKiVJktrS49nf651UJtkXeBxwF/C1qvpia1FJkiR1UY8n6syZVCY5Grizqt48fP0A4Hzg8fx65EAl+SLwnKr62biClSRJ0mRqMqbyhcDVU16/E3jo8PwDhseLgN8B/mFdN0myNMnyJMvP+vD56x+xJEnSpMoGOCZUk+7vBwHXTHn9bOA1VfWJKedOSbI18Hrg0JluUlXLgGUAF99wTq1XtJIkSZpITZLKHwHbTXl9H+5euVzrfxhULSVJkvqpxxN1mnR/nwe8KsnathcBfzxDuz9ikFhKkiSpZ5pUKt8AfBX4jyTHAicAJybZEfj8sM2+wDOBl4wlSkmSpC7ocaVyzqSyqr6f5MkMksmPAMVgmOhzhwfADcCfVtVHxxWoJEmSJlejdSqr6lpgvyQPBZ7MYPLOIuAm4ArgkqpaM7YoJUmSOqD6W6ic3+LnVfUd4DtjikWSJEkd5TaNkiRJbenxmMoms79JskOSI5K8L8nfJtlyhja7Jrmg/RAlSZI06Zps07gzsBzYGrgReDlwWJJDquoLU5puAew1hhglSZK6ocd7fzepVB4FrAZ2qartgd2Aq4Bzkxw8zuAkSZLUDU3GVD4VOKyqVgJU1ZVJ9gGOB05OsmVVvWecQUqSJHVCj8dUNkkqtwVWTT0xXD7olUluAY5LsgVwYfvhSZIkqQuaJJUrGXR5Xzz9QlUdnuQ24BgG2zlKkiT1V6Mp0BunJh/9IuCQdV2sqqOBQ4H92gpKkiRJ3dKkUrkMOCjJNlV100wNqurYJKsZ7AEuSZLUTz2e/d1k7+8VwIoG7U4FTm0jKEmSJHVLaz3/SfZ08XNJktRrizL+Y0K1uU3jElz8XJIk9VjZ/b1uSXZqeK8lI8YiSZKkjmpSqbwGqAbt0rCdJEnSxqnHSwo1SSpvZ7Cs0GlztNsDWDpyRJIkSeqcJknlZcCaqjpxtkbD3XVMKiVJUn9N8ESacWuSVK4ADmx4v0ZP8pY7elwbXg933rXQEXTPmurvX+r1sdliR67M1x7b/HKhQ+iUb97c5rzQfljsrzF1TJO/5W9j7q5vqup0ej2SQJIk9Z6zv9etqlYBqzZALJIkSeoo+yMkSZLa0uMxlXZXS5IkaWRWKiVJktrS30KllUpJkiSNzkqlJElSS8oxlZIkSdL6s1IpSZLUFiuVkiRJ0vozqZQkSWpLMv5jzhCyeZKvJrksyRVJ3jJDm82SfDzJ1Um+kmTnUT+6SaUkSdLG5RfAPlW1O/BYYL8kT5zW5uXAj6rqYcA7gX8c9U1NKiVJktqyaAMcc6iBnwxfbjI8alqz5wInDb8+Dfj9ZLSNy00qJUmSOiTJ0iTLpxxLZ2izOMmlwGrgc1X1lWlNdgC+B1BVdwK3AtuMEpezvyVJktoyWrGvkapaBiybo80a4LFJtgLOSPLoqrp8nHFZqZQkSdpIVdUtwBeB/aZdWgU8GCDJvYAtgZtGeS+TSkmSpLYsyviPOSRZMqxQkuTewB8C/zWt2VnAS4dfHwhcUFXTx13Oi93fkiRJbZmMxc8fCJyUZDGDAuInqursJEcCy6vqLOBE4MNJrgZuBg4a9U1NKiVJkjYiVfVN4HEznH/TlK9/Djy/zfc1qZQkSWpJbYCJOpPKMZWSJEkamZVKSZKktvS4XDfnR0/yGxsiEEmSJHVXk3z6+iT/meSVa6enS5IkaQbJ+I8J1SSpDPAw4F8ZJJifSPLMJPMq8E7dUuj8j523PrFKkiRpQjUdU/ksYFMGi2QeCPwxsDrJR4GTh1PXZzV1S6FPrzxvpMU1JUmSJtJkrFO5IJpWG6uqLq6qPwe2B14EXAb8DfCNJN9I8jdJlowrUEmSJE2uec9RqqqfV9UpVbUfgz0jDwcWA+8EvtdyfJIkSd0xAds0LpSRJr5X1Q1V9X+r6jHAHsB72wlLkiRJXdLaOpVV9XXg623dT5IkqXMmt5A4dk0qlX8KfHvcgUiSJKm75qxUVtVJGyIQSZKkrqsJHvM4bj3eTEiSJEltaTSmMskOwCuAHYBvAR+oqluntdkVOL6q9mk9SkmSpC6Y4B1vxm3OpDLJzsByYGvgRuDlwGFJDqmqL0xpugWw1xhilCRJ0oRr0v19FLAa2KWqtgd2A64Czk1y8DiDkyRJ6hTXqZzVU4Ejq2olQFVdCewDfBA4OclfjjE+SZIkdUCTMZXbAqumnqiqNcArk9wCHJdkC+DC9sOTJEnqkMktJI5dk6RyJYMu74unX6iqw5PcBhwDnNdybJIkSZ2yqMfr6jT56BcBh6zrYlUdDRwK7NdWUJIkSeqWJpXKZcBBSbapqptmalBVxyZZDezbanSSJEkd0uMVhRrtqLMCWNGg3anAqW0EJUmSpG5prec/yZ5JLmjrfpIkSV2TjP+YVG0OJ12Ci59LkiT1UpMddXZqeK8lI8YiSZLUaZnkUuKYNZmocw1QDdqlYTtJkiRtZJoklbczWFbotDna7QEsHTkiSZKkjupxobJRUnkZsKaqTpyt0XB3HZNKSZKkHmqSVK4ADmx4v0b5+Vab3tXwdgL46Z09Xp5/Pf1ijSMxNF7Lb2zy61Nr/fKuHpdv1tNmi/091kVWKmf3Nubu+qaqTqfd2eSSJEnqiCaLn68CVm2AWCRJkjotPS6v9fijS5IkqS0OCpIkSWpJn8dUWqmUJEnSyKxUSpIktWSRlUpJkiRp/VmplCRJaoljKiVJkqQRWKmUJElqSZ8rlSaVkiRJLUmPs0q7vyVJkjQyK5WSJEktcZtGSZIkaQRWKiVJklrS4yGVViolSZI0OiuVkiRJLbFSKUmSJI3ASqUkSVJLrFRKkiRJI7BSKUmS1JJFViolSZKk9de4Upnkt4BFVXXVlHPPBnYFVgFnVNXP2g9RkiSpG/o8pnLOpDLJtsBZwO8NX58LHAicDuw/pem1Sf5XVV0/jkAlSZI0uZp0f78Z+C3gfwOHAA8F/g14PPB0YCtgP2DzYdsZJVmaZHmS5Wd9+PxR45YkSZo4yfiPSdWk+/uZwBur6gSAJN8BLgH+oqo+P2zz2SRHAn+/rptU1TJgGcDFN5xTI0UtSZKkidIkqdwe+NaU11cM/7xyWrsrgQe2EZQkSVIXpcfTv5t0f18PPHLK60dO+3PqecdTSpIk9VCTSuXZwFuTrAFuA94InAEckeRqYDnwBOANwHnjClSSJGnSTfKYx3FrklS+BdgDeN/w9ZeAFwPvBy4A1o6PvB44ouX4JEmS1AFzJpVVdTPw5OE6lZtW1doxlQcn+SjwaOAG4JNVddv4QpUkSZpsViobqKr/meHcOcA5rUYkSZLUUX1OKt2mUZIkSSNrVKlMsgPwCmAHBssLfaCqbp3WZlfg+Krap/UoJUmSOqDHKwo12qZxZwYzvLcGbgReDhyW5JCq+sKUplsAe40hRkmSJE24Jt3fRwGrgV2qantgN+Aq4NwkB48zOEmSpC7p8zaNTZLKpwJHVtVKgKq6EtgH+CBwcpK/HGN8kiRJ6oAmYyq3BVZNPVFVa4BXJrkFOC7JFsCF7YcnSZLUHenxFOgmSeVKBl3eF0+/UFWHJ7kNOAZ305EkSeqtJvn0RcAh67pYVUcDhwL7tRWUJElSF/V5TGWTSuUy4KAk21TVTTM1qKpjk6wG9m01OkmSJHVCk20aVwArGrQ7FTi1jaAkSZK6KJNcShyz1oaTJtkzyQVt3U+SJEnd0Xjv7waW4OLnkiSpx3pcqGy0o85ODe+1ZMRYJEmS1FFNKpXXANWgXRq2kyRJ2ihZqZzd7QyWFTptjnZ7AEtHjkiSJEmd0ySpvAxYU1UnztZouLuOSaUkSeotK5WzWwEc2PB+jR7lL+/q8RNfD/eKowrmbbE/Y/Phz9j8PfspH17oEDrlwuUvWugQOufanyxe6BCkeWmSVL6Nubu+qarTaXGJIkmSpK5Z1OOaRpPFz1cBqzZALJIkSeqoNteplCRJ6rU+VyrtrpYkSdLIrFRKkiS1ZFGPJz6aVEqSJLXE7m9JkiRtFJJ8IMnqJJev4/reSW5NcunweFMb72ulUpIkqSUTUq37EHAccPIsbS6uqme1+aYT8tklSZLUhqq6CLh5Q7+vSaUkSVJLFqXGfiRZmmT5lGN9tsl+UpLLkpyXZLc2Prvd35IkSR1SVcuAZSPc4uvAQ6rqJ0n2Bz4F/NaocVmplCRJasmijP8YVVX9uKp+Mvz6XGCTJNuOel+TSkmSpB5Jsn2SDL9+AoN88KZR72v3tyRJUksmoVqX5BRgb2DbJNcBbwY2Aaiq9wIHAn+Z5E7gduCgqhp51XaTSkmSpI1IVb1wjuvHMVhyqFUmlZIkSS1xRx1JkiRpBFYqJUmSWpKMPDSxs6xUSpIkaWRWKiVJklrimEpJkiRpBFYqJUmSWtLnat28ksokDwQeDTwAuAu4HlhRVbePITZJkiR1RKOkMsmewNuB353h8u1JTgZeV1W3tBmcJElSlyxy9ve6JXk68Hng3sA/A8cAX2JQqXwj8FbgD4F/T7LVLPdZmmR5kuVnf+S8NmKXJEnShGhSqTwS+FRVvWDqySSvA15WVQ9PcjywHDgCOHSmm1TVMmAZwAXfP7e/abwkSdpoOft7do8BTpzh/AnAw5I8vKp+AvwT8EdtBidJktQlizbAMamaxPYTYLsZzj8QKGDN8PX/AL/RUlySJEnqkCbd32cD/5Dku1V1MUCSRzCoXn63qr49bLctsHo8YUqSJE2+Pnd/N0kqXw3sAVyY5Hbgl8AWwE3A86a0ezzwudYjlCRJ0sSbM6msqpuS7AG8APg9Bt3dVwEfq6pbp7R73diilCRJ6oA+LynUaJ3KqroD+MjwkCRJku7GbRolSZJa0ucxlY1mpifZIckRSd6X5G+TbDlDm12TXNB+iJIkSZp0c1Yqk+zMYGHzrYEbgZcDhyU5pKq+MKXpFsBeY4hRkiSpEyZ5Hclxa/LZj2KwVNAuVbU9sBuDiTrnJjl4nMFJkiSpG5qMqXwqcFhVrQSoqiuT7AMcD5ycZMuqes84g5QkSeoCZ3/Pbltg1dQTVbUGeGWSW4DjkmwBXNh+eJIkSeqCJknlSgZd3hdPv1BVhye5DTgGOK/l2CRJkjrF2d+zuwg4ZF0Xq+po4FBgv7aCkiRJUrc0qVQuAw5Ksk1V3TRTg6o6NslqYN9Wo5MkSeqQPlcqm2zTuAJY0aDdqcCpbQQlSZKkbmltOaUke7r4uSRJ6rNFG+CYVG3GtgQXP5ckSeqlJjvq7NTwXktGjEWSJKnTXKdydtcATZ5QGraTJEnSRqZJUnk7g2WFTpuj3R7A0pEjkiRJ6ihnf8/uMmBNVZ04W6Ph7jomlZIkqbcmeSLNuDVJKlcABza8X6P8fJvN72p4OwFc99PFCx1C53z8O/dZ6BA65VkPvn2hQ+icT/z7SxY6hE657yZrFjqEznn2ox1vAAAXLElEQVTkVncudAjSvDRJKt/G3F3fVNXp9DtBlyRJPWf39yyqahWwagPEIkmSpI5qUqmUJElSA+nxkkJ2V0uSJGlkViolSZJa0ucxlVYqJUmSNDIrlZIkSS3pc7Wuz59dkiRJLbFSKUmS1JJFzv6WJEmS1p+VSkmSpJY4+1uSJEkagZVKSZKklliplCRJkkZgpVKSJKklixc6gAVkpVKSJEkjs1IpSZLUEteplCRJkkZgpVKSJKklfZ79bVIpSZLUkj4nlXZ/S5IkaWRWKiVJklqyuMeVynkllUk2AR4GPGB46mbg6qr6ZduBSZIkqTsaJZVJHgMcCewLbDrt8h1JPgO8uaouazk+SZKkznBM5SySPBW4BHgk8I/AQcDTh8dBw3MPB/5z2HZd91maZHmS5aeddH4bsUuSJGlCNKlU/iNwHvCCqlozw/V/S/JW4OPA24EnzXSTqloGLAO47Oaz+7syqCRJ2mi5+PnsHgsct46EEoDhtX8Fdm8rMEmSJHVHk0rlLcAuwBfnaLfLsK0kSVIv9XlMZZOk8qPAPyW5E/hEVf186sUkmwPPZ9D1/cH2Q5QkSdKka5JUvgF4EPAhYFmS7wI/Gl7bmkGFclMGYypfP4YYJUmSOmHxQgewgOZMKqvqF8AhSd4OPAd4FL9ep3Il8DHg01V16diilCRJ0kRrvPj5cA1K16GUJElahz6PqXTvb0mSJI2sUVKZ5IAkZyY5Pcnew3P7J/lWkjuSXJnk+WONVJIkacItSo39mFRNdtR5BvBJ4HEMds45P8kBwOnAD4B3A7cCpyR54hhjlSRJ0oRqMqbyMOBs4HlVtSbJm4CTgDOr6iCAJAE+AxwOHDCuYCVJkibZYsdUzmo34H1TdtQ5Abg/cPLaBlVVwPtxRx1JkqRealKpvC/w4ymvfzj884Zp7W4Atm8jKEmSpC5y9vfsVgM7Tnl9F/AO7plUbs9gbKUkSZJ6pkml8lJgbwbbNa7t6n71DO2eDFzeWmSSJEkd0+dKZZOk8lXA/Rq0u5nBTHBJkqReMqmcRVWtbHKjqnrL6OFIkiSpi1rbUSfJnkkuaOt+kiRJXbM4NfZjUrW5TeMSYK8W7ydJkqSOmLP7O8lODe+1ZMRYJEmSOq3Nal3XNJmocw3QpNaahu0kSZK0kWmSVN4OXAScNke7PYClI0ckSZLUUc7+nt1lwJqqOnG2RkluwaRSkiSpl5oklSuAAxver1F+fseaHqfx62GTRY4qmK9XPOInCx1Cp/zg9sULHULnPOR+axY6hE75yupNFjqEztnUv5bz9pgHLHQEVirn8jbm7vqmqk6n3+NTJUmSeqvJ4uergFUbIBZJkqROm+R1JMfNyqIkSdJGJMl+Sa5KcnWSw2e4vlmSjw+vfyXJzm28r0mlJElSSxZl/MdskiwGjgeeATwKeGGSR01r9nLgR1X1MOCdwD+28tnbuIkkSZImwhOAq6vqO1V1B3Aq8NxpbZ4LnDT8+jTg95OMPMWoyUQdSZIkNTABs793AL435fV1wO+tq01V3ZnkVmAb4IejvLGVSkmSpA5JsjTJ8inHRKwTbqVSkiSpJRuiUllVy4Bl67i8CnjwlNc7cs9VfNa2uS7JvYAtgZtGjctKpSRJ0sbja8BvJdklyabAQcBZ09qcBbx0+PWBwAVVNfJaSFYqJUmSWrJ4gcdUDsdI/jXwGWAx8IGquiLJkcDyqjoLOBH4cJKrgZsZJJ4jM6mUJEnaiFTVucC50869acrXPwee3/b7mlRKkiS1ZJE76kiSJEnrz0qlJElSS/pcrTOplCRJaskELH6+YPqcUEuSJKklViolSZJastBLCi0kK5WSJEkamZVKSZKklrikkCRJkjQCK5WSJEktcfa3JEmSNAIrlZIkSS2xUtmCJH+cZM0s15cmWZ5k+Rknn9/W20qSJGkCbLBKZVUtA5YBfO3Gc/o7NUqSJG20+jyucM6kMslLGt7rd0eMRZIkSR3VpFL5IaCAJqMErEBKkqTeSo/HVDZJKm8GPg0cNUe7ZwDvHjkiSZIkdU6TpHIF8NCq+vZsjZJc305IkiRJ3dTjQmWj8aQrgMc1aHcjcNFo4UiSJKmL5kwqq+p1VbVFg3YXVdXT2glLkiSpe5LxH5OqzzPfJUmS1BJ31JEkSWpJn6t1jT57kgOSnJnk9CR7D8/tn+RbSe5IcmWS5481UkmSJE2sJoufPwP4JHAdcCtwfpKDgFOAS4BzgKcCpyT5XlVdMsZ4JUmSJlbS3yW7m3R/HwacDTyvqtYkeRNwEnBmVR0EkCTAZ4DDgQPGFawkSdIkm+B5NGPXpPt7N+B9VbVm+PoE4P7AyWsbVFUB7wd2bz1CSZIkTbwmlcr7Aj+e8vqHwz9vmNbuBmD7NoKSJEnqokle8mfcmlQqVwM7Tnl9F/AO7plUbs9gzKUkSZJ6pklSeSmw99oXNfDqqvr+tHZPBi5vMTZJkqROyQY4JlWT7u9XAfdr0O5m4N2jhSNJkqQumjOprKqVTW5UVW8ZPRxJkqTuWjTJpcQxa23h9yR7JrmgrftJkiSpO9rcpnEJsFeL95MkSeqUHhcqG+2os1PDey0ZMRZJkiR1VJNK5TVAkz2H0rCdJEnSRqnP61Q2SSpvBy4CTpuj3R7A0pEjkiRJUuc0SSovA9ZU1YmzNUpyCw2Tyotu2LRJMw0duMvPFzqEzjlr5WYLHUKnXHnLJgsdQufs86A7FjqETlmyuc9rvo65rMlqfprqxQ9b6Aj6PaayyezvFcDjG96vz89SkiSpt5pUKt/G3F3fVNXptLhEkSRJUtf0ubrWZPHzVcCqDRCLJEmSOqrNdSolSZJ6zR11JEmSpBFYqZQkSWpJjwuVViolSZI0OiuVkiRJLUn6u7mgSaUkSVJL7P6WJEmSRmClUpIkqSXpcanSSqUkSZJGZqVSkiSpJX2u1vX5s0uSJKklViolSZJa4phKSZIkaQRWKiVJklrS40KllUpJkiSNzkqlJElSSxxTKUmSJI3ASqUkSVJLelyotFIpSZKk0VmplCRJasmiHpcqG1Uqk+yQ5Igk70vyt0m2nKHNrkkuaD9ESZIkTbo5k8okOwOXAW8Eng28A7gqye9Pa7oFsNcs91maZHmS5Zecds56ByxJkjSpsgGOSdWkUnkUsBrYpaq2B3YDrgLOTXJw0zeqqmVVtUdV7fHEA5+5ftFKkiRpIjUZU/lU4LCqWglQVVcm2Qc4Hjg5yZZV9Z5xBilJktQFSS10CAumSVK5LbBq6omqWgO8MsktwHFJtgAubD88SZIkdUGTpHIlgy7vi6dfqKrDk9wGHAOc13JskiRJnTLJYx7HrcmYyouAQ9Z1saqOBg4F9msrKEmSpC5Kxn9MqiaVymXAQUm2qaqbZmpQVccmWQ3s22p0kiRJ6oQ5k8qqWgGsaNDuVODUNoKSJEnqogkuJI6d2zRKkiRpZE131DkgyZlJTk+y9/Dc/km+leSOJFcmef5YI5UkSZpwizbAMama7KjzDOCTwOOAhwPnJzkAOB34AfBu4FbglCRPHGOskiRJmlBNJuocBpwNPK+q1iR5E3AScGZVHQSQJMBngMOBA8YVrCRJ0iSb5NnZ49akirob8L7hgucAJwD3B05e26CqCng/sHvrEUqSJGniNalU3hf48ZTXPxz+ecO0djcA27cRlCRJUjf1t1TZpFK5Gthxyuu7gHdwz6RyewZjKyVJktQzTZLKS4G9176ogVdX1fentXsycHmLsUmSJHVKNsD/JlWT7u9XAfdr0O5mBjPBJUmS1DNNdtRZ2eRGVfWW0cORJEnqrmSSV5Icr9Y+eZI9k1zQ1v0kSZLUHU26v5taAuzV4v0kSZI6ZnLHPI7bnEllkp0a3mvJiLFIkiSpo5pUKq8BqkG7NGwnSZK0UZrk2dnj1iSpvB24CDhtjnZ7AEtHjkiSJEmd0ySpvAxYU1UnztYoyS2YVEqSpF6zUjmbFcCBDe/X6En+n99+SMPbCeDP/336OvOay1O3+8VCh9Apb/2d2xY6BG3kHBs1f/9xbZtzaXviSQsdQL81+Yl9G3N3fVNVp9PiEkWSJEldM+nrVCZ5PnAEsCvwhKpavo521wC3AWuAO6tqj7nu3WTx81XAqnnEK0mSpMl0OfBHwAkN2j6tqn7Y9MbW1iVJkloz2WMqq+pKgKT9OCe7RitJktQh2RD/S5YmWT7lGMdE6QI+m2RF0/tbqZQkSeqQqloGLFvX9SSfB7af4dLrq+rMhm/zlKpaleQ3gM8l+a+qumi2bzCplCRJaskkLH5eVX/Qwj1WDf9cneQM4AkM1i1fJ7u/JUmS9CtJ7pvk/mu/Bp7OYILPrEwqJUmSWrNoAxzrL8nzklzHYFXPc5J8Znj+QUnOHTbbDvj3JJcBXwXOqarz57q33d+SJEk9UVVnAGfMcP77wP7Dr78D7D7fe5tUSpIktWQcS/V0hd3fkiRJGpmVSkmSpNZYqZQkSZLWm5VKSZKklkzCOpULxUqlJEmSRmalUpIkqTX9rdf195NLkiSpNVYqJUmSWuKYSkmSJGkEViolSZJa4o46kiRJ0gisVEqSJLXGSqUkSZK03hollUkOSHJmktOT7D08t3+SbyW5I8mVSZ4/1kglSZImXFg09mNSzRlZkmcAnwQeBzwcOD/JAcDpwA+AdwO3AqckeeIs91maZHmS5cuWfbyV4CVJkiZLNsAxmZqMqTwMOBt4XlWtSfIm4CTgzKo6CCCDqU6fAQ4HDpjpJlW1DFg2ePXfNXLkkiRJmhhNaqi7Ae+rqjXD1ycA9wdOXtugqgp4P7B76xFKkiR1RJKxH5OqSVJ5X+DHU17/cPjnDdPa3QBs30ZQkiRJ6pYm3d+rgR2nvL4LeAf3TCq3ZzC2UpIkqacmt5I4bk0qlZcCe699UQOvrqrvT2v3ZODyFmOTJElSRzSpVL4KuF+DdjczmAkuSZLUS5O85M+4zZlUVtXKJjeqqreMHo4kSZK6yG0aJUmSWuOYylm5o44kSZJmM2elcsqOOtcxmN19fpKDgFOAS4BzgKcy2FHne1V1yRjjlSRJmljpcaVyg+2oI0mSpI2XO+pIkiS1xB11ZueOOpIkSZqVO+pIkiS1pr/rVLqjjiRJkkbmjjqSJEktcfb3LNxRR5IkSXNpreM/yZ5JLmjrfpIkSd2TDXBMpjZHky4B9mrxfpIkSeqIJjvq7NTwXktGjEWSJKnTJnkdyXFrMlHnGqAatEvDdpIkSRup/i4p1CSpvB24CDhtjnZ7AEtHjkiSJEmd0ySpvAxYU1UnztYoyS2YVEqSpB7r85JCTWq0K4DHN7xff5+kJElSj6Vq9mGQSXYAHlZVX9owIS2cJEuratlCx9ElPrP585nNj89r/nxm8+Pzmj+fmWYyZ1LZJ0mWV9UeCx1Hl/jM5s9nNj8+r/nzmc2Pz2v+fGaaSX+nKEmSJKk1JpWSJEkamUnl3Tk+ZP58ZvPnM5sfn9f8+czmx+c1fz4z3YNjKiVJkjQyK5WSJEkaWe+TyiQPTnJakluT/DjJJ+ex33kvJdkxyb8k+c8kP0tSSXZe6LgmVZIDk5ye5Noktye5KskxSe6/0LFNoiT7JrkgyQ1JfpHkuiSfSPKohY6tK5KcP/x7edRCxzKJkuw9fD7Tj1sWOrZJl2T/JBcl+cnw/zOXJ9lnoePSZGiyo85GK8l9gAuAXwAvZbB3+VHAF5M8pqp+upDxTbCHAS9gsDD+xcDTFzaciff3wErgdcB1wOOAI4CnJflfVXXXAsY2iR7A4GfrX4EbgZ2Aw4FLkvx2VV27kMFNuiQvBHZf6Dg64lXA16a8vnOhAumCJH8BHDc83sqgMPVY4D4LGZcmR6+TSuAVwEOBR1TV1QBJvgn8D/AXwD8vYGyT7KKq2g4gyZ9jUjmXZ1fVjVNefynJzcBJwN4M/mGjoao6BThl6rkkXwX+CzgQeMdCxNUFSbYG3gn8LfCxBQ6nC66sqksWOoguGPZGvQt4dVW9a8qlzyxIQJpIfe/+fg5wydqEEqCqvgt8GXjugkU14ayszc+0hHKttdWRHTZkLB120/BPK0mz+0fg8mFiLrXpz4C7gPcudCCaXH1PKncDLp/h/BWA47c0TnsN/7xyQaOYYEkWJ9k0yW8BJwA3MK2CqV9L8hTgJcBfLXQsHfLRJGuS3JTkY46nn9VTGPQWHJTk20nuTHJ1En/e9Ct97/5+APCjGc7fDGy9gWNRTyTZATgS+HxVLV/oeCbYV4DHD7++GtinqlYvYDwTK8mmDBLvf6qqqxY6ng64lcEwii8BP2Ywzvl1wH8meZw/ZzN60PD4vwye1beB5wPHJblXVb17IYPTZOh7UiltUEnuB5zJoBv3Txc4nEn3YmALBuOe/x74XJKnVNU1CxrVZHoNcG/g6IUOpAuq6hvAN6ac+lKSi4CvMpi884YFCWyyLQLuD7ysqj45PHfBcKzla5McWy583Xt97/7+ETNXJNdVwZTWW5J7A59mkCTtW1XXLXBIE62qrqyqrwzHB/4+cD8Gs8A1xbDL9vXAG4HNkmyVZKvh5bWvFy9chN1QVV8H/hv43YWOZUKtHdf8uWnnPwtsBzxww4ajSdT3pPIKBuMqp3sU8K0NHIs2Ykk2AU4D9gD2r6r/t8AhdUpV3cKgC/xhCx3LBHoosDnwEQb/GF57wKDC+yPgtxcmtE6y2jazK+a47gRO9T6pPAt4YpKHrj0xLOU/eXhNGlmSRcBHgX2AA1zCZP6SbAc8ksE4Lt3dpcDTZjhgkGg+jUFCrlkk2QN4BIMucN3TGcM/9512fj/guqq6YQPHownU9zGV7wP+GjgzyRsY/Av1rcD3GAx61zokOXD45dqJFM9IciNwY1V9aYHCmlTHMxjQfjTw0yRPnHLtOrvB7y7JGcDXgW8ymETxcAbrLt6Ja1Tew7CKe+H080kArq2qe1zruyQfBb7L4OfsFgYTdV4LrAKOXcDQJtm5wBeBE5JsC3yHwe+1p+P4cA2l7+Nqh+OR3gn8IRDgC8ChTgaYXZJ1/eB8qar23pCxTLok1wAPWcflt1TVERsumsmX5DAGOzb9JrApg3/kXQgc49/L5oZ/R4+uKiedTJPktcALGfy9vA+D5arOA95cVdcvZGyTLMkWwDEMNiHYmsESQ2+rKhfaF2BSKUmSpBb0fUylJEmSWmBSKUmSpJGZVEqSJGlkJpWSJEkamUmlJEmSRmZSKUmSpJGZVEoaqyTbJzk1ybeTrEhybpKHJ7l8Pe/3siQPajtOSdJoTColjU0G27qcAVxYVb9ZVY9nsHPJdiPc9mXAvJLKJH3fPUySxs6kUtI4PQ34ZVW9d+2JqrqMwS45wK8qj8dNeX12kr2TLE7yoSSXJ/l/Sf52uD3oHsBHk1ya5N5JHp/kS8Mq6GeSPHB4nwuTvCvJcuBvNtgnlqSe8l/vksbp0cCK9fzexwI7VNWjAZJsVVW3JPlr4O+ranmSTYB/AZ5bVTcm+RMGe6z/2fAem1bVHiN+BklSAyaVkibVd4CHJvkX4BzgszO0eQSDxPVzg552FgNT927++LiDlCQNmFRKGqcrgAPnaHMndx+KszlAVf0oye7AvsArgRfw6wrkWgGuqKonrePeP513xJKk9eKYSknjdAGwWZKla08keQzw4CltrgEem2RRkgcDTxi22xZYVFWnA28AfmfY/jbg/sOvrwKWJHnS8Hs2SbLbGD+PJGkdrFRKGpuqqiTPA96V5DDg5wySyEOnNPsy/397dmyDQAxEUfBvBRRwlVAaXSCiy6AiQggp40IT+KhgJRDSTGLJkSPreZ28kjySPJPc9/0lybWqPo/f077ekqxVtSU5Zk5CL1V1yLzTzpkTUgC+qMYYvz4DAAB/zvc3AABtohIAgDZRCQBAm6gEAKBNVAIA0CYqAQBoE5UAALSJSgAA2t47Aax59xidvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a heatmap in component space, using the seaborn library\n",
    "plt.figure(figsize = (12,9))\n",
    "ax = sns.heatmap(sub_cluster_centroids.T, cmap = 'YlGnBu')\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "ax.set_title(\"Attribute Value by Centroid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this diagram we can see that there is a strong relation between component 133 and classification in group 2,\n",
    "as a reminder of the features that have weight in component 133 we can plot the feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAAGDCAYAAAAYmcfWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xm87vW8///HM03IXIYMbSpDyFbrGA6igZKcilL7OAh9DT9+yJEhjmM65JAUGToOyVD5SlGi40SSiF12o0TaqUy7DClJ6vX94/NefLpa0972Z6+91n7cb7frtq/r/X5/3u/X57oueq33en0+K1WFJEmSpGGsNdsBSJIkSfOZCbckSZI0IBNuSZIkaUAm3JIkSdKATLglSZKkAZlwS5IkSQMy4ZYkzUlJKslmsx2HJE3HhFvSvJZkaZLrk1yb5FdJjkiyQa9/xySnJflDkmVJvpnkn0bmeFJL7l43g/XumOT9SX7W1rykvd5wiPNb3STZJ8np04w5tb2fjxhpP661P2nQIAc2k+/UfNb+N7fDDMdukeSM9vxtSV7R61s3yefbfLf6XiTZL8lPk1yT5OdJDk6ydq//G+39vybJOUl2XUmnKC03E25Ja4KnV9UGwFbAGPAmgCR7AP8XOBK4D3AP4M3A00eOfx7wG+C5Uy2SZF3gFOChwE7AHYHHAlcDj1pJ5zJfXEzv/UxyN7r3atmsRbQSLMd3Sp2tgcW952eP9J8O/AvwywmO/RKwVVXdEXgY8AjgFb3+VwL3av0vAj6d5F4rMXZpxky4Ja0xqupK4CvAw5IEeB/w9qr6WFX9vqpurqpvVtX/GT8mye2BPYCXAZsnGZtiiecC9wN2r6oL23y/rqq3V9VJbb6HtB3e3yW5oL/z2XbfP5TkK213/NtJ7tl2yH+b5KIkj+yNX5rkDUkubP2fSLJ+r///JPlJkt8k+VKSjXt9leQlSX7cYjmsvSfj/S9I8sM278lJNpnu2CQPAT4CPLbF/7sp3qvPAHsluU17vQg4Dvhzb51HJflOW+MXST7Yfqi5lSSPT3L5+C5okgcn+Vo79x8leVZv7KlJ9u29vsWufDu/V7Td06uSvCfJtP+9nMl3KslaSd6U5LIkv05yZJI7tb4Fbe3nt3P5bXuf/yHJue19+OBI3N9u78vv2/dj+17/xu1z/037HvS/129J8rm2/h/ad3Fs5Nhj2w7xpbnlzvOkxyb5FN3/Bk5o34HXTvO2jQFnteePBJaMd1TVn6vq/VV1OnDT6IFVdUlVjX/HAtwMbNbrP7eq/jL+ElgHuO808UjDqCofPnz4mLcPYCmwQ3t+X+AC4O3Ag+n+I3z/aY5/DvAL4DbACcAHphh7NPDJKfrXAX4CHACsC2wH/AF4UOs/AriKbqdvfeDrwKV0ifxtgHcA3xg5t/Pbed0V+Dbwjta3XZtrK2A94APAab1jCzgRuDNdgrQM2Kn17drifAiwNt1vBM6Y4bH7AKdP856eCuwL/A/w1Nb2Pbod7iuAJ7W2rYHHtBgWAD8EXjUSx2Z0v024HHhUa799e/38duwj23uxRX/93jy3iLnN+432nt6Pbjd+36nOqR037XcKeEF7bx8AbAB8AfhU61vQjv9I+/yfAvwJOB64O3Bv4NfAE3tx/wXYj+67tRfwe+Curf804ENtroXtc9qu9b2lzb0z3XfrXcB3W99adEnwm+m+pw8AfgrsON2xo/+bm+J9+Brwuxb/Ne1xU2v7ygTj//q9GGn/53ZstfN7xEj/iS3WAr4KrDXb/5/kY818uMMtaU1wfNttPR34JvBO4G6t7xfTHPs84Jiqugn4LLB3knUmGXu3aeZ7DF2SdWB1u3dfp0sIFvXGHFdVZ1XVn+h2fP9UVUe29Y+hSx77PlhVl1fVb4D/6M31bODjVXV2Vd0AvIFu53lB79gDq+p3VfUzugRzYWt/CfCuqvphdTuE7wQW9ne5pzh2eRwJPDfJg4E7V9V3+p3tffhuVf2lqpYCHwWeODLHnq39qVX1vda2C7C0qj7Rjv0BcGwbO1PvrqrftPN7P7f8jCYzk+/Us4H3VdVPq+paus9l7/Rqj+l2yP9UVf8DXAccVd1vSq4EvsUtvwO/Bt5fVTdW1THAj4CnJbkv8DjgdW2uJcDHuGVZ1OlVdVL7bn2KriQD4B+Ajarqbe17+lPgv4C9Z3DsjFTVk+nKrJZUV/JxIPD6qrpzVT11Oeb5bDv+gXQ/qPxqpH8X4A50Pxz8T1XdvDxxSiuLCbekNcFu7T/km1TV/1dV19PVVQNMWtPZkpZt6cofAL5It1v4tEkOuXqq+YCNgctH/qN/Gd3O5bh+wnD9BK834JYuH5lrvGxk4/YagJbcXT2yVr8u9o+9uTcBDmklDL+jq1/PDI9dHl+g24l/OV3SdgtJHpjkxCS/THINXeI/evHpq4DPVdX5vbZNgEePx9/O4dnAPZcjtsne16lM+51i5HNpz9emq/UetzzfgSurqiaIdWPgN1X1h5G+qT7D9Vvivwmw8cj7d8BIjJMdO60kL29zngM8tD1/O/Cmtt7dZzJPX1X9mO63Vx+aoO/GqvoK8JSsQRevavViwi1pTfUjuqTqmVOMeQ7d/0+ekOSXdL9WX59u13si/wvsmK7ueyI/B+47Ug98P+DK5Ql8RL8m9X5tjfG1+nXXt6fbgZ3JWpcDL24/pIw/bltVZ8zg2Jp+SBtY9Ue6mvqXMkHCDXwYuAjYvO1iHkCX+PftCeyW5JUj8X9zJP4Nquqlrf864Ha98RMl4pO9r1OZyXfqFp9Lm/svjOzMLod792vv+VusPwfumuQOI30z/fwvHXn/7lBVO88wpim/A1X1waq6M91vm7ajez+urKo7tbV+PcN1Rq0NbPp39EuDMeGWtEZqu4KvBv6tXaR2x3ZB2+OTHN6GPQ94K125xPjjmcDO6e6qMepTdMnKse2ivbWS3C3JAUl2Bs6k2w18bZJ12gV+T6er/V5RL0tynyR3Bd5IV3YCcBTw/CQLk6xHtzt8ZivNmM5HgDckeShAkjslmWk5xq+A+0x2ceMEDqCrSZ4orjvQ1ede28pOXjrBmJ8D2wOvTDLefyLwwCTPae/zOu3Cw4e0/iXAM5LcLt19vF84wbz7J7lL+y3HK2nva+/CxgWjB8zwO3UUsF+S+6e7PeU76UqW/jI63wzdHXhFO8c96eruT6qqy4EzgHclWT/Jlu08Pz2DOb8H/CHJ65LcNsltkjwsyT/MMKZf0dV9T2ch3S73Vtz67iQAJFkvf7sQeN12Lml9+47vhifZgq4855T2+sFJntriXyfJvwDb0CX50ipnwi1pjVVVn6e70OwFdInbr+guTPxiksfQ7bwdVlW/7D2+RHfR261qelut9A50u7Jfo0sWv0dXBnFmVf2ZLsF+Kt1FfB8CnltVF/0dp/FZuosPfwpc0uKnqv4X+De62uVf0O3s7T3JHKPncRzwbuDoVspxfot5Jr5O96v9Xya5agZr/by6u1BM5DV0F8X9ga6G+JiJBrU66+2B1yfZt5VRPIXufH9OV/7wbrqLRwEOprsbyq+AT/K3kqG+L9JdOLgE+DLw3639vnSlGRPuFE/1nWpDPk73g9lpdBfE/gn4/yc5/5k4E9ic7vv0H8AeVTVe2rKI7kLMn9NdD/Dv7XsxpVaXvQtdQnxpm/tjwJ1mGNO7+Ft5yGsmGpDkfsDV7bccW/G3O5WM+hFdGc29gZPb8/HfEDwOOC/JdcBJ7XHA+BJ0F3f+mu5iylcCe1XVhIm9NLTcsvRLkjRXJFlKd/eMaZMozVySoitj+ckEfW8CllXVR1d9ZLeKZR+6z//xsx2LpKnN6AIHSZIEVfWO2Y5B0txjSYkkSZI0IEtKJEmSpAG5wy1JkiQNyIRbkiRJGpAXTWq1suGGG9aCBQtmOwxJkqRpnXXWWVdV1UbTjTPh1mplwYIFLF68eLbDkCRJmlaSy2YyzpISSZIkaUDucGuN9Jjtd57tECRpSt895aTZDkHSSuIOtyRJkjQgE25JkiRpQCbckiRJ0oBMuCVJkqQBmXBLkiRJAzLhliRJkgZkwi1JkiQNyIRbkiRJGpAJtyRJkjQgE+4VkOTa3vOdk1ycZJMkb0lyZZIlSS5K8uEka/XGrp1kWZIDR+Z7eZKfJKkkG/bad01ybptvcZLHTxHTgiTXt7HnJDkjyYNGxry/xdeP6S1JXjMybul4HC2mT09wDieOHHN8ku+OtB2a5M29129Mcthk5yBJkjQfmXD/HZJsDxwKPLWqLmvNB1fVQmAL4OHAE3uHPBm4GNgzSXrt3wZ2AC7jlk4BHtHmewHwsWlCuqSqFlbVI4BPAgf0Yl0L2B24fCSm6VwHPCzJbXvncGV/QJI7A1sDd0rygF7Xm4B9kjygte8LvHE51pYkSZrzTLhXUJJtgP8CdqmqSyYYsi6wPvDbXtsi4BDgZ8Bjxxur6gdVtXR0gqq6tqqqvbw9UKNjpnDHkbWfBFwAfLjFsTxOAp7Wni8CjhrpfwZwAnA0sPd4Y1VdQ5dgf7A93lxVv1vOtSVJkuY0E+4Vsx5wPLBbVV000rdfkiXAL4CLq2oJQJL16XaxT6BLWGeU9CbZPclFwJfpdrmnsmkrKbkEeDXwvl7feKJ8HPC0JOvMZP3maGDvdg5bAmeO9I/PfavzqqqjgLsAd6yqT000eZIXtZKZxcuWLVuOsCRJklZ/Jtwr5kbgDOCFE/SNl5TcHbh9kvEd312Ab1TV9cCxwG5JbjPdQlV1XFU9GNgNePs0w8dLSjYFXgUcDpBkXWBn4Pi263wmsOP4EpMt3YvhXGABXTJ9Un9QknsAmwOnV9XFwI1JHtbrvw9wL2DjJBtMco6HV9VYVY1ttNFG05yiJEnS3GLCvWJuBp4FPCrJARMNqKobga8C27SmRcAOSZYCZwF3A7ab6YJVdRrwgP5FldP4Um/tHYE7A+e19R/P33air6bbge67AzBa+vEl4L3cupzkWe34S9vcC7jlLvchwL8Dn2v/SpIkrVFMuFdQVf2Rrq752UlutdPdLop8HHBJkjsCTwDuV1ULqmoB8DKmKStJstn4xZVJtqIrZbl6hiE+HhivLV8E7Ntb+/7Ak5PcDjgN+Kckd2jrPAM4p6puGpnv48Bbq+q8kfZFwE69ubem1XEneSrdTv+RdLvzz0iyxQzjlyRJmhfWnu0A5rKq+k2SnYDTkowXH++X5F+AdYBzgQ/R7QJ/vapu6B3+ReA/k6wHvBh4LXBP4NwkJ1XVvsAzgecmuRG4HtirdxHlRDZt9eMB/gzs25LqnYCX9OK+LsnpwNOr6pgkHwROT1LAr+nuJjJ6rlfQ3ZHlr5IsADYBvtsbd2mS3yd5IvB+YI8W83VJ9qe7eHLGO/uSJElzXabO36RVa2xsrBYvXjz4Oo/ZfufB15Ckv8d3Tzlp+kGSZlWSs6pqbLpxlpRIkiRJA7KkZI5J8nBg9PZ6N1TVo2cjHkmSJE3NhHuOaRctLpztOCRJkjQzlpRIkiRJAzLhliRJkgZkwi1JkiQNyIRbkiRJGpAXTWqN5P1tJUnSquIOtyRJkjQgE25JkiRpQCbckiRJ0oBMuCVJkqQBmXBLkiRJAzLhliRJkgbkbQGlWfb43Z8/2yFIWg2dftwnZjsESSuJO9ySJEnSgEy4JUmSpAGZcEuSJEkDMuGWJEmSBmTCLUmSJA3IhFuSJEkakAm3JEmSNCATbkmSJGlAJtySJEnSgEy456Ak90xydJJLkpyV5KQkD0xyfpIdkyxpj2uT/Kg9P3KCeSYbe1KSpUnu2Rt7WJI3JHlSkt+3cT9M8u/TxLplku8kuSDJeUnWH+I9kSRJWl35p93nmCQBjgM+WVV7t7ZHAPcAqKqTgZNb+6nAa6pq8URzTTU2yUuA9wL/kmQr4AnA1sDjgG9V1S5Jbg8sSXJCVZ09QaxrA58GnlNV5yS5G3DjSnkjJEmS5gh3uOeebYEbq+oj4w1VdQ5w+Upe53Bg0yTbAocBL6+qWyTLVXUdcBaw2SRzPAU4t8VHVV1dVTet5DglSZJWaybcc8/D6JLcQVXVzcBLgWOBH1XVaaNj2o71Y4ALJpnmgUAlOTnJ2UleO9GgJC9KsjjJ4mXLlq2kM5AkSVo9WFKiSVXVkiTnAx8a6XpCkh8ANwMHVtVkCffawOOBfwD+CJyS5KyqOmVkncPpdtQZGxurlXkOkiRJs82Ee+65ANhjFa53c3v0fauqdpnBsVcAp1XVVQBJTgK2Ak6Z8ihJkqR5xJKSuefrwHpJXjTekGRL4L6zF9KkTgYenuR27QLKJwIXznJMkiRJq5QJ9xxTVQXsDuzQbgt4AfAu4JfADbMa3Iiq+i3wPuD7wBLg7Kr68uxGJUmStGpZUjIHVdXPgWf125LsClwyMu5JyzHnhGNH26vqVODU5Zj303S3BpQkSVojmXDPA0neBuwK7DPLoUiSJGmECfc8UFVvBt481ZgkOwLvHmm+tKp2/3vXH3JuSZKkuc6Eew3R/6uSc2luSZKkuc6LJiVJkqQBmXBLkiRJAzLhliRJkgZkwi1JkiQNyIsmpVl2+nGfmO0QJEnSgNzhliRJkgZkwi1JkiQNyIRbkiRJGpAJtyRJkjQgE25JkiRpQN6lRJpDnrjP62Y7BEmryDePePdshyBpJXGHW5IkSRqQCbckSZI0IBNuSZIkaUAm3JIkSdKATLglSZKkAZlwS5IkSQMy4ZYkSZIGZMItSZIkDciEW5IkSRqQCbckSZI0IBPu1UySNya5IMm5SZYkeXSSU5P8qL1ekuTzbexbklSSzXrHv6q1jbXXS5Ns2J7fJ8kXk/w4ySVJDkmy7hSxPCnJib3X70jy1STr9WI6J8n3kyzsjVua5B69eH+Z5Mre60nXlCRJmm9MuFcjSR4L7AJsVVVbAjsAl7fuZ1fVwvbYo3fYecDevdd7AhdMMHeALwDHV9XmwAOBDYD/mGFsbwIeB+xeVTf0YnoE8CHgPSOH3DQeL/AR4OBe/H+eyZqSJEnzgQn36uVewFXjCW1VXVVVP5/mmOOBXQGSbAr8HrhqgnHbAX+qqk+0uW8C9gNekOR2Uy2Q5F+BpwJPr6rrJxjyHeDe08Q51fwvSrI4yeJly5at6DSSJEmrJRPu1cv/APdNcnGSDyV5Yq/vM72SjP5u8jXA5UkeRrfTfcwkcz8UOKvfUFXXAD8DNpvwiM7jgJcAT62qaycZsxNd4r9CqurwqhqrqrGNNtpoRaeRJElaLa092wHob6rq2iRbA08AtgWOSfL61v3sqlo8yaFH0yXbOwLbA89fiWH9BLgL8GTg2JG+z7R67A2AhaMHSpIkyR3u1U5V3VRVp1bVvwMvB545g8NOBJ4D/KztWk/kQmDrfkOSOwL3o0uqJ/MrYGfg/Um2Hel7NvAA4JPAB2YQpyRJ0hrHhHs1kuRBSTbvNS0ELpvuuKr6I/A6pr4A8hTgdkme29a6DXAQcEQ7fqr5LwaeAXy6fzeS1lfAvwGPSfLg6WKVJEla05hwr142AD6Z5MIk5wJbAG9pff0a7v8dPbCqjq6qsyebuCXGuwN7JvkxcDHwJ+CAmQRWVd+nK1X5Urs4s993PV3yvv9M5pIkSVqTpMvDpNXD2NhYLV48Wam6nrjP62Y7BEmryDePePdshyBpGknOqqqx6ca5wy1JkiQNyLuUiCQ7AqNbKZdW1e6zEY8kSdJ8YsItqupk4OTZjkOSJGk+sqREkiRJGpAJtyRJkjQgE25JkiRpQNZwS3OItwmTJGnucYdbkiRJGpAJtyRJkjQgE25JkiRpQCbckiRJ0oBMuCVJkqQBmXBLkiRJA/K2gJIkrYa2f+XBsx2CNKedcsh+sx3CX7nDLUmSJA3IhFuSJEkakAm3JEmSNCATbkmSJGlAJtySJEnSgEy4JUmSpAGZcEuSJEkDMuGWJEmSBmTCLUmSJA3IhHsWJbm293znJBcn2STJW5JcmWRJkouSfDjJWr2xaydZluTAkflenuQnSSrJhr32XZOc2+ZbnOTxM4jtVUn+lOROvbZ9knxwZNypScba86VJzmuPC5O8I8n6rW9BkvNX5H2SJEmay0y4VwNJtgcOBZ5aVZe15oOraiGwBfBw4Im9Q54MXAzsmSS99m8DOwCXcUunAI9o870A+NgMwloEfB94xnKezrZV9XDgUcADgI8u5/GSJEnzign3LEuyDfBfwC5VdckEQ9YF1gd+22tbBBwC/Ax47HhjVf2gqpaOTlBV11ZVtZe3B2p0zEhMmwIbAG9qay23qroWeAmwW5K7rsgckiRJ84EJ9+xaDzge2K2qLhrp2y/JEuAXwMVVtQSglWjsAJwAHMUME+Ikuye5CPgy3S73VPYGjga+BTwoyT1meD63UFXXAJcCm08T24taqcviZcuWrchSkiRJqy0T7tl1I3AG8MIJ+sZLSu4O3D7J3q19F+AbVXU9cCzdDvJtpluoqo6rqgcDuwFvn2b4IuDoqrq5rbHn+DSTTT/FXJmibzy2w6tqrKrGNtpoo+mGS5IkzSkm3LPrZuBZwKOSHDDRgKq6EfgqsE1rWgTskGQpcBZwN2C7mS5YVacBD+hfVNmX5OF0O9Jfa2vszd920a8G7jJyyF2BqyaZ6w7AArp6c0mSpDWSCfcsq6o/Ak8Dnp3kVjvd7aLIxwGXJLkj8ATgflW1oKoWAC9jmrKSJJuNX1yZZCu6UparJxm+CHjL+PxVtTGwcZJN6C6ifFySe7a5xtpcl0+w5gbAh4Djq+q3o/2SJElrirVnOwBBVf0myU7AaUnGi5j3S/IvwDrAuXTJ67OAr1fVDb3Dvwj8Z5L1gBcDrwXuCZyb5KSq2hd4JvDcJDcC1wN79S6iHLU3sPNI23HA3lX17iSvBE5qtym8FljUSk/GfaMl92u146YrX5EkSZrXMnneJa16Y2NjtXjx4tkOQ5Jm3favPHi2Q5DmtFMO2W/wNZKcVVVj042zpESSJEkakCUla6h2ceSnRppvqKpHz0Y8kiRJ85UJ9xqqqs4DFs52HJIkSfOdJSWSJEnSgEy4JUmSpAGZcEuSJEkDMuGWJEmSBuRFk5IkrYZWxT2EJa0a7nBLkiRJAzLhliRJkgZkwi1JkiQNyIRbkiRJGpAJtyRJkjQg71IiaU7a8c2fme0QpEGd/LZnz3YIklYSd7glSZKkAZlwS5IkSQMy4ZYkSZIGZMItSZIkDciEW5IkSRqQCbckSZI0IBNuSZIkaUAm3JIkSdKATLglSZKkAZlwS5IkSQNaroQ7yVpJ7jhUMKuzJDclWdJ7vL61n5pkrD1fmuTY3jF7JDmi93qnJN9LclGb45gk92t9RyS5tDf/Ga19nyTLeu1Hjq7bXi9Icn57/qQkvx+Jd4fWd48kn03y0yRnJflOkt2T7Ngbe22SH/XXm+J9eX+SK5Os1WvbJ0mNr9nadmtte/wdH4MkSdKcs/Z0A5J8FngJcBPwfeCOSQ6pqvcMHdxq5vqqWjiDcVsn2aKqLuw3JnkY8AHgn6rqh63tn4AFwM/asP2r6vMTzHlMVb18OeP9VlXtMhJDgOOBT1bVP7e2TVpMHwBObm2nAq+pqsVTLdCS7N2By4EnAt/odZ8H7A38b3u9CDhnOc9BkiRpzpvJDvcWVXUNsBvwFeD+wHMGjWpuOwh44wTtrwPeOZ5sA1TVl6rqtFUWGWwH/LmqPtKL4bKWbK+IJwEXAB+mS6j7vgU8Ksk6STYANgOWTDRJkhclWZxk8bJly1YwFEmSpNXTTBLudZKsQ5dwf6mqbgRq2LBWS7cdKdHYa5JxnwO2SrLZSPtDgbOnWeM9vfk/02vfq9f+/BnG+4SReDedYQzLYxFwFHAc8LT2PRlXdLvbOwK7Al+abJKqOryqxqpqbKONNlqJ4UmSJM2+aUtKgI8CS+nKAU5rJQjXDBnUamqmJSU3Ae8B3kD3G4FbSXI34BTgdsDhVfXe1rU8JSUT/dDTb5uopGQ0jsOAx9Ptev/DxKczsSTrAjsDr66qPyQ5ky65PrE37GjgFcCdgH8FDlieNSRJkuaDaXe4q+rQqrp3Ve1cncuAbVdBbHPZp4BtgPv22i4AtgKoqqtb8n44sMEKrnE1cJfe67sCV01zzF9jaHG8DNgeWJFt5R2BOwPnJVlKl7jfoqykqr4HPBzYsKouXoE1JEmS5rxpE+52V4v/TvKV9noL4HmDRzaHtbKbg4H9es3/CbwxyUN6bbf7O5Y5FfiX/G3b+nnc8qLFiXwdWD/JS1dCDIuAfatqQVUtoKvtf3KS0flejzvbkiRpDTaTGu4j6O5esXF7fTHwqqECWo2N1nAfOM34/6ZXslNV5wGvBI5st9z7NvAQ4LO9Y94zssa6U8x/OPAH4Jwk59DtlL+31z9aw71HVRVdLf4T2y0Ivwd8ku6CzhlrSfVOwJd753cdcDrw9P7YqvpKVU33g4AkSdK8lS4Hm2JA8v2q+ockP6iqR7a2JTOsZ5aWy9jYWC1ePOXdCCUAdnzzZ6YfJM1hJ7/t2bMdgqRpJDmrqsamGzeTHe7r2kV+1SZ+DPD7vzM+SZIkaY0wk7uUvJrulm6btjKIjQD/WuAaIsmOwLtHmi+tqt1nIx5JkqS5ZsqEu/0lwfXp/orgg4AAP2oXBWoNUFUn0/4CpSRJkpbflAl3Vd2c5LBWu33BKopJkiRJmjdmUsN9SpJn9m4/J0mSJGmGZpJwvxj4v8ANSa5J8ocka+JfmpQkSZKW27QXTVbVHVZFIJK0PLxlmiRprpg24U6yzUTtVXXayg9HkiRJml9mclvA/XvP1wceBZwFbDdIRJIkSdI8MpOSklv8qe4k9wXeP1hEkiRJ0jwyk4smR10BPGRlByJJkiTNRzOp4f4A7c+60yXoC4GzhwxKkiRJmi9mUsO9uPf8L8BRVfXtgeKRJEmS5pWZJNx3rqpD+g1JXjnaJkmSVp5nvvfE2Q5BmtKxr9lltkOYM2ZSw/28Cdr2WclxSJIkSfPSpDvcSRYB/wzcP8mXel13AH4zdGCSJEnSfDBVSckZwC+ADYGDeu1/AM4dMihJkiRpvpg04a6qy4DLgMeuunAkSZKk+WXaGu4kj0ny/STXJvlzkpuSXLMqgpMkSZLmupmanNMCAAAgAElEQVRcNPlBYBHwY+C2wL7AYUMGJUmSJM0XM/pLk1X1E+A2VXVTVX0C2GnYsCRJkqT5YSb34f5jknWBJUn+k+5CyhX5k/CSJEnSGmcmifNz2riXA9cB9wWeOWRQkiRJ0nwxbcLd7lYS4F5V9daqenUrMRlMkmtHXu+T5IPt+VuSvGakf2mSDaeY76YkS3qP17f2U5OM9eY4tnfMHkmOmGD9tZJ8MsnH07lTkiOT/CTJJe35ndrYBUkqyTt6826Y5MaR86kkm/XGvKq19WM7rxf/oa39iCRXJlmvN/fSKd6HtZIcmuT8Nt/3k9y/9W2Q5KPtHM5q782jW999knwxyY9b/yHttx4keVKS37e4Lkry3pHPbdnIe7/FZPFJkiTNRzO5S8nTgSXAV9vrhSN/CGcuuL6qFvYeB04ybuupEsIkAT4CrAPsW1UF/Dfw06rarKo2BS4FPtY77FLgab3XewIXjEx9HrD3NGO27cX/il77TcALJot5xF7AxsCWVfVwYHfgd63vY3R/0GjzqtoaeD6wYTvnLwDHV9XmwAOBDYD/6M37rapaCDwS2CXJ43p9x4y89xfOMFZJkqR5YSYlJW8BHkVLzKpqCXD/AWOaTQcBb5yi/1DgbsBzq+rmtiu9NfD23pi3AWNJNm2v/wj8cHy3mi7p/dzIvMcDuwK0434PXDXDmN8P7JdkJvX49wJ+UVU3A1TVFVX127bmo4E39fouraovA9sBf2oXy1JVNwH7AS9Icrv+5FV1Pd0PZ/eeYeySJEnz3kwS7hur6vcjbTVEMD237Zch0CWxffuN9G+8PPMl2WuScZ8DtuqXd/T8M7AVsHdV/aW1bQEsaUko8NeEdAnw0N6xRwN7J7kv3Y70z0fmvga4PMnD6Ha6j5lg/W/04t+v1/4z4HS6WvvpfA54epvjoCSPbO0PHT2PnocCZ/Ubquqatu4t3qckdwE2B07rNe818t7fdnSBJC9KsjjJ4mXLls3gNCRJkuaOmeyKXpDkn4HbJNkceAXdn30f0vWtRAHoaoGBsV7/wVXVrxVeujzzTeEm4D3AG4CvjPSdDTyYbrf/2zOYq++rdLvgv2LiZBpaUg7sCGxPV9LRt21VTbbr/S7gi8CXpwqiqq5I8iC6XevtgFOS7DmjM5jaE5KcQ5dsv7+qftnrO6aqXj5NXIcDhwOMjY0N/cOcJEnSKjXpDneST7Wnl9Dtct4AHEW3G/uq4UObNZ8CtqG7G0vfRcCzgGOSjO9eXwgsTPLX97E9X9j6AKiqP9PtEv8r8PlJ1j2Rbpf6Z20Hecaq6sd0u+rPmsHYG6rqK1W1P/BOYDe6evFHJLnNBIdcSFc281dJ7gjcDxi/ePZbVfUIuu/JC5PM5IcbSZKkNcJUJSVbJ9mYrub4ILqd16e057eb4rg5rapuBA6mq1Me7TsDeClwYpL7tbu1/AB4U2/Ym4CzJ7iTy0HA66rqN5Os+0fgddzyYsTl8R/Aa6YakGSr9pmO/2CwJXBZVV0CLAbe2i6SHL/DytOAU4DbJXlua79NO5cjWsz9c7gUOLCdhyRJkpg64f4IXbL1YLpkbPxxVvt3Lhmt4Z7sLiXj/ptJym2q6gS6mvKvJrkb8ELgge12eZfQ3cXjhRMcd0FVfXKqRavq6Ko6e5Lufg33kRPNT1f2MpW7AyckOR84F/gL8MHWty9wD+Anrf8I4NftTiy7A3sm+TFwMfAn4IBJ1vgIsE2SBe31aA33P04ToyRJ0rySLp+aYkDy4ap66SqKR2u4sbGxWrx4rv08J0kr3zPfe+JshyBN6djX7DLbIcy6JGdV1dh042byh29MtiVJkqQVNJO7lMwJrbzjlAm6tq+qq1d1PLMpycPpLv7su6GqHj0b8UiSJK3J5k3C3ZJq744BVNV5+F5IkiStFmbyh28kSZIkrSATbkmSJGlAJtySJEnSgEy4JUmSpAHNm4smJUmaT7zHsTR/uMMtSZIkDciEW5IkSRqQCbckSZI0IBNuSZIkaUAm3JIkSdKATLglSZKkAXlbQEmSVkMv+ugpsx2C1jCHv3j72Q5h3nKHW5IkSRqQCbckSZI0IBNuSZIkaUAm3JIkSdKATLglSZKkAZlwS5IkSQMy4ZYkSZIGZMItSZIkDciEW5IkSRqQCffAklSST/der51kWZITe227JTk3yQ+TnJdkt17fEUkuTbIkyUVJ/r3Xd2qSsSnWXtrmOzfJN5NsMtK/W4vvwb22tZIcmuT8duz3k9w/yZkthp+1+Je0x4LeOuNth04Q+zlJ/BNWkiRpjeOfdh/edcDDkty2qq4HngxcOd6Z5BHAe4EnV9WlSe4PfC3JT6vq3DZs/6r6fJL1gQuTHFlVl85w/W2r6qokbwXeBPyfXt8i4PT273givxewMbBlVd2c5D7AdVX16BbvPsBYVb28dw5/XWeC9cdj3xY4HNh8hnFLkiTNC+5wrxonAU9rzxcBR/X6XgO8czyBbv++C9h/gnnWb/9etwIxfAe49/iLJBsAjwdeCOzdG3cv4BdVdXOL54qq+u0KrDfl+pIkSWsKE+5V42hg77ZDvSVwZq/vocBZI+MXt/Zx70myBLgCOLqqfr0CMewEHN97vSvw1aq6GLg6ydat/XPA01sZyEFJHjnD+b/RKynZbwbr/1WSFyVZnGTxsmXLZricJEnS3GDCvQq00pAFdLvbJ63AFPtX1ULgnsD2Sf5xOY79RpIrgadyy531RXQ/CND+XdRivQJ4EPAG4GbglBnWXm9bVQvb4+Be+3uSXAx8Fnj3RAdW1eFVNVZVYxtttNFynJokSdLqz4R71fkSXa32USPtFwJbj7RtDVwwOkFVXQucSlcKMlPbApsAS4C3AiS5K7Ad8LEkS+nKV56VVoxdVTdU1Veqan/gncBuE008Q/tX1QOB1wEf/zvmkSRJmpNMuFedjwNvrarzRtrfC7whyQKA9u8BwEGjEyRZG3g0cMnyLFxVfwFeBTy3Jdt7AJ+qqk2qakFV3Re4FHhCkq2SbNzWW4uuBOay5VlvEh8E1kqy40qYS5Ikac4w4V5F2sWHh07QvoRu9/eEJBcBJwCvbe3jxmu4zwXOA76wAuv/gm53/WV05SPHjQw5trXfvcVyflvvL3TJ8nT6NdxHTrB+Ae8AXru8sUuSJM1l6fIgafUwNjZWixcvnu0wJGnWveijp8x2CFrDHP5i/1zG8kpyVlVN+jdRxrnDLUmSJA3IP3wzDyQ5E1hvpPk5E9SLS5IkaRUz4Z4Hxv8KpCRJklY/lpRIkiRJAzLhliRJkgZkwi1JkiQNyIRbkiRJGpAXTUqStBrynsjS/OEOtyRJkjQgE25JkiRpQCbckiRJ0oBMuCVJkqQBmXBLkiRJA/IuJZI0QwccdcZsh6A1yDsX/eNshyBpJXGHW5IkSRqQCbckSZI0IBNuSZIkaUAm3JIkSdKATLglSZKkAZlwS5IkSQMy4ZYkSZIGZMItSZIkDciEW5IkSRqQCbckSZI0oMES7iTX9p7vnOTiJJskeUuSK5MsSXJRkg8nWas3du0ky5IcODLfy5P8JEkl2bDXvmuSc9t8i5M8foqY1kpyaJLzk5yX5PtJ7t/6lra2Je1xaO+4V7dYz0tyTpL3JVlninWWJvnWSNuSJOe3509KcmKS5/fW+3Nv/V9N0n5gkn3a+7Ok99giyYLx+UfWPSLJHu35XZP8oK074fhpPoNd2vHnJLkwyYtb+4OSnNpi+WGSw3vn+fuRWHeY7H2TJEmaj9YeeoEk2wOHAjtW1WVJAA6uqve2RPs04InAN9ohTwYuBvZM8oaqqtb+beBE4NSRJU4BvlRVlWRL4HPAgycJZy9gY2DLqro5yX2A63r921bVVSPxvwR4CvCYqvpdknWBVwO3BW6c4tTvkOS+VXV5kodMNKCqPgF8oq2zdJL1b9GeZB/gmKp6+ci4BVPEQpI7AScDh1fVJ6YZf6vPoP2AcTjwqKq6Isl6wPgch9J9pl9saz28N9e3qmqXqWKTJEmazwYtKUmyDfBfwC5VdckEQ9YF1gd+22tbBBwC/Ax47HhjVf2gqpaOTlBV1/aS8tsDNTqm517AL6rq5nbsFVX12ynGA7wReGlV/a4d8+eqOrCqrpnmuM/RJfjj53TUNOOHtAHwFeCzVfXhGYyf6DO4A90PaFcDVNUNVfWj1ncv4Irxg6vqvOUJLsmL2m8nFi9btmx5DpUkSVrtDZlwrwccD+xWVReN9O2XZAnwC+DiqloCkGR9YAfgBLoEddFMFkqye5KLgC8DL5hi6OeAp7fShoOSPHKk/xu90of9ktwR2KCqLp1JHCOOBZ7Rnj+d7pxWlr1GyjRuO8349wGnV9XB00082WdQVb8BvgRcluSoJM/O30qBDga+nuQr7X27c2/KJ4zEuunomlV1eFWNVdXYRhttNO3JS5IkzSVDJtw3AmcAL5yg7+CqWgjcHbh9kr1b+y7AN6rqerqEdbckt5luoao6rqoeDOwGvH2KcVcADwLeANwMnNJKXsZtW1UL2+NWyWmSHVvSuDTJP04T1tXAb9u5/RD443TnsRyO6cW5sL1fU/k6sGuSu89g7kk/g6raF9ge+B7wGuDjrf0TwEOA/ws8CfhuKzmBrqSkH+tEv+mQJEmat4ZMuG8GngU8KskBEw2oqhuBrwLbtKZFwA6tbvks4G7AdjNdsKpOAx6Q3kWVE4y5oaq+UlX7A++kS9InG3sNcG3ahZVVdXL7QeF8unKY6RwDHMbslpMAHA18BDgpyR2mGTvlZ1BV57UfRp4MPLPX/vOq+nhV7Qr8BXjYyj0FSZKkuWnQGu6q+iPwNODZSW61053uCsrHAZe08o0nAPerqgVVtQB4GdOUlSTZrM1Dkq3oSlmunmTsVkk2bs/XArYELpvmNN4FfHi8TKKttf40x4w7DvhPuosVZ1VLkk8BvtAu/LyVqT6DJBskeVJv+ELae5dkp3ZRJUnuSZekXznUuUiSJM0lg9+Hu9X+7gS8Kck/tebxGu7zgdsAHwJ2B75eVTf0Dv8iXc31eklekeQK4D7AuUk+1sY8Ezi/zXcYsFfvIspRdwdOaLfDO5duJ/aDvf5+DfeRre3DdInqmUnOpbtbyg/aY7pz/0NVvbuq/jzd2OU0WsM9Xt7yoCRX9B57jsTzOrqLGz9F99nfYjxTfAZ0n9Nrk/yovddvBfZpY55C9xmcQ/fDxf5V9cvWN1rDvcdKfi8kSZJWa5k8N5VWvbGxsVq8ePFshyFN6ICjzpjtELQGeeei6S4VkjTbkpxVVWPTjfMvTUqSJEkDGvwP38yG9odXPjXSfENVPXolr3MmXc1433OW9z7UkiRJmr/mZcLdEt6Fq2CdlZrAS5Ikaf6xpESSJEkakAm3JEmSNCATbkmSJGlA87KGW5KG4G3aJEkrwh1uSZIkaUAm3JIkSdKATLglSZKkAZlwS5IkSQMy4ZYkSZIGZMItSZIkDcjbAkrSKnDQiWfPdgiaY/51l61mOwRJK4k73JIkSdKATLglSZKkAZlwS5IkSQMy4ZYkSZIGZMItSZIkDciEW5IkSRqQCbckSZI0IBNuSZIkaUAm3JIkSdKA5mXCneSmJEt6jwVJnpTkxNa/T5Kbk2zZO+b8JAt6rxcmqSQ7jcxdSQ7qvX5Nkre05yePrPvzJGdOEuPzkhw10rZhkmVJ1kuybpL3J/lJkh8n+WKS+0xwjucnOSHJnVv7WkkObe3nJfl+kvu3vjslObLNeUl7fqfWtyDJ9W3OC1vfOr31HpXk1BbL2Um+nOThre8tSa4cOfc7t/f89+31RUneu5wfpSRJ0pw3LxNu4PqqWth7LJ1gzBXAG6eYYxFwevu37wbgGUk2HD2gqnYcXxN4HHAN8KZJ5j8OeHKS2/Xa9gBOqKobgHcCdwAeVFWbA8cDX0iSkXN8GPAb4GWtfS9gY2DLqno4sDvwu9b338BPq2qzqtoUuBT4WG/9S1rsDwfuAzwLIMk9gM8BB1TV5lW1FfAuYNPesQePvOfja36rzflIYJckj5vk/ZAkSZqX5mvCPRMnAg9N8qDRjpbU7gnsQ5cUr9/r/gtwOLDfNPMfApxUVV+bqLOqrgG+CTy917w3cFRLwp8P7FdVN7Xxn6BL9rebYLrvAPduz+8F/KKqbm7HXVFVv02yGbA18PbecW8DxpL0E2famt/rzfly4JNVdUZvzOlVdfw070F/zuuBJb05JUmS1gjzNeG+ba+04bhJxtwM/CdwwAR9/whcWlWXAKcCTxvpPwx49ng5xqgkzwDGgDdME+dRdEk2STYGHgh8HdgM+FlLyvsWAw8dWes2wPbAl1rT54Cnt3M/KMkjW/sWwJLxBB7+mlgvmWDO9YFHA19tTQ8Fzp7mXPbrveffGO1Mchdgc+C0CfpelGRxksXLli2bZhlJkqS5Zb4m3P2Skt2nGPdZ4DHjNc49i4Cj2/OjGSkraYnwkcArRidMcm+63e1/bqUhU/ky8Lgkd6Qr3zi2nxBP47ZJlgC/BO4BfK3FdgXwILpk/2bglCTbz3DOTducv6LbJT93okFJzkzywySH9Jr7JSXb9tqfkOQc4Erg5Kr65eh8VXV4VY1V1dhGG200w1AlSZLmhvmacM9IVf0FOAh43Xhb2zF+JvDmJEuBDwA7JbnDyOHvB14I3L53bIBPAgdW1YUzWP96ul3k3WnlJK3rEuB+E6y5NXBBe359q43eBAh/q+Gmqm6oqq9U1f50teC7ARcCC5P89TNvzxe2PvhbDfemwNZJ/qm1XwBs1Zv/0cC/ARPu8I/4VlU9gm6X/IVJFs7gGEmSpHljjU64myOAHYDxrdXtgXOr6r5VtaCqNgGOpUuK/6qqfkNXvvHCXvNrgD9V1WHLsf5RwKvpdqm/0+a+ji5xf1/7AYAkzwVuR1dy0o/jj3Q77f+aZO0kW7XylPGEekvgsqr6CfADbnkR55uAs1tff86rgNfzt5KYw4B9kvxjb1j/Ys9pVdWlwIH0friRJElaE6zxCXdV/Rk4FLh7a1pEdweRvmO59d1KoNsd79+t5B3AQ0Zuj3ereuYRX6O7q8gxVVW99jcAfwIuTvJjuos4dx8ZM34OPwDObTHeHTghyfmt7S/AB9vQFwIPbLcEvISuZvyFo/M1xwO3S/KEVgayF/CudkvBM+juqPLB3vj9Rs57wQRzfgTYZpI+SZKkeSkT5G/SrBkbG6vFixfPdhjSSnfQidNddyzd0r/ustX0gyTNqiRnVdXYdOPW+B1uSZIkaUhrz3YAa4Ikh9H9IZy+Q9q9tSVJkjSPmXCvAlX1sulHSZIkaT6ypESSJEkakAm3JEmSNCATbkmSJGlAJtySJEnSgLxoUpJWAe+pLElrLne4JUmSpAGZcEuSJEkDMuGWJEmSBmTCLUmSJA3IhFuSJEkakHcpkSRpNXTEaT+c7RA0x+yzzUNmOwRNwh1uSZIkaUAm3JIkSdKATLglSZKkAZlwS5IkSQMy4ZYkSZIGZMItSZIkDciEW5IkSRqQCbckSZI0IBNuSZIkaUAm3JIkSdKATLgHkuTa3vOdk1ycZJMkb0lyZZIlSS5K8uEka/XGrp1kWZIDR+a7f5Izk/wkyTFJ1m3t+7TxS9pj3yli+mmSB420vT/J69rzxyf5XovroiQv6o3rx31hkkW9viOSXNo7p3/v9X0myY+SnJ/k40nWWbF3VJIkaW4y4R5Yku2BQ4GnVtVlrfngqloIbAE8HHhi75AnAxcDeyZJr/3d7bjNgN8CL+z1HVNVC9vjY1OEczSwdy+2tYA9gKOT3BP4LPCSqnow8HjgxUme1jt+PO5dgY+OJM/7t76FwPOS3L+1fwZ4cDvP2wKT/kAgSZI0H5lwDyjJNsB/AbtU1SUTDFkXWJ8ugR63CDgE+Bnw2DZPgO2Az7cxnwR2W4GQjgL26r3eBris/SDwMuCIqjoboKquAl4LvH50kqr6MfBH4C4TrLF++/e6NvakaoDv/b/27jXWsrq84/j3F6ZAI6XidOTiIGMDpgXFUY6g4kCsY0uFUhoIBQVnEkjLKxJIG0lBY0w0XmKwRo31grcUqKDcerFBwDKRAT3AeGSoclcHRxhBDAYdwXl8sdbRzfEMZ8Octfeevb+fN7Mu/7XWs+Y5Z84z//PstYDlcw9I8g9JppNMb9my5TncliRJ0uiy4O7ObsCVwAlV9d05+85JsgHYDNxVVRsAkuwOrAauoSmOZ9s2lgKPVdVT7fom4EU95zsxyUySy5Psv72Aquo7wLYkr2g3ndJeB+AQ4NY5h0y3258myauAu6vq4Z7NH2zvaRNw6Zx9tLPhpwNfnSeuT1bVVFVNLVu2bHvhS5Ik7ZQsuLvzJHATT2/9mDXbmvFC4HlJZts8jgNuqKpfAF8GTkiyywLXuQZYUVWHAtfSzH4/k0uAU5IsoZklv6yvu2mck2QjcAvwnjn7ZltK9gHemOR1c/Z/HLixqtY9i+tJkiTt9Cy4u7MNOBk4PMm/zDegqp6kmfE9qt10KrA6yQM0s81LaVpJHgGe3xbJ0LRlPNie45Gq2tpu/zRw2AJxXdrGtRqYqaqH2u13znPsYcDGnvULq+oQ4ETgM+2M/Nx7+jnwdZoecADaD1EuA85dIDZJkqSxY8Hdoap6AjgWeGuS35vpbnuzjwTuTbInsAp4cVWtqKoVNH3Vp7b9zzfQfMARYA1wVXuOfXtOeTzw/wvEdC/wE+B9/K6dBOBjwNokK9vzLqX5oOYH5jnH1TTtJmvmuaclwBHAve36mcBftfex7ZlikyRJGkcW3B2rqkeBY4ALkhzfbp7t4b4D2IWm3eLvgOt7ZquhKar/JsluwNuBc5PcQzPz/Zl2zNlJNib5NnA2sLaPsC6heXLIV3ri3AycBnwqyXdp2mEuqqprtnOOd7fxzH4NzfZwzwDf6Tn3J4C9gfXtYwPf2Ud8kiRJYyPN5Kk0Gqampmp6enrYYUjS0H3uxmf8haX0e9Ye9efDDmHiJLm1qqYWGucMtyRJktShJQsP0c4mycuBL87ZvLWqjhhGPJIkSZPMgnsMtc/bXjnsOCRJkmRLiSRJktQpC25JkiSpQxbckiRJUocsuCVJkqQO+aFJSZJGkM9UlsaHM9ySJElShyy4JUmSpA75aneNlCRbgO/v4Gn+BPjJIoSjxWVeRpN5GV3mZjSZl9E1jNwcUFXLFhpkwa2xk2S6qqaGHYeezryMJvMyuszNaDIvo2uUc2NLiSRJktQhC25JkiSpQxbcGkefHHYAmpd5GU3mZXSZm9FkXkbXyObGHm5JkiSpQ85wS5IkSR2y4NZOL8kLklyb5O72z73mGXNAktuSbEiyMclZw4h1kvSZl5VJ1rc5mUny98OIdZL0k5d23FeTPJbkPwcd46RJckyS7yW5J8l58+zfLcl/tPtvSbJi8FFOnj7yclT7c+WpJCcNI8ZJ1Edezk1yZ/sz5bokBwwjzrksuDUOzgOuq6qDgOva9bk2A6+tqpXAEcB5SfYbYIyTqJ+8PAG8raoOAY4BPpzk+QOMcRL1kxeADwKnDyyqCZVkF+BjwF8DBwOnJjl4zrAzgJ9W1YHAhcD7Bxvl5OkzLz8A1gIXDza6ydVnXm4HpqrqUOBy4AODjXJ+FtwaB38LfL5d/jxwwtwBVfWrqtraru6GX/uD0E9e7qqqu9vlHwEPAwu+QEA7ZMG8AFTVdcDjgwpqgh0O3FNV91XVr4BLaXLUqzdnlwNvTJIBxjiJFsxLVT1QVTPAtmEEOKH6ycsNVfVEu3ozsHzAMc7LokPjYO+q2twu/xjYe75BSfZPMgP8EHh/W+CpO33lZVaSw4FdgXu7DmzCPau8qHMvovk3adamdtu8Y6rqKeBnwNKBRDe5+smLBu/Z5uUM4H86jahPS4YdgNSPJF8D9pln1/m9K1VVSeZ99E5V/RA4tG0luTLJ5VX10OJHOzkWIy/tefYFvgisqSpni3bQYuVFknZWSU4DpoCjhx0LWHBrJ1FVq7e3L8lDSfatqs1t4fbwAuf6UZI7gFU0v57Vc7QYeUmyJ/BfwPlVdXNHoU6Uxfx+UeceBPbvWV/ebptvzKYkS4A/Bh4ZTHgTq5+8aPD6ykuS1TQTDEf3tJMOlS0lGgdXA2va5TXAVXMHJFme5A/b5b2A1wPfG1iEk6mfvOwKXAF8oar8z89gLJgXDdS3gIOSvKT9fjiFJke9enN2EnB9+RKNrvWTFw3egnlJ8krg34Djq2pkJhR88Y12ekmWAl8CXgx8Hzi5qh5NMgWcVVVnJnkT8CGggAAfraqRfSPVOOgzL6cBnwU29hy6tqo2DD7iydBPXtpx64A/A/agmU09o6r+d0hhj7UkbwY+DOwCXFRV70nybmC6qq5OsjtNy9UrgUeBU6rqvuFFPBn6yMuraSYM9gJ+Cfy4feKSOtRHXr4GvJzm6WQAP6iq44cU7m9ZcEuSJEkdsqVEkiRJ6pAFtyRJktQhC25JkiSpQxbckiRJUocsuCVJkqQOWXBLksZKkk8nOXiBMZ9LctI821ckeUt30UmaRBbckqSxUlVnVtWdz/HwFYAFt6RFZcEtSRpJSf45ydnt8oVJrm+X/yLJvyf5yyTrk9yW5LIke7T7v96+yIckZyS5K8k3k3wqyUd7LnFUkpuS3Ncz2/0+YFWSDUnOSXJIe+yGJDNJDhrgX4GkMWHBLUkaVeuAVe3yFLBHkj9ot80AFwCrq+pVwDRwbu/BSfYD3gG8BjiS5s2ZvfYFXg8cR1NoA5wHrKuqlVV1IXAW8K9VtbKNYdOi3qGkibBk2AFIkrQdtwKHJdkT2ArcRlP0rgKuBg4GvpEEYFdg/ZzjDwf+r6oeBUhyGfDSnv1XVtU24M4ke28nhvXA+UmWA1+pqrsX5c4kTRQLbknSSKqqJ5PcD6wFbqKZ1X4DcCBwP3BtVZ26A5fY2rOc7cRwcZJbgGOB/07yj1V1/Q5cU9IEstRz/fMAAADzSURBVKVEkjTK1gH/BNzYLp8F3A7cDByZ5ECAJM9L8tI5x34LODrJXkmWACf2cb3HgT+aXUnyp8B9VfUR4Crg0B28H0kTyIJbkjTK1tH0Wq+vqoeAX9L0WG+hmfm+JMkMTevH03q0q+pB4L3AN4FvAA8AP1vgejPAr5N8O8k5wMnAHUk2AC8DvrBI9yVpgqSqhh2DJEmdSLJHVf28neG+Arioqq4YdlySJosz3JKkcfaudnb6Dpq+7yuHHI+kCeQMtyRJktQhZ7glSZKkDllwS5IkSR2y4JYkSZI6ZMEtSZIkdciCW5IkSeqQBbckSZLUod8A7mYX3l8NtrsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_component(v, azdias_df.columns.values, component_num=133, n_components = N_COMPONENTS, n_weights=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see that KBA13_BAUMAX, CJT_TYP_6 (from CJT_GESAMTYP, 6 Advertising enthusiast with restricted crosselling) and SEMIO_KRIT strongly negative correlated and KBA13_AUDI is positive correlated.\n",
    "\n",
    "From the csv description of these features:\n",
    "    - KBA13_BAUMAX: Number of buildings in the area (1 low - 5 high)\n",
    "    - CJT_TYP_6: Customer journey type (1 Advertising & consumption minimalist - 6 Advertising enthusiast)\n",
    "    - SEMIO_KRIT: Critical mind ( 1 high - 7 low)\n",
    "    - KBA13_AUDI: Owner of an Audi\n",
    "    \n",
    "\n",
    "The profile we get from this info is that the buyers have a relatively high income (If they can spare to buy an Audi), live in low crowded neighbourhoods (KBA13_BAUMAX negative correlation), are Advertising and consumption minimalist (CJT_TYP_6 negative correlation) and have studies or interests (SEMIO_KRIT negative correlated)\n",
    "\n",
    "\n",
    "Note: for some reason seaborn changes all the strings beginning with CJT for QT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform azdias to 7 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 ms, sys: 116 µs, total: 26.1 ms\n",
      "Wall time: 339 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "kmeans_transformer = k_estimator.transformer(instance_count = 1, \n",
    "                                  instance_type = 'ml.m5.large',\n",
    "                                  output_path='s3://{}/{}/kmeans/transform/test'.format(bucket_name, prefix+\"/transform\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_sub_pca.to_csv('azdias_sub_pca',header = False,index=False, encoding=\"utf-8\")\n",
    "azdias_pca_location = session.upload_data(os.path.join('azdias_sub_pca'), key_prefix='test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loading entry points\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:06:57 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:06:57 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:06:57 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:06:57 +0000] [67] [INFO] Booting worker with pid: 67\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loading model...\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 WARNING 140282534803264] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] nvidia-smi took: 0.0253748893738 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:06:57 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loading entry points\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] Number of server workers: 2\u001b[0m\n",
      "\u001b[35m[2020-05-15 22:06:57 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-05-15 22:06:57 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-05-15 22:06:57 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2020-05-15 22:06:57 +0000] [67] [INFO] Booting worker with pid: 67\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loading model...\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 WARNING 140282534803264] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] nvidia-smi took: 0.0253748893738 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2020-05-15 22:06:57 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] loading model...\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 WARNING 140282534803264] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] nvidia-smi took: 0.0252120494843 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:06:57 INFO 140282534803264] ...model loaded.\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] loading model...\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 WARNING 140282534803264] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] nvidia-smi took: 0.0252120494843 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/15/2020 22:06:57 INFO 140282534803264] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580421.142987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580417.525747}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580421.142987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580417.525747}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-05-15T22:07:01.159:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.076224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580421.143113}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.135267, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580417.611174}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.076224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580421.143113}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.135267, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580417.611174}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.768903, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.076299}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.768903, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.076299}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.850502, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.135744}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580426.388917, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.76941}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580425.850502, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.135744}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580426.388917, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.76941}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.026941299438476562, \"sum\": 0.026941299438476562, \"min\": 0.026941299438476562}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580426.613733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.850595}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580427.080639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580426.614146}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580427.322944, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580426.388992}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.026941299438476562, \"sum\": 0.026941299438476562, \"min\": 0.026941299438476562}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580426.613733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580425.850595}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580427.080639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580426.614146}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580427.322944, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580426.388992}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580427.760191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580427.080716}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580428.088407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580427.32331}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580428.407563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580427.760267}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580427.760191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580427.080716}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580428.088407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580427.32331}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580428.407563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580427.760267}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580428.810203, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580428.088766}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580429.107029, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580428.407642}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580428.810203, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580428.088766}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580429.107029, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580428.407642}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580430.33539, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580429.620934}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580430.33539, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580429.620934}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580430.652045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580429.920331}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.074324, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580430.335878}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.267716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580430.65213}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580430.652045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580429.920331}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.074324, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580430.335878}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.267716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580430.65213}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.725934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.074823}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.92092, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.267792}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580432.369731, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.726417}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.725934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.074823}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580431.92092, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.267792}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580432.369731, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.726417}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580432.536796, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.920993}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.131445, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580432.370243}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.222807, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580432.536872}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580432.536796, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580431.920993}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.131445, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580432.370243}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.222807, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580432.536872}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.870438, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.223371}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.914408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.131565}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02288818359375, \"sum\": 0.02288818359375, \"min\": 0.02288818359375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580434.442228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.91492}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.870438, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.223371}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580433.914408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.131565}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02288818359375, \"sum\": 0.02288818359375, \"min\": 0.02288818359375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580434.442228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.91492}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580434.447848, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.870512}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.004436, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580434.447923}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.100782, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580434.442771}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580434.447848, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580433.870512}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.004436, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580434.447923}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.100782, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580434.442771}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.652257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.004518}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.807047, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.100863}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580436.320225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.652787}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580436.404005, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.807119}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.652257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.004518}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580435.807047, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.100863}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580436.320225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.652787}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580436.404005, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580435.807119}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580436.957073, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580436.404086}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580437.080392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580436.320728}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580436.957073, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580436.404086}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580437.080392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580436.320728}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580437.560266, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580436.95715}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.031948089599609375, \"sum\": 0.031948089599609375, \"min\": 0.031948089599609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580437.735717, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580437.080886}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580438.161823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580437.560341}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580437.560266, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580436.95715}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.031948089599609375, \"sum\": 0.031948089599609375, \"min\": 0.031948089599609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580437.735717, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580437.080886}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580438.161823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580437.560341}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580438.479433, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580437.736238}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580438.847226, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580438.1619}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02288818359375, \"sum\": 0.02288818359375, \"min\": 0.02288818359375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580439.100306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580438.479927}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580438.479433, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580437.736238}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580438.847226, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580438.1619}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02288818359375, \"sum\": 0.02288818359375, \"min\": 0.02288818359375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580439.100306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580438.479927}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580440.47014, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580439.796036}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580440.47014, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580439.796036}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580440.833303, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580440.221444}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580441.06321, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580440.470661}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580440.833303, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580440.221444}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580441.06321, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580440.470661}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580441.539063, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580440.833783}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580441.539063, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580440.833783}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580441.750421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580441.063281}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580442.226883, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580441.539564}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580442.356172, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580441.750499}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580441.750421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580441.063281}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580442.226883, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580441.539564}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580442.356172, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580441.750499}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580442.853751, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580442.227457}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580443.03452, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580442.35625}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580442.853751, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580442.227457}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580443.03452, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580442.35625}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580443.522622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580442.854343}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580443.624756, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580443.034592}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580444.14497, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580443.62484}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580444.394197, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580443.523159}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580443.522622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580442.854343}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580443.624756, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580443.034592}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580444.14497, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580443.62484}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580444.394197, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580443.523159}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.031948089599609375, \"sum\": 0.031948089599609375, \"min\": 0.031948089599609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580444.7841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580444.145049}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.078604, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580444.394685}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.031948089599609375, \"sum\": 0.031948089599609375, \"min\": 0.031948089599609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580444.7841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580444.145049}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.078604, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580444.394685}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.351584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580444.784174}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.351584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580444.784174}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.751247, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.079119}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.993828, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.351656}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580446.426389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.751917}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.751247, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.079119}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580445.993828, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.351656}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580446.426389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.751917}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580446.707864, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.994903}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580447.11384, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580446.426464}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580447.388211, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580446.708396}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580446.707864, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580445.994903}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580447.11384, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580446.426464}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580447.388211, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580446.708396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580447.716295, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580447.113914}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580447.716295, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580447.113914}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.004453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580447.388759}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.333082, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580447.71637}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.004453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580447.388759}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.333082, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580447.71637}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.688301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580448.005008}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.997849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580448.333155}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580449.340339, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580448.688802}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.688301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580448.005008}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580448.997849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580448.333155}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580449.340339, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580448.688802}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580450.608971, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580450.014824}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.013558, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580450.336538}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.241952, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580450.609045}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580450.608971, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580450.014824}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.013558, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580450.336538}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.241952, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580450.609045}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.662698, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.014061}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.894754, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.242028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580452.351678, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.663227}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.662698, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.014061}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580451.894754, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.242028}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580452.351678, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.663227}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580452.583335, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.894833}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.001688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580452.352211}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.159169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580452.583413}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580452.583335, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580451.894833}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.001688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580452.352211}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.159169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580452.583413}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.651704, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.002177}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.815706, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.159247}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580454.247949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.652167}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.651704, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.002177}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580453.815706, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.159247}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580454.247949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.652167}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580454.642699, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.815783}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580454.798413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580454.248024}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580455.312611, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580454.643205}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580455.441051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580454.798494}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580454.642699, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580453.815783}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580454.798413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580454.248024}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580455.312611, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580454.643205}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580455.441051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580454.798494}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580455.922239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580455.313129}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580456.003482, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580455.441125}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580455.922239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580455.313129}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580456.003482, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580455.441125}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.022172927856445312, \"sum\": 0.022172927856445312, \"min\": 0.022172927856445312}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580456.607603, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580455.922756}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580456.616292, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580456.003571}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580457.18366, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580456.608148}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580457.320457, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580456.616392}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.022172927856445312, \"sum\": 0.022172927856445312, \"min\": 0.022172927856445312}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580456.607603, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580455.922756}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580456.616292, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580456.003571}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580457.18366, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580456.608148}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580457.320457, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580456.616392}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580457.865843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580457.184304}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580458.097212, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580457.320531}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580457.865843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580457.184304}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580458.097212, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580457.320531}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580458.540694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580457.866331}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580458.802464, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580458.097288}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580459.228527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580458.541224}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580458.540694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580457.866331}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580458.802464, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580458.097288}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580459.228527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580458.541224}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580459.347155, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580458.802542}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580459.347155, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580458.802542}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580459.977787, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580459.347242}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580459.977787, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580459.347242}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580460.555121, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580459.977894}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580460.555121, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580459.977894}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580460.577334, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580459.914813}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580461.177492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580460.555276}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580460.577334, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580459.914813}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580461.177492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580460.555276}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580461.465899, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580460.577413}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580461.815702, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580461.177636}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580462.05661, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580461.465979}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580461.465899, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580460.577413}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580461.815702, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580461.177636}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580462.05661, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580461.465979}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580462.556394, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580461.815777}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580462.556394, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580461.815777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580462.659051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580462.056756}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580463.120195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580462.659123}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580463.359171, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580462.55689}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580462.659051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580462.056756}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580463.120195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580462.659123}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580463.359171, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580462.55689}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580463.706495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580463.120272}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580464.026213, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580463.359671}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580464.379114, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580463.706568}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580463.706495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580463.120272}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580464.026213, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580463.359671}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580464.379114, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580463.706568}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580464.69207, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580464.026686}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.032939, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580464.379188}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.410823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580464.692621}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580464.69207, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580464.026686}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.032939, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580464.379188}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.410823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580464.692621}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.754536, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.033015}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.98868, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.410901}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580466.401017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.755051}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.754536, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.033015}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580465.98868, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.410901}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580466.401017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.755051}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580466.665469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.98875}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.115359, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580466.401482}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.302421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580466.665546}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580466.665469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580465.98875}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.115359, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580466.401482}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.302421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580466.665546}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.739935, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.115821}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.025033950805664062, \"sum\": 0.025033950805664062, \"min\": 0.025033950805664062}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.897775, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.302492}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580468.373323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.740483}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.739935, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.115821}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.025033950805664062, \"sum\": 0.025033950805664062, \"min\": 0.025033950805664062}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580467.897775, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.302492}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580468.373323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.740483}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580468.513722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.897847}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580468.980142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580468.513798}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580469.231297, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580468.373775}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580468.513722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580467.897847}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580468.980142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580468.513798}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580469.231297, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580468.373775}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580470.579474, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580469.901233}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580470.895474, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580470.26461}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580471.257271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580470.579935}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580470.579474, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580469.901233}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580470.895474, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580470.26461}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580471.257271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580470.579935}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580471.498551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580470.895551}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580471.946376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580471.257724}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580472.166187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580471.498627}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580471.498551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580470.895551}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580471.946376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580471.257724}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580472.166187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580471.498627}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580472.497456, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580471.946925}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580472.723474, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580472.166309}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.041548, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580472.497923}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.274052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580472.723554}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580472.497456, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580471.946925}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580472.723474, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580472.166309}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.041548, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580472.497923}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.274052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580472.723554}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.59348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.042013}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.829616, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.274127}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.151189, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.593919}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.59348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.042013}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580473.829616, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.274127}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.151189, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.593919}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.377478, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.829723}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.377478, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580473.829723}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.738633, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.151647}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.934837, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.378034}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580475.29805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.738709}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.738633, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.151647}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580474.934837, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.378034}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580475.29805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.738709}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580475.498642, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.93533}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580475.498642, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580474.93533}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580475.878538, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580475.298124}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580476.074084, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580475.498719}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580476.445169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580475.879016}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580475.878538, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580475.298124}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580476.074084, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580475.498719}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580476.445169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580475.879016}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580476.628408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580476.074161}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.006747, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580476.445738}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.180765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580476.628482}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580476.628408, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580476.074161}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.006747, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580476.445738}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.180765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580476.628482}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.566467, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.007228}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.732534, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.180842}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.116853, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.567008}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.281522, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.732605}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.566467, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.007228}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580477.732534, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.180842}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.116853, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.567008}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.281522, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580477.732605}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.684592, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.117347}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.842995, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.281597}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580479.243318, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.685128}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580479.390573, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.84307}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.684592, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.117347}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580478.842995, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.281597}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580479.243318, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.685128}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580479.390573, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580478.84307}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580480.923074, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580480.364905}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580481.0228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580480.472664}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580480.923074, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580480.364905}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580481.0228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580480.472664}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580481.481504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580480.923145}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580481.578273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580481.023343}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.044284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580481.481577}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.168087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580481.578736}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580481.481504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580480.923145}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580481.578273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580481.023343}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.044284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580481.481577}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.168087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580481.578736}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.639612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.044776}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.757497, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.168163}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580483.137923, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.757575}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580483.168424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.640115}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.639612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.044776}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580482.757497, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.168163}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580483.137923, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.757575}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580483.168424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580482.640115}\n",
      "\u001b[0m\n",
      "\n",
      "CPU times: user 683 ms, sys: 38.5 ms, total: 721 ms\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_transformer.transform(azdias_pca_location, \n",
    "                             content_type=CONTENT_TYPE_CSV,                               \n",
    "                             split_type='Line')\n",
    "kmeans_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to local the result of the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/kmeans/transform/test/azdias_sub_pca.out to ./azdias_sub_pca.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://{}/{}/kmeans/transform/test/'.format(bucket_name, prefix+\"/transform\") + 'azdias_sub_pca.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closest_cluster</th>\n",
       "      <th>distance_to_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.608303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.544970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.577174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.579559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.273254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closest_cluster  distance_to_cluster\n",
       "0              3.0             3.608303\n",
       "1              2.0             3.544970\n",
       "2              1.0             3.577174\n",
       "3              6.0             4.579559\n",
       "4              1.0             3.273254"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_kmeans_csv = readKmeanResultToDF(\"azdias_sub_pca.out\")\n",
    "azdias_kmeans_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform customers to 7 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_sub_pca.to_csv('customers_sub_pca',header = False,index=False, encoding=\"utf-8\")\n",
    "customers_pca_location = session.upload_data(os.path.join('customers_sub_pca'), key_prefix='test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loading entry points\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:13:18 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:13:18 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:13:18 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loading model...\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 WARNING 140020032558912] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:13:18 +0000] [70] [INFO] Booting worker with pid: 70\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] nvidia-smi took: 0.025181055069 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-15 22:13:18 +0000] [91] [INFO] Booting worker with pid: 91\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] loading model...\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 WARNING 140020032558912] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] nvidia-smi took: 0.0251798629761 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 22:13:18 INFO 140020032558912] ...model loaded.\u001b[0m\n",
      "\u001b[32m2020-05-15T22:13:26.460:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580806.454294, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580798.946006}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580806.454294, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580798.946006}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580810.338867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580798.854872}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580810.338867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580798.854872}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580810.39687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580806.45442}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580810.991432, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580810.339057}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580811.012225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580810.397433}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580810.39687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580806.45442}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580810.991432, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580810.339057}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580811.012225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580810.397433}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580811.559269, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580811.012285}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580811.617486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580810.99151}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.137866, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580811.559342}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.191892, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580811.617805}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580811.559269, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580811.012285}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580811.617486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580810.99151}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.137866, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580811.559342}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.191892, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580811.617805}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.688332, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.137941}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.792499, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.192229}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.277528, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.68869}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.343606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.792568}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.688332, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.137941}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580812.792499, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.192229}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.277528, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.68869}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.343606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580812.792568}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.825068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.277887}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.825068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.277887}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.975798, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.343681}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580814.366327, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.825144}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580813.975798, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.343681}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580814.366327, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.825144}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580814.541368, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.976124}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580814.938537, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580814.366399}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580815.09855, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580814.541682}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580814.541368, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580813.976124}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580814.938537, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580814.366399}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580815.09855, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580814.541682}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580815.502361, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580814.938868}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580815.502361, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580814.938868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580815.650927, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580815.098625}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.040364, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580815.502432}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.215551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580815.651068}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580815.650927, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580815.098625}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.040364, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580815.502432}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.215551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580815.651068}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.604787, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.040783}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.776936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.215626}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.151729, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.604943}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.33365, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.777013}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.604787, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.040783}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580816.776936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.215626}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.151729, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.604943}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.33365, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580816.777013}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.723206, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.151882}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.902184, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.333725}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580818.27905, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.723363}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.723206, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.151882}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580817.902184, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.333725}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580818.27905, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.723363}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580818.456531, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.902259}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580818.825385, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580818.279231}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580819.047326, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580818.456606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580819.280636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580819.0474}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580818.456531, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580817.902259}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580818.825385, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580818.279231}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580819.047326, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580818.456606}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580819.280636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580819.0474}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580819.335776, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580818.825541}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589580819.335776, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1589580818.825541}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 508 ms, sys: 29.8 ms, total: 538 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_transformer.transform(customers_pca_location, \n",
    "                             content_type=CONTENT_TYPE_CSV,                               \n",
    "                             split_type='Line')\n",
    "kmeans_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/kmeans/transform/test/customers_sub_pca.out to ./customers_sub_pca.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://{}/{}/kmeans/transform/test/'.format(bucket_name, prefix+\"/transform\") + 'customers_sub_pca.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closest_cluster</th>\n",
       "      <th>distance_to_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.655507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.455957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.263944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.963450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closest_cluster  distance_to_cluster\n",
       "0              1.0             3.655507\n",
       "1              5.0             4.004987\n",
       "2              1.0             3.455957\n",
       "3              6.0             4.263944\n",
       "4              1.0             3.963450"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_kmeans_csv = readKmeanResultToDF(\"customers_sub_pca.out\")\n",
    "customers_kmeans_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     3400\n",
       "1.0    70927\n",
       "2.0     2029\n",
       "3.0     2053\n",
       "4.0      898\n",
       "5.0    20705\n",
       "6.0    37075\n",
       "Name: closest_cluster, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_kmeans_csv['closest_cluster'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a bar graph with number of samples in each group for azdias and customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucVXW9//HXWy6ieUGBzBgKTCiBFGW8lB0z8SiaCaYpnlQ0juRRymum/TqKpKVZXuiYHY6gaAZ6SBANM0I9WHlhULyiR0SJ4aggN0VFBT+/P9Z3aDvMwB5m9uy14f18PPZj1v6s71rrs/bA/sx37e9eX0UEZmZmebNVuRMwMzNriAuUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUGSApJO2eln8j6d9baL+fkbRKUpv0/CFJ/9oS+077u0/S0JbaX6VLr/Vu5c7DWoYLlJWEpCGSHpP0jqTFaflMSSp3bhsTEWdExE821k7Sq5IO3ci+/h4R20XE2ubmJWmkpN/W2/8RETG+ufveXKTXen6587CW4QJlLU7S+cD1wNXAp4BdgDOAA4H2jWzTptUSbCWS2pY7hy2FX+vNVET44UeLPYAdgXeAYzfS7hbgRmBaan9o2vZWYAmwAPgxsFVqPxL4bcH23YEA2qbnDwE/Ax4H3gLuBnbewPF/ALwG/B/wnbSv3QtyuzwtdwbuBVYAy4CHyf6wuw34CHgPWAVcWJDTMODvwMym5AkcDNTWy/PV9NoMBD4APkzHe6pgf/+alrdKr9kCYHF6LXes93oNTbm9Cfy/Dbw+2wC/TPtaCfwF2CatOxp4Lr0mDwF71Mv3B8DT6fc6luwPlPuAt4E/AzvVy2l4+j28BlxQsK/9gEfScV4D/gNoX7A+gLOAl4BXCmJ1v8cjgefTcRfV2/fpwLz0O50KfLrefs9I+10B3ACo3P+3tsRH2RPwY/N6pDfSNXVvyBtod0t64zswvbF2SG+odwPbpzev/wWGpfYj2XiBWgT0BT4B/L6wfQM5vlHQ9nc0XqB+BvwGaJce/1T3ZpXejA9tIKdb0363aUqebKBANfQaFOyvrkB9J73p7gZsB9wF3FYvt/9Kee0FvE9Bcam33xvSvrsCbYAvA1sDvcgKzz+n1+PCdMz2Bfk+SlaUupIVyieAvdPv+AHg0no5TUivxRfJ/jipO9/+wAFA29R2LnBOQY4BTAd25h/Fs/D3+BrwT2l5J2CftHwIWYHeJ53Tr4CZ9fZ7L9AR+EzKaWC5/29tiQ9f4rOW1hl4MyLW1AUk/U3SCknvSTqooO3dEfHXiPiIrGcwBLg4It6OiFfJ/oI/uQnHvi0ino2Id4B/B45v5NLh8cDNBW1HbmCfHwK7Ap+NiA8j4uFI72IbMDIi3omI95qZZ1N9G7gmIuZHxCrgYmBIvctfl0XEexHxFPAUWaH6GElbkRW7syNiUUSsjYi/RcT7wAnAHyJiekR8CPyCrOB9uWAXv4qINyJiEVmP87GIeDIiVgOTyYpVocvS6/UMcDNwIkBEzI6IRyNiTfr38J/AV+tt+7OIWNbIa/0h0FvSDhGxPCKeKHidxkXEE+mcLga+JKl7wbZXRsSKiPg78CDQr4H9W4m5QFlLWwp0LnxTjIgvR0THtK7w39zCguXOZH+RLyiILSD7K7xYhftbkPbXuYF2n26gbWOuJush/EnSfEkXNTGP5uTZVJ9m/devLVlvps7rBcvvkvW06utM1tt5eWPHSH9cLOTjv6c3Cpbfa+B5/WPWfz0+DSCpl6R7Jb0u6S3gp6z/Om3otT6W7DLfAkn/I+lLjZzDKrJ/m4XnUMzrZCXmAmUt7RGyS0eDimhb2BN5k+wv3s8WxD5DdjkMsstK2xas+1QD++tWb9sP037re62Btg0nmPXmzo+I3cg+ezlP0oAG8v/YZo3tbyN5fuwcU6+qSxP2+3+s//qt4eMFohhvAquBz23sGGlUZjf+8XvaFPVfj/9LyzcCLwA9I2IH4EdA/VGgjb4mETErIgYBnwSmAHc2cg6fADo18xysBFygrEVFxArgMuDXko6TtL2krST1I/ucobHt1pK9gVyRtvkscB5QN6x6DnBQ+l7RjmSXZeo7SVJvSdsCo4BJ0fDw7juBUwvaXtpYXpKOkrR7eiNeCawlGxwB2Rv/pnznprE8/xfoIOnrktqRDXjYumC7N4Du6RJcQyYA50rqIWk7sh7HHYWXW4uRekXjgGskfVpSG0lfkrQ12Wv3dUkDUo7nk/1B8remHKOef5e0raQ+wGnAHSm+PdlAklWSvgD8W7E7lNRe0rcl7ZguRb7FP35vE4DTJPVL5/RTssuQrzbjHKwEXKCsxUXEz8mKy4Vkb6pvkH1+8EM2/Eb2PbJexHyyUWO/I3ujJCKmk71xPQ3MJvsQu77byAY4vE52ier7jeR3H3Ad2Qf289LPxvQkG3m2iqx3+OuIeDCt+xnw4/T52gUb2EdReUbESuBM4Cayv+bfAWoLtvvv9HOppCdY37i075nAK2S9oO81Ia9CFwDPALPIRrpdRTai8kXgJLKBBW8C3wC+EREfbOJxAP6H7PcwA/hFRPypIId/IRuF91/8o3AV62Tg1XR58Ayyz56IiD+Tffb3e7Le9OfIPv+0nKkbjWRW0SQ9RDbC7aZy52LFSYMSXgHaNbWXZ1sG96DMzCyXXKDMzCyXfInPzMxyyT0oMzPLJd9gMencuXN079693GmYmW32Zs+e/WZEdNlYOxeopHv37tTU1JQ7DTOzzZ6kDd29ZR1f4jMzs1xygTIzs1xygTIzs1zyZ1BmtsX68MMPqa2tZfXq1eVOZbPUoUMHqqqqaNeu3SZtX7ICJWkccBSwOCL6FsS/RzYL5lqyeWUuTPGLyWYiXQt8PyLuT/GBZNOHtwFuiogrU7wHMJHsLsSzgZMj4oN088dbySY7Wwqc4JtAmllDamtr2X777enevTvZ/YCtpUQES5cupba2lh49emzSPkp5ie8WsplL15H0NbJpGPaKiD5kk50hqTfZzRr7pG1+ne6g3IZsZs8jgN7AiaktZDevvDYidgeWkxU30s/lKX5tamdmtp7Vq1fTqVMnF6cSkESnTp2a1TstWYGKiJlkd0Eu9G9kM1W+n9osTvFBwMSIeD8iXiG7s/F+6TEvzRD6AVmPaVCa+uAQYFLafjwwuGBf49PyJGCA/K/PzBrht4fSae5r29qDJHoB/yTpsTTD5b4p3pWPz4xZm2KNxTsBKwrugFwX/9i+0vqVqb2ZmVWQ1h4k0RbYGTgA2Be4U9KmTPjWIiQNB4YDfOYzjU6qamZbij9Wt+z+Bhb35f8pU6ZwzDHHMHfuXL7whS8Utc3IkSPZbrvtuOCCC7jkkks46KCDOPTQQ5uTbe60doGqBe6K7A61j0v6COhMNjlb4bTPVfxj+uWG4kuBjpLapl5SYfu6fdVKagvsmNqvJyLGAGMAqqurt9y75rbEf8oi/yOa2fomTJjAV77yFSZMmMBll13W5O1HjRpVgqzKr7Uv8U0BvgYgqRfQnmxWzqnAEElbp9F5PYHHyWbz7JmmsG5PNpBiaipwDwLHpf0OBe5Oy1PTc9L6B8K3bDeznFq1ahV/+ctfGDt2LBMnTgTgkksuoV+/fvTr14+uXbty2mmnAXDFFVfQq1cvvvKVr/Diiy+u28epp57KpEnZR/KjRo1i3333pW/fvgwfPpy6t7/Ro0fTu3dv9txzT4YMqYwJhEtWoCRNIJsi+/OSaiUNI5uSejdJz5INeBgameeAO4HngT8CZ0XE2tQ7GgHcD8wF7kxtIZs+/DxJ88g+Yxqb4mOBTil+HnBRqc7RzKy57r77bgYOHEivXr3o1KkTs2fPZtSoUcyZM4eHHnqInXfemREjRjB79mwmTpzInDlzmDZtGrNmzWpwfyNGjGDWrFk8++yzvPfee9x7770AXHnllTz55JM8/fTT/OY3v2nNU9xkJbvEFxEnNrLqpEbaXwFc0UB8GjCtgfh8slF+9eOrgW81KVkzszKZMGECZ599NgBDhgxhwoQJ9O/fn4jgpJNO4rzzzqN///5cd911HHPMMWy77bYAHH300Q3u78EHH+TnP/857777LsuWLaNPnz584xvfYM899+Tb3/42gwcPZvDgwQ1umze+k4SZWZksW7aMBx54gGeeeQZJrF27FklcffXVjBw5kqqqqnWX94qxevVqzjzzTGpqaujWrRsjR45c9z2kP/zhD8ycOZN77rmHK664gmeeeYa2bfNdAnwvPjOzMpk0aRInn3wyCxYs4NVXX2XhwoX06NGDUaNG8ec//5nRo0eva3vQQQcxZcoU3nvvPd5++23uueee9fZXV4w6d+7MqlWr1n0u9dFHH7Fw4UK+9rWvcdVVV7Fy5UpWrVrVOifZDPkun2ZmramVR6NOmDCBH/7whx+LHXvssUyePJlFixax337ZpxhHH300o0aN4oQTTmCvvfbik5/8JPvuu+96++vYsSOnn346ffv25VOf+tS6NmvXruWkk05i5cqVRATf//736dixY+lPsJnkAW6Z6urq2GInLPQwc9tCzZ07lz322KPcaWzWGnqNJc2OiI2+8fgSn5mZ5ZILlJmZ5ZILlJmZ5ZILlJmZ5ZILlJmZ5ZILlJmZ5ZK/B2VmllSPadnpNmqGb/zrF6+//jrnnHMOs2bNomPHjuyyyy5cd9119OrVq+jjTJkyhV69etG7d++NN64g7kGZmZVJRHDMMcdw8MEH8/LLLzN79mx+9rOf8cYbbzRpP1OmTOH5558vUZYNW7t2bcmP4QJlZlYmDz74IO3ateOMM85YF9trr71Yu3YtRx111LrYiBEjuOWWWwC46KKL1k2bccEFF/C3v/2NqVOn8oMf/IB+/frx8ssvM2fOHA444AD23HNPjjnmGJYvXw7AwQcfzLnnnkt1dTV77LEHs2bN4pvf/CY9e/bkxz/+8brj/fa3v2W//fajX79+fPe7311XjLbbbjvOP/989tprLx555JH1cmlpvsRnZlYmzz77LP379y+6/dKlS5k8eTIvvPACklixYgUdO3bk6KOP5qijjuK447Ip8vbcc09+9atf8dWvfpVLLrmEyy67jOuuuw6A9u3bU1NTw/XXX8+gQYOYPXs2O++8M5/73Oc499xzWbx4MXfccQd//etfadeuHWeeeSa33347p5xyCu+88w77778/v/zlL1m6dCnDhg37WC4tzT0oM7MKseOOO9KhQweGDRvGXXfdtW7qjUIrV65kxYoVfPWrXwVg6NChzJw5c936umk6vvjFL9KnTx923XVXtt56a3bbbTcWLlzIjBkzmD17Nvvuuy/9+vVjxowZzJ8/H4A2bdpw7LHHFp1Lc7lAmZmVSZ8+fZg9e/Z68bZt2/LRRx+te153l/K2bdvy+OOPc9xxx3HvvfcycODAJh9z6623BmCrrbZat1z3fM2aNUQEQ4cOZc6cOcyZM4cXX3yRkSNHAtChQwfatGnTYrlsjAuUmVmZHHLIIbz//vuMGTNmXezpp58mInj++ed5//33WbFiBTNmzACy6eFXrlzJkUceybXXXstTTz0FwPbbb8/bb78NZD2bnXbaiYcffhiA2267bV1vqhgDBgxg0qRJLF68GMjmrFqwYMF67RrLpSX5Mygzs6SYYeEtSRKTJ0/mnHPO4aqrrqJDhw50796d6667juOPP56+ffvSo0cP9t57bwDefvttBg0axOrVq4kIrrnmGiCbiff0009n9OjRTJo0ifHjx3PGGWfw7rvvsttuu3HzzTcXnVPv3r25/PLLOeyww/joo49o164dN9xwA5/97Gc/1q6xXFpSyabbkDQOOApYHBF96607H/gF0CUi3pQk4HrgSOBd4NSIeCK1HQrUDS+5PCLGp3h/4BZgG7Ip4c+OiJC0M3AH0B14FTg+IpZvLF9Pt9FMnm7DKpCn2yi9vE63cQuw3kVJSd2Aw4C/F4SPAHqmx3DgxtR2Z+BSYH9gP+BSSTulbW4ETi/Yru5YFwEzIqInMCM9NzOzClOyAhURM4FlDay6FrgQKOy6DQJujcyjQEdJuwKHA9MjYlnqBU0HBqZ1O0TEo5F1AW8FBhfsa3xaHl8QNzOzCtKqgyQkDQIWRUT9T9O6AgsLntem2IbitQ3EAXaJiNfS8uvALhvIZ7ikGkk1S5YsaerpmNlmwLOKl05zX9tWK1CStgV+BFzSWsdMvatGX6GIGBMR1RFR3aVLl9ZKy8xyokOHDixdutRFqgQigqVLl9KhQ4dN3kdrjuL7HNADeCobE0EV8ISk/YBFQLeCtlUptgg4uF78oRSvaqA9wBuSdo2I19KlwMUtfiZmtlmoqqqitrYWX0EpjQ4dOlBVVbXxho1otQIVEc8An6x7LulVoDqN4psKjJA0kWxAxMpUYO4HflowMOIw4OKIWCbpLUkHAI8BpwC/Sm2mAkOBK9PPu1vh9MysArVr144ePXqUOw1rRMku8UmaADwCfF5SraRhG2g+DZgPzAP+CzgTICKWAT8BZqXHqBQjtbkpbfMycF+KXwn8s6SXgEPTczMzqzAl60FFxIkbWd+9YDmAsxppNw4Y10C8BujbQHwpMKCJ6ZqZWc74VkdmZpZLLlBmZpZLLlBmZpZLvlmsmW15fP/JiuAelJmZ5ZILlJmZ5ZILlJmZ5ZILlJmZ5ZIHSVhl84fdZpst96DMzCyXXKDMzCyXfInPzKySbEGXtd2DMjOzXHKBMjOzXHKBMjOzXHKBMjOzXHKBMjOzXCrllO/jJC2W9GxB7GpJL0h6WtJkSR0L1l0saZ6kFyUdXhAfmGLzJF1UEO8h6bEUv0NS+xTfOj2fl9Z3L9U5mplZ6ZSyB3ULMLBebDrQNyL2BP4XuBhAUm9gCNAnbfNrSW0ktQFuAI4AegMnprYAVwHXRsTuwHJgWIoPA5an+LWpnZmZVZiSFaiImAksqxf7U0SsSU8fBarS8iBgYkS8HxGvAPOA/dJjXkTMj4gPgInAIEkCDgEmpe3HA4ML9jU+LU8CBqT2ZmZWQcr5GdR3gPvScldgYcG62hRrLN4JWFFQ7OriH9tXWr8ytV+PpOGSaiTVLFmypNknZGZmLacsBUrS/wPWALeX4/h1ImJMRFRHRHWXLl3KmYqZmdXT6rc6knQqcBQwICIihRcB3QqaVaUYjcSXAh0ltU29pML2dfuqldQW2DG1NzOzCtKqPShJA4ELgaMj4t2CVVOBIWkEXg+gJ/A4MAvomUbstScbSDE1FbYHgePS9kOBuwv2NTQtHwc8UFAIzcysQpSsByVpAnAw0FlSLXAp2ai9rYHpadzCoxFxRkQ8J+lO4HmyS39nRcTatJ8RwP1AG2BcRDyXDvFDYKKky4EngbEpPha4TdI8skEaQ0p1jmZmVjolK1ARcWID4bENxOraXwFc0UB8GjCtgfh8slF+9eOrgW81KVkzM8sd30nCzMxyyQXKzMxyyQXKzMxyyQXKzMxyyQXKzMxyqdW/qGtmyR+rm7+PgTXN34dZTrkHZWZmueQCZWZmueQCZWZmueQCZWZmueQCZWZmueQCZWZmueQCZWZmueQCZWZmueQCZWZmueQCZWZmueQCZWZmuVSyAiVpnKTFkp4tiO0sabqkl9LPnVJckkZLmifpaUn7FGwzNLV/SdLQgnh/Sc+kbUYrzSHf2DHMzKyylLIHdQswsF7sImBGRPQEZqTnAEcAPdNjOHAjZMUGuBTYn2x690sLCs6NwOkF2w3cyDHMzKyClKxARcRMYFm98CBgfFoeDwwuiN8amUeBjpJ2BQ4HpkfEsohYDkwHBqZ1O0TEoxERwK319tXQMczMrIK09mdQu0TEa2n5dWCXtNwVWFjQrjbFNhSvbSC+oWOsR9JwSTWSapYsWbIJp2NmZqVStkESqecT5TxGRIyJiOqIqO7SpUspUzEzsyZq7QL1Rro8R/q5OMUXAd0K2lWl2IbiVQ3EN3QMMzOrIK1doKYCdSPxhgJ3F8RPSaP5DgBWpst09wOHSdopDY44DLg/rXtL0gFp9N4p9fbV0DHMzKyClGzKd0kTgIOBzpJqyUbjXQncKWkYsAA4PjWfBhwJzAPeBU4DiIhlkn4CzErtRkVE3cCLM8lGCm4D3JcebOAYZmZWQYoqUJIOBOZExDuSTgL2Aa6PiAWNbRMRJzayakADbQM4q5H9jAPGNRCvAfo2EF/a0DHMzKyyFHuJ70bgXUl7AecDL5MN7TYzMyuJYgvUmtTLGQT8R0TcAGxfurTMzGxLV+xnUG9Luhg4CThI0lZAu9KlZWZmW7pie1AnAO8DwyLidbJh3VeXLCszM9viFdWDSkXpmoLnf8efQZmZWQkV1YOS9M10d/CVkt6S9Lakt0qdnJmZbbmK/Qzq58A3ImJuKZMxMzOrU+xnUG+4OJmZWWsqtgdVI+kOYArZYAkAIuKukmRlZmZbvGIL1A5ktyA6rCAWgAuUmZmVRLGj+E4rdSJmZmaFih3FVyVpsqTF6fF7SVUb39LMzGzTFDtI4mayaSw+nR73pJiZmVlJFFugukTEzRGxJj1uATwFrZmZlUyxBWqppJMktUmPk4ClpUzMzMy2bMUWqO+QTfz3enocR5pU0MzMrBSKHcW3ADi6xLmYmZmtU+wovp9L2kFSO0kzJC1Jl/nMzMxKothLfIdFxFvAUcCrwO7ADzb1oJLOlfScpGclTZDUQVIPSY9JmifpDkntU9ut0/N5aX33gv1cnOIvSjq8ID4wxeZJumhT8zQzs/IptkDVTU74deC/I2Llph5QUlfg+0B1RPQF2gBDgKuAayNid2A5MCxtMgxYnuLXpnZI6p226wMMBH5dN4gDuAE4AugNnJjamplZBSm2QE2V9ALQH5ghqQuwuhnHbQtsI6ktsC3wGnAIMCmtHw8MTsuD0nPS+gGSlOITI+L9iHgFmAfslx7zImJ+RHwATExtzcysgmy0QKXp3e8BvkzW6/mQ7L58m/SmHxGLgF8AfycrTCuB2cCKiFiTmtUCXdNyV2Bh2nZNat+pMF5vm8biDZ3bcEk1kmqWLFmyKadjZmYlstECFREfATdExLKIWJti76RZdptM0k5kxa0H2V0pPkF2ia7VRcSYiKiOiOouXfy9YzOzPCn2Et8MScemS2vNdSjwSkQsSb2xu4ADgY7pkh9AFbAoLS8CugGk9TuSfUl4XbzeNo3FzcysghRboL4L/DfwQQtM+f534ABJ26aCNwB4HniQ7AvAAEOBu9Py1PSctP6BiIgUH5JG+fUAegKPA7OAnmlUYHuygRRTNzFXMzMrk2K/qLt9Sx0wIh6TNAl4AlgDPAmMAf4ATJR0eYqNTZuMBW6TNA9YRlZwiIjnJN1JVtzWAGfVXYKUNAK4n2yE4LiIeK6l8m/UH6ubt/3AmpbJw8xsM1FUgUo9nW8DPSLiJ5K6AbtGxOObctCIuBS4tF54PtkIvPptVwPfamQ/VwBXNBCfBkzblNzMzCwfir3E92vgS8C/pOeryL5rZGZmVhLFTvm+f0TsI+lJgIhYXnenBzMzs1Iotgf1YbpDQwCkL+p+VLKszMxsi1dsgRoNTAY+KekK4C/AT0uWlZmZbfGKHcV3u6TZZEPCBQyOiLklzczMzLZoGyxQkjoAZ5DdvfwZ4D8LbkdkZmZWMhvrQY0HPgQeJrs7+B7AOaVOyipP9ZjmfQ+sZri/B2ZmH7exAtU7Ir4IIGks2Z0azMzMSm5jgyQ+rFvwpT0zM2tNG+tB7VVwzz2RzeH0VlqOiNihpNmZmdkWa4MFKiLatFYiZmZmhYr9HpSZmVmrcoEyM7NccoEyM7NccoEyM7NccoEyM7NccoEyM7NcKkuBktRR0iRJL0iaK+lLknaWNF3SS+nnTqmtJI2WNE/S05L2KdjP0NT+JUlDC+L9JT2TthmdZgQ2M7MKUq4e1PXAHyPiC8BewFzgImBGRPQEZqTnkN0DsGd6DAduBJC0M9m08fuTTRV/aV1RS21OL9huYCuck5mZtaBWL1CSdgQOAsYCRMQHEbECGER2c1rSz8FpeRBwa2QeBTpK2hU4HJgeEcsiYjkwHRiY1u0QEY9GRAC3FuzLzMwqRDl6UD2AJcDNkp6UdJOkTwC7RMRrqc3rwC5puSuwsGD72hTbULy2gfh6JA2XVCOpZsmSJc08LTMza0nlKFBtgX2AGyNib+Ad/nE5D8hu8keaXr6UImJMRFRHRHWXLl1KfTgzM2uCchSoWqA2Ih5LzyeRFaw30uU50s/Faf0ioFvB9lUptqF4VQNxMzOrIK1eoCLidWChpM+n0ADgeWAqUDcSbyhwd1qeCpySRvMdAKxMlwLvBw6TtFMaHHEYcH9a95akA9LovVMK9mVmZhViY9NtlMr3gNsltQfmA6eRFcs7JQ0DFgDHp7bTgCOBecC7qS0RsUzST4BZqd2oiFiWls8EbgG2Ae5LDzMzqyBlKVARMQdoaI7wAQ20DeCsRvYzDhjXQLwG6NvMNM3MrIx8JwkzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8slFygzM8ulshUoSW0kPSnp3vS8h6THJM2TdEeaDh5JW6fn89L67gX7uDjFX5R0eEF8YIrNk3RRa5+bmZk1Xzl7UGcDcwueXwVcGxG7A8uBYSk+DFie4temdkjqDQwB+gADgV+notcGuAE4AugNnJjamplZBSlLgZJUBXwduCk9F3AIMCk1GQ8MTsuD0nPS+gGp/SBgYkS8HxGvAPOA/dJjXkTMj4gPgImprZmZVZBy9aCuAy4EPkrPOwErImJNel4LdE3LXYGFAGn9ytR+XbzeNo3F1yNpuKQaSTVLlixp7jmZmVkLavUCJekoYHFEzG7tY9cXEWMiojoiqrt06VLudMzMrEDbMhzzQOBoSUcCHYAdgOuBjpLapl5SFbAotV8EdANqJbUFdgSWFsTrFG7TWNzMzCpEq/egIuLiiKiKiO5kgxweiIhvAw8Cx6VmQ4G70/LU9Jy0/oGIiBQfkkb59QB6Ao8Ds4DDv/vyAAAIwUlEQVSeaVRg+3SMqa1wamZm1oLK0YNqzA+BiZIuB54Exqb4WOA2SfOAZWQFh4h4TtKdwPPAGuCsiFgLIGkEcD/QBhgXEc+16pmYmeVY9ZjqZm1fM7ymhTLZsLIWqIh4CHgoLc8nG4FXv81q4FuNbH8FcEUD8WnAtBZM1czMWpnvJGFmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnkAmVmZrnU6gVKUjdJD0p6XtJzks5O8Z0lTZf0Uvq5U4pL0mhJ8yQ9LWmfgn0NTe1fkjS0IN5f0jNpm9GS1NrnaWZmzVOOHtQa4PyI6A0cAJwlqTdwETAjInoCM9JzgCOAnukxHLgRsoIGXArsTzZV/KV1RS21Ob1gu4GtcF5mZtaCWr1ARcRrEfFEWn4bmAt0BQYB41Oz8cDgtDwIuDUyjwIdJe0KHA5Mj4hlEbEcmA4MTOt2iIhHIyKAWwv2ZWZmFaJtOQ8uqTuwN/AYsEtEvJZWvQ7skpa7AgsLNqtNsQ3FaxuIm5m1mOox1c3avmZ4TQtlsvkq2yAJSdsBvwfOiYi3Ctelnk+0Qg7DJdVIqlmyZEmpD2dmZk1QlgIlqR1Zcbo9Iu5K4TfS5TnSz8UpvgjoVrB5VYptKF7VQHw9ETEmIqojorpLly7NOykzM2tR5RjFJ2AsMDcirilYNRWoG4k3FLi7IH5KGs13ALAyXQq8HzhM0k5pcMRhwP1p3VuSDkjHOqVgX2ZmViHK8RnUgcDJwDOS5qTYj4ArgTslDQMWAMenddOAI4F5wLvAaQARsUzST4BZqd2oiFiWls8EbgG2Ae5LDzMzqyCtXqAi4i9AY99LGtBA+wDOamRf44BxDcRrgL7NSNPMzMrMd5IwM7NccoEyM7NcKuv3oMysgv2xed8DYqC/B2Qb5h6UmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlkguUmZnlku9mnhPVY5p5Z2igZrjvDm1mmw/3oMzMLJc22x6UpIHA9UAb4KaIuLLMKVlONbf3Ws6eq3vetjnbLHtQktoANwBHAL2BEyX1Lm9WZmbWFJtrD2o/YF5EzAeQNBEYBDxf1qzMbB33/mxjFBHlzqHFSToOGBgR/5qenwzsHxEj6rUbDgxPTz8PvNiqiTZdZ+DNciexiZx7eVRy7lDZ+Tv3xn02IrpsrNHm2oMqSkSMAcaUO49iSaqJiOb/2VkGzr08Kjl3qOz8nXvzbZafQQGLgG4Fz6tSzMzMKsTmWqBmAT0l9ZDUHhgCTC1zTmZm1gSb5SW+iFgjaQRwP9kw83ER8VyZ02oJFXM5sgHOvTwqOXeo7PydezNtloMkzMys8m2ul/jMzKzCuUCZmVkuuUBVAEnjJC2W9Gy5c2kKSd0kPSjpeUnPSTq73Dk1haQOkh6X9FTK/7Jy59RUktpIelLSveXOpSkkvSrpGUlzJFXUt3EldZQ0SdILkuZK+lK5c6pU/gyqAkg6CFgF3BoRfcudT7Ek7QrsGhFPSNoemA0MjoiKuKOHJAGfiIhVktoBfwHOjohHy5xa0SSdB1QDO0TEUeXOp1iSXgWqI6LivugqaTzwcETclEYRbxsRK8qdVyVyD6oCRMRMYFm582iqiHgtIp5Iy28Dc4Gu5c2qeJFZlZ62S4+K+YtOUhXwdeCmcueypZC0I3AQMBYgIj5wcdp0LlDWKiR1B/YGHitvJk2TLpHNARYD0yOikvK/DrgQ+KjciWyCAP4kaXa6JVml6AEsAW5Ol1ZvkvSJcidVqVygrOQkbQf8HjgnIt4qdz5NERFrI6If2d1I9pNUEZdYJR0FLI6I2eXOZRN9JSL2IZuR4Kx0mbsStAX2AW6MiL2Bd4CLyptS5XKBspJKn938Hrg9Iu4qdz6bKl2meRAYWO5cinQgcHT6LGcicIik35Y3peJFxKL0czEwmWyGgkpQC9QW9LQnkRUs2wQuUFYyaZDBWGBuRFxT7nyaSlIXSR3T8jbAPwMvlDer4kTExRFRFRHdyW719UBEnFTmtIoi6RNpUA3p8thhQEWMYI2I14GFkj6fQgPwND+bbLO81dHmRtIE4GCgs6Ra4NKIGFverIpyIHAy8Ez6HAfgRxExrYw5NcWuwPg0AeZWwJ0RUVHDtSvULsDk7O8b2gK/i4g/ljelJvkecHsawTcfOK3M+VQsDzM3M7Nc8iU+MzPLJRcoMzPLJRcoMzPLJRcoMzPLJRcoMzPLJRcoszKStIuk30man27r84ikY8qdl1keuECZlUn6IvMUYGZE7BYR/cm+VFtVr52/r2hbJBcos/I5BPggIn5TF4iIBRHxK0mnSpoq6QFghjJXS3o2zZN0AoCkgwvnepL0H5JOTcuvSvp5av+4pN1T/FtpP09JmtmqZ2zWBP7LzKx8+gBPbGD9PsCeEbFM0rFAP2AvoDMwq8jisjIivijpFLK7mx8FXAIcHhGL6m7lZJZH7kGZ5YSkG1KvZlYKTY+IunnAvgJMSHdXfwP4H2DfInY7oeBn3cyufwVukXQ60KaF0jdrcS5QZuXzHAV3uo6Is8huLtolhd4pYh9r+Pj/4w711kf95Yg4A/gx0A2YLalT09I2ax0uUGbl8wDQQdK/FcS2baTtw8AJaQLFLmSztj4OLAB6S9o6Xa4bUG+7Ewp+PgIg6XMR8VhEXEI2uV63ljkds5blz6DMyiQiQtJg4FpJF5IVi3eAHwLb1Gs+mewS3VNkPaEL09QOSLqTbDqKV4An6223k6SngfeBE1Psakk9AQEz0j7Ncsd3MzfbTKXJCqsj4s1y52K2KXyJz8zMcsk9KDMzyyX3oMzMLJdcoMzMLJdcoMzMLJdcoMzMLJdcoMzMLJf+P/K7pd1MpzBPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "customers_kmeans_csv.loc[customers_kmeans_csv['closest_cluster'] == 7].count()\n",
    "\n",
    "\n",
    "\n",
    "# data to plot\n",
    "n_groups = 7\n",
    "azdias_groups = azdias_kmeans_csv['closest_cluster'].value_counts().sort_index()\n",
    "customers_groups = customers_kmeans_csv['closest_cluster'].value_counts().sort_index()\n",
    "\n",
    "#azdias_groups = (0,1,2,3,4)\n",
    "\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, azdias_groups, bar_width,\n",
    "                alpha=opacity,\n",
    "                color='orange',\n",
    "                label='Azdias')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, customers_groups, bar_width,\n",
    "                alpha=opacity,\n",
    "                color='g',\n",
    "                label='Customers')\n",
    "\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Persons')\n",
    "plt.title('Group distribution comparison')\n",
    "plt.xticks(index + bar_width, (range(1,7)))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the majority of customers are from group 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
