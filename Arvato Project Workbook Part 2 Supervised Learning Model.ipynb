{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be divided in several blocks\n",
    "\n",
    "+ Data load\n",
    "+ Data cleaning\n",
    "+ Feature engineering\n",
    "+ Data visualization\n",
    "+ Model training\n",
    "+ Model selection\n",
    "+ Model tuning\n",
    "+ Save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import general libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "\n",
    "#Import sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#Import SageMaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "#Import custom libraries\n",
    "from load_data import list_csv_files, load_dataframe_from_s3\n",
    "from clean_data import dropMissingColumns, dropLowVarianceCols, dropColumnsWithUniqueValues, replaceForNan, timestampToFloat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3 client to get S3 data\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name='sagemaker-eu-west-1-848439228145'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Capstone/Udacity_AZDIAS_052018.csv', 'Capstone/Udacity_CUSTOMERS_052018.csv', 'Capstone/Udacity_MAILOUT_052018_TEST.csv', 'Capstone/Udacity_MAILOUT_052018_TRAIN.csv', 'arvato/azdias.csv', 'arvato/customers.csv', 'arvato/transform/pca/transform/test/azdias.csv.out', 'arvato/transform/pca/transform/test/customers.csv.out', 'mailout-xgboost/mailout_test.csv', 'mailout-xgboost/mailout_train.csv', 'mailout-xgboost/mailout_validation.csv', 'mailout/transform/test/mailout_test.csv.out', 'test/customers.csv.out', 'xgboost-200512-2100-006-5d9003f4-2020-05-12-21-13-29-318/mailout_test.csv.out', 'xgboost-200513-1550-009-510b69c6-2020-05-13-16-00-48-200/mailout_test.csv.out', 'xgboost-200513-2107-008-571099bb-2020-05-13-21-17-53-739/mailout_test.csv.out', 'xgboost-200513-2210-004-d4b243f8-2020-05-13-22-22-41-620/mailout_test.csv.out']\n"
     ]
    }
   ],
   "source": [
    "# get a list of objects in the bucket\n",
    "obj_list=s3_client.list_objects(Bucket=bucket_name)\n",
    "#filter the list with to get only csv\n",
    "filtered_list = list_csv_files(obj_list)\n",
    "# print csv objects in in S3 bucket  \n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0           0  1763         2         1.0       8.0          NaN          NaN   \n",
       "1           1  1771         1         4.0      13.0          NaN          NaN   \n",
       "2           2  1776         1         1.0       9.0          NaN          NaN   \n",
       "3           3  1460         2         1.0       6.0          NaN          NaN   \n",
       "4           4  1783         2         1.0       9.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VK_DHT4A  VK_DISTANZ  \\\n",
       "0          NaN          NaN                   8.0  ...       5.0         2.0   \n",
       "1          NaN          NaN                  13.0  ...       1.0         2.0   \n",
       "2          NaN          NaN                   7.0  ...       6.0         4.0   \n",
       "3          NaN          NaN                   6.0  ...       8.0        11.0   \n",
       "4          NaN          NaN                   9.0  ...       2.0         2.0   \n",
       "\n",
       "   VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  RESPONSE  \\\n",
       "0      1.0             6.0             9.0       3.0         3         0   \n",
       "1      1.0             4.0             9.0       7.0         1         0   \n",
       "2      2.0             NaN             9.0       2.0         3         0   \n",
       "3     11.0             6.0             9.0       1.0         3         0   \n",
       "4      1.0             6.0             9.0       3.0         3         0   \n",
       "\n",
       "  ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         2                    4  \n",
       "1         2                    3  \n",
       "2         1                    4  \n",
       "3         2                    4  \n",
       "4         1                    3  \n",
       "\n",
       "[5 rows x 368 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_df = None\n",
    "mailout_train_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[3])\n",
    "mailout_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate features from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df_target = mailout_train_df['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.drop('RESPONSE', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1754</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1770</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1465</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1470</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1478</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0           0  1754         2         1.0       7.0          NaN          NaN   \n",
       "1           1  1770        -1         1.0       0.0          NaN          NaN   \n",
       "2           2  1465         2         9.0      16.0          NaN          NaN   \n",
       "3           3  1470        -1         7.0       0.0          NaN          NaN   \n",
       "4           4  1478         1         1.0      21.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VHN  VK_DHT4A  \\\n",
       "0          NaN          NaN                   6.0  ...  4.0       5.0   \n",
       "1          NaN          NaN                   0.0  ...  1.0       5.0   \n",
       "2          NaN          NaN                  11.0  ...  3.0       9.0   \n",
       "3          NaN          NaN                   0.0  ...  2.0       6.0   \n",
       "4          NaN          NaN                  13.0  ...  1.0       2.0   \n",
       "\n",
       "   VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "0         6.0      3.0             6.0             9.0       3.0         3   \n",
       "1         2.0      1.0             6.0             9.0       5.0         3   \n",
       "2         6.0      3.0             2.0             9.0       4.0         3   \n",
       "3         6.0      3.0             NaN             9.0       2.0         3   \n",
       "4         4.0      3.0             3.0             9.0       7.0         4   \n",
       "\n",
       "  ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         1                    4  \n",
       "1         1                    4  \n",
       "2         2                    4  \n",
       "3         2                    4  \n",
       "4         2                    4  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_df = None\n",
    "mailout_test_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[2])\n",
    "mailout_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find rows with more that 25% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTER_KIND4     99.904567\n",
       "ALTER_KIND3     99.594991\n",
       "ALTER_KIND2     98.240305\n",
       "ALTER_KIND1     95.372655\n",
       "KK_KUNDENTYP    58.926493\n",
       "EXTSEL992       37.121177\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = mailout_train_df.shape[0]\n",
    "missing_mailout_train = mailout_train_df.isnull().sum().sort_values(ascending = False).divide(other = (rows/100))\n",
    "\n",
    "display(missing_mailout_train.loc[missing_mailout_train > 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTER_KIND4     99.908949\n",
       "ALTER_KIND3     99.530736\n",
       "ALTER_KIND2     98.220998\n",
       "ALTER_KIND1     95.300353\n",
       "KK_KUNDENTYP    58.447926\n",
       "EXTSEL992       36.908458\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = mailout_test_df.shape[0]\n",
    "missing_mailout_test = mailout_test_df.isnull().sum().sort_values(ascending = False).divide(other = (rows/100))\n",
    "\n",
    "display(missing_mailout_test.loc[missing_mailout_test > 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Drop columns with more than a 60% of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42962, 363)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropMissingColumns(mailout_train_df, threshold = 60)\n",
    "mailout_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 363)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropMissingColumns(mailout_test_df, threshold = 60)\n",
    "mailout_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Drop low dispersion cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns:  ANZ_HH_TITEL                 0.380335\n",
      "ANZ_KINDER                   0.395995\n",
      "ANZ_TITEL                    0.104587\n",
      "D19_BANKEN_ANZ_12            0.454065\n",
      "D19_TELKO_ANZ_12             0.273082\n",
      "D19_TELKO_ANZ_24             0.368817\n",
      "D19_TELKO_ONLINE_DATUM       0.251425\n",
      "D19_TELKO_ONLINE_QUOTE_12    0.326480\n",
      "D19_VERSI_ANZ_12             0.422899\n",
      "D19_VERSI_ONLINE_DATUM       0.258214\n",
      "D19_VERSI_ONLINE_QUOTE_12    0.395185\n",
      "DSL_FLAG                     0.138167\n",
      "GREEN_AVANTGARDE             0.448932\n",
      "HH_DELTA_FLAG                0.335117\n",
      "KBA13_KRSSEG_KLEIN           0.289578\n",
      "KONSUMZELLE                  0.393734\n",
      "NATIONALITAET_KZ             0.465673\n",
      "SOHO_KZ                      0.097854\n",
      "TITEL_KZ                     0.128331\n",
      "UNGLEICHENN_FLAG             0.257269\n",
      "ANREDE_KZ                    0.490881\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mailout_train_drops = dropLowVarianceCols(mailout_train_df, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 342)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_df.drop(mailout_train_drops, axis = 1, inplace = True)\n",
    "mailout_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Drop columns with all its values unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42962, 342)\n",
      "(42962, 340)\n"
     ]
    }
   ],
   "source": [
    "print(mailout_train_df.shape)\n",
    "mailout_train_df = dropColumnsWithUniqueValues(mailout_train_df)\n",
    "print(mailout_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42833, 340)\n"
     ]
    }
   ],
   "source": [
    "#we will need this values later for the submission dataset\n",
    "LNR_test = mailout_test_df['LNR']\n",
    "\n",
    "mailout_test_df = dropColumnsWithUniqueValues(mailout_test_df)\n",
    "print(mailout_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Drop rows with more than 290 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34214, 340)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_df.dropna(thresh=290, inplace = True)\n",
    "mailout_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop samples from target feature that have been dropped from features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34214,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_df_target.drop(mailout_train_df_target.index.difference(mailout_train_df.index), inplace = True)\n",
    "mailout_train_df_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset index after dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df_target = mailout_train_df_target.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Impute missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMEO_DEU_2015</th>\n",
       "      <th>CAMEO_DEUG_2015</th>\n",
       "      <th>CAMEO_INTL_2015</th>\n",
       "      <th>D19_LETZTER_KAUF_BRANCHE</th>\n",
       "      <th>EINGEFUEGT_AM</th>\n",
       "      <th>OST_WEST_KZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5D</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>D19_UNBEKANNT</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5B</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>D19_TELKO_MOBILE</td>\n",
       "      <td>1997-05-14 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2D</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>D19_LEBENSMITTEL</td>\n",
       "      <td>1995-05-24 00:00:00</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2D</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>D19_UNBEKANNT</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7B</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>D19_BEKLEIDUNG_GEH</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CAMEO_DEU_2015 CAMEO_DEUG_2015 CAMEO_INTL_2015 D19_LETZTER_KAUF_BRANCHE  \\\n",
       "0             5D               5              34            D19_UNBEKANNT   \n",
       "1             5B               5              32         D19_TELKO_MOBILE   \n",
       "2             2D               2              14         D19_LEBENSMITTEL   \n",
       "3             2D               2              14            D19_UNBEKANNT   \n",
       "4             7B               7              41       D19_BEKLEIDUNG_GEH   \n",
       "\n",
       "         EINGEFUEGT_AM OST_WEST_KZ  \n",
       "0  1992-02-10 00:00:00           W  \n",
       "1  1997-05-14 00:00:00           W  \n",
       "2  1995-05-24 00:00:00           O  \n",
       "3  1992-02-10 00:00:00           W  \n",
       "4  1992-02-10 00:00:00           W  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_df.select_dtypes(exclude=['float', 'int']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns that supposedly contain numeric values but their dtype is not float or int, so they are suspicious to have categorical values instead of nan, let's find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.0 32.0 14.0 41.0 24.0 33.0 25.0 31.0 22.0 43.0 13.0 55.0 23.0 54.0\n",
      " 51.0 45.0 12.0 44.0 35.0 15.0 52.0 nan '23' '44' '14' '55' '51' '45' '43'\n",
      " '22' '54' '24' '25' '13' '12' '35' '33' '41' '15' '52' '32' '34' '31'\n",
      " 'XX']\n",
      "[5.0 2.0 7.0 4.0 3.0 6.0 1.0 8.0 9.0 nan '4' '6' '2' '9' '8' '7' '3' '1'\n",
      " '5' 'X']\n"
     ]
    }
   ],
   "source": [
    "print(mailout_train_df['CAMEO_INTL_2015'].unique())\n",
    "print(mailout_train_df['CAMEO_DEUG_2015'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that they have XX and X when it should be a nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceForNan(mailout_train_df)\n",
    "replaceForNan(mailout_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df['CAMEO_DEUG_2015'] = mailout_train_df['CAMEO_DEUG_2015'].astype('float32')\n",
    "mailout_train_df['CAMEO_INTL_2015'] = mailout_train_df['CAMEO_INTL_2015'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df['EINGEFUEGT_AM'] = mailout_train_df['EINGEFUEGT_AM'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df['CAMEO_DEUG_2015'] = mailout_test_df['CAMEO_DEUG_2015'].astype('float32')\n",
    "mailout_test_df['CAMEO_INTL_2015'] = mailout_test_df['CAMEO_INTL_2015'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_test_df['EINGEFUEGT_AM'] = mailout_test_df['EINGEFUEGT_AM'].astype('datetime64')\n",
    "mailout_test_df['EINGEFUEGT_AM'] = mailout_test_df['EINGEFUEGT_AM'].replace('NaT', 'NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also it is necessary to convert from timestamp to int the feature EINGEFUEGT_AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df['EINGEFUEGT_AM'] = timestampToFloat(mailout_train_df, 'EINGEFUEGT_AM')\n",
    "mailout_train_df['EINGEFUEGT_AM'] = mailout_train_df['EINGEFUEGT_AM'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df['EINGEFUEGT_AM'] = timestampToFloat(mailout_test_df, 'EINGEFUEGT_AM')\n",
    "mailout_test_df['EINGEFUEGT_AM'] = mailout_test_df['EINGEFUEGT_AM'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.select_dtypes(exclude=['float', 'int', 'float32']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_mailout_train = mailout_train_df.select_dtypes(include=['float', 'int','float32', 'datetime64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_list = ['WOHNLAGE','VERS_TYP','SHOPPER_TYP','RETOURTYP_BK_S','PLZ8_BAUMAX',\n",
    "                'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','KBA05_MODTEMP','KBA05_MAXHERST','KBA05_HERSTTEMP',\n",
    "                'HEALTH_TYP','GFK_URLAUBERTYP','GEBAEUDETYP','FINANZTYP','D19_KONSUMTYP_MAX',\n",
    "                'CJT_GESAMTTYP','AGER_TYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_mailout_train.drop(one_hot_list, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_mailout_test = mailout_test_df.select_dtypes(include=['float', 'int','float32','datetime64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_mailout_test.drop(one_hot_list, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "imp_mean = IterativeImputer(random_state=0, initial_strategy = 'median')\n",
    "imp_mean.fit(numerical_mailout_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_mailout_train = imp_mean.transform(numerical_mailout_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_mailout_test = imp_mean.transform(numerical_mailout_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.update(pd.DataFrame(imputed_mailout_train, columns = numerical_mailout_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df.update(pd.DataFrame(imputed_mailout_test, columns = numerical_mailout_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('category', inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df = to_category(mailout_train_df, one_hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df = to_category(mailout_test_df, one_hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.select_dtypes(include=['O','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mode_categorical(df):\n",
    "    categorical_columns= df.select_dtypes(include=['O','category'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in categorical_columns: \n",
    "        col_data = df[column]\n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        mode = col_data.mode()[0]\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(mode, inplace=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.update(impute_mode_categorical(mailout_train_df.select_dtypes(exclude=['float', 'int', 'float32'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df.update(impute_mode_categorical(mailout_test_df.select_dtypes(exclude=['float', 'int', 'float32'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df.select_dtypes(include=['O','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df.select_dtypes(include=['O','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_list = ['WOHNLAGE','VERS_TYP','SHOPPER_TYP','RETOURTYP_BK_S','PLZ8_BAUMAX',\n",
    "                'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','KBA05_MODTEMP','KBA05_MAXHERST','KBA05_HERSTTEMP',\n",
    "                'HEALTH_TYP','GFK_URLAUBERTYP','GEBAEUDETYP','FINANZTYP','D19_KONSUMTYP_MAX',\n",
    "                'CJT_GESAMTTYP','CAMEO_DEU_2015','AGER_TYP']\n",
    "one_hot_list.extend(mailout_test_df.select_dtypes(include=['O']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_df = pd.get_dummies(mailout_train_df, columns = one_hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df = pd.get_dummies(mailout_test_df, columns = one_hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_list = np.setdiff1d(mailout_test_df.columns,mailout_train_df.columns)\n",
    "main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df.drop(main_list, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mailout_test_df.shape)\n",
    "print(mailout_train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5 Second iteration dropping low variance columns after perform one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_drops = dropLowVarianceCols(mailout_train_df, threshold = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df.drop(mailout_train_drops,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mailout_test_df.shape)\n",
    "print(mailout_train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5 Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(mailout_train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mailout_train = scaler.transform(mailout_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mailout_test = scaler.transform(mailout_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO Repasar el scaler este"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Correlation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "def correlationMap(d):\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = d.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlationMap(mailout_train_df)\n",
    "total_train = mailout_train_df.copy()\n",
    "total_train['RESPONSE'] = mailout_train_df_target.copy()\n",
    "\n",
    "response_correlation = total_train[total_train.columns[1:]].corr()['RESPONSE'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_response_corr = response_correlation.sort_values(ascending = False)[1:11]\n",
    "sub_response_corr = sub_response_corr.append(response_correlation.sort_values(ascending = False).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center the data to make it diverging\n",
    "f, (ax2) = plt.subplots(1, 1, figsize=(7, 9), sharex=True)\n",
    "sns.barplot(x=sub_response_corr, y=sub_response_corr.index, palette=\"vlag\", ax=ax2)\n",
    "ax2.axhline(0, color=\"k\", clip_on=False)\n",
    "ax2.set_ylabel(\"Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Create estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain objects needed for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session = sagemaker.Session()\n",
    "prefix = 'mailout-xgboost'\n",
    "\n",
    "\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(session.default_bucket(),prefix)\n",
    "role = get_execution_role()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m5.large',\n",
    "                                    train_volume_size = 1,\n",
    "                                    output_path=s3_output_location,\n",
    "                                    sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the hyperparameter tuner object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'max_depth': IntegerParameter(2,8),\n",
    "                         'eta': ContinuousParameter(0.1, 0.5),\n",
    "                         'min_child_weight' : IntegerParameter(3,9),\n",
    "                         'num_round': IntegerParameter(6, 12),\n",
    "                         'gamma': IntegerParameter(2,6),\n",
    "                         'subsample': ContinuousParameter(0.5, 1.0)}\n",
    "\n",
    "objective_metric_name = 'validation:auc'\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=9,\n",
    "                            max_parallel_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mailout_train_df\n",
    "y = mailout_train_df_target\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X)], axis=1).to_csv(os.path.join(data_dir, 'mailout_train.csv'), header=None, index=None)\n",
    "\n",
    "pd.concat([pd.DataFrame(val_y), pd.DataFrame(val_X)], axis=1).to_csv(os.path.join(data_dir, 'mailout_validation.csv'), header=None, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = session.upload_data(os.path.join(data_dir, 'mailout_train.csv'),key_prefix=prefix)\n",
    "validation_location = session.upload_data(os.path.join(data_dir, 'mailout_validation.csv'),key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=validation_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "xgb_hyperparameter_tuner.wait()\n",
    "\n",
    "\n",
    "#xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new estimator object attached to the best training job found during hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_attached = xgb.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer = xgb_attached.transformer(instance_count=1, \n",
    "                                           instance_type='ml.m5.large',\n",
    "                                           output_path='s3://{}/mailout/transform/test'.format(bucket_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_df.to_csv(os.path.join(data_dir, 'mailout_test.csv'), header=None, index=None)\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'mailout_test.csv'),key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer.transform(data=test_location, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/mailout/transform/test/mailout_test.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_test_response = pd.DataFrame()\n",
    "filename = \"mailout_test.csv.out\"\n",
    "\n",
    "mailout_test_response = pd.read_csv(filename, header = None, names = ['Response'])\n",
    "mailout_test_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_response['LNR'] = LNR_test\n",
    "mailout_test_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_response.to_csv(\"Submission.csv\", header = True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[train_X.columns].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float32(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('float', inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = to_float32(train_X, train_X.select_dtypes(include=['float32']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X['RESPONSE']\n",
    "#print(mailout_train_df_target.shape)\n",
    "#print(X.shape)\n",
    "#y.isna().sum()\n",
    "#mailout_train_df['RESPONSE']\n",
    "pd.concat([pd.DataFrame(train_y.values), pd.DataFrame(train_X.values)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X, val_X, train_y, val_y\n",
    "\n",
    "gbr.fit(train_X, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
