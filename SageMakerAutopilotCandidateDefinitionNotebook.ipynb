{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Autopilot Candidate Definition Notebook\n",
    "\n",
    "This notebook was automatically generated by the AutoML job **ArvatoExperiment**.\n",
    "This notebook allows you to customize the candidate definitions and execute the SageMaker Autopilot workflow.\n",
    "\n",
    "The dataset has **368** columns and the column named **RESPONSE** is used as\n",
    "the target column. This is being treated as a **BinaryClassification** problem. The dataset also has **2** classes.\n",
    "This notebook will build a **[BinaryClassification](https://en.wikipedia.org/wiki/Binary_classification)** model that\n",
    "**maximizes** the \"**F1**\" quality metric of the trained models.\n",
    "The \"**F1**\" metric applies for binary classification with a positive and negative class. It mixes between precision and recall, and is recommended in cases where there are more negative examples compared to positive examples.\n",
    "\n",
    "As part of the AutoML job, the input dataset has been randomly split into two pieces, one for **training** and one for\n",
    "**validation**. This notebook helps you inspect and modify the data transformation approaches proposed by Amazon SageMaker Autopilot. You can interactively\n",
    "train the data transformation models and use them to transform the data. Finally, you can execute a multiple algorithm hyperparameter optimization (multi-algo HPO)\n",
    "job that helps you find the best model for your dataset by jointly optimizing the data transformations and machine learning algorithms.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "Look for sections like this for recommended settings that you can change.\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Sagemaker Setup](#Sagemaker-Setup)\n",
    "    1. [Downloading Generated Candidates](#Downloading-Generated-Modules)\n",
    "    1. [SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration](#SageMaker-Autopilot-Job-and-Amazon-Simple-Storage-Service-(Amazon-S3)-Configuration)\n",
    "1. [Candidate Pipelines](#Candidate-Pipelines)\n",
    "    1. [Generated Candidates](#Generated-Candidates)\n",
    "    1. [Selected Candidates](#Selected-Candidates)\n",
    "1. [Executing the Candidate Pipelines](#Executing-the-Candidate-Pipelines)\n",
    "    1. [Run Data Transformation Steps](#Run-Data-Transformation-Steps)\n",
    "    1. [Multi Algorithm Hyperparameter Tuning](#Multi-Algorithm-Hyperparameter-Tuning)\n",
    "1. [Model Selection and Deployment](#Model-Selection-and-Deployment)\n",
    "    1. [Tuning Job Result Overview](#Tuning-Job-Result-Overview)\n",
    "    1. [Model Deployment](#Model-Deployment)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Setup\n",
    "\n",
    "Before you launch the SageMaker Autopilot jobs, we'll setup the environment for Amazon SageMaker\n",
    "- Check environment & dependencies.\n",
    "- Create a few helper objects/function to organize input/output data and SageMaker sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimal Environment Requirements**\n",
    "\n",
    "- Jupyter: Tested on `JupyterLab 1.0.6`, `jupyter_core 4.5.0` and `IPython 6.4.0`\n",
    "- Kernel: `conda_python3`\n",
    "- Dependencies required\n",
    "  - `sagemaker-python-sdk>=v1.43.4`\n",
    "- Expected Execution Role/permission\n",
    "  - S3 access to the bucket that stores the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Generated Modules\n",
    "Download the generated data transformation modules and an SageMaker Autopilot helper module used by this notebook.\n",
    "Those artifacts will be downloaded to **ArvatoExperiment-artifacts** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ArvatoExperiment-artifacts\n",
    "!aws s3 sync s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment/sagemaker-automl-candidates/pr-1-d149676d02b64c93aca959e42e072009739d8d9b21d44aeb835d9e9f9b/generated_module ArvatoExperiment-artifacts/generated_module --only-show-errors\n",
    "!aws s3 sync s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment/sagemaker-automl-candidates/pr-1-d149676d02b64c93aca959e42e072009739d8d9b21d44aeb835d9e9f9b/notebooks/sagemaker_automl ArvatoExperiment-artifacts/sagemaker_automl --only-show-errors\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"ArvatoExperiment-artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration\n",
    "\n",
    "The following configuration has been derived from the SageMaker Autopilot job. These items configure where this notebook will\n",
    "look for generated candidates, and where input and output data is stored on Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This notebook is initialized to use the following configuration: \n",
       "        <table>\n",
       "        <tr><th colspan=2>Name</th><th>Value</th></tr>\n",
       "        <tr><th>General</th><th>Role</th><td>arn:aws:iam::848439228145:role/service-role/AmazonSageMaker-ExecutionRole-20200405T201559</td></tr>\n",
       "        <tr><th rowspan=2>Base AutoML Job</th><th>Job Name</th><td>ArvatoExperiment</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment</td></tr>\n",
       "        <tr><th rowspan=5>Interactive Job</th><th>Job Name</th><td>ArvatoExpe-notebook-run-23-08-53-56</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment/ArvatoExpe-notebook-run-23-08-53-56</td></tr>\n",
       "        <tr><th>Data Processing Trained Model Directory</th><td>s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment/ArvatoExpe-notebook-run-23-08-53-56/data-processor-models</td></tr>\n",
       "        <tr><th>Data Processing Transformed Output</th><td>s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment/ArvatoExpe-notebook-run-23-08-53-56/transformed-data</td></tr>\n",
       "        <tr><th>Algo Tuning Model Output Directory</th><td>s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment/ArvatoExpe-notebook-run-23-08-53-56/multi-algo-tuning</td></tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker_automl import uid, AutoMLLocalRunConfig\n",
    "\n",
    "# Where the preprocessed data from the existing AutoML job is stored\n",
    "BASE_AUTOML_JOB_NAME = 'ArvatoExperiment'\n",
    "BASE_AUTOML_JOB_CONFIG = {\n",
    "    'automl_job_name': BASE_AUTOML_JOB_NAME,\n",
    "    'automl_output_s3_base_path': 's3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment',\n",
    "    'data_transformer_image_repo_version': '0.1.0-cpu-py3',\n",
    "    'algo_image_repo_versions': {'xgboost': '0.90-1-cpu-py3', 'linear-learner': 'latest'}\n",
    "}\n",
    "\n",
    "# Path conventions of the output data storage path from the local AutoML job run of this notebook\n",
    "LOCAL_AUTOML_JOB_NAME = 'ArvatoExpe-notebook-run-{}'.format(uid())\n",
    "LOCAL_AUTOML_JOB_CONFIG = {\n",
    "    'local_automl_job_name': LOCAL_AUTOML_JOB_NAME,\n",
    "    'local_automl_job_output_s3_base_path': 's3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExperiment/{}'.format(LOCAL_AUTOML_JOB_NAME),\n",
    "    'data_processing_model_dir': 'data-processor-models',\n",
    "    'data_processing_transformed_output_dir': 'transformed-data',\n",
    "    'multi_algo_tuning_output_dir': 'multi-algo-tuning'\n",
    "}\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG = AutoMLLocalRunConfig(\n",
    "    role='arn:aws:iam::848439228145:role/service-role/AmazonSageMaker-ExecutionRole-20200405T201559',\n",
    "    base_automl_job_config=BASE_AUTOML_JOB_CONFIG,\n",
    "    local_automl_job_config=LOCAL_AUTOML_JOB_CONFIG,\n",
    "    security_config={'EnableInterContainerTrafficEncryption': False, 'VpcConfig': {}})\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Pipelines\n",
    "\n",
    "The `AutoMLLocalRunner` keeps track of selected candidates and automates many of the steps needed to execute feature engineering and tuning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_automl import AutoMLInteractiveRunner, AutoMLLocalCandidate\n",
    "\n",
    "automl_interactive_runner = AutoMLInteractiveRunner(AUTOML_LOCAL_RUN_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Candidates\n",
    "\n",
    "The SageMaker Autopilot Job has analyzed the dataset and has generated **10** machine learning\n",
    "pipeline(s) that use **2** algorithm(s). Each pipeline contains a set of feature transformers and an\n",
    "algorithm.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. The resource configuration: instance type & count\n",
    "1. Select candidate pipeline definitions by cells\n",
    "1. The linked data transformation script can be reviewed and updated. Please refer to the [README.md](./ArvatoExperiment-artifacts/generated_module/README.md) for detailed customization instructions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp0-xgboost](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp0.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 08:54:49,422 INFO root: Warning: pipeline candidate dpp0-xgboost has already been selected, replacing\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp0\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp1-linear-learner](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp1.py)**: This data transformation strategy first transforms 'numeric' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [LogExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp1\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp2-xgboost](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp2.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp2\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp3-xgboost](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp3.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp3\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp4-linear-learner](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp4.py)**: This data transformation strategy first transforms 'numeric' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [QuantileExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp4\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp5-xgboost](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp5.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py), 'text' features using [MultiColumnTfidfVectorizer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp5\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp6-xgboost](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp6.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp6\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp7-xgboost](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp7.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp7\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp8-linear-learner](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp8.py)**: This data transformation strategy first transforms 'numeric' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [QuantileExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp8\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp9-xgboost](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp9.py)**: This data transformation strategy first transforms 'numeric' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [QuantileExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp9\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.large\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Candidates\n",
    "\n",
    "You have selected the following candidates (please run the cell below and click on the feature transformer links for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <table>\n",
       "            <tr><th>Candidate Name</th><th>Algorithm</th><th>Feature Transformer</th></tr>\n",
       "            <tr><th>dpp0-xgboost</th><td>xgboost</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp0.py'>dpp0.py</a></td></tr>\n",
       "<tr><th>dpp1-linear-learner</th><td>linear-learner</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp1.py'>dpp1.py</a></td></tr>\n",
       "<tr><th>dpp2-xgboost</th><td>xgboost</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp2.py'>dpp2.py</a></td></tr>\n",
       "<tr><th>dpp3-xgboost</th><td>xgboost</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp3.py'>dpp3.py</a></td></tr>\n",
       "<tr><th>dpp4-linear-learner</th><td>linear-learner</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp4.py'>dpp4.py</a></td></tr>\n",
       "<tr><th>dpp5-xgboost</th><td>xgboost</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp5.py'>dpp5.py</a></td></tr>\n",
       "<tr><th>dpp6-xgboost</th><td>xgboost</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp6.py'>dpp6.py</a></td></tr>\n",
       "<tr><th>dpp7-xgboost</th><td>xgboost</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp7.py'>dpp7.py</a></td></tr>\n",
       "<tr><th>dpp8-linear-learner</th><td>linear-learner</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp8.py'>dpp8.py</a></td></tr>\n",
       "<tr><th>dpp9-xgboost</th><td>xgboost</td><td><a href='ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp9.py'>dpp9.py</a></td></tr>\n",
       "            </table>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl_interactive_runner.display_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature engineering pipeline consists of two SageMaker jobs:\n",
    "\n",
    "1. Generated trainable data transformer Python modules like [dpp0.py](ArvatoExperiment-artifacts/generated_module/candidate_data_processors/dpp0.py), which has been downloaded to local file system\n",
    "2. A **training** job to train the data transformers\n",
    "3. A **batch transform** job to apply the trained transformation to the dataset to generate the algorithm compatible data\n",
    "\n",
    "The transformers and its training pipeline are built using open sourced **[sagemaker-scikit-learn-container][]** and **[sagemaker-scikit-learn-extension][]**.\n",
    "\n",
    "[sagemaker-scikit-learn-container]: https://github.com/aws/sagemaker-scikit-learn-container\n",
    "[sagemaker-scikit-learn-extension]: https://github.com/aws/sagemaker-scikit-learn-extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Candidate Pipelines\n",
    "\n",
    "Each candidate pipeline consists of two steps, feature transformation and algorithm training.\n",
    "For efficiency first execute the feature transformation step which will generate a featurized dataset on S3\n",
    "for each pipeline.\n",
    "\n",
    "After each featurized dataset is prepared, execute a multi-algorithm tuning job that will run tuning jobs\n",
    "in parallel for each pipeline. This tuning job will execute training jobs to find the best set of\n",
    "hyper-parameters for each pipeline, as well as finding the overall best performing pipeline.\n",
    "\n",
    "### Run Data Transformation Steps\n",
    "\n",
    "Now you are ready to start execution all data transformation steps.  The cell below may take some time to finish,\n",
    "feel free to go grab a cup of coffee. To expedite the process you can set the number of `parallel_jobs` to be up to 10.\n",
    "Please check the account limits to increase the limits before increasing the number of jobs to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 08:57:44,879 INFO root: [Worker_0:dpp0-xgboost]Executing step: train_data_transformer\n",
      "2020-05-23 08:57:45,111 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp0-train-23-08-57-44\n",
      "\n",
      "2020-05-23 08:57:45 Starting - Starting the training job\n",
      "2020-05-23 08:57:47 Starting - Launching requested ML instances2020-05-23 08:57:52,891 INFO root: [Worker_1:dpp1-linear-learner]Executing step: train_data_transformer\n",
      "2020-05-23 08:57:53,064 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp1-train-23-08-57-44\n",
      "\n",
      "2020-05-23 08:57:53 Starting - Starting the training job.\n",
      "2020-05-23 08:57:55 Starting - Launching requested ML instances......................\n",
      "2020-05-23 08:58:53 Starting - Preparing the instances for training..\n",
      "2020-05-23 08:58:59 Starting - Preparing the instances for training..............\n",
      "2020-05-23 08:59:37 Downloading - Downloading input data\n",
      "2020-05-23 08:59:40 Downloading - Downloading input data............\n",
      "2020-05-23 09:00:11 Training - Downloading the training image\n",
      "2020-05-23 09:00:14 Training - Downloading the training image...\n",
      "2020-05-23 09:00:27 Training - Training image download completed. Training in progress.\n",
      "2020-05-23 09:00:30 Training - Training image download completed. Training in progress............\n",
      "2020-05-23 09:01:01 Uploading - Uploading generated training model...\n",
      "2020-05-23 09:01:07 Completed - Training job completed\n",
      "2020-05-23 09:01:11,432 INFO root: [Worker_0:dpp0-xgboost]Executing step: create_transformer_model\n",
      "2020-05-23 09:01:11,764 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-01-11-764\n",
      "2020-05-23 09:01:12,083 INFO root: [Worker_0:dpp0-xgboost]Executing step: perform_data_transform\n",
      "2020-05-23 09:01:12,084 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp0-transform-23-08-57-44\n",
      ".............................................\n",
      "2020-05-23 09:03:02 Uploading - Uploading generated training model.............\n",
      "2020-05-23 09:03:36 Completed - Training job completed\n",
      "..2020-05-23 09:03:48,080 INFO root: [Worker_1:dpp1-linear-learner]Executing step: create_transformer_model\n",
      "2020-05-23 09:03:48,104 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-03-48-104\n",
      ".2020-05-23 09:03:56,418 INFO root: [Worker_1:dpp1-linear-learner]Executing step: perform_data_transform\n",
      "2020-05-23 09:03:56,419 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp1-transform-23-08-57-44\n",
      "...................!\n",
      "2020-05-23 09:04:43,185 INFO root: Successfully fit data transformer for dpp0-xgboost\n",
      ".2020-05-23 09:04:51,192 INFO root: [Worker_0:dpp2-xgboost]Executing step: train_data_transformer\n",
      "2020-05-23 09:04:51,376 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp2-train-23-08-57-44\n",
      "\n",
      "2020-05-23 09:04:51 Starting - Starting the training job.\n",
      "2020-05-23 09:04:53 Starting - Launching requested ML instances...................................\n",
      "2020-05-23 09:06:25 Starting - Preparing the instances for training.................\n",
      "2020-05-23 09:07:11 Downloading - Downloading input data........!\n",
      "2020-05-23 09:07:32,725 INFO root: Successfully fit data transformer for dpp1-linear-learner\n",
      ".2020-05-23 09:07:39,729 INFO root: [Worker_1:dpp3-xgboost]Executing step: train_data_transformer\n",
      "2020-05-23 09:07:39,901 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp3-train-23-08-57-44\n",
      "\n",
      "2020-05-23 09:07:40 Starting - Starting the training job\n",
      "2020-05-23 09:07:40 Training - Downloading the training image\n",
      "2020-05-23 09:07:42 Starting - Launching requested ML instances....\n",
      "2020-05-23 09:07:55 Training - Training image download completed. Training in progress.................................\n",
      "2020-05-23 09:09:16 Starting - Preparing the instances for training.....................\n",
      "2020-05-23 09:10:14 Downloading - Downloading input data..\n",
      "2020-05-23 09:10:23 Uploading - Uploading generated training model...\n",
      "2020-05-23 09:10:29 Completed - Training job completed\n",
      "..2020-05-23 09:10:41,410 INFO root: [Worker_0:dpp2-xgboost]Executing step: create_transformer_model\n",
      "2020-05-23 09:10:41,431 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-10-41-431\n",
      "\n",
      "2020-05-23 09:10:45 Training - Downloading the training image2020-05-23 09:10:49,728 INFO root: [Worker_0:dpp2-xgboost]Executing step: perform_data_transform\n",
      "2020-05-23 09:10:49,729 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp2-transform-23-08-57-44\n",
      ".....\n",
      "2020-05-23 09:10:59 Training - Training image download completed. Training in progress..........\n",
      "2020-05-23 09:11:25 Uploading - Uploading generated training model...\n",
      "2020-05-23 09:11:32 Completed - Training job completed\n",
      ".2020-05-23 09:11:43,400 INFO root: [Worker_1:dpp3-xgboost]Executing step: create_transformer_model\n",
      "2020-05-23 09:11:43,422 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-11-43-422\n",
      "..2020-05-23 09:11:50,736 INFO root: [Worker_1:dpp3-xgboost]Executing step: perform_data_transform\n",
      "2020-05-23 09:11:50,737 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp3-transform-23-08-57-44\n",
      "..................................................................................!\n",
      "2020-05-23 09:15:16,837 INFO root: Successfully fit data transformer for dpp3-xgboost\n",
      "2020-05-23 09:15:18,839 INFO root: [Worker_1:dpp4-linear-learner]Executing step: train_data_transformer\n",
      "2020-05-23 09:15:19,021 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp4-train-23-08-57-44\n",
      "\n",
      "2020-05-23 09:15:19 Starting - Starting the training job!\n",
      "2020-05-23 09:15:21,074 INFO root: Successfully fit data transformer for dpp2-xgboost\n",
      "\n",
      "2020-05-23 09:15:21 Starting - Launching requested ML instances2020-05-23 09:15:29,080 INFO root: [Worker_0:dpp5-xgboost]Executing step: train_data_transformer\n",
      "2020-05-23 09:15:29,229 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44\n",
      ".\n",
      "2020-05-23 09:15:29 Starting - Starting the training job.\n",
      "2020-05-23 09:15:31 Starting - Launching requested ML instances....................\n",
      "2020-05-23 09:16:24 Starting - Preparing the instances for training....\n",
      "2020-05-23 09:16:37 Starting - Preparing the instances for training..............\n",
      "2020-05-23 09:17:19 Downloading - Downloading input data....\n",
      "2020-05-23 09:17:29 Downloading - Downloading input data......\n",
      "2020-05-23 09:17:46 Training - Downloading the training image....\n",
      "2020-05-23 09:17:56 Training - Downloading the training image\n",
      "2020-05-23 09:18:01 Training - Training image download completed. Training in progress.....\n",
      "2020-05-23 09:18:11 Training - Training image download completed. Training in progress......................\n",
      "2020-05-23 09:19:07 Uploading - Uploading generated training model.\n",
      "2020-05-23 09:19:14 Completed - Training job completed\n",
      ".2020-05-23 09:19:23,618 INFO root: [Worker_0:dpp5-xgboost]Executing step: create_transformer_model\n",
      "2020-05-23 09:19:23,657 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-19-23-657\n",
      "..2020-05-23 09:19:32,096 INFO root: [Worker_0:dpp5-xgboost]Executing step: perform_data_transform\n",
      "2020-05-23 09:19:32,097 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp5-transform-23-08-57-44\n",
      ".........................\n",
      "2020-05-23 09:20:33 Uploading - Uploading generated training model.\n",
      "2020-05-23 09:20:40 Completed - Training job completed\n",
      ".2020-05-23 09:20:42,853 INFO root: [Worker_1:dpp4-linear-learner]Executing step: create_transformer_model\n",
      "2020-05-23 09:20:42,876 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-20-42-876\n",
      "2020-05-23 09:20:45,163 INFO root: [Worker_1:dpp4-linear-learner]Executing step: perform_data_transform\n",
      "2020-05-23 09:20:45,164 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp4-transform-23-08-57-44\n",
      "...........................................................!\n",
      "2020-05-23 09:23:13,208 INFO root: Successfully fit data transformer for dpp5-xgboost\n",
      "2020-05-23 09:23:15,208 INFO root: [Worker_0:dpp6-xgboost]Executing step: train_data_transformer\n",
      "2020-05-23 09:23:15,369 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp6-train-23-08-57-44\n",
      "\n",
      "2020-05-23 09:23:15 Starting - Starting the training job.\n",
      "2020-05-23 09:23:17 Starting - Launching requested ML instances.........................\n",
      "2020-05-23 09:24:21 Starting - Preparing the instances for training!\n",
      "2020-05-23 09:24:26,308 INFO root: Successfully fit data transformer for dpp4-linear-learner\n",
      ".2020-05-23 09:24:32,314 INFO root: [Worker_1:dpp7-xgboost]Executing step: train_data_transformer\n",
      "2020-05-23 09:24:32,495 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp7-train-23-08-57-44\n",
      "\n",
      "2020-05-23 09:24:32 Starting - Starting the training job.\n",
      "2020-05-23 09:24:34 Starting - Launching requested ML instances..........\n",
      "2020-05-23 09:25:02 Downloading - Downloading input data...........\n",
      "2020-05-23 09:25:33 Training - Downloading the training image.....\n",
      "2020-05-23 09:25:46 Training - Training image download completed. Training in progress.......\n",
      "2020-05-23 09:26:07 Starting - Preparing the instances for training.....................\n",
      "2020-05-23 09:27:00 Downloading - Downloading input data...........\n",
      "2020-05-23 09:27:29 Training - Downloading the training image...\n",
      "2020-05-23 09:27:43 Training - Training image download completed. Training in progress...........\n",
      "2020-05-23 09:28:07 Uploading - Uploading generated training model\n",
      "2020-05-23 09:28:09 Uploading - Uploading generated training model\n",
      "2020-05-23 09:28:13 Completed - Training job completed\n",
      "\n",
      "2020-05-23 09:28:16 Completed - Training job completed\n",
      "2020-05-23 09:28:19,192 INFO root: [Worker_0:dpp6-xgboost]Executing step: create_transformer_model\n",
      "2020-05-23 09:28:19,212 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-28-19-212\n",
      "2020-05-23 09:28:21,544 INFO root: [Worker_0:dpp6-xgboost]Executing step: perform_data_transform\n",
      "2020-05-23 09:28:21,544 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp6-transform-23-08-57-44\n",
      ".2020-05-23 09:28:24,904 INFO root: [Worker_1:dpp7-xgboost]Executing step: create_transformer_model\n",
      "2020-05-23 09:28:24,926 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-28-24-926\n",
      ".2020-05-23 09:28:31,227 INFO root: [Worker_1:dpp7-xgboost]Executing step: perform_data_transform\n",
      "2020-05-23 09:28:31,228 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp7-transform-23-08-57-44\n",
      "......................................................................................!\n",
      "2020-05-23 09:32:07,384 INFO root: Successfully fit data transformer for dpp7-xgboost\n",
      "..2020-05-23 09:32:17,394 INFO root: [Worker_1:dpp8-linear-learner]Executing step: train_data_transformer\n",
      "2020-05-23 09:32:17,553 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp8-train-23-08-57-44\n",
      "\n",
      "2020-05-23 09:32:17 Starting - Starting the training job.\n",
      "2020-05-23 09:32:19 Starting - Launching requested ML instances......!\n",
      "2020-05-23 09:32:37,910 INFO root: Successfully fit data transformer for dpp6-xgboost\n",
      ".2020-05-23 09:32:46,916 INFO root: [Worker_0:dpp9-xgboost]Executing step: train_data_transformer\n",
      "2020-05-23 09:32:47,159 INFO sagemaker: Creating training-job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp9-train-23-08-57-44\n",
      "\n",
      "2020-05-23 09:32:47 Starting - Starting the training job.\n",
      "2020-05-23 09:32:49 Starting - Launching requested ML instances..............\n",
      "2020-05-23 09:33:26 Starting - Preparing the instances for training..........\n",
      "2020-05-23 09:33:55 Starting - Preparing the instances for training..........\n",
      "2020-05-23 09:34:20 Downloading - Downloading input data..\n",
      "2020-05-23 09:34:31 Downloading - Downloading input data........\n",
      "2020-05-23 09:34:52 Training - Downloading the training image..\n",
      "2020-05-23 09:35:02 Training - Downloading the training image..\n",
      "2020-05-23 09:35:06 Training - Training image download completed. Training in progress...\n",
      "2020-05-23 09:35:15 Training - Training image download completed. Training in progress.........................................................\n",
      "2020-05-23 09:37:36 Uploading - Uploading generated training model\n",
      "2020-05-23 09:37:42 Uploading - Uploading generated training model\n",
      "2020-05-23 09:37:43 Completed - Training job completed\n",
      ".\n",
      "2020-05-23 09:37:49 Completed - Training job completed\n",
      "2020-05-23 09:37:54,676 INFO root: [Worker_1:dpp8-linear-learner]Executing step: create_transformer_model\n",
      "2020-05-23 09:37:54,698 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-37-54-698\n",
      "2020-05-23 09:38:03,021 INFO root: [Worker_0:dpp9-xgboost]Executing step: create_transformer_model\n",
      "2020-05-23 09:38:03,064 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2020-05-23-09-38-03-064\n",
      "2020-05-23 09:38:04,994 INFO root: [Worker_1:dpp8-linear-learner]Executing step: perform_data_transform\n",
      "2020-05-23 09:38:04,995 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp8-transform-23-08-57-44\n",
      "..2020-05-23 09:38:12,351 INFO root: [Worker_0:dpp9-xgboost]Executing step: perform_data_transform\n",
      "2020-05-23 09:38:12,352 INFO sagemaker: Creating transform job with name: ArvatoExpe-notebook-run-23-08-53-56-dpp9-transform-23-08-57-44\n",
      "...................................................................................!\n",
      "2020-05-23 09:41:41,238 INFO root: Successfully fit data transformer for dpp8-linear-learner\n",
      "................!\n",
      "2020-05-23 09:43:03,934 INFO root: Successfully fit data transformer for dpp9-xgboost\n",
      "2020-05-23 09:43:03,935 INFO root: Successfully fit 10 data transformers\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.fit_data_transformers(parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Algorithm Hyperparameter Tuning\n",
    "\n",
    "Now that the algorithm compatible trasformed datasets are ready, you can start the multi-algorithm model tuning job\n",
    "to find the best predictive model. The following algorithm training job configuration for each\n",
    "algorithm is auto-generated by the AutoML Job as part of the recommendation.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Hyperparameter ranges\n",
    "2. Objective metrics\n",
    "3. Recommended static algorithm hyperparameters.\n",
    "\n",
    "Please refers to [Xgboost tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) and [Linear learner tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html) for detailed explanations of the parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML recommendation job has recommended the following hyperparameters, objectives and accuracy metrics for\n",
    "the algorithm and problem type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_OBJECTIVE_METRICS = {\n",
    "    'xgboost': 'validation:f1',\n",
    "    'linear-learner': 'validation:binary_f_beta',\n",
    "}\n",
    "\n",
    "STATIC_HYPERPARAMETERS = {\n",
    "    'xgboost': {\n",
    "        'objective': 'binary:hinge',\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'loss': 'logistic',\n",
    "        'mini_batch_size': 800,\n",
    "        'binary_classifier_model_selection_criteria': 'loss_function',\n",
    "        'num_models': 1,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tunable hyperparameters search ranges are recommended for the Multi-Algo tuning job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES = {\n",
    "    'xgboost': {\n",
    "        'num_round': IntegerParameter(2, 512, scaling_type='Logarithmic'),\n",
    "        'max_depth': IntegerParameter(2, 32, scaling_type='Logarithmic'),\n",
    "        'eta': ContinuousParameter(1e-3, 1.0, scaling_type='Logarithmic'),\n",
    "        'gamma': ContinuousParameter(1e-6, 64.0, scaling_type='Logarithmic'),\n",
    "        'min_child_weight': ContinuousParameter(1e-6, 32.0, scaling_type='Logarithmic'),\n",
    "        'subsample': ContinuousParameter(0.5, 1.0, scaling_type='Linear'),\n",
    "        'colsample_bytree': ContinuousParameter(0.3, 1.0, scaling_type='Linear'),\n",
    "        'lambda': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "        'alpha': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'wd': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'l1': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'learning_rate': ContinuousParameter(1e-5, 1.0, scaling_type='Logarithmic'),\n",
    "        'positive_example_weight_mult': CategoricalParameter(['balanced', '0.01', '1', '100']),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Multi-Algorithm Tuner Input\n",
    "\n",
    "To use the multi-algorithm HPO tuner, prepare some inputs and parameters. Prepare a dictionary whose key is the name of the trained pipeline candidates and the values are respectively:\n",
    "\n",
    "1. Estimators for the recommended algorithm\n",
    "2. Hyperparameters search ranges\n",
    "3. Objective metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_parameters = automl_interactive_runner.prepare_multi_algo_parameters(\n",
    "    objective_metrics=ALGORITHM_OBJECTIVE_METRICS,\n",
    "    static_hyperparameters=STATIC_HYPERPARAMETERS,\n",
    "    hyperparameters_search_ranges=ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you prepare the inputs data to the multi-algo tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_inputs = automl_interactive_runner.prepare_multi_algo_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Multi-Algorithm Tuner\n",
    "\n",
    "With the recommended Hyperparameter ranges and the transformed dataset, create a multi-algorithm model tuning job\n",
    "that coordinates hyper parameter optimizations across the different possible algorithms and feature processing strategies.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Tuner strategy: [Bayesian](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization), [Random Search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search)\n",
    "2. Objective type: `Minimize`, `Maximize`, see [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)\n",
    "3. Max Job size: the max number of training jobs HPO would be launching to run experiments. Note the default value is **250**\n",
    "    which is the default of the managed flow.\n",
    "4. Parallelism. Number of jobs that will be executed in parallel. Higher value will expedite the tuning process.\n",
    "    Please check the account limits to increase the limits before increasing the number of jobs to run in parallel\n",
    "5. Please use a different tuning job name if you re-run this cell after applied customizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "base_tuning_job_name = \"{}-tuning\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name)\n",
    "\n",
    "tuner = HyperparameterTuner.create(\n",
    "    base_tuning_job_name=base_tuning_job_name,\n",
    "    strategy='Bayesian',\n",
    "    objective_type='Maximize',\n",
    "    max_parallel_jobs=2,\n",
    "    max_jobs=250,\n",
    "    **multi_algo_tuning_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Multi-Algorithm Tuning\n",
    "\n",
    "Now you are ready to start running the **Multi-Algo Tuning** job. After the job is finished, store the tuning job name which you use to select models in the next section.\n",
    "The tuning process will take some time, please track the progress in the Amazon SageMaker Hyperparameter tuning jobs console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 09:44:25,239 INFO root: _TuningJob.start_new!!!\n",
      "2020-05-23 09:44:25,244 INFO sagemaker: Creating hyperparameter tuning job with name: ArvatoExpe-notebook--200523-0944\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tuning Job ArvatoExpe-notebook--200523-0944 started, please track the progress from [here](https://eu-west-1.console.aws.amazon.com/sagemaker/home?region=eu-west-1#/hyper-tuning-jobs/ArvatoExpe-notebook--200523-0944)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................._s\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Run tuning\n",
    "tuner.fit(inputs=multi_algo_tuning_inputs, include_cls_metadata=None)\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "\n",
    "display(\n",
    "    Markdown(f\"Tuning Job {tuning_job_name} started, please track the progress from [here](https://{AUTOML_LOCAL_RUN_CONFIG.region}.console.aws.amazon.com/sagemaker/home?region={AUTOML_LOCAL_RUN_CONFIG.region}#/hyper-tuning-jobs/{tuning_job_name})\"))\n",
    "\n",
    "# Wait for tuning job to finish\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Deployment\n",
    "\n",
    "This section guides you through the model selection process. Afterward, you construct an inference pipeline\n",
    "on Amazon SageMaker to host the best candidate.\n",
    "\n",
    "Because you executed the feature transformation and algorithm training in two separate steps, you now need to manually\n",
    "link each trained model with the feature transformer that it is associated with. When running a regular Amazon\n",
    "SageMaker Autopilot job, this will automatically be done for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Job Result Overview\n",
    "\n",
    "The performance of each candidate pipeline can be viewed as a Pandas dataframe. For more interactive usage please\n",
    "refers to [model tuning monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-monitor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lambda</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>num_round</th>\n",
       "      <th>subsample</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>TrainingJobDefinitionName</th>\n",
       "      <th>l1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>positive_example_weight_mult</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.825286</td>\n",
       "      <td>0.207616</td>\n",
       "      <td>2.182224</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.165931</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.988949</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-003-dad76254</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.504488</td>\n",
       "      <td>2020-05-23 09:52:10+00:00</td>\n",
       "      <td>2020-05-23 09:53:33+00:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>dpp5-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.378623</td>\n",
       "      <td>0.294812</td>\n",
       "      <td>6.078858</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.033048</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.606877</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-013-e8c68a8d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.496984</td>\n",
       "      <td>2020-05-23 10:16:21+00:00</td>\n",
       "      <td>2020-05-23 10:18:09+00:00</td>\n",
       "      <td>108.0</td>\n",
       "      <td>dpp2-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.035363</td>\n",
       "      <td>0.824353</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.646468</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.991928</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.771490</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-007-9712a953</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.496984</td>\n",
       "      <td>2020-05-23 10:03:12+00:00</td>\n",
       "      <td>2020-05-23 10:05:52+00:00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>dpp3-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.513653</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.046147</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.495125</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.883905</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-005-47f65142</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.496984</td>\n",
       "      <td>2020-05-23 09:55:30+00:00</td>\n",
       "      <td>2020-05-23 10:01:46+00:00</td>\n",
       "      <td>376.0</td>\n",
       "      <td>dpp9-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.539304</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>2.815771</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>472.0</td>\n",
       "      <td>0.698045</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-004-89e49eb8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.496984</td>\n",
       "      <td>2020-05-23 09:54:06+00:00</td>\n",
       "      <td>2020-05-23 09:56:57+00:00</td>\n",
       "      <td>171.0</td>\n",
       "      <td>dpp7-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-014-22cfbbe6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.032986</td>\n",
       "      <td>2020-05-23 10:17:34+00:00</td>\n",
       "      <td>2020-05-23 10:18:44+00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>dpp8-linear-learner</td>\n",
       "      <td>7.361511e-03</td>\n",
       "      <td>0.889374</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-008-1cbfe273</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>2020-05-23 10:04:32+00:00</td>\n",
       "      <td>2020-05-23 10:05:53+00:00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>dpp1-linear-learner</td>\n",
       "      <td>4.193069e-07</td>\n",
       "      <td>0.180807</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.199269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-006-3fdefd33</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.027517</td>\n",
       "      <td>2020-05-23 09:59:24+00:00</td>\n",
       "      <td>2020-05-23 10:00:40+00:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>dpp8-linear-learner</td>\n",
       "      <td>5.996115e-04</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>100</td>\n",
       "      <td>0.048836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.448690</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.776570</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.833810</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-012-30650e54</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>2020-05-23 10:12:23+00:00</td>\n",
       "      <td>2020-05-23 10:15:09+00:00</td>\n",
       "      <td>166.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.530300</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>2.106704</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.517566</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-011-a1f9cfd6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>2020-05-23 10:12:02+00:00</td>\n",
       "      <td>2020-05-23 10:13:16+00:00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>dpp5-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.780167</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.740083</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-002-db432cbe</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>2020-05-23 09:46:48+00:00</td>\n",
       "      <td>2020-05-23 09:50:00+00:00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>dpp7-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.780167</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.740083</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-001-389c4bc6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>2020-05-23 09:46:43+00:00</td>\n",
       "      <td>2020-05-23 09:51:35+00:00</td>\n",
       "      <td>292.0</td>\n",
       "      <td>dpp5-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-010-776fd0eb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-23 10:08:24+00:00</td>\n",
       "      <td>2020-05-23 10:09:44+00:00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>dpp4-linear-learner</td>\n",
       "      <td>8.554666e-02</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-009-60bf1108</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-23 10:08:54+00:00</td>\n",
       "      <td>2020-05-23 10:10:10+00:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>dpp4-linear-learner</td>\n",
       "      <td>2.805636e-03</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051460</td>\n",
       "      <td>0.640503</td>\n",
       "      <td>0.141742</td>\n",
       "      <td>7.565204</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.421275</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.905814</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-016-8e57a9b1</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-23 10:20:45+00:00</td>\n",
       "      <td>2020-05-23 10:21:20+00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ArvatoExpe-notebook--200523-0944-015-4b27ea4f</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-23 10:21:12+00:00</td>\n",
       "      <td>2020-05-23 10:21:22+00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>dpp1-linear-learner</td>\n",
       "      <td>6.732981e-03</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha  colsample_bytree       eta     gamma    lambda  max_depth  \\\n",
       "13  0.010386          0.825286  0.207616  2.182224  0.000871       21.0   \n",
       "3   0.000001          0.378623  0.294812  6.078858  0.007390        9.0   \n",
       "9   0.035363          0.824353  0.008977  0.000055  0.646468        2.0   \n",
       "11  0.002272          0.513653  0.012166  0.000266  0.046147        2.0   \n",
       "12  0.001873          0.539304  0.002351  2.815771  0.000003        3.0   \n",
       "2        NaN               NaN       NaN       NaN       NaN        NaN   \n",
       "8        NaN               NaN       NaN       NaN       NaN        NaN   \n",
       "10       NaN               NaN       NaN       NaN       NaN        NaN   \n",
       "4   0.000038          0.448690  0.001083  0.006412  0.012774        9.0   \n",
       "5   0.002988          0.530300  0.019854  2.106704  0.000514        2.0   \n",
       "14  0.011596          0.780167  0.001693  0.005921  0.000103        6.0   \n",
       "15  0.011596          0.780167  0.001693  0.005921  0.000103        6.0   \n",
       "6        NaN               NaN       NaN       NaN       NaN        NaN   \n",
       "7        NaN               NaN       NaN       NaN       NaN        NaN   \n",
       "0   0.051460          0.640503  0.141742  7.565204  0.006871        2.0   \n",
       "1        NaN               NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "    min_child_weight  num_round  subsample  \\\n",
       "13          0.165931        8.0   0.988949   \n",
       "3          15.033048       26.0   0.606877   \n",
       "9           3.991928      428.0   0.771490   \n",
       "11          2.495125      340.0   0.883905   \n",
       "12          0.000003      472.0   0.698045   \n",
       "2                NaN        NaN        NaN   \n",
       "8                NaN        NaN        NaN   \n",
       "10               NaN        NaN        NaN   \n",
       "4           0.776570       40.0   0.833810   \n",
       "5           0.000103        3.0   0.517566   \n",
       "14          0.000587      285.0   0.740083   \n",
       "15          0.000587      285.0   0.740083   \n",
       "6                NaN        NaN        NaN   \n",
       "7                NaN        NaN        NaN   \n",
       "0           9.421275        2.0   0.905814   \n",
       "1                NaN        NaN        NaN   \n",
       "\n",
       "                                  TrainingJobName TrainingJobStatus  \\\n",
       "13  ArvatoExpe-notebook--200523-0944-003-dad76254         Completed   \n",
       "3   ArvatoExpe-notebook--200523-0944-013-e8c68a8d         Completed   \n",
       "9   ArvatoExpe-notebook--200523-0944-007-9712a953         Completed   \n",
       "11  ArvatoExpe-notebook--200523-0944-005-47f65142         Completed   \n",
       "12  ArvatoExpe-notebook--200523-0944-004-89e49eb8         Completed   \n",
       "2   ArvatoExpe-notebook--200523-0944-014-22cfbbe6         Completed   \n",
       "8   ArvatoExpe-notebook--200523-0944-008-1cbfe273         Completed   \n",
       "10  ArvatoExpe-notebook--200523-0944-006-3fdefd33         Completed   \n",
       "4   ArvatoExpe-notebook--200523-0944-012-30650e54         Completed   \n",
       "5   ArvatoExpe-notebook--200523-0944-011-a1f9cfd6         Completed   \n",
       "14  ArvatoExpe-notebook--200523-0944-002-db432cbe         Completed   \n",
       "15  ArvatoExpe-notebook--200523-0944-001-389c4bc6         Completed   \n",
       "6   ArvatoExpe-notebook--200523-0944-010-776fd0eb         Completed   \n",
       "7   ArvatoExpe-notebook--200523-0944-009-60bf1108         Completed   \n",
       "0   ArvatoExpe-notebook--200523-0944-016-8e57a9b1           Stopped   \n",
       "1   ArvatoExpe-notebook--200523-0944-015-4b27ea4f           Stopped   \n",
       "\n",
       "    FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "13             0.504488 2020-05-23 09:52:10+00:00 2020-05-23 09:53:33+00:00   \n",
       "3              0.496984 2020-05-23 10:16:21+00:00 2020-05-23 10:18:09+00:00   \n",
       "9              0.496984 2020-05-23 10:03:12+00:00 2020-05-23 10:05:52+00:00   \n",
       "11             0.496984 2020-05-23 09:55:30+00:00 2020-05-23 10:01:46+00:00   \n",
       "12             0.496984 2020-05-23 09:54:06+00:00 2020-05-23 09:56:57+00:00   \n",
       "2              0.032986 2020-05-23 10:17:34+00:00 2020-05-23 10:18:44+00:00   \n",
       "8              0.029341 2020-05-23 10:04:32+00:00 2020-05-23 10:05:53+00:00   \n",
       "10             0.027517 2020-05-23 09:59:24+00:00 2020-05-23 10:00:40+00:00   \n",
       "4              0.011849 2020-05-23 10:12:23+00:00 2020-05-23 10:15:09+00:00   \n",
       "5              0.011849 2020-05-23 10:12:02+00:00 2020-05-23 10:13:16+00:00   \n",
       "14             0.011849 2020-05-23 09:46:48+00:00 2020-05-23 09:50:00+00:00   \n",
       "15             0.011849 2020-05-23 09:46:43+00:00 2020-05-23 09:51:35+00:00   \n",
       "6              0.000000 2020-05-23 10:08:24+00:00 2020-05-23 10:09:44+00:00   \n",
       "7              0.000000 2020-05-23 10:08:54+00:00 2020-05-23 10:10:10+00:00   \n",
       "0                   NaN 2020-05-23 10:20:45+00:00 2020-05-23 10:21:20+00:00   \n",
       "1                   NaN 2020-05-23 10:21:12+00:00 2020-05-23 10:21:22+00:00   \n",
       "\n",
       "    TrainingElapsedTimeSeconds TrainingJobDefinitionName            l1  \\\n",
       "13                        83.0              dpp5-xgboost           NaN   \n",
       "3                        108.0              dpp2-xgboost           NaN   \n",
       "9                        160.0              dpp3-xgboost           NaN   \n",
       "11                       376.0              dpp9-xgboost           NaN   \n",
       "12                       171.0              dpp7-xgboost           NaN   \n",
       "2                         70.0       dpp8-linear-learner  7.361511e-03   \n",
       "8                         81.0       dpp1-linear-learner  4.193069e-07   \n",
       "10                        76.0       dpp8-linear-learner  5.996115e-04   \n",
       "4                        166.0              dpp6-xgboost           NaN   \n",
       "5                         74.0              dpp5-xgboost           NaN   \n",
       "14                       192.0              dpp7-xgboost           NaN   \n",
       "15                       292.0              dpp5-xgboost           NaN   \n",
       "6                         80.0       dpp4-linear-learner  8.554666e-02   \n",
       "7                         76.0       dpp4-linear-learner  2.805636e-03   \n",
       "0                         35.0              dpp6-xgboost           NaN   \n",
       "1                         10.0       dpp1-linear-learner  6.732981e-03   \n",
       "\n",
       "    learning_rate positive_example_weight_mult        wd  \n",
       "13            NaN                          NaN       NaN  \n",
       "3             NaN                          NaN       NaN  \n",
       "9             NaN                          NaN       NaN  \n",
       "11            NaN                          NaN       NaN  \n",
       "12            NaN                          NaN       NaN  \n",
       "2        0.889374                     balanced  0.001121  \n",
       "8        0.180807                     balanced  0.199269  \n",
       "10       0.000024                          100  0.048836  \n",
       "4             NaN                          NaN       NaN  \n",
       "5             NaN                          NaN       NaN  \n",
       "14            NaN                          NaN       NaN  \n",
       "15            NaN                          NaN       NaN  \n",
       "6        0.002519                            1  0.475576  \n",
       "7        0.006648                            1  0.025826  \n",
       "0             NaN                          NaN       NaN  \n",
       "1        0.002824                          100  0.000561  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "SAGEMAKER_SESSION = AUTOML_LOCAL_RUN_CONFIG.sagemaker_session\n",
    "SAGEMAKER_ROLE = AUTOML_LOCAL_RUN_CONFIG.role\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best training job can be selected as below:\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong>Tips: </strong>\n",
    "You could select alternative job by using the value from `TrainingJobName` column above and assign to `best_training_job` below\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Multi Algorithm HPO training job name is ArvatoExpe-notebook--200523-0944-003-dad76254\n"
     ]
    }
   ],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "best_training_job = attached_tuner.best_training_job()\n",
    "\n",
    "print(\"Best Multi Algorithm HPO training job name is {}\".format(best_training_job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Best Training Job with Feature Pipelines\n",
    "\n",
    "Finally, deploy the best training job to Amazon SageMaker along with its companion feature engineering models.\n",
    "At the end of the section, you get an endpoint that's ready to serve online inference or start batch transform jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a [PipelineModel](https://sagemaker.readthedocs.io/en/stable/pipeline.html) that has multiple containers of the following:\n",
    "\n",
    "1. Data Transformation Container: a container built from the model we selected and trained during the data transformer sections\n",
    "2. Algorithm Container: a container built from the trained model we selected above from the best HPO training job.\n",
    "3. Inverse Label Transformer Container: a container that converts numerical intermediate prediction value back to non-numerical label value.\n",
    "\n",
    "Get both best data transformation model and algorithm model from best training job and create an pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 10:22:52,190 INFO root: Chosen Data Processing pipeline candidate name is dpp5-xgboost\n",
      "2020-05-23 09:19:14 Starting - Preparing the instances for training\n",
      "2020-05-23 09:19:14 Downloading - Downloading input data\n",
      "2020-05-23 09:19:14 Training - Training image download completed. Training in progress.\n",
      "2020-05-23 09:19:14 Uploading - Uploading generated training model\n",
      "2020-05-23 09:19:14 Completed - Training job completed\u001b[34m2020-05-23 09:18:12,150 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,153 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,162 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,410 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,410 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,410 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,411 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp_xhe2jnl/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=4367 sha256=87d18485fbd2b124651ec579e92a37d385ee69cb076751a195d9e3b9b6e0b573\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ulzuc8un/wheels/fe/12/6b/ba371323305b866de1e8ddaf7bf025e28f9deb42b8a49eeb1a\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:13,794 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:16,848 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:16,860 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:16,870 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"processor_module\": \"dpp5\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"trainer\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"trainer.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"processor_module\":\"dpp5\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=trainer.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=trainer\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"processor_module\":\"dpp5\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44/source/sourcedir.tar.gz\",\"module_name\":\"trainer\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"trainer.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--processor_module\",\"dpp5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_PROCESSOR_MODULE=dpp5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python trainer.py --processor_module dpp5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-05-23 09:19:06,470 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 105\n",
      "Billable seconds: 105\n",
      "2020-05-23 09:53:33 Starting - Preparing the instances for training\n",
      "2020-05-23 09:53:33 Downloading - Downloading input data\n",
      "2020-05-23 09:53:33 Training - Training image download completed. Training in progress.\n",
      "2020-05-23 09:53:33 Uploading - Uploading generated training model\n",
      "2020-05-23 09:53:33 Completed - Training job completed\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:f1 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:hinge to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Setting up HPO optimized metric to be : f1\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 34372 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 8590 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.987519#011validation-error:0.988009#011train-f1:0.012327#011validation-f1:0.011849\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.987519#011validation-error:0.988009#011train-f1:0.012327#011validation-f1:0.011849\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.003811#011validation-error:0.035157#011train-f1:0.920966#011validation-f1:0.513198\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.001309#011validation-error:0.039464#011train-f1:0.972978#011validation-f1:0.507022\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.002822#011validation-error:0.017229#011train-f1:0.935555#011validation-f1:0.515134\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.002007#011validation-error:0.017695#011train-f1:0.955766#011validation-f1:0.508356\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.003288#011validation-error:0.014203#011train-f1:0.923533#011validation-f1:0.504488\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.002357#011validation-error:0.014203#011train-f1:0.947281#011validation-f1:0.504488\u001b[0m\n",
      "Training seconds: 83\n",
      "Billable seconds: 83\n",
      "2020-05-23 09:19:14 Starting - Preparing the instances for training\n",
      "2020-05-23 09:19:14 Downloading - Downloading input data\n",
      "2020-05-23 09:19:14 Training - Training image download completed. Training in progress.\n",
      "2020-05-23 09:19:14 Uploading - Uploading generated training model\n",
      "2020-05-23 09:19:14 Completed - Training job completed\u001b[34m2020-05-23 09:18:12,150 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,153 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,162 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,410 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,410 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,410 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:12,411 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp_xhe2jnl/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=4367 sha256=87d18485fbd2b124651ec579e92a37d385ee69cb076751a195d9e3b9b6e0b573\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ulzuc8un/wheels/fe/12/6b/ba371323305b866de1e8ddaf7bf025e28f9deb42b8a49eeb1a\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:13,794 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:16,848 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:16,860 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 09:18:16,870 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"processor_module\": \"dpp5\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"trainer\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"trainer.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"processor_module\":\"dpp5\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=trainer.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=trainer\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"processor_module\":\"dpp5\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-studio-848439228145-ktemu68nnu/ArvatoExpe-notebook-run-23-08-53-56-dpp5-train-23-08-57-44/source/sourcedir.tar.gz\",\"module_name\":\"trainer\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"trainer.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--processor_module\",\"dpp5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_PROCESSOR_MODULE=dpp5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python trainer.py --processor_module dpp5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-05-23 09:19:06,470 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 105\n",
      "Billable seconds: 105\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import PipelineModel\n",
    "\n",
    "# Get a data transformation model from chosen candidate\n",
    "best_candidate = automl_interactive_runner.choose_candidate(df_tuning_job_analytics, best_training_job)\n",
    "best_data_transformer_model = best_candidate.get_data_transformer_model(role=SAGEMAKER_ROLE, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "# Our first data transformation container will always return recordio-protobuf format\n",
    "best_data_transformer_model.env[\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\"] = 'application/x-recordio-protobuf'\n",
    "# Add environment variable for sparse encoding\n",
    "if best_candidate.data_transformer_step.sparse_encoding:\n",
    "    best_data_transformer_model.env[\"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\"] = '1'\n",
    "\n",
    "# Get a algo model from chosen training job of the candidate\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})\n",
    "\n",
    "# Final pipeline model is composed of data transformation models and algo model and an\n",
    "# inverse label transform model if we need to transform the intermediates back to non-numerical value\n",
    "model_containers = [best_data_transformer_model, best_algo_model]\n",
    "if best_candidate.transforms_label:\n",
    "    model_containers.append(best_candidate.get_data_transformer_model(\n",
    "        transform_mode=\"inverse-label-transform\",\n",
    "        role=SAGEMAKER_ROLE,\n",
    "        sagemaker_session=SAGEMAKER_SESSION))\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=\"AutoML-{}\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name),\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    models=model_containers,\n",
    "    vpc_config=AUTOML_LOCAL_RUN_CONFIG.vpc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Best Pipeline\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. You can customize the initial instance count and instance type used to deploy this model.\n",
    "2. Endpoint name can be changed to avoid conflict with existing endpoints.\n",
    "\n",
    "</div>\n",
    "\n",
    "Finally, deploy the model to SageMaker to make it functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 10:26:34,214 INFO sagemaker: Creating model with name: AutoML-ArvatoExpe-notebook-run-23-08-53-56\n"
     ]
    }
   ],
   "source": [
    "pipeline_transformer = pipeline_model.transformer(instance_count=1,\n",
    "                      instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 10:40:18,685 INFO sagemaker: Creating transform job with name: AutoML-ArvatoExpe-notebook-run-23-08-53-2020-05-23-10-40-18-507\n",
      "......................\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker-serve\n",
      "  Building wheel for sagemaker-serve (setup.py): started\n",
      "  Building wheel for sagemaker-serve (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-serve: filename=sagemaker_serve-1.0.0-py2.py3-none-any.whl size=8398 sha256=5df8033ada5692a949d2574bfa722d91f221315f5ce6599419db1d48a3d8e362\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vgcmb185/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker-serve\u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sagemaker-serve\n",
      "  Building wheel for sagemaker-serve (setup.py): started\n",
      "  Building wheel for sagemaker-serve (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-serve: filename=sagemaker_serve-1.0.0-py2.py3-none-any.whl size=8398 sha256=5df8033ada5692a949d2574bfa722d91f221315f5ce6599419db1d48a3d8e362\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vgcmb185/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[35mSuccessfully built sagemaker-serve\u001b[0m\n",
      "\u001b[32m[2020-05-23 10:43:49 +0000] [11] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[32m[2020-05-23 10:43:49 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[32m[2020-05-23 10:43:49 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[32m[2020-05-23 10:43:49 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[32m[2020-05-23 10:43:49 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[36mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[36mBuilding wheels for collected packages: sagemaker-serve\n",
      "  Building wheel for sagemaker-serve (setup.py): started\n",
      "  Building wheel for sagemaker-serve (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-serve: filename=sagemaker_serve-1.0.0-py2.py3-none-any.whl size=8400 sha256=78291ba974238669fe279e958267bcd89280175bf334d07b1391c26c0627b026\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_w9pvxt0/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[36mSuccessfully built sagemaker-serve\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sagemaker-serve\u001b[0m\n",
      "\u001b[34mSuccessfully installed sagemaker-serve-1.0.0\u001b[0m\n",
      "\u001b[35mInstalling collected packages: sagemaker-serve\u001b[0m\n",
      "\u001b[35mSuccessfully installed sagemaker-serve-1.0.0\u001b[0m\n",
      "\u001b[36mInstalling collected packages: sagemaker-serve\u001b[0m\n",
      "\u001b[36mSuccessfully installed sagemaker-serve-1.0.0\u001b[0m\n",
      "\u001b[34m[2020-05-23 10:43:52 +0000] [28] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-05-23 10:43:52 +0000] [28] [INFO] Listening at: unix:/tmp/gunicorn.sock (28)\u001b[0m\n",
      "\u001b[34m[2020-05-23 10:43:52 +0000] [28] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-05-23 10:43:52 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[34m[2020-05-23 10:43:52 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[35m[2020-05-23 10:43:52 +0000] [28] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2020-05-23 10:43:52 +0000] [28] [INFO] Listening at: unix:/tmp/gunicorn.sock (28)\u001b[0m\n",
      "\u001b[35m[2020-05-23 10:43:52 +0000] [28] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-05-23 10:43:52 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[35m[2020-05-23 10:43:52 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[36m[2020-05-23 10:43:52 +0000] [29] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[36m[2020-05-23 10:43:52 +0000] [29] [INFO] Listening at: unix:/tmp/gunicorn.sock (29)\u001b[0m\n",
      "\u001b[36m[2020-05-23 10:43:52 +0000] [29] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[36m[2020-05-23 10:43:52 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[36m[2020-05-23 10:43:52 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m2020-05-23 10:43:55,618 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020-05-23 10:43:55,618 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-05-23 10:43:56,459 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020-05-23 10:43:56,459 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2020-05-23:10:43:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:43:56 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:43:56,035 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:43:56 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:43:56 +0000] \"GET /execution-parameters HTTP/1.1\" 200 20 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:43:57,470 INFO - root - Shape of the requested data: '(885, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:43:56 +0000] \"GET /execution-parameters HTTP/1.1\" 200 20 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:43:57,470 INFO - root - Shape of the requested data: '(885, 367)'\u001b[0m\n",
      "\u001b[32m[2020-05-23:10:43:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:43:56 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:43:56,878 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:43:57 +0000] \"GET /execution-parameters HTTP/1.1\" 200 20 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:43:58 +0000] \"POST /invocations HTTP/1.1\" 200 3504528 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:43:58 +0000] \"POST /invocations HTTP/1.1\" 200 3504528 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:43:58 +0000] \"POST /invocations HTTP/1.1\" 200 3540 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:43:58,541 INFO - root - Shape of the requested data: '(885, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:43:58 +0000] \"POST /invocations HTTP/1.1\" 200 1770 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:43:58,826 INFO - root - Shape of the requested data: '(902, 367)'\u001b[0m\n",
      "\u001b[35m2020-05-23 10:43:58,826 INFO - root - Shape of the requested data: '(902, 367)'\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:43:59 +0000] \"POST /invocations HTTP/1.1\" 200 3573712 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:43:59,919 INFO - root - Shape of the requested data: '(894, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:43:59 +0000] \"POST /invocations HTTP/1.1\" 200 3573712 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:43:59,919 INFO - root - Shape of the requested data: '(894, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:43:59 +0000] \"POST /invocations HTTP/1.1\" 200 3608 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:43:59,765 INFO - root - Shape of the requested data: '(902, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:43:59 +0000] \"POST /invocations HTTP/1.1\" 200 1804 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:00 +0000] \"POST /invocations HTTP/1.1\" 200 3538960 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:00,991 INFO - root - Shape of the requested data: '(882, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:00 +0000] \"POST /invocations HTTP/1.1\" 200 3538960 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:00,991 INFO - root - Shape of the requested data: '(882, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:00 +0000] \"POST /invocations HTTP/1.1\" 200 3576 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:00,842 INFO - root - Shape of the requested data: '(894, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:00 +0000] \"POST /invocations HTTP/1.1\" 200 1788 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[33m2020-05-23T10:43:57.219:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=1, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:01 +0000] \"POST /invocations HTTP/1.1\" 200 3489768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:02,095 INFO - root - Shape of the requested data: '(886, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:01 +0000] \"POST /invocations HTTP/1.1\" 200 3489768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:02,095 INFO - root - Shape of the requested data: '(886, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:01 +0000] \"POST /invocations HTTP/1.1\" 200 3528 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:01,930 INFO - root - Shape of the requested data: '(882, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:01 +0000] \"POST /invocations HTTP/1.1\" 200 1764 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:02 +0000] \"POST /invocations HTTP/1.1\" 200 3510768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:03,144 INFO - root - Shape of the requested data: '(883, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:02 +0000] \"POST /invocations HTTP/1.1\" 200 3510768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:03,144 INFO - root - Shape of the requested data: '(883, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:02 +0000] \"POST /invocations HTTP/1.1\" 200 3544 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:02,994 INFO - root - Shape of the requested data: '(886, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:02 +0000] \"POST /invocations HTTP/1.1\" 200 1772 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:03 +0000] \"POST /invocations HTTP/1.1\" 200 3496628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:04,204 INFO - root - Shape of the requested data: '(873, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:03 +0000] \"POST /invocations HTTP/1.1\" 200 3496628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:04,204 INFO - root - Shape of the requested data: '(873, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:04 +0000] \"POST /invocations HTTP/1.1\" 200 3532 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:04,050 INFO - root - Shape of the requested data: '(883, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:04 +0000] \"POST /invocations HTTP/1.1\" 200 1766 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:05 +0000] \"POST /invocations HTTP/1.1\" 200 3454616 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:05 +0000] \"POST /invocations HTTP/1.1\" 200 3454616 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:05,270 INFO - root - Shape of the requested data: '(890, 367)'\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:05,270 INFO - root - Shape of the requested data: '(890, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:05 +0000] \"POST /invocations HTTP/1.1\" 200 3492 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:05,121 INFO - root - Shape of the requested data: '(873, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:05 +0000] \"POST /invocations HTTP/1.1\" 200 1746 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:06,336 INFO - root - Shape of the requested data: '(909, 367)'\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:06,336 INFO - root - Shape of the requested data: '(909, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:06 +0000] \"POST /invocations HTTP/1.1\" 200 3560 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:06,187 INFO - root - Shape of the requested data: '(890, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:06 +0000] \"POST /invocations HTTP/1.1\" 200 1780 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:07 +0000] \"POST /invocations HTTP/1.1\" 200 3601124 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:07,405 INFO - root - Shape of the requested data: '(888, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:07 +0000] \"POST /invocations HTTP/1.1\" 200 3601124 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:07,405 INFO - root - Shape of the requested data: '(888, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:07 +0000] \"POST /invocations HTTP/1.1\" 200 3636 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:07,263 INFO - root - Shape of the requested data: '(909, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:07 +0000] \"POST /invocations HTTP/1.1\" 200 1818 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:08 +0000] \"POST /invocations HTTP/1.1\" 200 3516724 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:08,488 INFO - root - Shape of the requested data: '(886, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:08 +0000] \"POST /invocations HTTP/1.1\" 200 3516724 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:08,488 INFO - root - Shape of the requested data: '(886, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:08 +0000] \"POST /invocations HTTP/1.1\" 200 3552 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:08,340 INFO - root - Shape of the requested data: '(888, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:08 +0000] \"POST /invocations HTTP/1.1\" 200 1776 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:09 +0000] \"POST /invocations HTTP/1.1\" 200 3506020 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:09,551 INFO - root - Shape of the requested data: '(895, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:09 +0000] \"POST /invocations HTTP/1.1\" 200 3506020 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:09,551 INFO - root - Shape of the requested data: '(895, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:09 +0000] \"POST /invocations HTTP/1.1\" 200 3544 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:09,398 INFO - root - Shape of the requested data: '(886, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:09 +0000] \"POST /invocations HTTP/1.1\" 200 1772 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:10 +0000] \"POST /invocations HTTP/1.1\" 200 3546676 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:10,602 INFO - root - Shape of the requested data: '(875, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:10 +0000] \"POST /invocations HTTP/1.1\" 200 3546676 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:10,602 INFO - root - Shape of the requested data: '(875, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:10 +0000] \"POST /invocations HTTP/1.1\" 200 3580 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:10,457 INFO - root - Shape of the requested data: '(895, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:10 +0000] \"POST /invocations HTTP/1.1\" 200 1790 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:11 +0000] \"POST /invocations HTTP/1.1\" 200 3466312 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:11,624 INFO - root - Shape of the requested data: '(885, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:11 +0000] \"POST /invocations HTTP/1.1\" 200 3466312 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:11,624 INFO - root - Shape of the requested data: '(885, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:11 +0000] \"POST /invocations HTTP/1.1\" 200 3500 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:11,480 INFO - root - Shape of the requested data: '(875, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:11 +0000] \"POST /invocations HTTP/1.1\" 200 1750 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:12 +0000] \"POST /invocations HTTP/1.1\" 200 3505056 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:12 +0000] \"POST /invocations HTTP/1.1\" 200 3505056 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:12 +0000] \"POST /invocations HTTP/1.1\" 200 3540 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:12,544 INFO - root - Shape of the requested data: '(885, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:12 +0000] \"POST /invocations HTTP/1.1\" 200 1770 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:12,690 INFO - root - Shape of the requested data: '(874, 367)'\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:13 +0000] \"POST /invocations HTTP/1.1\" 200 3460116 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:12,690 INFO - root - Shape of the requested data: '(874, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:13 +0000] \"POST /invocations HTTP/1.1\" 200 3460116 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:13 +0000] \"POST /invocations HTTP/1.1\" 200 3496 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:13,580 INFO - root - Shape of the requested data: '(874, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:13 +0000] \"POST /invocations HTTP/1.1\" 200 1748 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:13,724 INFO - root - Shape of the requested data: '(906, 367)'\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:14 +0000] \"POST /invocations HTTP/1.1\" 200 3586832 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:13,724 INFO - root - Shape of the requested data: '(906, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:14 +0000] \"POST /invocations HTTP/1.1\" 200 3586832 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:14 +0000] \"POST /invocations HTTP/1.1\" 200 3624 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:14,652 INFO - root - Shape of the requested data: '(906, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:14 +0000] \"POST /invocations HTTP/1.1\" 200 1812 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:14,791 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:15 +0000] \"POST /invocations HTTP/1.1\" 200 3502676 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:14,791 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:15 +0000] \"POST /invocations HTTP/1.1\" 200 3502676 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:15 +0000] \"POST /invocations HTTP/1.1\" 200 3536 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:15,690 INFO - root - Shape of the requested data: '(884, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:15 +0000] \"POST /invocations HTTP/1.1\" 200 1768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:16,883 INFO - root - Shape of the requested data: '(890, 367)'\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:16,883 INFO - root - Shape of the requested data: '(890, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:16 +0000] \"POST /invocations HTTP/1.1\" 200 3584 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:16,740 INFO - root - Shape of the requested data: '(896, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:16 +0000] \"POST /invocations HTTP/1.1\" 200 1792 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:17 +0000] \"POST /invocations HTTP/1.1\" 200 3525516 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:17,958 INFO - root - Shape of the requested data: '(891, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:17 +0000] \"POST /invocations HTTP/1.1\" 200 3525516 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:17,958 INFO - root - Shape of the requested data: '(891, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:17 +0000] \"POST /invocations HTTP/1.1\" 200 3560 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:17,802 INFO - root - Shape of the requested data: '(890, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:17 +0000] \"POST /invocations HTTP/1.1\" 200 1780 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:18 +0000] \"POST /invocations HTTP/1.1\" 200 3528880 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:18 +0000] \"POST /invocations HTTP/1.1\" 200 3528880 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:18,999 INFO - root - Shape of the requested data: '(883, 367)'\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:18,999 INFO - root - Shape of the requested data: '(883, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:18 +0000] \"POST /invocations HTTP/1.1\" 200 3564 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:18,858 INFO - root - Shape of the requested data: '(891, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:18 +0000] \"POST /invocations HTTP/1.1\" 200 1782 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:19 +0000] \"POST /invocations HTTP/1.1\" 200 3495984 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:20,042 INFO - root - Shape of the requested data: '(882, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:19 +0000] \"POST /invocations HTTP/1.1\" 200 3495984 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:20,042 INFO - root - Shape of the requested data: '(882, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:19 +0000] \"POST /invocations HTTP/1.1\" 200 3532 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:19,891 INFO - root - Shape of the requested data: '(883, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:19 +0000] \"POST /invocations HTTP/1.1\" 200 1766 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:20 +0000] \"POST /invocations HTTP/1.1\" 200 3492232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:21,079 INFO - root - Shape of the requested data: '(878, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:20 +0000] \"POST /invocations HTTP/1.1\" 200 3492232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:21,079 INFO - root - Shape of the requested data: '(878, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:20 +0000] \"POST /invocations HTTP/1.1\" 200 3528 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:20,935 INFO - root - Shape of the requested data: '(882, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:20 +0000] \"POST /invocations HTTP/1.1\" 200 1764 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:21 +0000] \"POST /invocations HTTP/1.1\" 200 3477764 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:22,106 INFO - root - Shape of the requested data: '(897, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:21 +0000] \"POST /invocations HTTP/1.1\" 200 3477764 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:22,106 INFO - root - Shape of the requested data: '(897, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:21 +0000] \"POST /invocations HTTP/1.1\" 200 3512 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:21,961 INFO - root - Shape of the requested data: '(878, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:21 +0000] \"POST /invocations HTTP/1.1\" 200 1756 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:22 +0000] \"POST /invocations HTTP/1.1\" 200 3554108 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:23,175 INFO - root - Shape of the requested data: '(889, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:22 +0000] \"POST /invocations HTTP/1.1\" 200 3554108 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:23,175 INFO - root - Shape of the requested data: '(889, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:23 +0000] \"POST /invocations HTTP/1.1\" 200 3588 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:23,027 INFO - root - Shape of the requested data: '(897, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:23 +0000] \"POST /invocations HTTP/1.1\" 200 1794 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:24 +0000] \"POST /invocations HTTP/1.1\" 200 3517612 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:24,230 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:24 +0000] \"POST /invocations HTTP/1.1\" 200 3517612 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:24,230 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:24 +0000] \"POST /invocations HTTP/1.1\" 200 3556 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:24,086 INFO - root - Shape of the requested data: '(889, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:24 +0000] \"POST /invocations HTTP/1.1\" 200 1778 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:25 +0000] \"POST /invocations HTTP/1.1\" 200 3500556 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:25,271 INFO - root - Shape of the requested data: '(897, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:25 +0000] \"POST /invocations HTTP/1.1\" 200 3500556 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:25,271 INFO - root - Shape of the requested data: '(897, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:25 +0000] \"POST /invocations HTTP/1.1\" 200 3536 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:25,125 INFO - root - Shape of the requested data: '(884, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:25 +0000] \"POST /invocations HTTP/1.1\" 200 1768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:26 +0000] \"POST /invocations HTTP/1.1\" 200 3588 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:26,185 INFO - root - Shape of the requested data: '(897, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:26 +0000] \"POST /invocations HTTP/1.1\" 200 1794 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:27 +0000] \"POST /invocations HTTP/1.1\" 200 3506036 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:27,370 INFO - root - Shape of the requested data: '(906, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:27 +0000] \"POST /invocations HTTP/1.1\" 200 3506036 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:27,370 INFO - root - Shape of the requested data: '(906, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:27 +0000] \"POST /invocations HTTP/1.1\" 200 3540 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:27,226 INFO - root - Shape of the requested data: '(885, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:27 +0000] \"POST /invocations HTTP/1.1\" 200 1770 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:28 +0000] \"POST /invocations HTTP/1.1\" 200 3590280 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:28,418 INFO - root - Shape of the requested data: '(881, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:28 +0000] \"POST /invocations HTTP/1.1\" 200 3590280 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:28,418 INFO - root - Shape of the requested data: '(881, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:28 +0000] \"POST /invocations HTTP/1.1\" 200 3624 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:28,279 INFO - root - Shape of the requested data: '(906, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:28 +0000] \"POST /invocations HTTP/1.1\" 200 1812 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:29 +0000] \"POST /invocations HTTP/1.1\" 200 3486500 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:29,449 INFO - root - Shape of the requested data: '(881, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:29 +0000] \"POST /invocations HTTP/1.1\" 200 3486500 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:29,449 INFO - root - Shape of the requested data: '(881, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:29 +0000] \"POST /invocations HTTP/1.1\" 200 3524 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:29,312 INFO - root - Shape of the requested data: '(881, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:29 +0000] \"POST /invocations HTTP/1.1\" 200 1762 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:30 +0000] \"POST /invocations HTTP/1.1\" 200 3487096 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:30,489 INFO - root - Shape of the requested data: '(875, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:30 +0000] \"POST /invocations HTTP/1.1\" 200 3487096 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:30,489 INFO - root - Shape of the requested data: '(875, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:30 +0000] \"POST /invocations HTTP/1.1\" 200 3524 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:30,353 INFO - root - Shape of the requested data: '(881, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:30 +0000] \"POST /invocations HTTP/1.1\" 200 1762 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:31 +0000] \"POST /invocations HTTP/1.1\" 200 3462068 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:31,526 INFO - root - Shape of the requested data: '(888, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:31 +0000] \"POST /invocations HTTP/1.1\" 200 3462068 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:31,526 INFO - root - Shape of the requested data: '(888, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:31 +0000] \"POST /invocations HTTP/1.1\" 200 3500 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:31,386 INFO - root - Shape of the requested data: '(875, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:31 +0000] \"POST /invocations HTTP/1.1\" 200 1750 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:32 +0000] \"POST /invocations HTTP/1.1\" 200 3517988 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:32,589 INFO - root - Shape of the requested data: '(894, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:32 +0000] \"POST /invocations HTTP/1.1\" 200 3517988 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:32,589 INFO - root - Shape of the requested data: '(894, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:32 +0000] \"POST /invocations HTTP/1.1\" 200 3552 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:32,441 INFO - root - Shape of the requested data: '(888, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:32 +0000] \"POST /invocations HTTP/1.1\" 200 1776 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:33 +0000] \"POST /invocations HTTP/1.1\" 200 3540044 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:33,655 INFO - root - Shape of the requested data: '(902, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:33 +0000] \"POST /invocations HTTP/1.1\" 200 3540044 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:33,655 INFO - root - Shape of the requested data: '(902, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:33 +0000] \"POST /invocations HTTP/1.1\" 200 3576 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:33,506 INFO - root - Shape of the requested data: '(894, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:33 +0000] \"POST /invocations HTTP/1.1\" 200 1788 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:34 +0000] \"POST /invocations HTTP/1.1\" 200 3570392 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:34 +0000] \"POST /invocations HTTP/1.1\" 200 3570392 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:34 +0000] \"POST /invocations HTTP/1.1\" 200 3608 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:34,554 INFO - root - Shape of the requested data: '(902, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:34 +0000] \"POST /invocations HTTP/1.1\" 200 1804 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:34,702 INFO - root - Shape of the requested data: '(902, 367)'\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:35 +0000] \"POST /invocations HTTP/1.1\" 200 3570872 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:34,702 INFO - root - Shape of the requested data: '(902, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:35 +0000] \"POST /invocations HTTP/1.1\" 200 3570872 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:35 +0000] \"POST /invocations HTTP/1.1\" 200 3608 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:35,610 INFO - root - Shape of the requested data: '(902, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:35 +0000] \"POST /invocations HTTP/1.1\" 200 1804 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:36 +0000] \"POST /invocations HTTP/1.1\" 200 3532 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:36,670 INFO - root - Shape of the requested data: '(883, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:36 +0000] \"POST /invocations HTTP/1.1\" 200 1766 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:36,829 INFO - root - Shape of the requested data: '(889, 367)'\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:37 +0000] \"POST /invocations HTTP/1.1\" 200 3519380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:36,829 INFO - root - Shape of the requested data: '(889, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:37 +0000] \"POST /invocations HTTP/1.1\" 200 3519380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:37,890 INFO - root - Shape of the requested data: '(875, 367)'\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:37,890 INFO - root - Shape of the requested data: '(875, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:37 +0000] \"POST /invocations HTTP/1.1\" 200 3556 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:37,752 INFO - root - Shape of the requested data: '(889, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:37 +0000] \"POST /invocations HTTP/1.1\" 200 1778 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:38 +0000] \"POST /invocations HTTP/1.1\" 200 3465544 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:38,963 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:38 +0000] \"POST /invocations HTTP/1.1\" 200 3465544 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:38,963 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:38 +0000] \"POST /invocations HTTP/1.1\" 200 3500 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:38,798 INFO - root - Shape of the requested data: '(875, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:38 +0000] \"POST /invocations HTTP/1.1\" 200 1750 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:39 +0000] \"POST /invocations HTTP/1.1\" 200 3499784 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:39,996 INFO - root - Shape of the requested data: '(897, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:39 +0000] \"POST /invocations HTTP/1.1\" 200 3499784 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:39,996 INFO - root - Shape of the requested data: '(897, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:39 +0000] \"POST /invocations HTTP/1.1\" 200 3536 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:39,851 INFO - root - Shape of the requested data: '(884, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:39 +0000] \"POST /invocations HTTP/1.1\" 200 1768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:40 +0000] \"POST /invocations HTTP/1.1\" 200 3551128 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:40 +0000] \"POST /invocations HTTP/1.1\" 200 3551128 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:41,051 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:41,051 INFO - root - Shape of the requested data: '(884, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:40 +0000] \"POST /invocations HTTP/1.1\" 200 3588 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:40,909 INFO - root - Shape of the requested data: '(897, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:40 +0000] \"POST /invocations HTTP/1.1\" 200 1794 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:41 +0000] \"POST /invocations HTTP/1.1\" 200 3498032 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:42,116 INFO - root - Shape of the requested data: '(896, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:41 +0000] \"POST /invocations HTTP/1.1\" 200 3498032 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:42,116 INFO - root - Shape of the requested data: '(896, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:41 +0000] \"POST /invocations HTTP/1.1\" 200 3536 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:41,961 INFO - root - Shape of the requested data: '(884, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:41 +0000] \"POST /invocations HTTP/1.1\" 200 1768 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:42 +0000] \"POST /invocations HTTP/1.1\" 200 3551836 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:43,172 INFO - root - Shape of the requested data: '(887, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:42 +0000] \"POST /invocations HTTP/1.1\" 200 3551836 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:43,172 INFO - root - Shape of the requested data: '(887, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:43 +0000] \"POST /invocations HTTP/1.1\" 200 3584 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:43,031 INFO - root - Shape of the requested data: '(896, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:43 +0000] \"POST /invocations HTTP/1.1\" 200 1792 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:44 +0000] \"POST /invocations HTTP/1.1\" 200 3513688 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:44,224 INFO - root - Shape of the requested data: '(896, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:44 +0000] \"POST /invocations HTTP/1.1\" 200 3513688 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:44,224 INFO - root - Shape of the requested data: '(896, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:44 +0000] \"POST /invocations HTTP/1.1\" 200 3548 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:44,083 INFO - root - Shape of the requested data: '(887, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:44 +0000] \"POST /invocations HTTP/1.1\" 200 1774 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:45 +0000] \"POST /invocations HTTP/1.1\" 200 3552284 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:45,272 INFO - root - Shape of the requested data: '(891, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:45 +0000] \"POST /invocations HTTP/1.1\" 200 3552284 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:45,272 INFO - root - Shape of the requested data: '(891, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:45 +0000] \"POST /invocations HTTP/1.1\" 200 3584 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:45,128 INFO - root - Shape of the requested data: '(896, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:45 +0000] \"POST /invocations HTTP/1.1\" 200 1792 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:46 +0000] \"POST /invocations HTTP/1.1\" 200 3564 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:46,186 INFO - root - Shape of the requested data: '(891, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:46 +0000] \"POST /invocations HTTP/1.1\" 200 1782 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 3453560 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:47,367 INFO - root - Shape of the requested data: '(898, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 3453560 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:47,367 INFO - root - Shape of the requested data: '(898, 367)'\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 3492 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:47,210 INFO - root - Shape of the requested data: '(873, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 1746 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 3557144 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 3557144 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-05-23 10:44:48,328 INFO - root - Shape of the requested data: '(183, 367)'\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 725244 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-05-23 10:44:48,328 INFO - root - Shape of the requested data: '(183, 367)'\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 725244 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 3592 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 732 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:48,285 INFO - root - Shape of the requested data: '(898, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 1796 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-05-23 10:44:48,524 INFO - root - Shape of the requested data: '(183, 1)'\u001b[0m\n",
      "\u001b[36m169.254.255.130 - - [23/May/2020:10:44:48 +0000] \"POST /invocations HTTP/1.1\" 200 366 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline_transformer.transform(data='s3://sagemaker-eu-west-1-848439228145/Capstone/Udacity_MAILOUT_052018_TEST.csv', data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "pipeline_transformer.wait()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
