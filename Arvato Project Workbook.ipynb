{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3 client to get S3 data\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name='sagemaker-eu-west-1-848439228145'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list withe files in the bucket and print the file names to be sure that we will be retrieving from the correct location and obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Capstone/Udacity_AZDIAS_052018.csv', 'Capstone/Udacity_CUSTOMERS_052018.csv', 'Capstone/Udacity_MAILOUT_052018_TEST.csv', 'Capstone/Udacity_MAILOUT_052018_TRAIN.csv', 'arvato/azdias.csv', 'arvato/customers.csv', 'arvato/transform/pca/transform/test/azdias.csv.out', 'arvato/transform/pca/transform/test/customers.csv.out']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "# get a list of objects in the bucket\n",
    "obj_list=s3_client.list_objects(Bucket=bucket_name)\n",
    "\n",
    "def filter_csv(string):\n",
    "    return re.search(r'.csv', string)\n",
    "\n",
    "\n",
    "files=[]\n",
    "for contents in obj_list['Contents']:\n",
    "    files.append(contents['Key'])\n",
    "    \n",
    "filtered_list = list(filter(filter_csv, files))\n",
    "    \n",
    "    \n",
    "# print csv objects in in S3 bucket  \n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_from_s3(s3_client, bucket, name):\n",
    "    data_object = s3_client.get_object(Bucket=bucket, Key=name)\n",
    "    data_body = data_object[\"Body\"].read()\n",
    "    data_stream = io.BytesIO(data_body)\n",
    "    \n",
    "    return pd.read_csv(data_stream, header=0, delimiter=\",\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9628</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0    9626         2         1.0      10.0          NaN   \n",
       "1           1    9628        -1         9.0      11.0          NaN   \n",
       "2           2  143872        -1         1.0       6.0          NaN   \n",
       "3           3  143873         1         1.0       8.0          NaN   \n",
       "4           4  143874        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VK_ZG11  \\\n",
       "0          NaN          NaN          NaN                  10.0  ...      2.0   \n",
       "1          NaN          NaN          NaN                   NaN  ...      3.0   \n",
       "2          NaN          NaN          NaN                   0.0  ...     11.0   \n",
       "3          NaN          NaN          NaN                   8.0  ...      2.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...      4.0   \n",
       "\n",
       "   W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0             6.0             9.0       7.0         3  COSMETIC_AND_FOOD   \n",
       "1             0.0             9.0       NaN         3               FOOD   \n",
       "2             6.0             9.0       2.0         3  COSMETIC_AND_FOOD   \n",
       "3             NaN             9.0       7.0         1           COSMETIC   \n",
       "4             2.0             9.0       3.0         1               FOOD   \n",
       "\n",
       "   CUSTOMER_GROUP  ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0     MULTI_BUYER                0         1                    4  \n",
       "1    SINGLE_BUYER                0         1                    4  \n",
       "2     MULTI_BUYER                0         2                    4  \n",
       "3     MULTI_BUYER                0         1                    4  \n",
       "4     MULTI_BUYER                0         1                    3  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df = None\n",
    "customers_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[1])\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0  910215        -1         NaN       NaN          NaN   \n",
       "1           1  910220        -1         9.0       0.0          NaN   \n",
       "2           2  910225        -1         9.0      17.0          NaN   \n",
       "3           3  910226         2         1.0      13.0          NaN   \n",
       "4           4  910241        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VHN  \\\n",
       "0          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "1          NaN          NaN          NaN                  21.0  ...  4.0   \n",
       "2          NaN          NaN          NaN                  17.0  ...  2.0   \n",
       "3          NaN          NaN          NaN                  13.0  ...  0.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...  2.0   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1       8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2       9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3       7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4       3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3         1                    2  \n",
       "1         5         2                    1  \n",
       "2         5         2                    3  \n",
       "3         3         2                    4  \n",
       "4         4         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df = None\n",
    "azdias_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[0])\n",
    "azdias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>11766.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>139810.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>137910.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>141725.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>1.747525</td>\n",
       "      <td>11.352009</td>\n",
       "      <td>12.337243</td>\n",
       "      <td>13.672353</td>\n",
       "      <td>14.647059</td>\n",
       "      <td>15.377119</td>\n",
       "      <td>10.331579</td>\n",
       "      <td>...</td>\n",
       "      <td>4.374417</td>\n",
       "      <td>4.564769</td>\n",
       "      <td>3.168868</td>\n",
       "      <td>4.152716</td>\n",
       "      <td>8.646371</td>\n",
       "      <td>3.723133</td>\n",
       "      <td>2.576806</td>\n",
       "      <td>0.090247</td>\n",
       "      <td>1.376432</td>\n",
       "      <td>3.060907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55325.311233</td>\n",
       "      <td>55325.311233</td>\n",
       "      <td>1.391672</td>\n",
       "      <td>1.966334</td>\n",
       "      <td>6.275026</td>\n",
       "      <td>4.006050</td>\n",
       "      <td>3.243335</td>\n",
       "      <td>2.753787</td>\n",
       "      <td>2.307653</td>\n",
       "      <td>4.134828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.924355</td>\n",
       "      <td>2.887035</td>\n",
       "      <td>2.233516</td>\n",
       "      <td>1.974375</td>\n",
       "      <td>1.154001</td>\n",
       "      <td>2.095540</td>\n",
       "      <td>1.168486</td>\n",
       "      <td>0.286536</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>1.086254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47912.750000</td>\n",
       "      <td>47913.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>143738.250000</td>\n",
       "      <td>143739.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191651.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0            LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  191652.000000  191652.000000  191652.000000  145056.000000   \n",
       "mean    95825.500000   95826.500000       0.344359       1.747525   \n",
       "std     55325.311233   55325.311233       1.391672       1.966334   \n",
       "min         0.000000       1.000000      -1.000000       1.000000   \n",
       "25%     47912.750000   47913.750000      -1.000000       1.000000   \n",
       "50%     95825.500000   95826.500000       0.000000       1.000000   \n",
       "75%    143738.250000  143739.250000       2.000000       1.000000   \n",
       "max    191651.000000  191652.000000       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  145056.000000  11766.000000  5100.000000  1275.000000   236.000000   \n",
       "mean       11.352009     12.337243    13.672353    14.647059    15.377119   \n",
       "std         6.275026      4.006050     3.243335     2.753787     2.307653   \n",
       "min         0.000000      2.000000     2.000000     5.000000     8.000000   \n",
       "25%         8.000000      9.000000    11.000000    13.000000    14.000000   \n",
       "50%        11.000000     13.000000    14.000000    15.000000    16.000000   \n",
       "75%        16.000000     16.000000    16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000    18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...       VK_DHT4A     VK_DISTANZ        VK_ZG11  \\\n",
       "count         139810.000000  ...  143781.000000  143781.000000  143781.000000   \n",
       "mean              10.331579  ...       4.374417       4.564769       3.168868   \n",
       "std                4.134828  ...       2.924355       2.887035       2.233516   \n",
       "min                0.000000  ...       1.000000       1.000000       1.000000   \n",
       "25%                9.000000  ...       2.000000       2.000000       1.000000   \n",
       "50%               10.000000  ...       4.000000       4.000000       3.000000   \n",
       "75%               13.000000  ...       7.000000       7.000000       4.000000   \n",
       "max               25.000000  ...      11.000000      13.000000      11.000000   \n",
       "\n",
       "       W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE       ZABEOTYP  \\\n",
       "count   137910.000000   145056.000000  141725.000000  191652.000000   \n",
       "mean         4.152716        8.646371       3.723133       2.576806   \n",
       "std          1.974375        1.154001       2.095540       1.168486   \n",
       "min          0.000000        1.000000       0.000000       1.000000   \n",
       "25%          2.000000        9.000000       2.000000       1.000000   \n",
       "50%          5.000000        9.000000       3.000000       3.000000   \n",
       "75%          6.000000        9.000000       5.000000       3.000000   \n",
       "max          6.000000        9.000000       8.000000       6.000000   \n",
       "\n",
       "       ONLINE_PURCHASE      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count    191652.000000  191652.000000         191652.000000  \n",
       "mean          0.090247       1.376432              3.060907  \n",
       "std           0.286536       0.484492              1.086254  \n",
       "min           0.000000       1.000000              1.000000  \n",
       "25%           0.000000       1.000000              3.000000  \n",
       "50%           0.000000       1.000000              3.000000  \n",
       "75%           0.000000       2.000000              4.000000  \n",
       "max           1.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(customers_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891221.000000</td>\n",
       "      <td>8.912210e+05</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>81058.000000</td>\n",
       "      <td>29499.000000</td>\n",
       "      <td>6170.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>628274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>770025.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>783619.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>798073.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-0.358435</td>\n",
       "      <td>4.421928</td>\n",
       "      <td>10.864126</td>\n",
       "      <td>11.745392</td>\n",
       "      <td>13.402658</td>\n",
       "      <td>14.476013</td>\n",
       "      <td>15.089627</td>\n",
       "      <td>13.700717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417322</td>\n",
       "      <td>6.001214</td>\n",
       "      <td>7.532130</td>\n",
       "      <td>5.945972</td>\n",
       "      <td>3.933406</td>\n",
       "      <td>7.908791</td>\n",
       "      <td>4.052836</td>\n",
       "      <td>3.362438</td>\n",
       "      <td>1.522098</td>\n",
       "      <td>2.777398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257273.486465</td>\n",
       "      <td>2.572735e+05</td>\n",
       "      <td>1.198724</td>\n",
       "      <td>3.638805</td>\n",
       "      <td>7.639683</td>\n",
       "      <td>4.097660</td>\n",
       "      <td>3.243300</td>\n",
       "      <td>2.712427</td>\n",
       "      <td>2.452932</td>\n",
       "      <td>5.079849</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166572</td>\n",
       "      <td>2.856091</td>\n",
       "      <td>3.247789</td>\n",
       "      <td>2.771464</td>\n",
       "      <td>1.964701</td>\n",
       "      <td>1.923137</td>\n",
       "      <td>1.949539</td>\n",
       "      <td>1.352704</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>1.068775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916530e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222805.000000</td>\n",
       "      <td>4.144580e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668415.000000</td>\n",
       "      <td>8.600680e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891220.000000</td>\n",
       "      <td>1.082873e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0           LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  891221.000000  8.912210e+05  891221.000000  817722.000000   \n",
       "mean   445610.000000  6.372630e+05      -0.358435       4.421928   \n",
       "std    257273.486465  2.572735e+05       1.198724       3.638805   \n",
       "min         0.000000  1.916530e+05      -1.000000       1.000000   \n",
       "25%    222805.000000  4.144580e+05      -1.000000       1.000000   \n",
       "50%    445610.000000  6.372630e+05      -1.000000       3.000000   \n",
       "75%    668415.000000  8.600680e+05      -1.000000       9.000000   \n",
       "max    891220.000000  1.082873e+06       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  817722.000000  81058.000000  29499.000000  6170.000000  1205.000000   \n",
       "mean       10.864126     11.745392     13.402658    14.476013    15.089627   \n",
       "std         7.639683      4.097660      3.243300     2.712427     2.452932   \n",
       "min         0.000000      2.000000      2.000000     4.000000     7.000000   \n",
       "25%         0.000000      8.000000     11.000000    13.000000    14.000000   \n",
       "50%        13.000000     12.000000     14.000000    15.000000    15.000000   \n",
       "75%        17.000000     15.000000     16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000     18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...            VHN       VK_DHT4A     VK_DISTANZ  \\\n",
       "count         628274.000000  ...  770025.000000  815304.000000  815304.000000   \n",
       "mean              13.700717  ...       2.417322       6.001214       7.532130   \n",
       "std                5.079849  ...       1.166572       2.856091       3.247789   \n",
       "min                0.000000  ...       0.000000       1.000000       1.000000   \n",
       "25%               11.000000  ...       2.000000       3.000000       5.000000   \n",
       "50%               14.000000  ...       2.000000       6.000000       8.000000   \n",
       "75%               17.000000  ...       3.000000       9.000000      10.000000   \n",
       "max               25.000000  ...       4.000000      11.000000      13.000000   \n",
       "\n",
       "             VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE  \\\n",
       "count  815304.000000   783619.000000   817722.000000  798073.000000   \n",
       "mean        5.945972        3.933406        7.908791       4.052836   \n",
       "std         2.771464        1.964701        1.923137       1.949539   \n",
       "min         1.000000        0.000000        1.000000       0.000000   \n",
       "25%         4.000000        2.000000        8.000000       3.000000   \n",
       "50%         6.000000        4.000000        9.000000       3.000000   \n",
       "75%         8.000000        6.000000        9.000000       5.000000   \n",
       "max        11.000000        6.000000        9.000000       8.000000   \n",
       "\n",
       "            ZABEOTYP      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count  891221.000000  891221.000000         891221.000000  \n",
       "mean        3.362438       1.522098              2.777398  \n",
       "std         1.352704       0.499512              1.068775  \n",
       "min         1.000000       1.000000              1.000000  \n",
       "25%         3.000000       1.000000              2.000000  \n",
       "50%         3.000000       2.000000              3.000000  \n",
       "75%         4.000000       2.000000              4.000000  \n",
       "max         6.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 361 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(azdias_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTER_KIND4                    99.864792\n",
       "ALTER_KIND3                    99.307691\n",
       "ALTER_KIND2                    96.690047\n",
       "ALTER_KIND1                    90.904837\n",
       "EXTSEL992                      73.399639\n",
       "KK_KUNDENTYP                   65.596749\n",
       "ALTERSKATEGORIE_FEIN           29.504130\n",
       "D19_VERSI_ONLINE_QUOTE_12      28.849522\n",
       "D19_LETZTER_KAUF_BRANCHE       28.849522\n",
       "D19_BANKEN_ONLINE_QUOTE_12     28.849522\n",
       "D19_TELKO_ONLINE_QUOTE_12      28.849522\n",
       "D19_VERSAND_ONLINE_QUOTE_12    28.849522\n",
       "D19_KONSUMTYP                  28.849522\n",
       "D19_SOZIALES                   28.849522\n",
       "D19_GESAMT_ONLINE_QUOTE_12     28.849522\n",
       "D19_LOTTO                      28.849522\n",
       "KBA05_SEG8                     14.959701\n",
       "KBA05_SEG7                     14.959701\n",
       "KBA05_KW2                      14.959701\n",
       "KBA05_KW3                      14.959701\n",
       "KBA05_MAXAH                    14.959701\n",
       "KBA05_MAXBJ                    14.959701\n",
       "KBA05_MAXHERST                 14.959701\n",
       "KBA05_MAXSEG                   14.959701\n",
       "KBA05_MAXVORB                  14.959701\n",
       "KBA05_MOD1                     14.959701\n",
       "KBA05_MOD2                     14.959701\n",
       "KBA05_MOD3                     14.959701\n",
       "KBA05_MOD4                     14.959701\n",
       "KBA05_MOD8                     14.959701\n",
       "                                 ...    \n",
       "D19_RATGEBER                    0.000000\n",
       "FINANZ_ANLEGER                  0.000000\n",
       "D19_REISEN                      0.000000\n",
       "D19_SAMMELARTIKEL               0.000000\n",
       "D19_SCHUHE                      0.000000\n",
       "D19_SONSTIGE                    0.000000\n",
       "D19_TECHNIK                     0.000000\n",
       "D19_TELKO_ANZ_12                0.000000\n",
       "D19_TELKO_ANZ_24                0.000000\n",
       "D19_TELKO_DATUM                 0.000000\n",
       "D19_TELKO_MOBILE                0.000000\n",
       "D19_TELKO_OFFLINE_DATUM         0.000000\n",
       "D19_TELKO_ONLINE_DATUM          0.000000\n",
       "D19_TELKO_REST                  0.000000\n",
       "D19_TIERARTIKEL                 0.000000\n",
       "D19_VERSAND_ANZ_12              0.000000\n",
       "D19_VERSAND_ANZ_24              0.000000\n",
       "D19_VERSAND_DATUM               0.000000\n",
       "D19_VERSAND_OFFLINE_DATUM       0.000000\n",
       "D19_VERSAND_ONLINE_DATUM        0.000000\n",
       "D19_VERSAND_REST                0.000000\n",
       "D19_VERSI_ANZ_12                0.000000\n",
       "D19_VERSI_ANZ_24                0.000000\n",
       "D19_VERSI_DATUM                 0.000000\n",
       "D19_VERSI_OFFLINE_DATUM         0.000000\n",
       "D19_VERSI_ONLINE_DATUM          0.000000\n",
       "D19_VERSICHERUNGEN              0.000000\n",
       "D19_VOLLSORTIMENT               0.000000\n",
       "D19_WEIN_FEINKOST               0.000000\n",
       "Unnamed: 0                      0.000000\n",
       "Length: 367, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = azdias_df.shape[0]\n",
    "missing_values_azdias = azdias_df.isnull().sum().sort_values(ascending = False).divide(other = (rows/100))\n",
    "\n",
    "display(missing_values_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have more than 28% of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 351)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a dict with the names of the columns and then drop this columns from dataframe\n",
    "drop_columns = missing_values_azdias[missing_values_azdias > 28]\n",
    "\n",
    "azdias_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)\n",
    "\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have less than 0.5 variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_description = azdias_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropLowVarianceCols(df):\n",
    "    df_description = df.describe()\n",
    "    std_df = df_description.loc[['std']].values.reshape(df_description.shape[1],)\n",
    "    std_serie = pd.Series(std_df, index =df_description.columns) \n",
    "\n",
    "    drop_lowdispersion_cols = std_serie[std_serie < 0.5]\n",
    "\n",
    "    return df.drop(columns = list(drop_lowdispersion_cols.index), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropLowVarianceCols(azdias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 335)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 2486.31 Mb\n"
     ]
    }
   ],
   "source": [
    "def memory_usage(df):\n",
    "    return(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2))\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'LNR', 'AGER_TYP', 'AKT_DAT_KL', 'ALTER_HH', 'ANZ_HAUSHALTE_AKTIV', 'ANZ_KINDER', 'ANZ_PERSONEN', 'ANZ_STATISTISCHE_HAUSHALTE', 'ARBEIT', 'BALLRAUM', 'CAMEO_DEU_2015', 'CAMEO_DEUG_2015', 'CAMEO_INTL_2015', 'CJT_GESAMTTYP', 'CJT_KATALOGNUTZER', 'CJT_TYP_1', 'CJT_TYP_2', 'CJT_TYP_3', 'CJT_TYP_4', 'CJT_TYP_5', 'CJT_TYP_6', 'D19_BANKEN_ANZ_12', 'D19_BANKEN_ANZ_24', 'D19_BANKEN_DATUM', 'D19_BANKEN_DIREKT', 'D19_BANKEN_GROSS', 'D19_BANKEN_LOKAL', 'D19_BANKEN_OFFLINE_DATUM', 'D19_BANKEN_ONLINE_DATUM', 'D19_BANKEN_REST', 'D19_BEKLEIDUNG_GEH', 'D19_BEKLEIDUNG_REST', 'D19_BILDUNG', 'D19_BIO_OEKO', 'D19_BUCH_CD', 'D19_DIGIT_SERV', 'D19_DROGERIEARTIKEL', 'D19_ENERGIE', 'D19_FREIZEIT', 'D19_GARTEN', 'D19_GESAMT_ANZ_12', 'D19_GESAMT_ANZ_24', 'D19_GESAMT_DATUM', 'D19_GESAMT_OFFLINE_DATUM', 'D19_GESAMT_ONLINE_DATUM', 'D19_HANDWERK', 'D19_HAUS_DEKO', 'D19_KINDERARTIKEL', 'D19_KONSUMTYP_MAX', 'D19_KOSMETIK', 'D19_LEBENSMITTEL', 'D19_NAHRUNGSERGAENZUNG', 'D19_RATGEBER', 'D19_REISEN', 'D19_SAMMELARTIKEL', 'D19_SCHUHE', 'D19_SONSTIGE', 'D19_TECHNIK', 'D19_TELKO_DATUM', 'D19_TELKO_MOBILE', 'D19_TELKO_OFFLINE_DATUM', 'D19_TELKO_REST', 'D19_TIERARTIKEL', 'D19_VERSAND_ANZ_12', 'D19_VERSAND_ANZ_24', 'D19_VERSAND_DATUM', 'D19_VERSAND_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM', 'D19_VERSAND_REST', 'D19_VERSI_ANZ_24', 'D19_VERSI_DATUM', 'D19_VERSI_OFFLINE_DATUM', 'D19_VERSICHERUNGEN', 'D19_VOLLSORTIMENT', 'D19_WEIN_FEINKOST', 'EINGEFUEGT_AM', 'EINGEZOGENAM_HH_JAHR', 'EWDICHTE', 'FINANZ_ANLEGER', 'FINANZ_HAUSBAUER', 'FINANZ_MINIMALIST', 'FINANZ_SPARER', 'FINANZ_UNAUFFAELLIGER', 'FINANZ_VORSORGER', 'FINANZTYP', 'FIRMENDICHTE', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GEBURTSJAHR', 'GEMEINDETYP', 'GFK_URLAUBERTYP', 'HEALTH_TYP', 'HH_EINKOMMEN_SCORE', 'INNENSTADT', 'KBA05_ALTER1', 'KBA05_ALTER2', 'KBA05_ALTER3', 'KBA05_ALTER4', 'KBA05_ANHANG', 'KBA05_ANTG1', 'KBA05_ANTG2', 'KBA05_ANTG3', 'KBA05_ANTG4', 'KBA05_AUTOQUOT', 'KBA05_BAUMAX', 'KBA05_CCM1', 'KBA05_CCM2', 'KBA05_CCM3', 'KBA05_CCM4', 'KBA05_DIESEL', 'KBA05_FRAU', 'KBA05_GBZ', 'KBA05_HERST1', 'KBA05_HERST2', 'KBA05_HERST3', 'KBA05_HERST4', 'KBA05_HERST5', 'KBA05_HERSTTEMP', 'KBA05_KRSAQUOT', 'KBA05_KRSHERST1', 'KBA05_KRSHERST2', 'KBA05_KRSHERST3', 'KBA05_KRSKLEIN', 'KBA05_KRSOBER', 'KBA05_KRSVAN', 'KBA05_KRSZUL', 'KBA05_KW1', 'KBA05_KW2', 'KBA05_KW3', 'KBA05_MAXAH', 'KBA05_MAXBJ', 'KBA05_MAXHERST', 'KBA05_MAXSEG', 'KBA05_MAXVORB', 'KBA05_MOD1', 'KBA05_MOD2', 'KBA05_MOD3', 'KBA05_MOD4', 'KBA05_MOD8', 'KBA05_MODTEMP', 'KBA05_MOTOR', 'KBA05_MOTRAD', 'KBA05_SEG1', 'KBA05_SEG10', 'KBA05_SEG2', 'KBA05_SEG3', 'KBA05_SEG4', 'KBA05_SEG5', 'KBA05_SEG6', 'KBA05_SEG7', 'KBA05_SEG8', 'KBA05_SEG9', 'KBA05_VORB0', 'KBA05_VORB1', 'KBA05_VORB2', 'KBA05_ZUL1', 'KBA05_ZUL2', 'KBA05_ZUL3', 'KBA05_ZUL4', 'KBA13_ALTERHALTER_30', 'KBA13_ALTERHALTER_45', 'KBA13_ALTERHALTER_60', 'KBA13_ALTERHALTER_61', 'KBA13_ANTG1', 'KBA13_ANTG2', 'KBA13_ANTG3', 'KBA13_ANTG4', 'KBA13_ANZAHL_PKW', 'KBA13_AUDI', 'KBA13_AUTOQUOTE', 'KBA13_BAUMAX', 'KBA13_BJ_1999', 'KBA13_BJ_2000', 'KBA13_BJ_2004', 'KBA13_BJ_2006', 'KBA13_BJ_2008', 'KBA13_BJ_2009', 'KBA13_BMW', 'KBA13_CCM_0_1400', 'KBA13_CCM_1000', 'KBA13_CCM_1200', 'KBA13_CCM_1400', 'KBA13_CCM_1401_2500', 'KBA13_CCM_1500', 'KBA13_CCM_1600', 'KBA13_CCM_1800', 'KBA13_CCM_2000', 'KBA13_CCM_2500', 'KBA13_CCM_2501', 'KBA13_CCM_3000', 'KBA13_CCM_3001', 'KBA13_FAB_ASIEN', 'KBA13_FAB_SONSTIGE', 'KBA13_FIAT', 'KBA13_FORD', 'KBA13_GBZ', 'KBA13_HALTER_20', 'KBA13_HALTER_25', 'KBA13_HALTER_30', 'KBA13_HALTER_35', 'KBA13_HALTER_40', 'KBA13_HALTER_45', 'KBA13_HALTER_50', 'KBA13_HALTER_55', 'KBA13_HALTER_60', 'KBA13_HALTER_65', 'KBA13_HALTER_66', 'KBA13_HERST_ASIEN', 'KBA13_HERST_AUDI_VW', 'KBA13_HERST_BMW_BENZ', 'KBA13_HERST_EUROPA', 'KBA13_HERST_FORD_OPEL', 'KBA13_HERST_SONST', 'KBA13_HHZ', 'KBA13_KMH_0_140', 'KBA13_KMH_110', 'KBA13_KMH_140', 'KBA13_KMH_140_210', 'KBA13_KMH_180', 'KBA13_KMH_210', 'KBA13_KMH_211', 'KBA13_KMH_250', 'KBA13_KMH_251', 'KBA13_KRSAQUOT', 'KBA13_KRSHERST_AUDI_VW', 'KBA13_KRSHERST_BMW_BENZ', 'KBA13_KRSHERST_FORD_OPEL', 'KBA13_KRSSEG_OBER', 'KBA13_KRSSEG_VAN', 'KBA13_KRSZUL_NEU', 'KBA13_KW_0_60', 'KBA13_KW_110', 'KBA13_KW_120', 'KBA13_KW_121', 'KBA13_KW_30', 'KBA13_KW_40', 'KBA13_KW_50', 'KBA13_KW_60', 'KBA13_KW_61_120', 'KBA13_KW_70', 'KBA13_KW_80', 'KBA13_KW_90', 'KBA13_MAZDA', 'KBA13_MERCEDES', 'KBA13_MOTOR', 'KBA13_NISSAN', 'KBA13_OPEL', 'KBA13_PEUGEOT', 'KBA13_RENAULT', 'KBA13_SEG_GELAENDEWAGEN', 'KBA13_SEG_GROSSRAUMVANS', 'KBA13_SEG_KLEINST', 'KBA13_SEG_KLEINWAGEN', 'KBA13_SEG_KOMPAKTKLASSE', 'KBA13_SEG_MINIVANS', 'KBA13_SEG_MINIWAGEN', 'KBA13_SEG_MITTELKLASSE', 'KBA13_SEG_OBEREMITTELKLASSE', 'KBA13_SEG_OBERKLASSE', 'KBA13_SEG_SONSTIGE', 'KBA13_SEG_SPORTWAGEN', 'KBA13_SEG_UTILITIES', 'KBA13_SEG_VAN', 'KBA13_SEG_WOHNMOBILE', 'KBA13_SITZE_4', 'KBA13_SITZE_5', 'KBA13_SITZE_6', 'KBA13_TOYOTA', 'KBA13_VORB_0', 'KBA13_VORB_1', 'KBA13_VORB_1_2', 'KBA13_VORB_2', 'KBA13_VORB_3', 'KBA13_VW', 'KKK', 'KOMBIALTER', 'KONSUMNAEHE', 'LP_FAMILIE_FEIN', 'LP_FAMILIE_GROB', 'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'LP_STATUS_FEIN', 'LP_STATUS_GROB', 'MIN_GEBAEUDEJAHR', 'MOBI_RASTER', 'MOBI_REGIO', 'NATIONALITAET_KZ', 'ONLINE_AFFINITAET', 'ORTSGR_KLS9', 'OST_WEST_KZ', 'PLZ8_ANTG1', 'PLZ8_ANTG2', 'PLZ8_ANTG3', 'PLZ8_ANTG4', 'PLZ8_BAUMAX', 'PLZ8_GBZ', 'PLZ8_HHZ', 'PRAEGENDE_JUGENDJAHRE', 'REGIOTYP', 'RELAT_AB', 'RETOURTYP_BK_S', 'RT_KEIN_ANREIZ', 'RT_SCHNAEPPCHEN', 'RT_UEBERGROESSE', 'SEMIO_DOM', 'SEMIO_ERL', 'SEMIO_FAM', 'SEMIO_KAEM', 'SEMIO_KRIT', 'SEMIO_KULT', 'SEMIO_LUST', 'SEMIO_MAT', 'SEMIO_PFLICHT', 'SEMIO_RAT', 'SEMIO_REL', 'SEMIO_SOZ', 'SEMIO_TRADV', 'SEMIO_VERT', 'SHOPPER_TYP', 'STRUKTURTYP', 'UMFELD_ALT', 'UMFELD_JUNG', 'VERDICHTUNGSRAUM', 'VERS_TYP', 'VHA', 'VHN', 'VK_DHT4A', 'VK_DISTANZ', 'VK_ZG11', 'W_KEIT_KIND_HH', 'WOHNDAUER_2008', 'WOHNLAGE', 'ZABEOTYP', 'ALTERSKATEGORIE_GROB']\n"
     ]
    }
   ],
   "source": [
    "print(list(azdias_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceForNan(df):\n",
    "    df['CAMEO_INTL_2015'].replace('XX',np.nan, inplace = True)\n",
    "    df['CAMEO_DEUG_2015'].replace('X',np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceForNan(azdias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 650.54 Mb\n"
     ]
    }
   ],
   "source": [
    "#It is necessary to reduce the size of the dataframe in order to optimize the memory usage\n",
    "\n",
    "def to_category(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('category', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def to_int(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('uint8', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "categorical_columns = [\n",
    "                        'ALTERSKATEGORIE_GROB','AGER_TYP','ALTER_HH',\n",
    "                      'BALLRAUM','CAMEO_DEUG_2015','CAMEO_DEU_2015','D19_BANKEN_ANZ_24',\n",
    "                      'CJT_GESAMTTYP','D19_BANKEN_ANZ_12','D19_BANKEN_DATUM',\n",
    "                      'D19_BANKEN_OFFLINE_DATUM',\n",
    "                      'D19_BANKEN_ONLINE_DATUM','D19_BANKEN_DIREKT','D19_BANKEN_GROSS',\n",
    "                      'D19_BANKEN_LOKAL','D19_BANKEN_REST',\n",
    "                      'D19_BEKLEIDUNG_GEH','D19_BEKLEIDUNG_REST','D19_BILDUNG',\n",
    "                      'D19_BIO_OEKO','D19_BUCH_CD','D19_DIGIT_SERV','D19_DROGERIEARTIKEL',\n",
    "                      'D19_ENERGIE','D19_FREIZEIT','D19_GARTEN','D19_GESAMT_ANZ_12',\n",
    "                      'D19_GESAMT_ANZ_24','D19_GESAMT_DATUM','D19_GESAMT_OFFLINE_DATUM','D19_GESAMT_ONLINE_DATUM',\n",
    "                      'D19_HANDWERK','D19_HAUS_DEKO','D19_KINDERARTIKEL',\n",
    "                      'D19_KONSUMTYP_MAX','D19_KOSMETIK','D19_LEBENSMITTEL','D19_NAHRUNGSERGAENZUNG',\n",
    "                      'D19_RATGEBER','D19_REISEN','D19_SAMMELARTIKEL','D19_SCHUHE','D19_SONSTIGE',\n",
    "                      'D19_TECHNIK','D19_TELKO_DATUM',\n",
    "                      'D19_TELKO_MOBILE','D19_TELKO_OFFLINE_DATUM',\n",
    "                       'D19_TELKO_REST','D19_TIERARTIKEL','D19_VERSAND_ANZ_12',\n",
    "                      'D19_VERSAND_ANZ_24','D19_VERSAND_DATUM','D19_VERSAND_DATUM',\n",
    "                      'D19_VERSAND_ONLINE_DATUM','D19_VERSAND_REST','D19_VERSICHERUNGEN',\n",
    "                      'D19_VERSI_ANZ_24','D19_VOLLSORTIMENT','D19_WEIN_FEINKOST','EWDICHTE',\n",
    "                      'FINANZTYP','FINANZ_ANLEGER','FINANZ_HAUSBAUER','FINANZ_MINIMALIST',\n",
    "                      'FINANZ_SPARER','FINANZ_UNAUFFAELLIGER','FINANZ_VORSORGER',\n",
    "                      'GEBAEUDETYP','GEBAEUDETYP_RASTER','GFK_URLAUBERTYP',\n",
    "                      'STRUKTURTYP','HEALTH_TYP',\n",
    "                      'HH_EINKOMMEN_SCORE','INNENSTADT','KBA05_ALTER1','KBA05_ALTER2',\n",
    "                      'KBA05_ALTER3','KBA05_ALTER4','KBA05_ANHANG','KBA05_ANTG1','KBA05_ANTG2',\n",
    "                      'KBA05_ANTG3','KBA05_ANTG4','KBA05_AUTOQUOT','KBA05_BAUMAX','KBA05_CCM1',\n",
    "                    'KBA05_CCM2','KBA05_CCM3','KBA05_CCM4','KBA05_DIESEL','KBA05_FRAU','KBA05_GBZ',\n",
    "                    'KBA05_HERST1','KBA05_HERST2','KBA05_HERST3','KBA05_HERST4','KBA05_HERST5',\n",
    "                    'KBA05_HERSTTEMP','KBA05_KRSAQUOT','KBA05_KRSHERST1','KBA05_KRSHERST2',\n",
    "                    'KBA05_KRSHERST3','KBA05_KRSKLEIN','KBA05_KRSOBER','KBA05_KRSVAN',\n",
    "                    'KBA05_KRSZUL','KBA05_KW1','KBA05_KW2','KBA05_KW3','KBA05_MAXAH','KBA05_MAXBJ',\n",
    "                    'KBA05_MAXHERST','KBA05_MAXSEG','KBA05_MAXVORB','KBA05_MOD1','KBA05_MOD2',\n",
    "                    'KBA05_MOD3','KBA05_MOD4','KBA05_MOD8','KBA05_MODTEMP','KBA05_MOTOR',\n",
    "                    'KBA05_MOTRAD','KBA05_SEG1','KBA05_SEG10','KBA05_SEG2','KBA05_SEG3',\n",
    "                    'KBA05_SEG4','KBA05_SEG5','KBA05_SEG6','KBA05_SEG7','KBA05_SEG8','KBA05_SEG9',\n",
    "                    'KBA05_VORB0','KBA05_VORB1','KBA05_VORB2','KBA05_ZUL1','KBA05_ZUL2',\n",
    "                    'KBA05_ZUL3','KBA05_ZUL4','KBA13_ALTERHALTER_30','KBA13_ALTERHALTER_45',\n",
    "                    'KBA13_ALTERHALTER_60','KBA13_ALTERHALTER_61','KBA13_AUDI','KBA13_AUTOQUOTE',\n",
    "                    'KBA13_BJ_1999','KBA13_BJ_2000','KBA13_BJ_2004','KBA13_BJ_2006',\n",
    "                    'KBA13_BJ_2008','KBA13_BJ_2009','KBA13_BMW','KBA13_CCM_1000','KBA13_CCM_1200',\n",
    "                    'KBA13_CCM_1400','KBA13_CCM_0_1400','KBA13_CCM_1500','KBA13_CCM_1401_2500',\n",
    "                    'KBA13_CCM_1600','KBA13_CCM_1800','KBA13_CCM_2000','KBA13_CCM_2500',\n",
    "                    'KBA13_CCM_2501','KBA13_CCM_3000','KBA13_CCM_3001','KBA13_FAB_ASIEN',\n",
    "                    'KBA13_FAB_SONSTIGE','KBA13_FIAT','KBA13_FORD','KBA13_HALTER_20',\n",
    "                    'KBA13_HALTER_25','KBA13_HALTER_30','KBA13_HALTER_35','KBA13_HALTER_40',\n",
    "                    'KBA13_HALTER_45','KBA13_HALTER_50','KBA13_HALTER_55','KBA13_HALTER_60',\n",
    "                    'KBA13_HALTER_65','KBA13_HALTER_66','KBA13_HERST_ASIEN','KBA13_HERST_AUDI_VW',\n",
    "                    'KBA13_HERST_BMW_BENZ','KBA13_HERST_EUROPA','KBA13_HERST_FORD_OPEL',\n",
    "                    'KBA13_HERST_SONST','KBA13_KMH_110','KBA13_KMH_140','KBA13_KMH_180',\n",
    "                    'KBA13_KMH_0_140','KBA13_KMH_140_210','KBA13_KMH_211','KBA13_KMH_250',\n",
    "                    'KBA13_KMH_251','KBA13_KRSAQUOT','KBA13_KRSHERST_AUDI_VW',\n",
    "                    'KBA13_KRSHERST_BMW_BENZ','KBA13_KRSHERST_FORD_OPEL',\n",
    "                    'KBA13_KRSSEG_OBER','KBA13_KRSSEG_VAN','KBA13_KRSZUL_NEU','KBA13_KW_30',\n",
    "                    'KBA13_KW_40','KBA13_KW_50','KBA13_KW_60','KBA13_KW_0_60','KBA13_KW_70',\n",
    "                    'KBA13_KW_61_120','KBA13_KW_80','KBA13_KW_90','KBA13_KW_110','KBA13_KW_120',\n",
    "                    'KBA13_KW_121','KBA13_MAZDA','KBA13_MERCEDES','KBA13_MOTOR','KBA13_NISSAN',\n",
    "                    'KBA13_OPEL','KBA13_PEUGEOT','KBA13_RENAULT','KBA13_SEG_GELAENDEWAGEN',\n",
    "                    'KBA13_SEG_GROSSRAUMVANS','KBA13_SEG_KLEINST','KBA13_SEG_KLEINWAGEN',\n",
    "                    'KBA13_SEG_KOMPAKTKLASSE','KBA13_SEG_MINIVANS','KBA13_SEG_MINIWAGEN',\n",
    "                    'KBA13_SEG_MITTELKLASSE','KBA13_SEG_OBEREMITTELKLASSE','KBA13_SEG_OBERKLASSE',\n",
    "                    'KBA13_SEG_SONSTIGE','KBA13_SEG_SPORTWAGEN','KBA13_SEG_UTILITIES',\n",
    "                    'KBA13_SEG_VAN','KBA13_SEG_WOHNMOBILE','KBA13_SITZE_4','KBA13_SITZE_5',\n",
    "                    'KBA13_SITZE_6','KBA13_TOYOTA','KBA13_VORB_0','KBA13_VORB_1','KBA13_VORB_1_2',\n",
    "                    'KBA13_VORB_2','KBA13_VORB_3','KBA13_VW','KKK','KONSUMNAEHE','LP_FAMILIE_FEIN',\n",
    "                    'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','LP_LEBENSPHASE_GROB','LP_STATUS_FEIN',\n",
    "                    'LP_STATUS_GROB','MOBI_REGIO','NATIONALITAET_KZ','ONLINE_AFFINITAET','ORTSGR_KLS9',\n",
    "                    'OST_WEST_KZ','PLZ8_ANTG1','PLZ8_ANTG2','PLZ8_ANTG3','PLZ8_ANTG4','PLZ8_BAUMAX',\n",
    "                    'PLZ8_GBZ','PLZ8_HHZ','PRAEGENDE_JUGENDJAHRE','REGIOTYP','RELAT_AB',\n",
    "                    'RETOURTYP_BK_S','SEMIO_DOM','SEMIO_ERL','SEMIO_FAM','SEMIO_KAEM','SEMIO_KRIT',\n",
    "                    'SEMIO_KULT','SEMIO_LUST','SEMIO_MAT','SEMIO_PFLICHT','SEMIO_RAT','SEMIO_REL',\n",
    "                    'SEMIO_SOZ','SEMIO_TRADV','SEMIO_VERT','SHOPPER_TYP',\n",
    "                    'VERS_TYP','WOHNDAUER_2008','WOHNLAGE','W_KEIT_KIND_HH','ZABEOTYP']\n",
    "\n",
    "#GEBURTSJAHR year of birth, to int or to date\n",
    "#GREEN_AVANTGARDE maybe can be a bool\n",
    "azdias_df = to_category(azdias_df, categorical_columns)\n",
    "#azdias_df = to_int(azdias_df, categorical_columns)\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging for more space it can be seen that there are columns that are not listed in the csv description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EINGEFUEGT_AM                 60.686382\n",
       "CAMEO_INTL_2015               39.016406\n",
       "ANZ_STATISTISCHE_HAUSHALTE     6.799477\n",
       "KBA13_GBZ                      6.799477\n",
       "CJT_KATALOGNUTZER              6.799477\n",
       "RT_SCHNAEPPCHEN                6.799477\n",
       "RT_KEIN_ANREIZ                 6.799477\n",
       "AKT_DAT_KL                     6.799477\n",
       "KBA13_HHZ                      6.799477\n",
       "ANZ_HAUSHALTE_AKTIV            6.799477\n",
       "ANZ_KINDER                     6.799477\n",
       "ANZ_PERSONEN                   6.799477\n",
       "ARBEIT                         6.799477\n",
       "D19_VERSI_OFFLINE_DATUM        6.799477\n",
       "D19_VERSAND_OFFLINE_DATUM      6.799477\n",
       "CJT_TYP_6                      6.799477\n",
       "CJT_TYP_5                      6.799477\n",
       "CJT_TYP_4                      6.799477\n",
       "MOBI_RASTER                    6.799477\n",
       "MIN_GEBAEUDEJAHR               6.799477\n",
       "CJT_TYP_3                      6.799477\n",
       "CJT_TYP_2                      6.799477\n",
       "CJT_TYP_1                      6.799477\n",
       "KOMBIALTER                     6.799477\n",
       "D19_VERSI_DATUM                6.799477\n",
       "KBA13_ANTG3                    6.799477\n",
       "VERDICHTUNGSRAUM               6.799477\n",
       "LNR                            6.799477\n",
       "FIRMENDICHTE                   6.799477\n",
       "KBA13_ANTG1                    6.799477\n",
       "                                ...    \n",
       "KBA13_CCM_3001                 0.850125\n",
       "KBA13_HALTER_35                0.850125\n",
       "KBA13_HALTER_30                0.850125\n",
       "KBA13_FIAT                     0.850125\n",
       "KBA13_HALTER_20                0.850125\n",
       "KBA13_FAB_ASIEN                0.850125\n",
       "KBA13_FORD                     0.850125\n",
       "KBA13_FAB_SONSTIGE             0.850125\n",
       "KBA13_KRSZUL_NEU               0.850118\n",
       "KBA05_KRSVAN                   0.850118\n",
       "PLZ8_ANTG3                     0.850118\n",
       "KBA13_MOTOR                    0.850118\n",
       "NATIONALITAET_KZ               0.850118\n",
       "KBA05_MAXVORB                  0.850118\n",
       "KBA05_KRSKLEIN                 0.850118\n",
       "KBA13_KRSSEG_VAN               0.850118\n",
       "KBA05_KRSOBER                  0.850118\n",
       "HEALTH_TYP                     0.850118\n",
       "KBA05_KRSZUL                   0.850118\n",
       "KBA13_KRSSEG_OBER              0.850118\n",
       "KBA05_ANTG3                    0.850118\n",
       "VERS_TYP                       0.850034\n",
       "STRUKTURTYP                    0.850034\n",
       "KBA13_KMH_110                  0.850034\n",
       "KBA05_ANTG4                    0.850034\n",
       "PLZ8_ANTG4                     0.850034\n",
       "KBA05_SEG6                     0.850034\n",
       "KBA13_KMH_251                  0.850034\n",
       "KBA13_KW_30                    0.850034\n",
       "Index                          0.000076\n",
       "Length: 336, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(azdias_df.memory_usage(deep=True) / 1024 ** 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 364.24 Mb\n"
     ]
    }
   ],
   "source": [
    "categorical_columns2 = ['CAMEO_INTL_2015','KBA13_ANTG1','KBA13_GBZ','D19_VERSI_DATUM','RT_UEBERGROESSE',\n",
    "                       'RT_SCHNAEPPCHEN','RT_KEIN_ANREIZ','ANZ_HAUSHALTE_AKTIV','ANZ_KINDER',\n",
    "                       'ANZ_PERSONEN','ANZ_STATISTISCHE_HAUSHALTE','ARBEIT','MOBI_RASTER',\n",
    "                       'D19_VERSI_OFFLINE_DATUM','MIN_GEBAEUDEJAHR','KOMBIALTER',\n",
    "                       'CJT_KATALOGNUTZER','CJT_TYP_1','CJT_TYP_2','CJT_TYP_3','CJT_TYP_4','CJT_TYP_5',\n",
    "                        'CJT_TYP_6','KBA13_HHZ','KBA13_KMH_210','KBA13_BAUMAX',\n",
    "                       'UMFELD_JUNG','EINGEZOGENAM_HH_JAHR','GEMEINDETYP',\n",
    "                       'GEBURTSJAHR','AKT_DAT_KL','KBA13_ANTG2','D19_VERSAND_OFFLINE_DATUM','UMFELD_ALT',\n",
    "                       'KBA13_ANTG3','VK_DISTANZ','FIRMENDICHTE','VERDICHTUNGSRAUM',\n",
    "                       'VK_ZG11','KBA13_ANTG4','VK_DHT4A','VHN','VHA']\n",
    "\n",
    "azdias_df = to_category(azdias_df, categorical_columns2)\n",
    "#KBA13_ANZAHL_PKW to int\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows that not have at least 270 (80%) non null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired in https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4\n",
    "\n",
    "def impute_mode_categorical(df):\n",
    "    categorical_columns= df.select_dtypes(include=['category'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in categorical_columns: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        #col_data.replace('XX',np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        mode = col_data.mode()[0]\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(mode, inplace=True)\n",
    "            \n",
    "    return df\n",
    "    \n",
    "def impute_median_numerical(df):\n",
    "    numeric_cols = df.select_dtypes(include=['int','float'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in numeric_cols: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        median = col_data.median()\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(median, inplace=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 316.11 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_df.dropna(thresh=290, inplace = True)\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace nulls and unknown (-1) values with mode or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 335)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of the non ordinal categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 435.76 Mb\n"
     ]
    }
   ],
   "source": [
    "one_hot_list = ['WOHNLAGE','VERS_TYP','SHOPPER_TYP','RETOURTYP_BK_S','PLZ8_BAUMAX','NATIONALITAET_KZ',\n",
    "                'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','KBA05_MODTEMP','KBA05_MAXHERST','KBA05_HERSTTEMP',\n",
    "                'HEALTH_TYP','GFK_URLAUBERTYP','GEBAEUDETYP','FINANZTYP','D19_KONSUMTYP_MAX',\n",
    "                'CJT_GESAMTTYP','CAMEO_DEU_2015','AGER_TYP']\n",
    "azdias_df = pd.get_dummies(azdias_df, columns =one_hot_list)\n",
    "\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once performed one hot encoded, drop low variance resulting columns that are result of having previous columns with a value that appears few times and it is not statistically relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 316)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropLowVarianceCols(azdias_df)\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode into numerical values binary feature OST_WEST_KZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encodeColumnByLabel(df, label):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df[label])\n",
    "    return label_encoder.transform(df[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['OST_WEST_KZ'] = encodeColumnByLabel(azdias_df, 'OST_WEST_KZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp into an integer formed by year month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestampToInt(df, column):\n",
    "    timestamp =  pd.to_datetime(df[column]) ## pandas recognizes your format\n",
    "\n",
    "    df[column] = timestamp.dt.strftime('%Y%m%d')\n",
    "    return azdias_df[column].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['EINGEFUEGT_AM'] = timestampToInt(azdias_df, 'EINGEFUEGT_AM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize values before aplying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "np_azdias = azdias_df.values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np_azdias)\n",
    "np_azdias = scaler.transform(np_azdias)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in the dataframe the normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df = pd.DataFrame(data=np_azdias,\n",
    "          index=azdias_df.index,\n",
    "          columns=azdias_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "session = sagemaker.Session()\n",
    "# get IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'arvato'\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix+\"/train\")\n",
    "#num_components = 400\n",
    "#since removing columns with low variance after performing one hot encoding the remaining number of columns is\n",
    "#less than the previously specified number of components (316) so I set a new number of components\n",
    "num_components = 300\n",
    "\n",
    "\n",
    "\n",
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to recordset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_azdias_data = pca.record_set(np_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit data to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-05 18:13:41 Starting - Starting the training job...\n",
      "2020-05-05 18:13:41 Starting - Launching requested ML instances...\n",
      "2020-05-05 18:14:39 Starting - Preparing the instances for training......\n",
      "2020-05-05 18:15:15 Downloading - Downloading input data......\n",
      "2020-05-05 18:16:26 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:28 INFO 139730773792576] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:28 INFO 139730773792576] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'316', u'mini_batch_size': u'500', u'num_components': u'300'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:28 INFO 139730773792576] Final configuration: {u'num_components': u'300', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'316', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:28 WARNING 139730773792576] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/865d8dd5-3fc0-444d-9e22-c52482bc6fc8', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-13-40-862', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-243.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/163a358d-457d-4400-8397-db5ce84b2c13', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-13-40-862', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/865d8dd5-3fc0-444d-9e22-c52482bc6fc8', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.156.243', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-13-40-862', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-243.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/163a358d-457d-4400-8397-db5ce84b2c13', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-13-40-862', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/865d8dd5-3fc0-444d-9e22-c52482bc6fc8', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-13-40-862', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-243.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/163a358d-457d-4400-8397-db5ce84b2c13', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-13-40-862', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/865d8dd5-3fc0-444d-9e22-c52482bc6fc8', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.156.243', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-13-40-862', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-243.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/163a358d-457d-4400-8397-db5ce84b2c13', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-13-40-862', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/865d8dd5-3fc0-444d-9e22-c52482bc6fc8', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.156.243', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-13-40-862', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-156-243.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/163a358d-457d-4400-8397-db5ce84b2c13', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-13-40-862', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 60 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 69 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:30 INFO 139730773792576] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:31 INFO 139730773792576] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:31 INFO 139730773792576] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:31 INFO 139730773792576] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:32 INFO 139730773792576] nvidia-smi took: 0.0251429080963 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:32 INFO 139730773792576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:32 INFO 139730773792576] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:32 INFO 139730773792576] 316 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:32 INFO 139730773792576] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1487.2429370880127, \"sum\": 1487.2429370880127, \"min\": 1487.2429370880127}}, \"EndTime\": 1588702592.530186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702591.027937}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588702592.530452, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702592.530378}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:16:32.536] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1507, \"num_examples\": 1, \"num_bytes\": 1278000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2020-05-05 18:16:42.902] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 10359, \"num_examples\": 1503, \"num_bytes\": 1920402036}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 10366.017818450928, \"sum\": 10366.017818450928, \"min\": 10366.017818450928}}, \"EndTime\": 1588702602.902857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702592.530287}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:42 INFO 139730773792576] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588702602.903907, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1588702592.536617}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:42 INFO 139730773792576] #throughput_metric: host=algo-1, train throughput=72467.3450459 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 35.62521934509277, \"sum\": 35.62521934509277, \"min\": 35.62521934509277}}, \"EndTime\": 1588702602.940369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702602.902954}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:16:42 INFO 139730773792576] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 14596.349000930786, \"sum\": 14596.349000930786, \"min\": 14596.349000930786}, \"setuptime\": {\"count\": 1, \"max\": 2577.2039890289307, \"sum\": 2577.2039890289307, \"min\": 2577.2039890289307}}, \"EndTime\": 1588702602.96182, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702602.940425}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-05 18:16:53 Uploading - Uploading generated training model\n",
      "2020-05-05 18:16:53 Completed - Training job completed\n",
      "Training seconds: 98\n",
      "Billable seconds: 98\n"
     ]
    }
   ],
   "source": [
    "#train_inputs = sagemaker.s3_input(train_s3, content_type='text/csv;label_size=0')\n",
    "\n",
    "pca.fit(formatted_azdias_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arvato/train/pca-2020-05-05-18-13-40-862/output/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the training job, it's suggested that you copy-paste\n",
    "# from the notebook or from a specific job in the AWS console\n",
    "\n",
    "training_job_name=pca._current_job_name\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix+\"/train\", training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as model_algo-1\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# loading the unzipped artifacts\n",
    "pca_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selected params\n",
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the explained variance for the top n principal components\n",
    "# you may assume you have access to the global var N_COMPONENTS\n",
    "def explained_variance(s, n_top_components):\n",
    "    '''Calculates the approx. data variance that n_top_components captures.\n",
    "       :param s: A dataframe of singular values for top components; \n",
    "           the top value is in the last row.\n",
    "       :param n_top_components: An integer, the number of top components to use.\n",
    "       :return: The expected data variance covered by the n_top_components.'''\n",
    "    \n",
    "    n_components = len(s) - n_top_components\n",
    "    partial = s[n_components:].pow(2).sum(axis=0)\n",
    "    total = s.pow(2).sum(axis=0)\n",
    "\n",
    "    return partial/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0    0.980038\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "n_top_components = 220 # select a value for the number of top components\n",
    "\n",
    "# calculate the explained variance\n",
    "exp_variance = explained_variance(s, n_top_components)\n",
    "print('Explained variance: ', exp_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for x in range(num_components):\n",
    "    y.append(explained_variance(s, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y)\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how many components are needed for 90% of explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "#convert list of series to list of floats\n",
    "floats_y = [float(i) for i in y]\n",
    "#construct an comprehension to locate the index of the first element with more than 0.9 explained variance\n",
    "components = (i for i,v in enumerate(floats_y) if (v > 0.9))\n",
    "num_components = next(components)\n",
    "print(num_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-fit PCA with the number of components obtained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-05 18:17:28 Starting - Starting the training job...\n",
      "2020-05-05 18:17:30 Starting - Launching requested ML instances...\n",
      "2020-05-05 18:18:28 Starting - Preparing the instances for training......\n",
      "2020-05-05 18:19:07 Downloading - Downloading input data...\n",
      "2020-05-05 18:19:58 Training - Downloading the training image...\n",
      "2020-05-05 18:20:12 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:14 INFO 140056124393280] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:14 INFO 140056124393280] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'316', u'mini_batch_size': u'500', u'num_components': u'134'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:14 INFO 140056124393280] Final configuration: {u'num_components': u'134', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'316', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:14 WARNING 140056124393280] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/48f6161d-97c2-4641-995a-bfa78adf4d8b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-17-28-676', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-65-43.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/f0b1a628-fbab-41f7-be82-9f3fabe750c3', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-17-28-676', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/48f6161d-97c2-4641-995a-bfa78adf4d8b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.65.43', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-17-28-676', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-65-43.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/f0b1a628-fbab-41f7-be82-9f3fabe750c3', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-17-28-676', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/48f6161d-97c2-4641-995a-bfa78adf4d8b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-17-28-676', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-65-43.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/f0b1a628-fbab-41f7-be82-9f3fabe750c3', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-17-28-676', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/48f6161d-97c2-4641-995a-bfa78adf4d8b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.65.43', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-17-28-676', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-65-43.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/f0b1a628-fbab-41f7-be82-9f3fabe750c3', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-17-28-676', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/48f6161d-97c2-4641-995a-bfa78adf4d8b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.65.43', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-05-18-17-28-676', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-65-43.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/f0b1a628-fbab-41f7-be82-9f3fabe750c3', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-05-18-17-28-676', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 61 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 70 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:16 INFO 140056124393280] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:17 INFO 140056124393280] nvidia-smi took: 0.0251491069794 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:17 INFO 140056124393280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:17 INFO 140056124393280] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:17 INFO 140056124393280] 316 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:17 INFO 140056124393280] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1074.8710632324219, \"sum\": 1074.8710632324219, \"min\": 1074.8710632324219}}, \"EndTime\": 1588702817.38305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702816.281789}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588702817.383315, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702817.383243}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:20:17.396] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1111, \"num_examples\": 1, \"num_bytes\": 1278000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2020-05-05 18:20:28.069] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 10662, \"num_examples\": 1503, \"num_bytes\": 1920402036}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 10673.184156417847, \"sum\": 10673.184156417847, \"min\": 10673.184156417847}}, \"EndTime\": 1588702828.069699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702817.383154}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:28 INFO 140056124393280] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588702828.071467, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1588702817.396469}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:28 INFO 140056124393280] #throughput_metric: host=algo-1, train throughput=70381.2076315 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 35.73489189147949, \"sum\": 35.73489189147949, \"min\": 35.73489189147949}}, \"EndTime\": 1588702828.107652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702828.069849}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:20:28 INFO 140056124393280] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 14139.619827270508, \"sum\": 14139.619827270508, \"min\": 14139.619827270508}, \"setuptime\": {\"count\": 1, \"max\": 2064.3677711486816, \"sum\": 2064.3677711486816, \"min\": 2064.3677711486816}}, \"EndTime\": 1588702828.129881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588702828.107713}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-05 18:20:39 Uploading - Uploading generated training model\n",
      "2020-05-05 18:20:39 Completed - Training job completed\n",
      "Training seconds: 92\n",
      "Billable seconds: 92\n"
     ]
    }
   ],
   "source": [
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)\n",
    "\n",
    "pca.fit(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 ms, sys: 1.39 ms, total: 23 ms\n",
      "Wall time: 342 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pca_transformer = pca.transformer(instance_count = 1, \n",
    "                                  instance_type = 'ml.m5.large',\n",
    "                                  output_path='s3://{}/{}/pca/transform/test'.format(bucket_name, prefix+\"/transform\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'azdias.csv'\n",
    "\n",
    "\n",
    "u = azdias_df.select_dtypes(object)\n",
    "azdias_df[u.columns] = u.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into local notebook storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df.to_csv(filename,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "np_azdias_location = session.upload_data(os.path.join(filename), key_prefix=prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print dataset location in order to avoid previous computation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-848439228145/arvato/azdias.csv\n"
     ]
    }
   ],
   "source": [
    "print(np_azdias_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete temp file from sagemaker notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] nvidia-smi took: 0.100437879562 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loading entry points\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:28:30 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:28:30 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:28:30 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:28:30 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loading model...\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:28:30 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] loading model...\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:30 INFO 139697717761856] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703321.358422, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703310.89119}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703321.358422, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703310.89119}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703325.745344, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703321.358584}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703325.745344, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703321.358584}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703325.783918, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703310.962016}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703325.783918, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703310.962016}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-05-05T18:28:41.373:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703327.136314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703325.745427}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703327.244557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703325.784299}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703327.136314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703325.745427}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703327.244557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703325.784299}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703328.486716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703327.136406}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703328.798135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703327.24541}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703328.486716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703327.136406}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703328.798135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703327.24541}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703329.893832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703328.486795}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703330.205386, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703328.798949}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703329.893832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703328.486795}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703330.205386, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703328.798949}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:28:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703332.630411, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703331.278813}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703332.630411, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703331.278813}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703333.333389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703331.710614}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703333.83472, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703332.630501}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703333.333389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703331.710614}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703333.83472, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703332.630501}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703334.669191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703333.333932}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703335.181876, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703333.834803}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703334.669191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703333.333932}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703335.181876, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703333.834803}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703335.967248, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703334.669659}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703335.967248, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703334.669659}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703336.394463, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703335.181956}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:56 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703336.394463, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703335.181956}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:56 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703337.43129, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703335.967734}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703337.597086, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703336.39455}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703337.43129, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703335.967734}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703337.597086, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703336.39455}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703338.842974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703337.597175}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703338.871306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703337.431822}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703338.842974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703337.597175}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703338.871306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703337.431822}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:28:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703340.100463, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703338.871375}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703340.163017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703338.843058}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:28:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703340.100463, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703338.871375}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703340.163017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703338.843058}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703341.771454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703340.163103}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703341.771454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703340.163103}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703343.038107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703341.771807}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703343.038107, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703341.771807}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703343.321394, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703341.759005}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703343.321394, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703341.759005}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703344.394145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703343.038445}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703344.882511, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703343.321476}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703344.394145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703343.038445}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703344.882511, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703343.321476}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703345.908228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703344.394459}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703345.908228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703344.394459}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703346.305961, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703344.882795}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:06 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:06 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:06 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:06 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2464.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:07 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:07 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:07 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703347.215174, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703345.908308}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703346.305961, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703344.882795}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:06 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:06 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:06 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:06 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2464.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:07 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:07 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:07 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703347.215174, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703345.908308}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703347.822072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703346.306445}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703347.822072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703346.306445}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703348.748921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703347.215249}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703348.748921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703347.215249}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703349.290321, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703347.822973}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703350.134514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703348.749433}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703349.290321, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703347.822973}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703350.134514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703348.749433}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703350.773152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703349.290797}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703350.773152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703349.290797}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:29:11 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:11 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703352.254891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703350.773588}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:11 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:11 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703352.254891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703350.773588}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703352.781188, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703351.457375}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703352.781188, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703351.457375}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703353.590001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703352.255866}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703354.092921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703352.781268}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703353.590001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703352.255866}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703354.092921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703352.781268}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703355.065087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703353.590894}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703355.065087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703353.590894}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703355.511578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703354.093003}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703355.511578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703354.093003}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703356.632459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703355.06558}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703356.632459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703355.06558}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703357.30001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703355.511731}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703358.250795, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703356.633188}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703357.30001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703355.511731}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703358.250795, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703356.633188}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703358.650355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703357.300355}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703358.650355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703357.300355}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703359.673598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703358.25127}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703360.10618, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703358.650433}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703359.673598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703358.25127}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703360.10618, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703358.650433}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703361.138563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703359.674108}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703361.138563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703359.674108}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:29:22 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:22 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:22 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:22 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:22 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:22 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:22 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:22 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703362.527252, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703361.13951}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703362.956851, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703361.616548}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703362.527252, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703361.13951}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703362.956851, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703361.616548}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703363.910261, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703362.52772}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703363.910261, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703362.52772}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703364.356314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703362.957383}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703364.356314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703362.957383}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703365.420943, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703363.910339}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703365.420943, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703363.910339}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703365.653681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703364.356471}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703365.653681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703364.356471}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703366.878837, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703365.654174}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703366.998613, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703365.42102}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703366.878837, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703365.654174}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703366.998613, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703365.42102}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2460.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703368.199259, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703366.998696}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703368.272212, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703366.879331}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2460.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703368.199259, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703366.998696}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703368.272212, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703366.879331}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703369.634888, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703368.199341}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703369.950507, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703368.27308}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703369.634888, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703368.199341}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703369.950507, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703368.27308}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703371.015393, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703369.635434}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703371.015393, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703369.635434}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:29:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703372.473345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703371.015896}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703372.881186, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703371.364175}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703372.473345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703371.015896}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703372.881186, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703371.364175}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703374.004574, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703372.473881}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703374.004574, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703372.473881}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703374.469028, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703372.881268}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:34 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:34 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:34 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:34 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703374.469028, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703372.881268}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:34 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:34 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:34 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:34 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703375.354662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703374.005086}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703375.884246, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703374.469109}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703375.354662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703374.005086}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703375.884246, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703374.469109}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703376.932009, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703375.355189}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703376.932009, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703375.355189}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703377.445913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703375.884323}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:37 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:37 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:37 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:37 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703377.445913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703375.884323}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:37 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:37 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:37 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:37 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703378.460889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703376.932124}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703378.963242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703377.446718}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703378.460889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703376.932124}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703378.963242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703377.446718}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703379.850015, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703378.460997}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703379.850015, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703378.460997}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703380.365968, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703378.963763}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703380.365968, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703378.963763}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:29:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703382.69595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703381.31597}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703382.69595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703381.31597}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703383.14345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703381.712085}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703383.14345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703381.712085}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:43 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703384.124508, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703382.696445}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:43 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703384.124508, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703382.696445}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703384.602777, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703383.143615}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703384.602777, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703383.143615}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703385.414243, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703384.125551}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703386.047439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703384.602862}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703385.414243, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703384.125551}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703386.047439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703384.602862}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703386.73453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703385.415094}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703386.73453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703385.415094}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703387.508649, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703386.04752}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703388.088959, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703386.735055}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703387.508649, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703386.04752}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703388.088959, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703386.735055}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703388.919196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703387.508725}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703388.919196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703387.508725}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703389.543189, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703388.089857}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703390.312299, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703388.919271}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703389.543189, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703388.089857}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703390.312299, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703388.919271}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703391.074176, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703389.543711}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703391.074176, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703389.543711}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:29:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703392.492232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703391.074643}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703393.104203, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703391.647668}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703392.492232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703391.074643}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703393.104203, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703391.647668}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703393.830746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703392.492311}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703393.830746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703392.492311}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703394.449019, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703393.104722}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703394.449019, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703393.104722}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703395.345163, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703393.831187}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703396.006703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703394.449526}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703395.345163, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703393.831187}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703396.006703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703394.449526}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703396.62138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703395.346119}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:56 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703396.62138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703395.346119}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:56 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:56 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:56 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:56 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:56 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:56 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:56 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703397.532714, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703396.006783}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703398.105803, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703396.622227}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703397.532714, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703396.006783}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703398.105803, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703396.622227}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703398.828658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703397.532791}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703398.828658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703397.532791}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703399.398812, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703398.106241}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:29:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703399.398812, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703398.106241}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:29:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703400.358286, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703398.82916}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703400.840027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703399.399194}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703400.358286, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703398.82916}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703400.840027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703399.399194}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:30:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703403.340871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703401.759679}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703403.629817, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703402.179642}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703403.340871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703401.759679}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703403.629817, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703402.179642}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703404.703284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703403.340945}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703405.08711, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703403.630387}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703404.703284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703403.340945}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703405.08711, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703403.630387}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703406.025929, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703404.70336}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703406.025929, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703404.70336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703406.423916, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703405.087872}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:06 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:06 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:06 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:06 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703407.289116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703406.026005}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703406.423916, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703405.087872}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:06 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:06 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:06 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:06 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703407.289116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703406.026005}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703407.891051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703406.424862}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703407.891051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703406.424862}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703408.675015, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703407.289197}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703408.675015, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703407.289197}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703409.369318, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703407.891841}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703410.082778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703408.675093}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703409.369318, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703407.891841}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703410.082778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703408.675093}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703410.785824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703409.369854}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703410.785824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703409.369854}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:30:11 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703411.406011, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703410.083346}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703412.108306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703410.786298}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:11 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703411.406011, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703410.083346}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703412.108306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703410.786298}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703412.784371, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703411.406509}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703412.784371, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703411.406509}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703413.589149, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703412.108861}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703414.151402, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703412.784886}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703413.589149, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703412.108861}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703414.151402, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703412.784886}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703414.913324, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703413.589633}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703414.913324, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703413.589633}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703415.689439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703414.151904}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703415.689439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703414.151904}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703416.364876, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703414.913401}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703417.244794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703415.689976}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703416.364876, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703414.913401}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703417.244794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703415.689976}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703417.725389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703416.365338}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703417.725389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703416.365338}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703418.60359, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703417.245348}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703419.056073, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703417.725468}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703418.60359, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703417.245348}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703419.056073, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703417.725468}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2494.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703420.0443, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703418.604096}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2494.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703420.0443, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703418.604096}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703420.429913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703419.056518}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703420.429913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703419.056518}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2500.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:21 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:21 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:21 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:21 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2492.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2500.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:21 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:21 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:21 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:21 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2492.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:30:22 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:22 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703422.940488, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703421.479639}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703423.213564, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703421.837147}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:22 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:22 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703422.940488, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703421.479639}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703423.213564, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703421.837147}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703424.506389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703422.941011}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703424.803835, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703423.21407}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703424.506389, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703422.941011}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703424.803835, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703423.21407}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703425.918832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703424.506929}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703426.295584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703424.804309}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703425.918832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703424.506929}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703426.295584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703424.804309}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703427.366316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703425.919383}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703427.674334, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703426.295666}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703427.366316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703425.919383}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703427.674334, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703426.295666}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703428.705826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703427.366862}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703429.040866, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703427.674415}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703428.705826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703427.366862}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703429.040866, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703427.674415}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703430.250227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703428.706332}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703430.250227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703428.706332}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703430.432276, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703429.040948}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:31 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:31 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:31 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:31 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703430.432276, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703429.040948}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:31 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:31 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:31 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:31 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:30:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703433.059796, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703431.646467}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703433.134377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703431.806423}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703433.059796, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703431.646467}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703433.134377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703431.806423}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:33 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703434.40956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703433.134916}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703434.606451, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703433.059883}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703434.40956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703433.134916}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703434.606451, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703433.059883}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703435.79984, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703434.409635}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703436.070278, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703434.606875}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703435.79984, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703434.409635}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703436.070278, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703434.606875}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703437.145765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703435.800362}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703437.145765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703435.800362}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703437.55789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703436.070367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:37 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:37 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:37 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:37 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703437.55789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703436.070367}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:37 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:37 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:37 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:37 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703438.541345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703437.146276}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703439.043905, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703437.557969}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703438.541345, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703437.146276}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703439.043905, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703437.557969}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703440.118675, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703438.541909}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703440.118675, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703438.541909}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703440.58669, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703439.044484}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703440.58669, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703439.044484}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703442.143, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703440.587184}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703442.143, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703440.587184}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703442.998794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703441.552255}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703442.998794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703441.552255}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703443.608152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703442.143515}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:43 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:43 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:43 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:43 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703443.608152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703442.143515}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:43 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:43 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:43 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:43 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703444.473806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703442.99887}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703444.473806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703442.99887}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703445.007219, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703443.608312}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703445.007219, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703443.608312}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703445.813687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703444.47396}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703445.813687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703444.47396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703446.454224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703445.007305}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703447.253983, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703445.813779}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703446.454224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703445.007305}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:46 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:46 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:46 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:46 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703447.253983, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703445.813779}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703447.889196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703446.454305}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703447.889196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703446.454305}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:47 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703448.63452, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703447.254484}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703449.205723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703447.889288}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703448.63452, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703447.254484}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703449.205723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703447.889288}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703450.15101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703448.635028}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703450.15101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703448.635028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703450.81808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703449.20582}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703450.81808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703449.20582}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:51 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:51 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703451.686622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703450.151087}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703452.213771, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703450.818587}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:51 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:51 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703451.686622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703450.151087}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703452.213771, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703450.818587}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703452.98191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703451.6867}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703452.98191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703451.6867}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703453.689296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703452.214268}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703453.689296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703452.214268}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703454.400007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703452.981985}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703455.055771, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703453.689951}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703454.400007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703452.981985}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703455.055771, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703453.689951}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703455.974712, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703454.400086}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703455.974712, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703454.400086}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:30:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703457.291678, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703455.974789}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703457.291678, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703455.974789}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703457.997399, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703456.53122}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703457.997399, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703456.53122}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703458.649169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703457.291756}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703458.649169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703457.291756}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:30:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703459.390271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703457.997924}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703460.070302, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703458.64925}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:30:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703459.390271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703457.997924}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703460.070302, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703458.64925}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703460.767982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703459.390768}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703460.767982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703459.390768}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703461.394284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703460.07038}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703462.247431, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703460.768475}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703461.394284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703460.07038}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703462.247431, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703460.768475}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703462.827865, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703461.394375}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703462.827865, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703461.394375}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:02 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703463.706409, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703462.247936}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703463.706409, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703462.247936}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703464.120684, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703462.827947}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703464.120684, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703462.827947}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703465.154172, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703463.706913}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703465.154172, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703463.706913}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703465.484161, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703464.120772}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:06 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:06 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:06 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:06 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703465.484161, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703464.120772}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:06 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:06 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:06 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:06 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:31:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703467.941658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703466.557216}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703468.337908, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703466.987954}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:07 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703467.941658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703466.557216}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703468.337908, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703466.987954}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703469.302505, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703467.941778}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703469.302505, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703467.941778}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703469.788758, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703468.338295}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703469.788758, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703468.338295}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703470.684911, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703469.302848}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703471.132527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703469.788841}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703470.684911, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703469.302848}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703471.132527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703469.788841}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703472.081367, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703470.685315}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703472.081367, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703470.685315}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703472.633095, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703471.132607}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703472.633095, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703471.132607}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703473.458808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703472.081442}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703474.083873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703472.633613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703473.458808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703472.081442}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703474.083873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703472.633613}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703474.888455, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703473.458886}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703474.888455, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703473.458886}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703475.493033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703474.084374}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703475.493033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703474.084374}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703476.26632, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703474.888534}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703476.26632, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703474.888534}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703476.902017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703475.493109}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2497.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703476.902017, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703475.493109}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2497.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703477.731263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703476.266827}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703478.207241, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703476.902534}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703477.731263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703476.266827}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703478.207241, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703476.902534}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703479.079698, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703477.731343}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:18 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703479.079698, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703477.731343}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703479.585245, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703478.207932}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703479.585245, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703478.207932}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:19 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:19 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:19 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:19 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:20 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:20 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:20 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:20 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703480.493362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703479.079775}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703480.493362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703479.079775}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703480.907941, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703479.585775}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:21 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:21 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:21 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:21 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703480.907941, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703479.585775}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:21 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:21 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:21 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:21 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703482.440982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703480.908086}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:22 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:22 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:22 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:22 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703482.440982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703480.908086}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:22 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:22 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:22 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:22 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:23 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:23 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:23 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:23 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703483.426801, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703481.947814}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703483.904912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703482.441617}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703483.426801, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703481.947814}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703483.904912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703482.441617}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703484.807187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703483.426879}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703485.327267, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703483.905533}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:24 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703484.807187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703483.426879}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703485.327267, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703483.905533}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703486.344988, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703484.807262}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:25 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703486.344988, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703484.807262}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703486.723938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703485.327346}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703486.723938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703485.327346}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:26 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:26 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:26 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:26 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:27 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:27 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:27 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:27 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703487.674145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703486.345065}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703488.077207, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703486.724443}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703487.674145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703486.345065}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703488.077207, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703486.724443}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703489.079444, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703487.674222}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:28 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703489.079444, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703487.674222}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703489.512622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703488.077768}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703489.512622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703488.077768}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:29 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:29 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:29 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:29 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:30 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:30 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:30 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:30 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703490.487815, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703489.079522}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703490.956571, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703489.512706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703490.487815, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703489.079522}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703490.956571, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703489.512706}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:31 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703491.823811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703490.488318}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703492.287704, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703490.95665}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:31 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703491.823811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703490.488318}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703492.287704, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703490.95665}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703493.363602, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703491.824322}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:32 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703493.363602, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703491.824322}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703493.637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703492.287785}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703493.637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703492.287785}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:34 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703494.743989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703493.363679}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703495.121439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703493.637079}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:34 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703494.743989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703493.363679}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703495.121439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703493.637079}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703496.075591, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703494.744495}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:35 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703496.075591, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703494.744495}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:31:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:37 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:37 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:37 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:37 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:36 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:37 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:37 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:37 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:37 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703497.532941, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703496.076118}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703498.071687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703496.600502}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703497.532941, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703496.076118}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703498.071687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703496.600502}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703499.017902, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703497.533451}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:38 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703499.017902, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703497.533451}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703499.503391, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703498.072207}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703499.503391, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703498.072207}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:39 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:39 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:39 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:39 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:40 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:40 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:40 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:40 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703500.551834, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703499.017977}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703500.89838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703499.503918}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703500.551834, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703499.017977}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703500.89838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703499.503918}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:41 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:41 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703501.884995, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703500.551911}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703502.33035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703500.89888}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703501.884995, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703500.551911}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703502.33035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703500.89888}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:42 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703503.402679, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703501.88507}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703503.652377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703502.330767}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703503.402679, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703501.88507}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703503.652377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703502.330767}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:44 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703504.778251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703503.402756}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703504.778251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703503.402756}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703505.040909, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703503.652888}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703505.040909, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703503.652888}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703506.229613, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703504.778358}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:45 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703506.229613, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703504.778358}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703507.646302, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703506.229689}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703507.646302, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703506.229689}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703507.920791, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703506.467413}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703507.920791, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703506.467413}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703509.169482, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703507.646378}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703509.331468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703507.921302}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:48 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703509.169482, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703507.646378}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703509.331468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703507.921302}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2496.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:49 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:49 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:49 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:49 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:50 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:50 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:50 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:50 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2496.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703510.563419, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703509.169558}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703510.792147, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703509.332011}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703510.563419, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703509.169558}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703510.792147, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703509.332011}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703511.882695, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703510.563498}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703512.294605, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703510.792674}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:51 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703511.882695, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703510.563498}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703512.294605, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703510.792674}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703513.279459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703511.882773}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:52 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:52 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:52 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:52 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703513.279459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703511.882773}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703513.746181, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703512.295228}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703513.746181, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703512.295228}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:53 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703514.571213, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703513.279539}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:54 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:54 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:54 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:54 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703514.571213, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703513.279539}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703515.178891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703513.746692}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703515.178891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703513.746692}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703515.853536, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703514.57129}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:55 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703515.853536, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703514.57129}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703517.173803, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703515.853613}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703517.173803, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703515.853613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703518.13993, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703516.628336}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:57 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703518.13993, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703516.628336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703518.474257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703517.173881}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:31:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703518.474257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703517.173881}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:58 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:58 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:58 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:58 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:59 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:59 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:59 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:31:59 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703519.573789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703518.140441}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703519.736764, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703518.474336}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703519.573789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703518.140441}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703519.736764, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703518.474336}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:00 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703520.926039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703519.736855}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703521.104611, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703519.574301}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703520.926039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703519.736855}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703521.104611, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703519.574301}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703522.370001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703520.926114}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:01 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703522.370001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703520.926114}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703522.497046, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703521.105316}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2498.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703522.497046, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703521.105316}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2498.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:03 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703523.758833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703522.370083}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703523.975369, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703522.497866}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703523.758833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703522.370083}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703523.975369, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703522.497866}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703524.994182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703523.758913}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703525.213651, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703523.975919}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:04 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703524.994182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703523.758913}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703525.213651, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703523.975919}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703526.201855, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703524.994259}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:05 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703526.201855, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703524.994259}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703527.451268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703526.201931}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703527.756011, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703526.437205}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703527.451268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703526.201931}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703527.756011, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703526.437205}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703528.911432, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703527.451345}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703529.229042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703527.756093}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:08 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703528.911432, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703527.451345}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703529.229042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703527.756093}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703530.222662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703528.911943}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:09 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703530.222662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703528.911943}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703530.626223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703529.229124}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:11 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:11 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703530.626223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703529.229124}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:10 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:10 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:10 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:10 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:11 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:11 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:11 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:11 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703531.565926, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703530.223177}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703532.064469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703530.626301}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703531.565926, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703530.223177}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703532.064469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703530.626301}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703533.028584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703531.566434}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703533.377524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703532.064551}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:12 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703533.028584, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703531.566434}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703533.377524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703532.064551}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703534.361978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703533.029093}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:13 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:13 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:13 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:13 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:14 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:14 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:14 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:14 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703534.361978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703533.029093}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703534.750956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703533.377606}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703534.750956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703533.377606}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:15 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703535.760641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703534.362054}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703535.760641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703534.362054}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703536.046726, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703534.75161}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703536.046726, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703534.75161}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/05/2020 18:32:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703537.220925, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703535.76072}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703537.355895, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703536.047238}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:16 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:16 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:16 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:16 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703537.220925, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703535.76072}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703537.355895, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703536.047238}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:32:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 WARNING 139697717761856] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 INFO 139697717761856] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 INFO 139697717761856] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:32:17 INFO 139697717761856] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703538.469158, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703537.221007}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703538.469158, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703537.221007}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703538.543165, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703537.356431}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588703538.543165, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588703537.356431}\n",
      "\u001b[0m\n",
      "\n",
      "CPU times: user 1.57 s, sys: 96 ms, total: 1.66 s\n",
      "Wall time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "\n",
    "pca_transformer.transform(np_azdias_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/azdias.csv.out to ./azdias.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/azdias.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvToDataFrame(filename):\n",
    "    df = pd.read_csv(filename, usecols = [0], header = None)\n",
    "    #df[0] = df[0].apply(lambda x: str(x)[15:])\n",
    "    #df[0] = pd.to_numeric(df[0], downcast='float')\n",
    "    \n",
    "    df = pd.read_csv(filename, nrows = 1, header = None)\n",
    "    \n",
    "    col_types = []\n",
    "    for column in range(1, df.shape[1]-1):\n",
    "        df[column] = pd.to_numeric(df[column], downcast='float')\n",
    "        \n",
    "    # create the dict of index names and optimized datatypes\n",
    "    dtypes = df.dtypes\n",
    "    colnames = dtypes.index\n",
    "    types = [i.name for i in dtypes.values]\n",
    "    column_types = dict(zip(colnames, types))\n",
    "\n",
    "    df = pd.read_csv(filename,dtype=column_types, header = None)\n",
    "\n",
    "    last_col_index = df.shape[1]-1\n",
    "\n",
    "    df[0] = df[0].apply(lambda x: str(x)[15:])\n",
    "    df[0] = pd.to_numeric(df[0], downcast='float')\n",
    "    df[last_col_index] = df[last_col_index].apply(lambda x: str(x)[:-2])\n",
    "    df[last_col_index] = pd.to_numeric(df[last_col_index], downcast='float')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 384.06 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_sub_pca = pd.DataFrame()\n",
    "\n",
    "azdias_sub_pca = csvToDataFrame('azdias.csv.out')\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 134)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_sub_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data visualization azdias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.4 Apply same transformations done on azdias to customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.dropna(thresh=290, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceForNan(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = to_category(customers_df, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 93.49 Mb\n"
     ]
    }
   ],
   "source": [
    "customers_df = to_category(customers_df, categorical_columns2)\n",
    "\n",
    "#azdias_df = to_int(azdias_df, categorical_columns)\n",
    "\n",
    "print('Memory used:', memory_usage(customers_df), 'Mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "0           0    9626        2        1.0     10.0                 1.0   \n",
       "2           2  143872        2        1.0      6.0                 1.0   \n",
       "3           3  143873        1        1.0      8.0                 0.0   \n",
       "4           4  143874        2        1.0     20.0                 7.0   \n",
       "5           5  143888        1        1.0     11.0                 1.0   \n",
       "\n",
       "   ANZ_HH_TITEL ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ...  \\\n",
       "0           0.0        0.0          2.0                        1.0  ...   \n",
       "2           0.0        0.0          1.0                        1.0  ...   \n",
       "3           NaN        0.0          0.0                        1.0  ...   \n",
       "4           0.0        0.0          4.0                        7.0  ...   \n",
       "5           0.0        0.0          2.0                        1.0  ...   \n",
       "\n",
       "   VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0      2.0            6.0            9.0      7.0        3  COSMETIC_AND_FOOD   \n",
       "2     11.0            6.0            9.0      2.0        3  COSMETIC_AND_FOOD   \n",
       "3      2.0            6.0            9.0      7.0        1           COSMETIC   \n",
       "4      4.0            2.0            9.0      3.0        1               FOOD   \n",
       "5      1.0            6.0            9.0      1.0        2  COSMETIC_AND_FOOD   \n",
       "\n",
       "  CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0    MULTI_BUYER               0         1                    4  \n",
       "2    MULTI_BUYER               0         2                    4  \n",
       "3    MULTI_BUYER               0         1                    4  \n",
       "4    MULTI_BUYER               0         1                    3  \n",
       "5    MULTI_BUYER               0         1                    3  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(customers_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "0           0    9626        2        1.0     10.0                 1.0   \n",
       "2           2  143872        2        1.0      6.0                 1.0   \n",
       "3           3  143873        1        1.0      8.0                 0.0   \n",
       "4           4  143874        2        1.0     20.0                 7.0   \n",
       "5           5  143888        1        1.0     11.0                 1.0   \n",
       "\n",
       "   ANZ_HH_TITEL ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ...  \\\n",
       "0           0.0        0.0          2.0                        1.0  ...   \n",
       "2           0.0        0.0          1.0                        1.0  ...   \n",
       "3           0.0        0.0          0.0                        1.0  ...   \n",
       "4           0.0        0.0          4.0                        7.0  ...   \n",
       "5           0.0        0.0          2.0                        1.0  ...   \n",
       "\n",
       "   VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0      2.0            6.0            9.0      7.0        3  COSMETIC_AND_FOOD   \n",
       "2     11.0            6.0            9.0      2.0        3  COSMETIC_AND_FOOD   \n",
       "3      2.0            6.0            9.0      7.0        1           COSMETIC   \n",
       "4      4.0            2.0            9.0      3.0        1               FOOD   \n",
       "5      1.0            6.0            9.0      1.0        2  COSMETIC_AND_FOOD   \n",
       "\n",
       "  CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0    MULTI_BUYER               0         1                    4  \n",
       "2    MULTI_BUYER               0         2                    4  \n",
       "3    MULTI_BUYER               0         1                    4  \n",
       "4    MULTI_BUYER               0         1                    3  \n",
       "5    MULTI_BUYER               0         1                    3  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(customers_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = pd.get_dummies(customers_df, columns =one_hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>CAMEO_DEU_2015_9B</th>\n",
       "      <th>CAMEO_DEU_2015_9C</th>\n",
       "      <th>CAMEO_DEU_2015_9D</th>\n",
       "      <th>CAMEO_DEU_2015_9E</th>\n",
       "      <th>CAMEO_DEU_2015_XX</th>\n",
       "      <th>AGER_TYP_-1</th>\n",
       "      <th>AGER_TYP_0</th>\n",
       "      <th>AGER_TYP_1</th>\n",
       "      <th>AGER_TYP_2</th>\n",
       "      <th>AGER_TYP_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\n",
       "0           0    9626        1.0     10.0                 1.0           0.0   \n",
       "2           2  143872        1.0      6.0                 1.0           0.0   \n",
       "3           3  143873        1.0      8.0                 0.0           0.0   \n",
       "4           4  143874        1.0     20.0                 7.0           0.0   \n",
       "5           5  143888        1.0     11.0                 1.0           0.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ...  \\\n",
       "0        0.0          2.0                        1.0        0.0  ...   \n",
       "2        0.0          1.0                        1.0        0.0  ...   \n",
       "3        0.0          0.0                        1.0        0.0  ...   \n",
       "4        0.0          4.0                        7.0        0.0  ...   \n",
       "5        0.0          2.0                        1.0        0.0  ...   \n",
       "\n",
       "  CAMEO_DEU_2015_9B CAMEO_DEU_2015_9C CAMEO_DEU_2015_9D CAMEO_DEU_2015_9E  \\\n",
       "0                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "5                 0                 0                 0                 0   \n",
       "\n",
       "  CAMEO_DEU_2015_XX AGER_TYP_-1 AGER_TYP_0 AGER_TYP_1 AGER_TYP_2 AGER_TYP_3  \n",
       "0                 0           0          0          0          1          0  \n",
       "2                 0           0          0          0          1          0  \n",
       "3                 0           0          0          1          0          0  \n",
       "4                 0           0          0          0          1          0  \n",
       "5                 0           0          0          1          0          0  \n",
       "\n",
       "[5 rows x 520 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_median_numerical(customers_df).head()\n",
    "impute_mode_categorical(customers_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df['OST_WEST_KZ'] = encodeColumnByLabel(customers_df, 'OST_WEST_KZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df['EINGEFUEGT_AM'] = timestampToInt(customers_df, 'EINGEFUEGT_AM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137087, 520)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that come from one hot encoding that do not exist in azdias and add with zeros the ones that exists in azdias but not in customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to add []\n",
      "Columns to drop ['AGER_TYP_-1' 'AGER_TYP_0' 'AGER_TYP_1' 'AGER_TYP_2' 'AGER_TYP_3'\n",
      " 'ANREDE_KZ' 'ANZ_HH_TITEL' 'ANZ_TITEL' 'CAMEO_DEU_2015_1A'\n",
      " 'CAMEO_DEU_2015_1B' 'CAMEO_DEU_2015_1C' 'CAMEO_DEU_2015_1D'\n",
      " 'CAMEO_DEU_2015_1E' 'CAMEO_DEU_2015_2A' 'CAMEO_DEU_2015_2B'\n",
      " 'CAMEO_DEU_2015_2C' 'CAMEO_DEU_2015_2D' 'CAMEO_DEU_2015_3A'\n",
      " 'CAMEO_DEU_2015_3B' 'CAMEO_DEU_2015_3C' 'CAMEO_DEU_2015_3D'\n",
      " 'CAMEO_DEU_2015_4A' 'CAMEO_DEU_2015_4B' 'CAMEO_DEU_2015_4C'\n",
      " 'CAMEO_DEU_2015_4D' 'CAMEO_DEU_2015_4E' 'CAMEO_DEU_2015_5A'\n",
      " 'CAMEO_DEU_2015_5B' 'CAMEO_DEU_2015_5C' 'CAMEO_DEU_2015_5D'\n",
      " 'CAMEO_DEU_2015_5E' 'CAMEO_DEU_2015_5F' 'CAMEO_DEU_2015_6A'\n",
      " 'CAMEO_DEU_2015_6B' 'CAMEO_DEU_2015_6C' 'CAMEO_DEU_2015_6D'\n",
      " 'CAMEO_DEU_2015_6E' 'CAMEO_DEU_2015_6F' 'CAMEO_DEU_2015_7A'\n",
      " 'CAMEO_DEU_2015_7B' 'CAMEO_DEU_2015_7C' 'CAMEO_DEU_2015_7D'\n",
      " 'CAMEO_DEU_2015_7E' 'CAMEO_DEU_2015_8A' 'CAMEO_DEU_2015_8B'\n",
      " 'CAMEO_DEU_2015_8C' 'CAMEO_DEU_2015_8D' 'CAMEO_DEU_2015_9A'\n",
      " 'CAMEO_DEU_2015_9B' 'CAMEO_DEU_2015_9C' 'CAMEO_DEU_2015_9D'\n",
      " 'CAMEO_DEU_2015_9E' 'CAMEO_DEU_2015_XX' 'CJT_GESAMTTYP_1.0'\n",
      " 'CJT_GESAMTTYP_2.0' 'CJT_GESAMTTYP_3.0' 'CJT_GESAMTTYP_4.0'\n",
      " 'CJT_GESAMTTYP_5.0' 'CJT_GESAMTTYP_6.0' 'CUSTOMER_GROUP'\n",
      " 'D19_KONSUMTYP_MAX_1' 'D19_KONSUMTYP_MAX_2' 'D19_KONSUMTYP_MAX_3'\n",
      " 'D19_KONSUMTYP_MAX_4' 'D19_KONSUMTYP_MAX_8' 'D19_KONSUMTYP_MAX_9'\n",
      " 'D19_TELKO_ANZ_12' 'D19_TELKO_ANZ_24' 'D19_TELKO_ONLINE_DATUM'\n",
      " 'D19_VERSI_ANZ_12' 'D19_VERSI_ONLINE_DATUM' 'DSL_FLAG' 'FINANZTYP_1'\n",
      " 'FINANZTYP_2' 'FINANZTYP_3' 'FINANZTYP_4' 'FINANZTYP_5' 'FINANZTYP_6'\n",
      " 'GEBAEUDETYP_1.0' 'GEBAEUDETYP_2.0' 'GEBAEUDETYP_3.0' 'GEBAEUDETYP_4.0'\n",
      " 'GEBAEUDETYP_6.0' 'GEBAEUDETYP_8.0' 'GFK_URLAUBERTYP_1.0'\n",
      " 'GFK_URLAUBERTYP_10.0' 'GFK_URLAUBERTYP_11.0' 'GFK_URLAUBERTYP_12.0'\n",
      " 'GFK_URLAUBERTYP_2.0' 'GFK_URLAUBERTYP_3.0' 'GFK_URLAUBERTYP_4.0'\n",
      " 'GFK_URLAUBERTYP_5.0' 'GFK_URLAUBERTYP_6.0' 'GFK_URLAUBERTYP_7.0'\n",
      " 'GFK_URLAUBERTYP_8.0' 'GFK_URLAUBERTYP_9.0' 'GREEN_AVANTGARDE'\n",
      " 'HEALTH_TYP_-1' 'HEALTH_TYP_1' 'HEALTH_TYP_2' 'HEALTH_TYP_3'\n",
      " 'HH_DELTA_FLAG' 'KBA05_HERSTTEMP_1.0' 'KBA05_HERSTTEMP_2.0'\n",
      " 'KBA05_HERSTTEMP_3.0' 'KBA05_HERSTTEMP_4.0' 'KBA05_HERSTTEMP_5.0'\n",
      " 'KBA05_HERSTTEMP_9.0' 'KBA05_MAXHERST_1.0' 'KBA05_MAXHERST_2.0'\n",
      " 'KBA05_MAXHERST_3.0' 'KBA05_MAXHERST_4.0' 'KBA05_MAXHERST_5.0'\n",
      " 'KBA05_MAXHERST_9.0' 'KBA05_MODTEMP_1.0' 'KBA05_MODTEMP_2.0'\n",
      " 'KBA05_MODTEMP_3.0' 'KBA05_MODTEMP_4.0' 'KBA05_MODTEMP_5.0'\n",
      " 'KBA05_MODTEMP_6.0' 'KBA13_KRSSEG_KLEIN' 'KONSUMZELLE'\n",
      " 'LP_FAMILIE_GROB_0.0' 'LP_FAMILIE_GROB_1.0' 'LP_FAMILIE_GROB_2.0'\n",
      " 'LP_FAMILIE_GROB_3.0' 'LP_FAMILIE_GROB_4.0' 'LP_FAMILIE_GROB_5.0'\n",
      " 'LP_LEBENSPHASE_FEIN_0.0' 'LP_LEBENSPHASE_FEIN_1.0'\n",
      " 'LP_LEBENSPHASE_FEIN_10.0' 'LP_LEBENSPHASE_FEIN_11.0'\n",
      " 'LP_LEBENSPHASE_FEIN_12.0' 'LP_LEBENSPHASE_FEIN_13.0'\n",
      " 'LP_LEBENSPHASE_FEIN_14.0' 'LP_LEBENSPHASE_FEIN_15.0'\n",
      " 'LP_LEBENSPHASE_FEIN_16.0' 'LP_LEBENSPHASE_FEIN_17.0'\n",
      " 'LP_LEBENSPHASE_FEIN_18.0' 'LP_LEBENSPHASE_FEIN_19.0'\n",
      " 'LP_LEBENSPHASE_FEIN_2.0' 'LP_LEBENSPHASE_FEIN_20.0'\n",
      " 'LP_LEBENSPHASE_FEIN_21.0' 'LP_LEBENSPHASE_FEIN_22.0'\n",
      " 'LP_LEBENSPHASE_FEIN_23.0' 'LP_LEBENSPHASE_FEIN_24.0'\n",
      " 'LP_LEBENSPHASE_FEIN_25.0' 'LP_LEBENSPHASE_FEIN_26.0'\n",
      " 'LP_LEBENSPHASE_FEIN_27.0' 'LP_LEBENSPHASE_FEIN_28.0'\n",
      " 'LP_LEBENSPHASE_FEIN_29.0' 'LP_LEBENSPHASE_FEIN_3.0'\n",
      " 'LP_LEBENSPHASE_FEIN_30.0' 'LP_LEBENSPHASE_FEIN_31.0'\n",
      " 'LP_LEBENSPHASE_FEIN_32.0' 'LP_LEBENSPHASE_FEIN_33.0'\n",
      " 'LP_LEBENSPHASE_FEIN_34.0' 'LP_LEBENSPHASE_FEIN_35.0'\n",
      " 'LP_LEBENSPHASE_FEIN_36.0' 'LP_LEBENSPHASE_FEIN_37.0'\n",
      " 'LP_LEBENSPHASE_FEIN_38.0' 'LP_LEBENSPHASE_FEIN_39.0'\n",
      " 'LP_LEBENSPHASE_FEIN_4.0' 'LP_LEBENSPHASE_FEIN_40.0'\n",
      " 'LP_LEBENSPHASE_FEIN_5.0' 'LP_LEBENSPHASE_FEIN_6.0'\n",
      " 'LP_LEBENSPHASE_FEIN_7.0' 'LP_LEBENSPHASE_FEIN_8.0'\n",
      " 'LP_LEBENSPHASE_FEIN_9.0' 'NATIONALITAET_KZ_0' 'NATIONALITAET_KZ_1'\n",
      " 'NATIONALITAET_KZ_2' 'NATIONALITAET_KZ_3' 'ONLINE_PURCHASE'\n",
      " 'PLZ8_BAUMAX_1.0' 'PLZ8_BAUMAX_2.0' 'PLZ8_BAUMAX_3.0' 'PLZ8_BAUMAX_4.0'\n",
      " 'PLZ8_BAUMAX_5.0' 'PRODUCT_GROUP' 'RETOURTYP_BK_S_1.0'\n",
      " 'RETOURTYP_BK_S_2.0' 'RETOURTYP_BK_S_3.0' 'RETOURTYP_BK_S_4.0'\n",
      " 'RETOURTYP_BK_S_5.0' 'SHOPPER_TYP_-1' 'SHOPPER_TYP_0' 'SHOPPER_TYP_1'\n",
      " 'SHOPPER_TYP_2' 'SHOPPER_TYP_3' 'SOHO_KZ' 'TITEL_KZ' 'UNGLEICHENN_FLAG'\n",
      " 'VERS_TYP_-1' 'VERS_TYP_1' 'VERS_TYP_2' 'WOHNLAGE_0.0' 'WOHNLAGE_1.0'\n",
      " 'WOHNLAGE_2.0' 'WOHNLAGE_3.0' 'WOHNLAGE_4.0' 'WOHNLAGE_5.0'\n",
      " 'WOHNLAGE_7.0' 'WOHNLAGE_8.0']\n"
     ]
    }
   ],
   "source": [
    "#Drop and add columns\n",
    "\n",
    "addColumnList = np.setdiff1d(azdias_df.columns,customers_df.columns)\n",
    "print(\"Columns to add\", addColumnList)\n",
    "\n",
    "dropColumnList = np.setdiff1d(customers_df.columns, azdias_df.columns)\n",
    "print(\"Columns to drop\", dropColumnList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.drop(list(dropColumnList), axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_customers = customers_df.values\n",
    "np_customers = scaler.transform(np_customers)\n",
    "\n",
    "customers_df = pd.DataFrame(data=np_customers,\n",
    "          index=customers_df.index,\n",
    "          columns=customers_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA transformation on customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_file = 'customers.csv'\n",
    "\n",
    "customers_dtypes = customers_df.select_dtypes(object)\n",
    "customers_df[u.columns] = customers_dtypes.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n",
    "customers_df.to_csv(customers_file,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "customers_location = session.upload_data(os.path.join(customers_file), key_prefix=prefix)\n",
    "\n",
    "#os.remove(customers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] nvidia-smi took: 0.0251760482788 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loading entry points\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:45:50 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:45:50 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:45:50 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:45:50 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loading model...\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-05 18:45:50 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] loading model...\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:45:50 INFO 140710047012672] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704366.443692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704350.87445}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704366.443692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704350.87445}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:46:10 ERROR 140710047012672] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:46:10 ERROR 140710047012672] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:06.481:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.764:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: ClientError: 400\u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.764:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: \u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.765:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: Message:\u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.765:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: unable to evaluate payload provided\u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.772:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: ClientError: 400\u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.772:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: \u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.772:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: Message:\u001b[0m\n",
      "\u001b[32m2020-05-05T18:46:10.772:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: unable to evaluate payload provided\u001b[0m\n",
      "\u001b[34mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[35mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.747362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704350.837281}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.747362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704350.837281}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.747637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704370.747507}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.747637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704370.747507}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 18:46:10 ERROR 140710047012672] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[34mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[35m[05/05/2020 18:46:10 ERROR 140710047012672] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[35mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.766756, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704366.443833}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.766756, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704366.443833}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.767249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704370.767096}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588704370.767249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588704370.767096}\n",
      "\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Transform job pca-2020-05-05-18-42-59-453: Failed. Reason: ClientError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Placeholder docstring\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_last_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_transform_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TransformJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2636\u001b[0m                 ),\n\u001b[1;32m   2637\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2638\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m             )\n\u001b[1;32m   2640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Transform job pca-2020-05-05-18-42-59-453: Failed. Reason: ClientError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "pca_transformer.transform(customers_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the transformed data to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/customers.csv.out to ./customers.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/customers.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 70.07 Mb\n"
     ]
    }
   ],
   "source": [
    "customers_sub_pca = csvToDataFrame('customers.csv.out')\n",
    "\n",
    "print('Memory used:', memory_usage(customers_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137087, 134)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_sub_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data visualization PCA Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a KMeans estimator\n",
    "k_estimator = sagemaker.KMeans(role,\n",
    "                               train_instance_count = 1,\n",
    "                               train_instance_type = 'ml.m5.large',\n",
    "                               k = 8\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_formatted_azdias_data = pca.record_set(azdias_sub_pca.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-05 19:05:49 Starting - Starting the training job...\n",
      "2020-05-05 19:05:50 Starting - Launching requested ML instances......\n",
      "2020-05-05 19:07:16 Starting - Preparing the instances for training......\n",
      "2020-05-05 19:07:50 Downloading - Downloading input data...\n",
      "2020-05-05 19:08:44 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'8', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'8', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 WARNING 140580794894144] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] nvidia-smi took: 0.0251548290253 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'8', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588705727.147204, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588705727.147172}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-05 19:08:47.157] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 73, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:47 INFO 140580794894144] Iter 10: Short term msd 13.410755. Long term msd 14.061287\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:48 INFO 140580794894144] Iter 20: Short term msd 12.843184. Long term msd 13.114590\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:48 INFO 140580794894144] Iter 30: Short term msd 12.737465. Long term msd 12.853688\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:48 INFO 140580794894144] Iter 40: Short term msd 12.753810. Long term msd 12.786136\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:48 INFO 140580794894144] Iter 50: Short term msd 12.698277. Long term msd 12.729308\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:49 INFO 140580794894144] Iter 60: Short term msd 12.763512. Long term msd 12.756443\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:49 INFO 140580794894144] Iter 70: Short term msd 12.786462. Long term msd 12.776859\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:49 INFO 140580794894144] Iter 80: Short term msd 12.756552. Long term msd 12.770308\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:49 INFO 140580794894144] Iter 90: Short term msd 12.785950. Long term msd 12.776564\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:50 INFO 140580794894144] Iter 100: Short term msd 12.791675. Long term msd 12.786850\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:50 INFO 140580794894144] Iter 110: Short term msd 12.779932. Long term msd 12.788828\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:50 INFO 140580794894144] Iter 120: Short term msd 12.829842. Long term msd 12.819629\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] Iter 130: Short term msd 12.908234. Long term msd 12.879381\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] Iter 140: Short term msd 12.906109. Long term msd 12.897508\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] Iter 150: Short term msd 12.912077. Long term msd 12.906201\u001b[0m\n",
      "\u001b[34m[2020-05-05 19:08:51.466] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4308, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588705731.466984, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588705727.157544}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] #throughput_metric: host=algo-1, train throughput=174339.761875 records/second\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 WARNING 140580794894144] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] shrinking 80 centers into 8\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #0. Current mean square distance 2.844337\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #1. Current mean square distance 2.833290\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #2. Current mean square distance 3.229069\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #3. Current mean square distance 2.763155\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #4. Current mean square distance 2.862755\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #5. Current mean square distance 2.726199\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #6. Current mean square distance 2.828335\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #7. Current mean square distance 3.333085\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #8. Current mean square distance 2.805319\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] local kmeans attempt #9. Current mean square distance 2.865757\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] #quality_metric: host=algo-1, train msd <loss>=2.72619891167\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] compute all data-center distances: point norm took: 26.5957%, (1.147757 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] predict compute msd took: 24.1911%, (1.043983 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] compute all data-center distances: inner product took: 17.2340%, (0.743747 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] gradient: cluster size  took: 14.6469%, (0.632095 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] gradient: cluster center took: 7.9617%, (0.343595 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] batch data loading with context took: 3.7211%, (0.160588 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] update state and report convergance took: 1.6287%, (0.070286 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] collect from kv store took: 1.2880%, (0.055583 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] compute all data-center distances: center norm took: 1.2136%, (0.052376 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] gradient: one_hot took: 0.7889%, (0.034047 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] splitting centers key-value pair took: 0.6519%, (0.028135 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] predict minus dist took: 0.0717%, (0.003093 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] update set-up time took: 0.0066%, (0.000286 secs)\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] TOTAL took: 4.31557059288\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 230.5459976196289, \"sum\": 230.5459976196289, \"min\": 230.5459976196289}, \"initialize.time\": {\"count\": 1, \"max\": 47.017812728881836, \"sum\": 47.017812728881836, \"min\": 47.017812728881836}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.15020370483398438, \"sum\": 0.15020370483398438, \"min\": 0.15020370483398438}, \"update.time\": {\"count\": 1, \"max\": 4309.207916259766, \"sum\": 4309.207916259766, \"min\": 4309.207916259766}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.8358955383300781, \"sum\": 0.8358955383300781, \"min\": 0.8358955383300781}, \"_shrink.time\": {\"count\": 1, \"max\": 229.03203964233398, \"sum\": 229.03203964233398, \"min\": 229.03203964233398}}, \"EndTime\": 1588705731.698967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588705727.083407}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/05/2020 19:08:51 INFO 140580794894144] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4694.2760944366455, \"sum\": 4694.2760944366455, \"min\": 4694.2760944366455}, \"setuptime\": {\"count\": 1, \"max\": 12.197017669677734, \"sum\": 12.197017669677734, \"min\": 12.197017669677734}}, \"EndTime\": 1588705731.716489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588705731.699102}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-05 19:09:02 Uploading - Uploading generated training model\n",
      "2020-05-05 19:09:02 Completed - Training job completed\n",
      "Training seconds: 72\n",
      "Billable seconds: 72\n",
      "CPU times: user 423 ms, sys: 27.1 ms, total: 450 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train kmeans\n",
    "k_estimator.fit(k_formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO choose k groups using https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
