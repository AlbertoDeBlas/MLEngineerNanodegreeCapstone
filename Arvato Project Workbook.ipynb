{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "import mxnet as mx\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3 client to get S3 data\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name='sagemaker-eu-west-1-848439228145'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list withe files in the bucket and print the file names to be sure that we will be retrieving from the correct location and obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Capstone/Udacity_AZDIAS_052018.csv', 'Capstone/Udacity_CUSTOMERS_052018.csv', 'Capstone/Udacity_MAILOUT_052018_TEST.csv', 'Capstone/Udacity_MAILOUT_052018_TRAIN.csv', 'arvato/azdias.csv', 'arvato/customers.csv', 'arvato/transform/pca/transform/test/azdias.csv.out', 'arvato/transform/pca/transform/test/customers.csv.out']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "# get a list of objects in the bucket\n",
    "obj_list=s3_client.list_objects(Bucket=bucket_name)\n",
    "\n",
    "def filter_csv(string):\n",
    "    return re.search(r'.csv', string)\n",
    "\n",
    "\n",
    "files=[]\n",
    "for contents in obj_list['Contents']:\n",
    "    files.append(contents['Key'])\n",
    "    \n",
    "filtered_list = list(filter(filter_csv, files))\n",
    "    \n",
    "    \n",
    "# print csv objects in in S3 bucket  \n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_from_s3(s3_client, bucket, name):\n",
    "    data_object = s3_client.get_object(Bucket=bucket, Key=name)\n",
    "    data_body = data_object[\"Body\"].read()\n",
    "    data_stream = io.BytesIO(data_body)\n",
    "    \n",
    "    return pd.read_csv(data_stream, header=0, delimiter=\",\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9628</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0    9626         2         1.0      10.0          NaN   \n",
       "1           1    9628        -1         9.0      11.0          NaN   \n",
       "2           2  143872        -1         1.0       6.0          NaN   \n",
       "3           3  143873         1         1.0       8.0          NaN   \n",
       "4           4  143874        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VK_ZG11  \\\n",
       "0          NaN          NaN          NaN                  10.0  ...      2.0   \n",
       "1          NaN          NaN          NaN                   NaN  ...      3.0   \n",
       "2          NaN          NaN          NaN                   0.0  ...     11.0   \n",
       "3          NaN          NaN          NaN                   8.0  ...      2.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...      4.0   \n",
       "\n",
       "   W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0             6.0             9.0       7.0         3  COSMETIC_AND_FOOD   \n",
       "1             0.0             9.0       NaN         3               FOOD   \n",
       "2             6.0             9.0       2.0         3  COSMETIC_AND_FOOD   \n",
       "3             NaN             9.0       7.0         1           COSMETIC   \n",
       "4             2.0             9.0       3.0         1               FOOD   \n",
       "\n",
       "   CUSTOMER_GROUP  ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0     MULTI_BUYER                0         1                    4  \n",
       "1    SINGLE_BUYER                0         1                    4  \n",
       "2     MULTI_BUYER                0         2                    4  \n",
       "3     MULTI_BUYER                0         1                    4  \n",
       "4     MULTI_BUYER                0         1                    3  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df = None\n",
    "customers_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[1])\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0  910215        -1         NaN       NaN          NaN   \n",
       "1           1  910220        -1         9.0       0.0          NaN   \n",
       "2           2  910225        -1         9.0      17.0          NaN   \n",
       "3           3  910226         2         1.0      13.0          NaN   \n",
       "4           4  910241        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VHN  \\\n",
       "0          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "1          NaN          NaN          NaN                  21.0  ...  4.0   \n",
       "2          NaN          NaN          NaN                  17.0  ...  2.0   \n",
       "3          NaN          NaN          NaN                  13.0  ...  0.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...  2.0   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1       8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2       9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3       7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4       3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3         1                    2  \n",
       "1         5         2                    1  \n",
       "2         5         2                    3  \n",
       "3         3         2                    4  \n",
       "4         4         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df = None\n",
    "azdias_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[0])\n",
    "azdias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>11766.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>139810.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>137910.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>141725.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>1.747525</td>\n",
       "      <td>11.352009</td>\n",
       "      <td>12.337243</td>\n",
       "      <td>13.672353</td>\n",
       "      <td>14.647059</td>\n",
       "      <td>15.377119</td>\n",
       "      <td>10.331579</td>\n",
       "      <td>...</td>\n",
       "      <td>4.374417</td>\n",
       "      <td>4.564769</td>\n",
       "      <td>3.168868</td>\n",
       "      <td>4.152716</td>\n",
       "      <td>8.646371</td>\n",
       "      <td>3.723133</td>\n",
       "      <td>2.576806</td>\n",
       "      <td>0.090247</td>\n",
       "      <td>1.376432</td>\n",
       "      <td>3.060907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55325.311233</td>\n",
       "      <td>55325.311233</td>\n",
       "      <td>1.391672</td>\n",
       "      <td>1.966334</td>\n",
       "      <td>6.275026</td>\n",
       "      <td>4.006050</td>\n",
       "      <td>3.243335</td>\n",
       "      <td>2.753787</td>\n",
       "      <td>2.307653</td>\n",
       "      <td>4.134828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.924355</td>\n",
       "      <td>2.887035</td>\n",
       "      <td>2.233516</td>\n",
       "      <td>1.974375</td>\n",
       "      <td>1.154001</td>\n",
       "      <td>2.095540</td>\n",
       "      <td>1.168486</td>\n",
       "      <td>0.286536</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>1.086254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47912.750000</td>\n",
       "      <td>47913.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>143738.250000</td>\n",
       "      <td>143739.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191651.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0            LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  191652.000000  191652.000000  191652.000000  145056.000000   \n",
       "mean    95825.500000   95826.500000       0.344359       1.747525   \n",
       "std     55325.311233   55325.311233       1.391672       1.966334   \n",
       "min         0.000000       1.000000      -1.000000       1.000000   \n",
       "25%     47912.750000   47913.750000      -1.000000       1.000000   \n",
       "50%     95825.500000   95826.500000       0.000000       1.000000   \n",
       "75%    143738.250000  143739.250000       2.000000       1.000000   \n",
       "max    191651.000000  191652.000000       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  145056.000000  11766.000000  5100.000000  1275.000000   236.000000   \n",
       "mean       11.352009     12.337243    13.672353    14.647059    15.377119   \n",
       "std         6.275026      4.006050     3.243335     2.753787     2.307653   \n",
       "min         0.000000      2.000000     2.000000     5.000000     8.000000   \n",
       "25%         8.000000      9.000000    11.000000    13.000000    14.000000   \n",
       "50%        11.000000     13.000000    14.000000    15.000000    16.000000   \n",
       "75%        16.000000     16.000000    16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000    18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...       VK_DHT4A     VK_DISTANZ        VK_ZG11  \\\n",
       "count         139810.000000  ...  143781.000000  143781.000000  143781.000000   \n",
       "mean              10.331579  ...       4.374417       4.564769       3.168868   \n",
       "std                4.134828  ...       2.924355       2.887035       2.233516   \n",
       "min                0.000000  ...       1.000000       1.000000       1.000000   \n",
       "25%                9.000000  ...       2.000000       2.000000       1.000000   \n",
       "50%               10.000000  ...       4.000000       4.000000       3.000000   \n",
       "75%               13.000000  ...       7.000000       7.000000       4.000000   \n",
       "max               25.000000  ...      11.000000      13.000000      11.000000   \n",
       "\n",
       "       W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE       ZABEOTYP  \\\n",
       "count   137910.000000   145056.000000  141725.000000  191652.000000   \n",
       "mean         4.152716        8.646371       3.723133       2.576806   \n",
       "std          1.974375        1.154001       2.095540       1.168486   \n",
       "min          0.000000        1.000000       0.000000       1.000000   \n",
       "25%          2.000000        9.000000       2.000000       1.000000   \n",
       "50%          5.000000        9.000000       3.000000       3.000000   \n",
       "75%          6.000000        9.000000       5.000000       3.000000   \n",
       "max          6.000000        9.000000       8.000000       6.000000   \n",
       "\n",
       "       ONLINE_PURCHASE      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count    191652.000000  191652.000000         191652.000000  \n",
       "mean          0.090247       1.376432              3.060907  \n",
       "std           0.286536       0.484492              1.086254  \n",
       "min           0.000000       1.000000              1.000000  \n",
       "25%           0.000000       1.000000              3.000000  \n",
       "50%           0.000000       1.000000              3.000000  \n",
       "75%           0.000000       2.000000              4.000000  \n",
       "max           1.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(customers_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891221.000000</td>\n",
       "      <td>8.912210e+05</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>81058.000000</td>\n",
       "      <td>29499.000000</td>\n",
       "      <td>6170.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>628274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>770025.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>783619.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>798073.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-0.358435</td>\n",
       "      <td>4.421928</td>\n",
       "      <td>10.864126</td>\n",
       "      <td>11.745392</td>\n",
       "      <td>13.402658</td>\n",
       "      <td>14.476013</td>\n",
       "      <td>15.089627</td>\n",
       "      <td>13.700717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417322</td>\n",
       "      <td>6.001214</td>\n",
       "      <td>7.532130</td>\n",
       "      <td>5.945972</td>\n",
       "      <td>3.933406</td>\n",
       "      <td>7.908791</td>\n",
       "      <td>4.052836</td>\n",
       "      <td>3.362438</td>\n",
       "      <td>1.522098</td>\n",
       "      <td>2.777398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257273.486465</td>\n",
       "      <td>2.572735e+05</td>\n",
       "      <td>1.198724</td>\n",
       "      <td>3.638805</td>\n",
       "      <td>7.639683</td>\n",
       "      <td>4.097660</td>\n",
       "      <td>3.243300</td>\n",
       "      <td>2.712427</td>\n",
       "      <td>2.452932</td>\n",
       "      <td>5.079849</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166572</td>\n",
       "      <td>2.856091</td>\n",
       "      <td>3.247789</td>\n",
       "      <td>2.771464</td>\n",
       "      <td>1.964701</td>\n",
       "      <td>1.923137</td>\n",
       "      <td>1.949539</td>\n",
       "      <td>1.352704</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>1.068775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916530e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222805.000000</td>\n",
       "      <td>4.144580e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668415.000000</td>\n",
       "      <td>8.600680e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891220.000000</td>\n",
       "      <td>1.082873e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0           LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  891221.000000  8.912210e+05  891221.000000  817722.000000   \n",
       "mean   445610.000000  6.372630e+05      -0.358435       4.421928   \n",
       "std    257273.486465  2.572735e+05       1.198724       3.638805   \n",
       "min         0.000000  1.916530e+05      -1.000000       1.000000   \n",
       "25%    222805.000000  4.144580e+05      -1.000000       1.000000   \n",
       "50%    445610.000000  6.372630e+05      -1.000000       3.000000   \n",
       "75%    668415.000000  8.600680e+05      -1.000000       9.000000   \n",
       "max    891220.000000  1.082873e+06       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  817722.000000  81058.000000  29499.000000  6170.000000  1205.000000   \n",
       "mean       10.864126     11.745392     13.402658    14.476013    15.089627   \n",
       "std         7.639683      4.097660      3.243300     2.712427     2.452932   \n",
       "min         0.000000      2.000000      2.000000     4.000000     7.000000   \n",
       "25%         0.000000      8.000000     11.000000    13.000000    14.000000   \n",
       "50%        13.000000     12.000000     14.000000    15.000000    15.000000   \n",
       "75%        17.000000     15.000000     16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000     18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...            VHN       VK_DHT4A     VK_DISTANZ  \\\n",
       "count         628274.000000  ...  770025.000000  815304.000000  815304.000000   \n",
       "mean              13.700717  ...       2.417322       6.001214       7.532130   \n",
       "std                5.079849  ...       1.166572       2.856091       3.247789   \n",
       "min                0.000000  ...       0.000000       1.000000       1.000000   \n",
       "25%               11.000000  ...       2.000000       3.000000       5.000000   \n",
       "50%               14.000000  ...       2.000000       6.000000       8.000000   \n",
       "75%               17.000000  ...       3.000000       9.000000      10.000000   \n",
       "max               25.000000  ...       4.000000      11.000000      13.000000   \n",
       "\n",
       "             VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE  \\\n",
       "count  815304.000000   783619.000000   817722.000000  798073.000000   \n",
       "mean        5.945972        3.933406        7.908791       4.052836   \n",
       "std         2.771464        1.964701        1.923137       1.949539   \n",
       "min         1.000000        0.000000        1.000000       0.000000   \n",
       "25%         4.000000        2.000000        8.000000       3.000000   \n",
       "50%         6.000000        4.000000        9.000000       3.000000   \n",
       "75%         8.000000        6.000000        9.000000       5.000000   \n",
       "max        11.000000        6.000000        9.000000       8.000000   \n",
       "\n",
       "            ZABEOTYP      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count  891221.000000  891221.000000         891221.000000  \n",
       "mean        3.362438       1.522098              2.777398  \n",
       "std         1.352704       0.499512              1.068775  \n",
       "min         1.000000       1.000000              1.000000  \n",
       "25%         3.000000       1.000000              2.000000  \n",
       "50%         3.000000       2.000000              3.000000  \n",
       "75%         4.000000       2.000000              4.000000  \n",
       "max         6.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 361 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(azdias_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTER_KIND4                    99.864792\n",
       "ALTER_KIND3                    99.307691\n",
       "ALTER_KIND2                    96.690047\n",
       "ALTER_KIND1                    90.904837\n",
       "EXTSEL992                      73.399639\n",
       "KK_KUNDENTYP                   65.596749\n",
       "ALTERSKATEGORIE_FEIN           29.504130\n",
       "D19_VERSI_ONLINE_QUOTE_12      28.849522\n",
       "D19_LETZTER_KAUF_BRANCHE       28.849522\n",
       "D19_BANKEN_ONLINE_QUOTE_12     28.849522\n",
       "D19_TELKO_ONLINE_QUOTE_12      28.849522\n",
       "D19_VERSAND_ONLINE_QUOTE_12    28.849522\n",
       "D19_KONSUMTYP                  28.849522\n",
       "D19_SOZIALES                   28.849522\n",
       "D19_GESAMT_ONLINE_QUOTE_12     28.849522\n",
       "D19_LOTTO                      28.849522\n",
       "KBA05_SEG8                     14.959701\n",
       "KBA05_SEG7                     14.959701\n",
       "KBA05_KW2                      14.959701\n",
       "KBA05_KW3                      14.959701\n",
       "KBA05_MAXAH                    14.959701\n",
       "KBA05_MAXBJ                    14.959701\n",
       "KBA05_MAXHERST                 14.959701\n",
       "KBA05_MAXSEG                   14.959701\n",
       "KBA05_MAXVORB                  14.959701\n",
       "KBA05_MOD1                     14.959701\n",
       "KBA05_MOD2                     14.959701\n",
       "KBA05_MOD3                     14.959701\n",
       "KBA05_MOD4                     14.959701\n",
       "KBA05_MOD8                     14.959701\n",
       "                                 ...    \n",
       "D19_RATGEBER                    0.000000\n",
       "FINANZ_ANLEGER                  0.000000\n",
       "D19_REISEN                      0.000000\n",
       "D19_SAMMELARTIKEL               0.000000\n",
       "D19_SCHUHE                      0.000000\n",
       "D19_SONSTIGE                    0.000000\n",
       "D19_TECHNIK                     0.000000\n",
       "D19_TELKO_ANZ_12                0.000000\n",
       "D19_TELKO_ANZ_24                0.000000\n",
       "D19_TELKO_DATUM                 0.000000\n",
       "D19_TELKO_MOBILE                0.000000\n",
       "D19_TELKO_OFFLINE_DATUM         0.000000\n",
       "D19_TELKO_ONLINE_DATUM          0.000000\n",
       "D19_TELKO_REST                  0.000000\n",
       "D19_TIERARTIKEL                 0.000000\n",
       "D19_VERSAND_ANZ_12              0.000000\n",
       "D19_VERSAND_ANZ_24              0.000000\n",
       "D19_VERSAND_DATUM               0.000000\n",
       "D19_VERSAND_OFFLINE_DATUM       0.000000\n",
       "D19_VERSAND_ONLINE_DATUM        0.000000\n",
       "D19_VERSAND_REST                0.000000\n",
       "D19_VERSI_ANZ_12                0.000000\n",
       "D19_VERSI_ANZ_24                0.000000\n",
       "D19_VERSI_DATUM                 0.000000\n",
       "D19_VERSI_OFFLINE_DATUM         0.000000\n",
       "D19_VERSI_ONLINE_DATUM          0.000000\n",
       "D19_VERSICHERUNGEN              0.000000\n",
       "D19_VOLLSORTIMENT               0.000000\n",
       "D19_WEIN_FEINKOST               0.000000\n",
       "Unnamed: 0                      0.000000\n",
       "Length: 367, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = azdias_df.shape[0]\n",
    "missing_values_azdias = azdias_df.isnull().sum().sort_values(ascending = False).divide(other = (rows/100))\n",
    "\n",
    "display(missing_values_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have more than 28% of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 351)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a dict with the names of the columns and then drop this columns from dataframe\n",
    "drop_columns = missing_values_azdias[missing_values_azdias > 28]\n",
    "\n",
    "azdias_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)\n",
    "\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have less than 0.5 variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_description = azdias_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropLowVarianceCols(df):\n",
    "    df_description = df.describe()\n",
    "    std_df = df_description.loc[['std']].values.reshape(df_description.shape[1],)\n",
    "    std_serie = pd.Series(std_df, index =df_description.columns) \n",
    "\n",
    "    drop_lowdispersion_cols = std_serie[std_serie < 0.5]\n",
    "\n",
    "    return df.drop(columns = list(drop_lowdispersion_cols.index), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropLowVarianceCols(azdias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 335)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage(df):\n",
    "    return(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2))\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'LNR', 'AGER_TYP', 'AKT_DAT_KL', 'ALTER_HH', 'ANZ_HAUSHALTE_AKTIV', 'ANZ_KINDER', 'ANZ_PERSONEN', 'ANZ_STATISTISCHE_HAUSHALTE', 'ARBEIT', 'BALLRAUM', 'CAMEO_DEU_2015', 'CAMEO_DEUG_2015', 'CAMEO_INTL_2015', 'CJT_GESAMTTYP', 'CJT_KATALOGNUTZER', 'CJT_TYP_1', 'CJT_TYP_2', 'CJT_TYP_3', 'CJT_TYP_4', 'CJT_TYP_5', 'CJT_TYP_6', 'D19_BANKEN_ANZ_12', 'D19_BANKEN_ANZ_24', 'D19_BANKEN_DATUM', 'D19_BANKEN_DIREKT', 'D19_BANKEN_GROSS', 'D19_BANKEN_LOKAL', 'D19_BANKEN_OFFLINE_DATUM', 'D19_BANKEN_ONLINE_DATUM', 'D19_BANKEN_REST', 'D19_BEKLEIDUNG_GEH', 'D19_BEKLEIDUNG_REST', 'D19_BILDUNG', 'D19_BIO_OEKO', 'D19_BUCH_CD', 'D19_DIGIT_SERV', 'D19_DROGERIEARTIKEL', 'D19_ENERGIE', 'D19_FREIZEIT', 'D19_GARTEN', 'D19_GESAMT_ANZ_12', 'D19_GESAMT_ANZ_24', 'D19_GESAMT_DATUM', 'D19_GESAMT_OFFLINE_DATUM', 'D19_GESAMT_ONLINE_DATUM', 'D19_HANDWERK', 'D19_HAUS_DEKO', 'D19_KINDERARTIKEL', 'D19_KONSUMTYP_MAX', 'D19_KOSMETIK', 'D19_LEBENSMITTEL', 'D19_NAHRUNGSERGAENZUNG', 'D19_RATGEBER', 'D19_REISEN', 'D19_SAMMELARTIKEL', 'D19_SCHUHE', 'D19_SONSTIGE', 'D19_TECHNIK', 'D19_TELKO_DATUM', 'D19_TELKO_MOBILE', 'D19_TELKO_OFFLINE_DATUM', 'D19_TELKO_REST', 'D19_TIERARTIKEL', 'D19_VERSAND_ANZ_12', 'D19_VERSAND_ANZ_24', 'D19_VERSAND_DATUM', 'D19_VERSAND_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM', 'D19_VERSAND_REST', 'D19_VERSI_ANZ_24', 'D19_VERSI_DATUM', 'D19_VERSI_OFFLINE_DATUM', 'D19_VERSICHERUNGEN', 'D19_VOLLSORTIMENT', 'D19_WEIN_FEINKOST', 'EINGEFUEGT_AM', 'EINGEZOGENAM_HH_JAHR', 'EWDICHTE', 'FINANZ_ANLEGER', 'FINANZ_HAUSBAUER', 'FINANZ_MINIMALIST', 'FINANZ_SPARER', 'FINANZ_UNAUFFAELLIGER', 'FINANZ_VORSORGER', 'FINANZTYP', 'FIRMENDICHTE', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GEBURTSJAHR', 'GEMEINDETYP', 'GFK_URLAUBERTYP', 'HEALTH_TYP', 'HH_EINKOMMEN_SCORE', 'INNENSTADT', 'KBA05_ALTER1', 'KBA05_ALTER2', 'KBA05_ALTER3', 'KBA05_ALTER4', 'KBA05_ANHANG', 'KBA05_ANTG1', 'KBA05_ANTG2', 'KBA05_ANTG3', 'KBA05_ANTG4', 'KBA05_AUTOQUOT', 'KBA05_BAUMAX', 'KBA05_CCM1', 'KBA05_CCM2', 'KBA05_CCM3', 'KBA05_CCM4', 'KBA05_DIESEL', 'KBA05_FRAU', 'KBA05_GBZ', 'KBA05_HERST1', 'KBA05_HERST2', 'KBA05_HERST3', 'KBA05_HERST4', 'KBA05_HERST5', 'KBA05_HERSTTEMP', 'KBA05_KRSAQUOT', 'KBA05_KRSHERST1', 'KBA05_KRSHERST2', 'KBA05_KRSHERST3', 'KBA05_KRSKLEIN', 'KBA05_KRSOBER', 'KBA05_KRSVAN', 'KBA05_KRSZUL', 'KBA05_KW1', 'KBA05_KW2', 'KBA05_KW3', 'KBA05_MAXAH', 'KBA05_MAXBJ', 'KBA05_MAXHERST', 'KBA05_MAXSEG', 'KBA05_MAXVORB', 'KBA05_MOD1', 'KBA05_MOD2', 'KBA05_MOD3', 'KBA05_MOD4', 'KBA05_MOD8', 'KBA05_MODTEMP', 'KBA05_MOTOR', 'KBA05_MOTRAD', 'KBA05_SEG1', 'KBA05_SEG10', 'KBA05_SEG2', 'KBA05_SEG3', 'KBA05_SEG4', 'KBA05_SEG5', 'KBA05_SEG6', 'KBA05_SEG7', 'KBA05_SEG8', 'KBA05_SEG9', 'KBA05_VORB0', 'KBA05_VORB1', 'KBA05_VORB2', 'KBA05_ZUL1', 'KBA05_ZUL2', 'KBA05_ZUL3', 'KBA05_ZUL4', 'KBA13_ALTERHALTER_30', 'KBA13_ALTERHALTER_45', 'KBA13_ALTERHALTER_60', 'KBA13_ALTERHALTER_61', 'KBA13_ANTG1', 'KBA13_ANTG2', 'KBA13_ANTG3', 'KBA13_ANTG4', 'KBA13_ANZAHL_PKW', 'KBA13_AUDI', 'KBA13_AUTOQUOTE', 'KBA13_BAUMAX', 'KBA13_BJ_1999', 'KBA13_BJ_2000', 'KBA13_BJ_2004', 'KBA13_BJ_2006', 'KBA13_BJ_2008', 'KBA13_BJ_2009', 'KBA13_BMW', 'KBA13_CCM_0_1400', 'KBA13_CCM_1000', 'KBA13_CCM_1200', 'KBA13_CCM_1400', 'KBA13_CCM_1401_2500', 'KBA13_CCM_1500', 'KBA13_CCM_1600', 'KBA13_CCM_1800', 'KBA13_CCM_2000', 'KBA13_CCM_2500', 'KBA13_CCM_2501', 'KBA13_CCM_3000', 'KBA13_CCM_3001', 'KBA13_FAB_ASIEN', 'KBA13_FAB_SONSTIGE', 'KBA13_FIAT', 'KBA13_FORD', 'KBA13_GBZ', 'KBA13_HALTER_20', 'KBA13_HALTER_25', 'KBA13_HALTER_30', 'KBA13_HALTER_35', 'KBA13_HALTER_40', 'KBA13_HALTER_45', 'KBA13_HALTER_50', 'KBA13_HALTER_55', 'KBA13_HALTER_60', 'KBA13_HALTER_65', 'KBA13_HALTER_66', 'KBA13_HERST_ASIEN', 'KBA13_HERST_AUDI_VW', 'KBA13_HERST_BMW_BENZ', 'KBA13_HERST_EUROPA', 'KBA13_HERST_FORD_OPEL', 'KBA13_HERST_SONST', 'KBA13_HHZ', 'KBA13_KMH_0_140', 'KBA13_KMH_110', 'KBA13_KMH_140', 'KBA13_KMH_140_210', 'KBA13_KMH_180', 'KBA13_KMH_210', 'KBA13_KMH_211', 'KBA13_KMH_250', 'KBA13_KMH_251', 'KBA13_KRSAQUOT', 'KBA13_KRSHERST_AUDI_VW', 'KBA13_KRSHERST_BMW_BENZ', 'KBA13_KRSHERST_FORD_OPEL', 'KBA13_KRSSEG_OBER', 'KBA13_KRSSEG_VAN', 'KBA13_KRSZUL_NEU', 'KBA13_KW_0_60', 'KBA13_KW_110', 'KBA13_KW_120', 'KBA13_KW_121', 'KBA13_KW_30', 'KBA13_KW_40', 'KBA13_KW_50', 'KBA13_KW_60', 'KBA13_KW_61_120', 'KBA13_KW_70', 'KBA13_KW_80', 'KBA13_KW_90', 'KBA13_MAZDA', 'KBA13_MERCEDES', 'KBA13_MOTOR', 'KBA13_NISSAN', 'KBA13_OPEL', 'KBA13_PEUGEOT', 'KBA13_RENAULT', 'KBA13_SEG_GELAENDEWAGEN', 'KBA13_SEG_GROSSRAUMVANS', 'KBA13_SEG_KLEINST', 'KBA13_SEG_KLEINWAGEN', 'KBA13_SEG_KOMPAKTKLASSE', 'KBA13_SEG_MINIVANS', 'KBA13_SEG_MINIWAGEN', 'KBA13_SEG_MITTELKLASSE', 'KBA13_SEG_OBEREMITTELKLASSE', 'KBA13_SEG_OBERKLASSE', 'KBA13_SEG_SONSTIGE', 'KBA13_SEG_SPORTWAGEN', 'KBA13_SEG_UTILITIES', 'KBA13_SEG_VAN', 'KBA13_SEG_WOHNMOBILE', 'KBA13_SITZE_4', 'KBA13_SITZE_5', 'KBA13_SITZE_6', 'KBA13_TOYOTA', 'KBA13_VORB_0', 'KBA13_VORB_1', 'KBA13_VORB_1_2', 'KBA13_VORB_2', 'KBA13_VORB_3', 'KBA13_VW', 'KKK', 'KOMBIALTER', 'KONSUMNAEHE', 'LP_FAMILIE_FEIN', 'LP_FAMILIE_GROB', 'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'LP_STATUS_FEIN', 'LP_STATUS_GROB', 'MIN_GEBAEUDEJAHR', 'MOBI_RASTER', 'MOBI_REGIO', 'NATIONALITAET_KZ', 'ONLINE_AFFINITAET', 'ORTSGR_KLS9', 'OST_WEST_KZ', 'PLZ8_ANTG1', 'PLZ8_ANTG2', 'PLZ8_ANTG3', 'PLZ8_ANTG4', 'PLZ8_BAUMAX', 'PLZ8_GBZ', 'PLZ8_HHZ', 'PRAEGENDE_JUGENDJAHRE', 'REGIOTYP', 'RELAT_AB', 'RETOURTYP_BK_S', 'RT_KEIN_ANREIZ', 'RT_SCHNAEPPCHEN', 'RT_UEBERGROESSE', 'SEMIO_DOM', 'SEMIO_ERL', 'SEMIO_FAM', 'SEMIO_KAEM', 'SEMIO_KRIT', 'SEMIO_KULT', 'SEMIO_LUST', 'SEMIO_MAT', 'SEMIO_PFLICHT', 'SEMIO_RAT', 'SEMIO_REL', 'SEMIO_SOZ', 'SEMIO_TRADV', 'SEMIO_VERT', 'SHOPPER_TYP', 'STRUKTURTYP', 'UMFELD_ALT', 'UMFELD_JUNG', 'VERDICHTUNGSRAUM', 'VERS_TYP', 'VHA', 'VHN', 'VK_DHT4A', 'VK_DISTANZ', 'VK_ZG11', 'W_KEIT_KIND_HH', 'WOHNDAUER_2008', 'WOHNLAGE', 'ZABEOTYP', 'ALTERSKATEGORIE_GROB']\n"
     ]
    }
   ],
   "source": [
    "print(list(azdias_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceForNan(df):\n",
    "    df['CAMEO_INTL_2015'].replace('XX',np.nan, inplace = True)\n",
    "    df['CAMEO_DEUG_2015'].replace('X',np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceForNan(azdias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 650.54 Mb\n"
     ]
    }
   ],
   "source": [
    "#It is necessary to reduce the size of the dataframe in order to optimize the memory usage\n",
    "\n",
    "def to_category(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('category', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def to_int(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('uint8', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "categorical_columns = [\n",
    "                        'ALTERSKATEGORIE_GROB','AGER_TYP','ALTER_HH',\n",
    "                      'BALLRAUM','CAMEO_DEUG_2015','CAMEO_DEU_2015','D19_BANKEN_ANZ_24',\n",
    "                      'CJT_GESAMTTYP','D19_BANKEN_ANZ_12','D19_BANKEN_DATUM',\n",
    "                      'D19_BANKEN_OFFLINE_DATUM',\n",
    "                      'D19_BANKEN_ONLINE_DATUM','D19_BANKEN_DIREKT','D19_BANKEN_GROSS',\n",
    "                      'D19_BANKEN_LOKAL','D19_BANKEN_REST',\n",
    "                      'D19_BEKLEIDUNG_GEH','D19_BEKLEIDUNG_REST','D19_BILDUNG',\n",
    "                      'D19_BIO_OEKO','D19_BUCH_CD','D19_DIGIT_SERV','D19_DROGERIEARTIKEL',\n",
    "                      'D19_ENERGIE','D19_FREIZEIT','D19_GARTEN','D19_GESAMT_ANZ_12',\n",
    "                      'D19_GESAMT_ANZ_24','D19_GESAMT_DATUM','D19_GESAMT_OFFLINE_DATUM','D19_GESAMT_ONLINE_DATUM',\n",
    "                      'D19_HANDWERK','D19_HAUS_DEKO','D19_KINDERARTIKEL',\n",
    "                      'D19_KONSUMTYP_MAX','D19_KOSMETIK','D19_LEBENSMITTEL','D19_NAHRUNGSERGAENZUNG',\n",
    "                      'D19_RATGEBER','D19_REISEN','D19_SAMMELARTIKEL','D19_SCHUHE','D19_SONSTIGE',\n",
    "                      'D19_TECHNIK','D19_TELKO_DATUM',\n",
    "                      'D19_TELKO_MOBILE','D19_TELKO_OFFLINE_DATUM',\n",
    "                       'D19_TELKO_REST','D19_TIERARTIKEL','D19_VERSAND_ANZ_12',\n",
    "                      'D19_VERSAND_ANZ_24','D19_VERSAND_DATUM','D19_VERSAND_DATUM',\n",
    "                      'D19_VERSAND_ONLINE_DATUM','D19_VERSAND_REST','D19_VERSICHERUNGEN',\n",
    "                      'D19_VERSI_ANZ_24','D19_VOLLSORTIMENT','D19_WEIN_FEINKOST','EWDICHTE',\n",
    "                      'FINANZTYP','FINANZ_ANLEGER','FINANZ_HAUSBAUER','FINANZ_MINIMALIST',\n",
    "                      'FINANZ_SPARER','FINANZ_UNAUFFAELLIGER','FINANZ_VORSORGER',\n",
    "                      'GEBAEUDETYP','GEBAEUDETYP_RASTER','GFK_URLAUBERTYP',\n",
    "                      'STRUKTURTYP','HEALTH_TYP',\n",
    "                      'HH_EINKOMMEN_SCORE','INNENSTADT','KBA05_ALTER1','KBA05_ALTER2',\n",
    "                      'KBA05_ALTER3','KBA05_ALTER4','KBA05_ANHANG','KBA05_ANTG1','KBA05_ANTG2',\n",
    "                      'KBA05_ANTG3','KBA05_ANTG4','KBA05_AUTOQUOT','KBA05_BAUMAX','KBA05_CCM1',\n",
    "                    'KBA05_CCM2','KBA05_CCM3','KBA05_CCM4','KBA05_DIESEL','KBA05_FRAU','KBA05_GBZ',\n",
    "                    'KBA05_HERST1','KBA05_HERST2','KBA05_HERST3','KBA05_HERST4','KBA05_HERST5',\n",
    "                    'KBA05_HERSTTEMP','KBA05_KRSAQUOT','KBA05_KRSHERST1','KBA05_KRSHERST2',\n",
    "                    'KBA05_KRSHERST3','KBA05_KRSKLEIN','KBA05_KRSOBER','KBA05_KRSVAN',\n",
    "                    'KBA05_KRSZUL','KBA05_KW1','KBA05_KW2','KBA05_KW3','KBA05_MAXAH','KBA05_MAXBJ',\n",
    "                    'KBA05_MAXHERST','KBA05_MAXSEG','KBA05_MAXVORB','KBA05_MOD1','KBA05_MOD2',\n",
    "                    'KBA05_MOD3','KBA05_MOD4','KBA05_MOD8','KBA05_MODTEMP','KBA05_MOTOR',\n",
    "                    'KBA05_MOTRAD','KBA05_SEG1','KBA05_SEG10','KBA05_SEG2','KBA05_SEG3',\n",
    "                    'KBA05_SEG4','KBA05_SEG5','KBA05_SEG6','KBA05_SEG7','KBA05_SEG8','KBA05_SEG9',\n",
    "                    'KBA05_VORB0','KBA05_VORB1','KBA05_VORB2','KBA05_ZUL1','KBA05_ZUL2',\n",
    "                    'KBA05_ZUL3','KBA05_ZUL4','KBA13_ALTERHALTER_30','KBA13_ALTERHALTER_45',\n",
    "                    'KBA13_ALTERHALTER_60','KBA13_ALTERHALTER_61','KBA13_AUDI','KBA13_AUTOQUOTE',\n",
    "                    'KBA13_BJ_1999','KBA13_BJ_2000','KBA13_BJ_2004','KBA13_BJ_2006',\n",
    "                    'KBA13_BJ_2008','KBA13_BJ_2009','KBA13_BMW','KBA13_CCM_1000','KBA13_CCM_1200',\n",
    "                    'KBA13_CCM_1400','KBA13_CCM_0_1400','KBA13_CCM_1500','KBA13_CCM_1401_2500',\n",
    "                    'KBA13_CCM_1600','KBA13_CCM_1800','KBA13_CCM_2000','KBA13_CCM_2500',\n",
    "                    'KBA13_CCM_2501','KBA13_CCM_3000','KBA13_CCM_3001','KBA13_FAB_ASIEN',\n",
    "                    'KBA13_FAB_SONSTIGE','KBA13_FIAT','KBA13_FORD','KBA13_HALTER_20',\n",
    "                    'KBA13_HALTER_25','KBA13_HALTER_30','KBA13_HALTER_35','KBA13_HALTER_40',\n",
    "                    'KBA13_HALTER_45','KBA13_HALTER_50','KBA13_HALTER_55','KBA13_HALTER_60',\n",
    "                    'KBA13_HALTER_65','KBA13_HALTER_66','KBA13_HERST_ASIEN','KBA13_HERST_AUDI_VW',\n",
    "                    'KBA13_HERST_BMW_BENZ','KBA13_HERST_EUROPA','KBA13_HERST_FORD_OPEL',\n",
    "                    'KBA13_HERST_SONST','KBA13_KMH_110','KBA13_KMH_140','KBA13_KMH_180',\n",
    "                    'KBA13_KMH_0_140','KBA13_KMH_140_210','KBA13_KMH_211','KBA13_KMH_250',\n",
    "                    'KBA13_KMH_251','KBA13_KRSAQUOT','KBA13_KRSHERST_AUDI_VW',\n",
    "                    'KBA13_KRSHERST_BMW_BENZ','KBA13_KRSHERST_FORD_OPEL',\n",
    "                    'KBA13_KRSSEG_OBER','KBA13_KRSSEG_VAN','KBA13_KRSZUL_NEU','KBA13_KW_30',\n",
    "                    'KBA13_KW_40','KBA13_KW_50','KBA13_KW_60','KBA13_KW_0_60','KBA13_KW_70',\n",
    "                    'KBA13_KW_61_120','KBA13_KW_80','KBA13_KW_90','KBA13_KW_110','KBA13_KW_120',\n",
    "                    'KBA13_KW_121','KBA13_MAZDA','KBA13_MERCEDES','KBA13_MOTOR','KBA13_NISSAN',\n",
    "                    'KBA13_OPEL','KBA13_PEUGEOT','KBA13_RENAULT','KBA13_SEG_GELAENDEWAGEN',\n",
    "                    'KBA13_SEG_GROSSRAUMVANS','KBA13_SEG_KLEINST','KBA13_SEG_KLEINWAGEN',\n",
    "                    'KBA13_SEG_KOMPAKTKLASSE','KBA13_SEG_MINIVANS','KBA13_SEG_MINIWAGEN',\n",
    "                    'KBA13_SEG_MITTELKLASSE','KBA13_SEG_OBEREMITTELKLASSE','KBA13_SEG_OBERKLASSE',\n",
    "                    'KBA13_SEG_SONSTIGE','KBA13_SEG_SPORTWAGEN','KBA13_SEG_UTILITIES',\n",
    "                    'KBA13_SEG_VAN','KBA13_SEG_WOHNMOBILE','KBA13_SITZE_4','KBA13_SITZE_5',\n",
    "                    'KBA13_SITZE_6','KBA13_TOYOTA','KBA13_VORB_0','KBA13_VORB_1','KBA13_VORB_1_2',\n",
    "                    'KBA13_VORB_2','KBA13_VORB_3','KBA13_VW','KKK','KONSUMNAEHE','LP_FAMILIE_FEIN',\n",
    "                    'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','LP_LEBENSPHASE_GROB','LP_STATUS_FEIN',\n",
    "                    'LP_STATUS_GROB','MOBI_REGIO','NATIONALITAET_KZ','ONLINE_AFFINITAET','ORTSGR_KLS9',\n",
    "                    'OST_WEST_KZ','PLZ8_ANTG1','PLZ8_ANTG2','PLZ8_ANTG3','PLZ8_ANTG4','PLZ8_BAUMAX',\n",
    "                    'PLZ8_GBZ','PLZ8_HHZ','PRAEGENDE_JUGENDJAHRE','REGIOTYP','RELAT_AB',\n",
    "                    'RETOURTYP_BK_S','SEMIO_DOM','SEMIO_ERL','SEMIO_FAM','SEMIO_KAEM','SEMIO_KRIT',\n",
    "                    'SEMIO_KULT','SEMIO_LUST','SEMIO_MAT','SEMIO_PFLICHT','SEMIO_RAT','SEMIO_REL',\n",
    "                    'SEMIO_SOZ','SEMIO_TRADV','SEMIO_VERT','SHOPPER_TYP',\n",
    "                    'VERS_TYP','WOHNDAUER_2008','WOHNLAGE','W_KEIT_KIND_HH','ZABEOTYP']\n",
    "\n",
    "#GEBURTSJAHR year of birth, to int or to date\n",
    "#GREEN_AVANTGARDE maybe can be a bool\n",
    "azdias_df = to_category(azdias_df, categorical_columns)\n",
    "#azdias_df = to_int(azdias_df, categorical_columns)\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging for more space it can be seen that there are columns that are not listed in the csv description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EINGEFUEGT_AM                 60.686382\n",
       "CAMEO_INTL_2015               39.016406\n",
       "ANZ_STATISTISCHE_HAUSHALTE     6.799477\n",
       "KBA13_GBZ                      6.799477\n",
       "CJT_KATALOGNUTZER              6.799477\n",
       "RT_SCHNAEPPCHEN                6.799477\n",
       "RT_KEIN_ANREIZ                 6.799477\n",
       "AKT_DAT_KL                     6.799477\n",
       "KBA13_HHZ                      6.799477\n",
       "ANZ_HAUSHALTE_AKTIV            6.799477\n",
       "ANZ_KINDER                     6.799477\n",
       "ANZ_PERSONEN                   6.799477\n",
       "ARBEIT                         6.799477\n",
       "D19_VERSI_OFFLINE_DATUM        6.799477\n",
       "D19_VERSAND_OFFLINE_DATUM      6.799477\n",
       "CJT_TYP_6                      6.799477\n",
       "CJT_TYP_5                      6.799477\n",
       "CJT_TYP_4                      6.799477\n",
       "MOBI_RASTER                    6.799477\n",
       "MIN_GEBAEUDEJAHR               6.799477\n",
       "CJT_TYP_3                      6.799477\n",
       "CJT_TYP_2                      6.799477\n",
       "CJT_TYP_1                      6.799477\n",
       "KOMBIALTER                     6.799477\n",
       "D19_VERSI_DATUM                6.799477\n",
       "KBA13_ANTG3                    6.799477\n",
       "VERDICHTUNGSRAUM               6.799477\n",
       "LNR                            6.799477\n",
       "FIRMENDICHTE                   6.799477\n",
       "KBA13_ANTG1                    6.799477\n",
       "                                ...    \n",
       "KBA13_CCM_3001                 0.850125\n",
       "KBA13_HALTER_35                0.850125\n",
       "KBA13_HALTER_30                0.850125\n",
       "KBA13_FIAT                     0.850125\n",
       "KBA13_HALTER_20                0.850125\n",
       "KBA13_FAB_ASIEN                0.850125\n",
       "KBA13_FORD                     0.850125\n",
       "KBA13_FAB_SONSTIGE             0.850125\n",
       "KBA13_KRSZUL_NEU               0.850118\n",
       "KBA05_KRSVAN                   0.850118\n",
       "PLZ8_ANTG3                     0.850118\n",
       "KBA13_MOTOR                    0.850118\n",
       "NATIONALITAET_KZ               0.850118\n",
       "KBA05_MAXVORB                  0.850118\n",
       "KBA05_KRSKLEIN                 0.850118\n",
       "KBA13_KRSSEG_VAN               0.850118\n",
       "KBA05_KRSOBER                  0.850118\n",
       "HEALTH_TYP                     0.850118\n",
       "KBA05_KRSZUL                   0.850118\n",
       "KBA13_KRSSEG_OBER              0.850118\n",
       "KBA05_ANTG3                    0.850118\n",
       "VERS_TYP                       0.850034\n",
       "STRUKTURTYP                    0.850034\n",
       "KBA13_KMH_110                  0.850034\n",
       "KBA05_ANTG4                    0.850034\n",
       "PLZ8_ANTG4                     0.850034\n",
       "KBA05_SEG6                     0.850034\n",
       "KBA13_KMH_251                  0.850034\n",
       "KBA13_KW_30                    0.850034\n",
       "Index                          0.000076\n",
       "Length: 336, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(azdias_df.memory_usage(deep=True) / 1024 ** 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 364.24 Mb\n"
     ]
    }
   ],
   "source": [
    "categorical_columns2 = ['CAMEO_INTL_2015','KBA13_ANTG1','KBA13_GBZ','D19_VERSI_DATUM','RT_UEBERGROESSE',\n",
    "                       'RT_SCHNAEPPCHEN','RT_KEIN_ANREIZ','ANZ_HAUSHALTE_AKTIV','ANZ_KINDER',\n",
    "                       'ANZ_PERSONEN','ANZ_STATISTISCHE_HAUSHALTE','ARBEIT','MOBI_RASTER',\n",
    "                       'D19_VERSI_OFFLINE_DATUM','MIN_GEBAEUDEJAHR','KOMBIALTER',\n",
    "                       'CJT_KATALOGNUTZER','CJT_TYP_1','CJT_TYP_2','CJT_TYP_3','CJT_TYP_4','CJT_TYP_5',\n",
    "                        'CJT_TYP_6','KBA13_HHZ','KBA13_KMH_210','KBA13_BAUMAX',\n",
    "                       'UMFELD_JUNG','EINGEZOGENAM_HH_JAHR','GEMEINDETYP',\n",
    "                       'GEBURTSJAHR','AKT_DAT_KL','KBA13_ANTG2','D19_VERSAND_OFFLINE_DATUM','UMFELD_ALT',\n",
    "                       'KBA13_ANTG3','VK_DISTANZ','FIRMENDICHTE','VERDICHTUNGSRAUM',\n",
    "                       'VK_ZG11','KBA13_ANTG4','VK_DHT4A','VHN','VHA']\n",
    "\n",
    "azdias_df = to_category(azdias_df, categorical_columns2)\n",
    "#KBA13_ANZAHL_PKW to int\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows that not have at least 270 (80%) non null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired in https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4\n",
    "\n",
    "def impute_mode_categorical(df):\n",
    "    categorical_columns= df.select_dtypes(include=['category'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in categorical_columns: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        #col_data.replace('XX',np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        mode = col_data.mode()[0]\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(mode, inplace=True)\n",
    "            \n",
    "    return df\n",
    "    \n",
    "def impute_median_numerical(df):\n",
    "    numeric_cols = df.select_dtypes(include=['int','float'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in numeric_cols: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        median = col_data.median()\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(median, inplace=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 316.11 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_df.dropna(thresh=290, inplace = True)\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace nulls and unknown (-1) values with mode or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 335)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of the non ordinal categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 435.76 Mb\n"
     ]
    }
   ],
   "source": [
    "one_hot_list = ['WOHNLAGE','VERS_TYP','SHOPPER_TYP','RETOURTYP_BK_S','PLZ8_BAUMAX','NATIONALITAET_KZ',\n",
    "                'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','KBA05_MODTEMP','KBA05_MAXHERST','KBA05_HERSTTEMP',\n",
    "                'HEALTH_TYP','GFK_URLAUBERTYP','GEBAEUDETYP','FINANZTYP','D19_KONSUMTYP_MAX',\n",
    "                'CJT_GESAMTTYP','CAMEO_DEU_2015','AGER_TYP']\n",
    "azdias_df = pd.get_dummies(azdias_df, columns =one_hot_list)\n",
    "\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once performed one hot encoded, drop low variance resulting columns that are result of having previous columns with a value that appears few times and it is not statistically relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 316)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropLowVarianceCols(azdias_df)\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode into numerical values binary feature OST_WEST_KZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encodeColumnByLabel(df, label):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df[label])\n",
    "    return label_encoder.transform(df[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['OST_WEST_KZ'] = encodeColumnByLabel(azdias_df, 'OST_WEST_KZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp into an integer formed by year month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestampToInt(df, column):\n",
    "    timestamp =  pd.to_datetime(df[column]) ## pandas recognizes your format\n",
    "\n",
    "    df[column] = timestamp.dt.strftime('%Y%m%d')\n",
    "    return azdias_df[column].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['EINGEFUEGT_AM'] = timestampToInt(azdias_df, 'EINGEFUEGT_AM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize values before aplying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "np_azdias = azdias_df.values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np_azdias)\n",
    "np_azdias = scaler.transform(np_azdias)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in the dataframe the normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df = pd.DataFrame(data=np_azdias,\n",
    "          index=azdias_df.index,\n",
    "          columns=azdias_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "session = sagemaker.Session()\n",
    "# get IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'arvato'\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix+\"/train\")\n",
    "#num_components = 400\n",
    "#since removing columns with low variance after performing one hot encoding the remaining number of columns is\n",
    "#less than the previously specified number of components (316) so I set a new number of components\n",
    "num_components = 300\n",
    "\n",
    "\n",
    "\n",
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to recordset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_azdias_data = pca.record_set(np_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit data to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-06 10:39:36 Starting - Starting the training job...\n",
      "2020-05-06 10:39:37 Starting - Launching requested ML instances...\n",
      "2020-05-06 10:40:35 Starting - Preparing the instances for training......\n",
      "2020-05-06 10:41:11 Downloading - Downloading input data......\n",
      "2020-05-06 10:42:28 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'316', u'mini_batch_size': u'500', u'num_components': u'300'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Final configuration: {u'num_components': u'300', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'316', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 WARNING 140371717224256] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/c50a1e26-3c37-4261-a48c-b33d588d23c5', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-39-36-048', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-91-222.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/b2672fe6-2576-4775-85f1-dd86b97f553b', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-39-36-048', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/c50a1e26-3c37-4261-a48c-b33d588d23c5', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.91.222', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-39-36-048', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-91-222.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/b2672fe6-2576-4775-85f1-dd86b97f553b', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-39-36-048', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/c50a1e26-3c37-4261-a48c-b33d588d23c5', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-39-36-048', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-91-222.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/b2672fe6-2576-4775-85f1-dd86b97f553b', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-39-36-048', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/c50a1e26-3c37-4261-a48c-b33d588d23c5', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.91.222', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-39-36-048', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-91-222.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/b2672fe6-2576-4775-85f1-dd86b97f553b', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-39-36-048', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/c50a1e26-3c37-4261-a48c-b33d588d23c5', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.91.222', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-39-36-048', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-91-222.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/b2672fe6-2576-4775-85f1-dd86b97f553b', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-39-36-048', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 58 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 67 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:30 INFO 140371717224256] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:32 INFO 140371717224256] nvidia-smi took: 0.0251519680023 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:32 INFO 140371717224256] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:32 INFO 140371717224256] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:32 INFO 140371717224256] 316 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:32 INFO 140371717224256] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1509.427785873413, \"sum\": 1509.427785873413, \"min\": 1509.427785873413}}, \"EndTime\": 1588761752.305266, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761750.773696}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588761752.305588, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761752.305535}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 10:42:32.311] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1537, \"num_examples\": 1, \"num_bytes\": 1278000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2020-05-06 10:42:42.383] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 10061, \"num_examples\": 1503, \"num_bytes\": 1920402036}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 10072.019815444946, \"sum\": 10072.019815444946, \"min\": 10072.019815444946}}, \"EndTime\": 1588761762.384135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761752.305382}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:42 INFO 140371717224256] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588761762.384523, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1588761752.311878}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:42 INFO 140371717224256] #throughput_metric: host=algo-1, train throughput=74589.8481938 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 35.69197654724121, \"sum\": 35.69197654724121, \"min\": 35.69197654724121}}, \"EndTime\": 1588761762.421813, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761762.384227}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:42:42 INFO 140371717224256] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 11802.695989608765, \"sum\": 11802.695989608765, \"min\": 11802.695989608765}, \"setuptime\": {\"count\": 1, \"max\": 41.96000099182129, \"sum\": 41.96000099182129, \"min\": 41.96000099182129}}, \"EndTime\": 1588761762.441923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761762.421876}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-06 10:42:49 Uploading - Uploading generated training model\n",
      "2020-05-06 10:42:49 Completed - Training job completed\n",
      "Training seconds: 98\n",
      "Billable seconds: 98\n"
     ]
    }
   ],
   "source": [
    "#train_inputs = sagemaker.s3_input(train_s3, content_type='text/csv;label_size=0')\n",
    "\n",
    "pca.fit(formatted_azdias_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arvato/train/pca-2020-05-06-10-39-36-048/output/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the training job, it's suggested that you copy-paste\n",
    "# from the notebook or from a specific job in the AWS console\n",
    "\n",
    "training_job_name=pca._current_job_name\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix+\"/train\", training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as model_algo-1\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# loading the unzipped artifacts\n",
    "pca_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selected params\n",
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the explained variance for the top n principal components\n",
    "# you may assume you have access to the global var N_COMPONENTS\n",
    "def explained_variance(s, n_top_components):\n",
    "    '''Calculates the approx. data variance that n_top_components captures.\n",
    "       :param s: A dataframe of singular values for top components; \n",
    "           the top value is in the last row.\n",
    "       :param n_top_components: An integer, the number of top components to use.\n",
    "       :return: The expected data variance covered by the n_top_components.'''\n",
    "    \n",
    "    n_components = len(s) - n_top_components\n",
    "    partial = s[n_components:].pow(2).sum(axis=0)\n",
    "    total = s.pow(2).sum(axis=0)\n",
    "\n",
    "    return partial/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0    0.980038\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "n_top_components = 220 # select a value for the number of top components\n",
    "\n",
    "# calculate the explained variance\n",
    "exp_variance = explained_variance(s, n_top_components)\n",
    "print('Explained variance: ', exp_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for x in range(num_components):\n",
    "    y.append(explained_variance(s, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y)\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how many components are needed for 90% of explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "#convert list of series to list of floats\n",
    "floats_y = [float(i) for i in y]\n",
    "#construct an comprehension to locate the index of the first element with more than 0.9 explained variance\n",
    "components = (i for i,v in enumerate(floats_y) if (v > 0.9))\n",
    "num_components = next(components)\n",
    "print(num_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-fit PCA with the number of components obtained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-06 10:43:23 Starting - Starting the training job...\n",
      "2020-05-06 10:43:24 Starting - Launching requested ML instances......\n",
      "2020-05-06 10:44:25 Starting - Preparing the instances for training...\n",
      "2020-05-06 10:45:17 Downloading - Downloading input data......\n",
      "2020-05-06 10:46:17 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'316', u'mini_batch_size': u'500', u'num_components': u'134'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Final configuration: {u'num_components': u'134', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'316', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 WARNING 140579577567040] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/6912e1e5-3193-4028-8961-8bd9c8929e0a', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-43-23-063', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-161-95.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/cb4dc180-4839-4e31-820b-20251245e4bf', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-43-23-063', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/6912e1e5-3193-4028-8961-8bd9c8929e0a', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.161.95', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-43-23-063', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-161-95.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/cb4dc180-4839-4e31-820b-20251245e4bf', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-43-23-063', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/6912e1e5-3193-4028-8961-8bd9c8929e0a', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-43-23-063', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-161-95.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/cb4dc180-4839-4e31-820b-20251245e4bf', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-43-23-063', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/6912e1e5-3193-4028-8961-8bd9c8929e0a', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.161.95', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-43-23-063', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-161-95.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/cb4dc180-4839-4e31-820b-20251245e4bf', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-43-23-063', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/6912e1e5-3193-4028-8961-8bd9c8929e0a', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.161.95', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-06-10-43-23-063', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-161-95.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/cb4dc180-4839-4e31-820b-20251245e4bf', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-06-10-43-23-063', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 60 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 69 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:31 INFO 140579577567040] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:32 INFO 140579577567040] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:32 INFO 140579577567040] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:32 INFO 140579577567040] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:33 INFO 140579577567040] nvidia-smi took: 0.0251491069794 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:33 INFO 140579577567040] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:33 INFO 140579577567040] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:33 INFO 140579577567040] 316 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:33 INFO 140579577567040] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1217.2160148620605, \"sum\": 1217.2160148620605, \"min\": 1217.2160148620605}}, \"EndTime\": 1588761993.286206, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761992.048841}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588761993.286779, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761993.286721}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 10:46:33.294] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1245, \"num_examples\": 1, \"num_bytes\": 1278000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 10:46:51 Uploading - Uploading generated training model\n",
      "2020-05-06 10:46:51 Completed - Training job completed\n",
      "\u001b[34m[2020-05-06 10:46:43.900] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 10598, \"num_examples\": 1503, \"num_bytes\": 1920402036}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 10605.908155441284, \"sum\": 10605.908155441284, \"min\": 10605.908155441284}}, \"EndTime\": 1588762003.901056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588761993.286305}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:43 INFO 140579577567040] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762003.90302, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1588761993.295105}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:43 INFO 140579577567040] #throughput_metric: host=algo-1, train throughput=70825.9068671 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 35.14981269836426, \"sum\": 35.14981269836426, \"min\": 35.14981269836426}}, \"EndTime\": 1588762003.938565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588762003.902103}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:46:43 INFO 140579577567040] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 12083.604097366333, \"sum\": 12083.604097366333, \"min\": 12083.604097366333}, \"setuptime\": {\"count\": 1, \"max\": 41.47601127624512, \"sum\": 41.47601127624512, \"min\": 41.47601127624512}}, \"EndTime\": 1588762003.95832, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588762003.938619}\n",
      "\u001b[0m\n",
      "Training seconds: 94\n",
      "Billable seconds: 94\n"
     ]
    }
   ],
   "source": [
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)\n",
    "\n",
    "pca.fit(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 ms, sys: 2.47 ms, total: 23.5 ms\n",
      "Wall time: 342 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pca_transformer = pca.transformer(instance_count = 1, \n",
    "                                  instance_type = 'ml.m5.large',\n",
    "                                  output_path='s3://{}/{}/pca/transform/test'.format(bucket_name, prefix+\"/transform\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'azdias.csv'\n",
    "\n",
    "\n",
    "u = azdias_df.select_dtypes(object)\n",
    "azdias_df[u.columns] = u.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into local notebook storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df.to_csv(filename,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "np_azdias_location = session.upload_data(os.path.join(filename), key_prefix=prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print dataset location in order to avoid previous computation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-848439228145/arvato/azdias.csv\n"
     ]
    }
   ],
   "source": [
    "print(np_azdias_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete temp file from sagemaker notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:27 INFO 140544065312576] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] nvidia-smi took: 0.10049700737 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loading entry points\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-06 10:54:29 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-06 10:54:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-06 10:54:29 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-06 10:54:29 +0000] [83] [INFO] Booting worker with pid: 83\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loading model...\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-06 10:54:29 +0000] [93] [INFO] Booting worker with pid: 93\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] loading model...\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:29 INFO 140544065312576] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762478.330707, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762469.403104}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[32m2020-05-06T10:54:38.335:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762482.525116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762469.453387}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762482.544954, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762478.330821}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762482.525116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762469.453387}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762482.544954, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762478.330821}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762483.865782, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762482.525578}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762484.017166, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762482.54563}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762483.865782, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762482.525578}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762484.017166, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762482.54563}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762485.229387, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762483.865862}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762485.353813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762484.018067}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762485.229387, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762483.865862}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762485.353813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762484.018067}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762486.578921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762485.354418}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762486.77566, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762485.22975}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762486.578921, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762485.354418}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762486.77566, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762485.22975}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762487.963732, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762486.579383}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762488.223349, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762486.775998}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762487.963732, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762486.579383}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762488.223349, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762486.775998}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762489.273299, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762487.964305}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762489.273299, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762487.964305}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762489.775734, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762488.223706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762489.775734, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762488.223706}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762490.501033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762489.273377}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762491.095641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762489.77626}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762490.501033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762489.273377}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762491.095641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762489.77626}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762491.821745, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762490.501623}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762492.412454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762491.096158}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762491.821745, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762490.501623}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762492.412454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762491.096158}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762494.375862, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762493.014742}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762494.375862, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762493.014742}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762495.18913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762493.773865}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762495.18913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762493.773865}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762495.658841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762494.376236}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762496.421224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762495.189651}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762495.658841, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762494.376236}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762496.421224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762495.189651}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762497.050742, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762495.659367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762497.050742, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762495.659367}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762498.138736, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762496.421718}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762498.138736, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762496.421718}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762498.457982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762497.051162}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:54:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762498.457982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762497.051162}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:54:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762499.582543, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762498.139247}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762499.892479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762498.458543}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762499.582543, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762498.139247}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762499.892479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762498.458543}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762501.015469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762499.583028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762501.318597, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762499.892873}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762501.015469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762499.583028}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762501.318597, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762499.892873}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762502.412183, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762501.015973}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762502.412183, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762501.015973}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762503.834166, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762502.412682}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762504.159048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762502.740832}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762503.834166, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762502.412682}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762504.159048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762502.740832}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762505.396649, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762503.83467}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762505.396649, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762503.83467}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762505.542641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762504.159418}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762505.542641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762504.159418}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762506.884744, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762505.397199}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762507.06785, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762505.543163}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762506.884744, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762505.397199}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762507.06785, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762505.543163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762508.24381, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762506.88482}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762508.24381, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762506.88482}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762508.471978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762507.068256}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762508.471978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762507.068256}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762509.643051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762508.244297}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762509.643051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762508.244297}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762509.895637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762508.472063}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762509.895637, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762508.472063}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762511.07737, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762509.643126}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762511.271422, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762509.896448}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762511.07737, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762509.643126}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762511.271422, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762509.896448}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:55:13 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:13 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762514.047313, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762512.674462}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762514.298815, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762512.513859}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:13 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:13 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762514.047313, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762512.674462}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762514.298815, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762512.513859}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762515.556141, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762514.298896}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762515.629386, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762514.048104}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762515.556141, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762514.298896}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762515.629386, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762514.048104}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762516.921581, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762515.556664}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762517.166501, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762515.629773}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762516.921581, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762515.556664}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762517.166501, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762515.629773}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762518.306692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762516.922063}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762518.306692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762516.922063}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762518.599681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762517.166957}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762518.599681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762517.166957}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762519.775811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762518.307177}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762520.166099, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762518.599761}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762519.775811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762518.307177}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762520.166099, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762518.599761}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:20 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762521.130844, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762519.775888}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:20 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762521.130844, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762519.775888}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762521.692838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762520.166608}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762521.692838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762520.166608}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:55:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762523.184596, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762521.69334}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762523.184596, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762521.69334}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762523.808649, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762522.514192}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2460.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762523.808649, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762522.514192}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2460.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:24 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:24 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:24 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:24 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762524.674746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762523.184672}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762525.204169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762523.809133}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:24 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:24 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:24 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:24 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762524.674746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762523.184672}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762525.204169, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762523.809133}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762526.079454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762524.674825}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762526.079454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762524.674825}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762526.534651, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762525.204651}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:27 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:27 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:27 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:27 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762526.534651, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762525.204651}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:27 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:27 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:27 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:27 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762527.468748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762526.079532}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762528.030084, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762526.535149}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762527.468748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762526.079532}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762528.030084, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762526.535149}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762528.894421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762527.468825}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762528.894421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762527.468825}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762529.641532, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762528.03056}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:30 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:30 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:30 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:30 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762530.407022, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762528.894528}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762529.641532, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762528.03056}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:30 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:30 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:30 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:30 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762530.407022, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762528.894528}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762531.096833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762529.642047}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762531.096833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762529.642047}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762531.923103, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762530.407098}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762531.923103, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762530.407098}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:55:33 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:33 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:33 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762533.355072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762531.923565}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762533.355072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762531.923565}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762533.940537, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762532.587415}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:33 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:33 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:33 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762533.940537, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762532.587415}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:34 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:34 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:34 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:34 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:34 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:34 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:34 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:34 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762534.736249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762533.355557}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762535.38459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762533.940615}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762534.736249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762533.355557}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762535.38459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762533.940615}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762536.168862, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762534.736755}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762536.168862, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762534.736755}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762536.847543, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762535.38507}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762536.847543, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762535.38507}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:37 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:37 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:37 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:37 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762537.630053, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762536.169327}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:37 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:37 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:37 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:37 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762537.630053, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762536.169327}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762538.33471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762536.848142}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762538.33471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762536.848142}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762539.097735, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762537.630498}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762539.097735, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762537.630498}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762539.795322, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762538.33523}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762540.425476, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762539.100075}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762539.795322, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762538.33523}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762540.425476, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762539.100075}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762541.149625, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762539.795787}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762541.149625, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762539.795787}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762541.730484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762540.425927}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:42 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:42 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:42 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:42 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762541.730484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762540.425927}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:42 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:42 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:42 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:42 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:55:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762543.959095, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762542.545907}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762543.959095, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762542.545907}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762544.539545, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762543.176026}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762544.539545, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762543.176026}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762545.512035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762543.9596}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762545.512035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762543.9596}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762546.035398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762544.53998}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762546.035398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762544.53998}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762546.786741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762545.512527}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762547.427826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762546.03577}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762546.786741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762545.512527}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762547.427826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762546.03577}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762548.290271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762546.787248}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762548.290271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762546.787248}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762548.780693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762547.428249}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762548.780693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762547.428249}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762549.661035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762548.290792}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762550.199843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762548.780771}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762549.661035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762548.290792}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762550.199843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762548.780771}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762551.293417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762549.661513}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762551.293417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762549.661513}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762551.585316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762550.200406}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762551.585316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762550.200406}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:55:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762554.057034, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762552.892273}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762554.296688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762552.827766}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762554.057034, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762552.892273}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762554.296688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762552.827766}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762555.402765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762554.057408}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762555.402765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762554.057408}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762555.665363, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762554.300613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762555.665363, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762554.300613}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762556.769552, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762555.403118}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762556.769552, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762555.403118}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762557.044145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762555.66588}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762557.044145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762555.66588}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762558.128347, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762556.769891}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762558.417761, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762557.044649}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762558.128347, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762556.769891}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762558.417761, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762557.044649}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:55:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762559.46607, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762558.128693}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:55:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762559.46607, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762558.128693}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762559.947873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762558.418247}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762559.947873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762558.418247}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762560.81824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762559.466385}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762560.81824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762559.466385}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762561.528048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762559.948358}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:02 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:02 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:02 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:02 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762562.287099, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762560.818627}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762561.528048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762559.948358}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:02 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:02 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:02 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:02 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762562.287099, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762560.818627}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:56:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762564.479179, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762562.959548}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762564.479179, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762562.959548}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762565.044746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762563.629262}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762565.044746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762563.629262}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762565.886666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762564.479675}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762566.379243, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762565.045216}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762565.886666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762564.479675}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762566.379243, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762565.045216}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762567.404529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762565.887152}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762567.404529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762565.887152}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762567.724306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762566.379659}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762567.724306, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762566.379659}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762568.838275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762567.404606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762569.181271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762567.724457}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762568.838275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762567.404606}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762569.181271, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762567.724457}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762570.340528, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762568.838354}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762570.340528, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762568.838354}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762570.582711, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762569.181589}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762570.582711, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762569.181589}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762571.68807, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762570.340856}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762571.962762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762570.583148}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:12 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:12 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:12 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:12 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762571.68807, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762570.340856}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762571.962762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762570.583148}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:12 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:12 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:12 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:12 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:56:13 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:13 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:13 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:13 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762574.395007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762573.083225}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:13 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:13 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:13 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:13 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762574.395007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762573.083225}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762574.716394, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762573.378166}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762574.716394, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762573.378166}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762575.73527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762574.395082}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762576.079173, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762574.716885}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762575.73527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762574.395082}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762576.079173, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762574.716885}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2494.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2494.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2500.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762577.132867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762575.735764}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2500.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762577.132867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762575.735764}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762577.61672, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762576.079514}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762577.61672, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762576.079514}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2492.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:18 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:18 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:18 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:18 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2492.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:18 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:18 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:18 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:18 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762578.555311, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762577.133357}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762579.13242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762577.617109}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762578.555311, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762577.133357}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762579.13242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762577.617109}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762579.935693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762578.55579}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762579.935693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762578.55579}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762580.516563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762579.13279}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:20 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:20 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:20 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762580.516563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762579.13279}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:20 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:20 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:20 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:20 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762581.321967, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762579.93577}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:20 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762581.321967, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762579.93577}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762581.846251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762580.517049}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:22 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:22 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:22 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:22 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762581.846251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762580.517049}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:22 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:22 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:22 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:22 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762583.286403, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762581.846755}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762583.286403, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762581.846755}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762584.188093, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762582.713373}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762584.188093, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762582.713373}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762584.811823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762583.286914}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:24 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762584.811823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762583.286914}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:24 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762585.590871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762584.188169}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762586.226403, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762584.812326}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762585.590871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762584.188169}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762586.226403, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762584.812326}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762587.0824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762585.590946}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762587.0824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762585.590946}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762587.705786, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762586.22702}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:27 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:27 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:27 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:27 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762588.49888, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762587.08287}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762587.705786, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762586.22702}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:27 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:27 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:27 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:27 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762588.49888, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762587.08287}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762589.055166, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762587.705868}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762589.055166, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762587.705868}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762589.952454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762588.499359}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762589.952454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762588.499359}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762590.391661, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762589.055251}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762590.391661, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762589.055251}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:30 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:30 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:30 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:30 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762591.466508, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762589.952949}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:30 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:30 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:30 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:30 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762591.466508, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762589.952949}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762591.772253, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762590.391787}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:32 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762591.772253, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762590.391787}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:32 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:56:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762594.345434, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762592.893297}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762594.345434, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762592.893297}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762594.700513, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762593.184092}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762594.700513, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762593.184092}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762595.731461, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762594.34551}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762596.175847, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762594.700876}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762595.731461, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762594.34551}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762596.175847, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762594.700876}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762597.294207, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762595.731536}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762597.294207, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762595.731536}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762597.57086, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762596.176365}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762597.57086, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762596.176365}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762598.815357, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762597.294281}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762598.966044, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762597.571348}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762598.815357, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762597.294281}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762598.966044, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762597.571348}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762600.15795, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762598.815435}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762600.361646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762598.966575}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762600.15795, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762598.815435}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762600.361646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762598.966575}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762601.458896, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762600.158433}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762601.458896, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762600.158433}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762601.875469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762600.361726}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:42 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:42 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:42 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:42 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762601.875469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762600.361726}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:42 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:42 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:42 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:42 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762603.313087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762601.875547}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762603.313087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762601.875547}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:43 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762604.213414, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762602.780744}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762604.213414, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762602.780744}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762604.778027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762603.313572}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762604.778027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762603.313572}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2466.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762605.588156, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762604.213488}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762606.106232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762604.778533}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762605.588156, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762604.213488}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762606.106232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762604.778533}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762606.830911, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762605.588232}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762606.830911, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762605.588232}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762607.531228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762606.106789}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762608.294141, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762606.830988}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762607.531228, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762606.106789}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762608.294141, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762606.830988}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762608.929239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762607.531726}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762608.929239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762607.531726}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762609.817856, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762608.294216}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762610.430094, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762608.929705}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762609.817856, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762608.294216}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762610.430094, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762608.929705}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762611.120942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762609.818334}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762611.120942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762609.818334}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762611.901284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762610.430163}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762611.901284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762610.430163}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:56:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762613.336454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762611.901362}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762613.336454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762611.901362}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762613.947376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762612.572231}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762613.947376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762612.572231}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762614.718676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762613.336933}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762614.718676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762613.336933}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762615.300273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762613.947455}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762615.300273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762613.947455}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762616.038068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762614.719162}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762616.038068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762614.719162}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762616.70198, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762615.300348}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762616.70198, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762615.300348}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762617.524372, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762616.038563}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762617.524372, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762616.038563}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762618.144763, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762616.702059}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762618.144763, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762616.702059}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762619.032289, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762617.524448}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762619.032289, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762617.524448}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762619.571757, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762618.145234}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:56:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762620.397829, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762619.032365}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762619.571757, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762618.145234}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:56:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762620.397829, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762619.032365}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762620.913157, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762619.572265}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762620.913157, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762619.572265}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762621.878949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762620.397907}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762622.399348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762620.913644}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2473.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762621.878949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762620.397907}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762622.399348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762620.913644}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:57:03 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:03 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762623.296453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762621.879025}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:03 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:03 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762623.296453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762621.879025}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762623.826173, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762622.399829}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762623.826173, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762622.399829}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762624.834789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762623.29653}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762625.187142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762623.826255}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762624.834789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762623.29653}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762625.187142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762623.826255}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762626.263272, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762624.835274}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762626.47492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762625.187225}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762626.263272, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762624.835274}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762626.47492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762625.187225}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762627.645051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762626.263748}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762627.93621, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762626.475}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762627.645051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762626.263748}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762627.93621, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762626.475}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762628.913176, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762627.645504}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762629.443396, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762627.936297}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762628.913176, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762627.645504}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762629.443396, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762627.936297}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762630.287722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762628.913653}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762630.287722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762628.913653}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762630.825084, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762629.443476}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762630.825084, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762629.443476}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762631.655987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762630.288209}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:12 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:12 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:12 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:12 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762632.290083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762630.825163}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762631.655987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762630.288209}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:12 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:12 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:12 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:12 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762632.290083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762630.825163}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:57:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762634.515933, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762633.012692}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762634.515933, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762633.012692}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762635.149196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762633.70844}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762635.149196, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762633.70844}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2465.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762636.041738, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762634.516009}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:15 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762636.041738, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762634.516009}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762636.565889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762635.14969}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762637.500557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762636.041814}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762636.565889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762635.14969}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:16 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:16 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:16 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:16 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:17 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:17 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:17 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:17 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2467.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762637.500557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762636.041814}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762637.852251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762636.566376}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:18 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762637.852251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762636.566376}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:18 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2469.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762638.829958, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762637.500634}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762639.208162, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762637.852744}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762638.829958, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762637.500634}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762639.208162, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762637.852744}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762640.282459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762638.830034}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:19 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762640.282459, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762638.830034}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762640.619499, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762639.208645}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762640.619499, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762639.208645}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:21 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762641.890132, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762640.282539}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762641.97686, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762640.620023}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762641.890132, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762640.282539}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762641.97686, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762640.620023}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:57:22 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:22 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:22 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:22 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:22 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:22 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762643.257332, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762641.977372}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762643.357222, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762641.890214}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:22 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:22 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:22 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:22 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:22 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:22 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762643.257332, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762641.977372}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762643.357222, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762641.890214}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:23 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762644.626008, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762643.257857}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762644.650415, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762643.357308}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762644.626008, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762643.257857}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762644.650415, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762643.357308}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:25 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762645.878338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762644.650505}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762646.120838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762644.626677}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762645.878338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762644.650505}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762646.120838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762644.626677}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762647.306633, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762645.878443}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762647.421931, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762646.121331}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:26 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762647.306633, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762645.878443}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762647.421931, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762646.121331}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:27 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:27 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:27 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:27 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:27 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:27 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:27 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:27 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:28 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:28 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:28 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:28 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762648.677417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762647.422433}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762648.916238, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762647.306709}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762648.677417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762647.422433}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762648.916238, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762647.306709}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2495.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762650.129275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762648.677911}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762650.391895, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762648.916319}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:29 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762650.129275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762648.677911}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762650.391895, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762648.916319}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:30 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:30 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:30 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:30 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762651.517956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762650.129777}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:30 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:30 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:30 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:30 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2493.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:31 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:31 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:31 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:31 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762651.517956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762650.129777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762651.735833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762650.391977}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:32 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:32 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:32 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:32 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762651.735833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762650.391977}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:32 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:32 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:32 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:32 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762653.346901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762651.735915}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762653.346901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762651.735915}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:33 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:33 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:33 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762654.26701, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762652.978314}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:33 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:33 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:33 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:33 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762654.26701, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762652.978314}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762654.796273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762653.346977}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:34 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762654.796273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762653.346977}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:34 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:35 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762655.713954, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762654.267506}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762656.320438, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762654.796356}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:35 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:35 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:35 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762655.713954, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762654.267506}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762656.320438, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762654.796356}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:36 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:36 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:36 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:36 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762657.180793, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762655.714032}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762657.180793, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762655.714032}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762657.887518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762656.32091}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:37 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762657.887518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762656.32091}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:37 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762658.798495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762657.180867}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762658.798495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762657.180867}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:38 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:38 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:38 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:38 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:39 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:39 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:39 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:39 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762659.599372, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762657.887998}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762659.599372, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762657.887998}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762660.271794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762658.799051}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762660.271794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762658.799051}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762660.948387, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762659.599447}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:40 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762660.948387, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762659.599447}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:41 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762661.582079, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762660.272285}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:42 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:42 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:42 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:42 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762662.299441, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762660.948463}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:41 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:41 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:41 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762661.582079, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762660.272285}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:42 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:42 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:42 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:42 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762662.299441, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762660.948463}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762663.741972, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762662.299516}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762663.741972, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762662.299516}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:44 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:44 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:44 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:44 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762664.389546, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762663.022619}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762664.389546, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762663.022619}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762665.110442, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762663.742478}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762665.110442, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762663.742478}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762665.873041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762664.389636}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762666.539837, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762665.11099}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:45 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762665.873041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762664.389636}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762666.539837, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762665.11099}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2496.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:46 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:46 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:46 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:46 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2496.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762667.32715, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762665.873117}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762667.32715, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762665.873117}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762667.885988, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762666.540368}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762667.885988, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762666.540368}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:47 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762668.616628, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762667.327227}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762669.350126, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762667.886074}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:48 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:48 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:48 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:48 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762668.616628, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762667.327227}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:49 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:49 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762669.350126, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762667.886074}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:49 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:49 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2489.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762670.046057, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762668.617176}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762670.046057, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762668.617176}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762670.802695, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762669.35022}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762671.318042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762670.046561}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:50 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2487.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762670.802695, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762669.35022}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762671.318042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762670.046561}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:51 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:51 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:51 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:51 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2484.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762672.299697, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762670.802836}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:52 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:52 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:52 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:52 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2491.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762672.299697, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762670.802836}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:57:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:53 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:53 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:53 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:53 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762673.636682, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762672.299773}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762674.209601, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762672.82532}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762673.636682, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762672.299773}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762674.209601, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762672.82532}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762674.962471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762673.637136}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762675.528639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762674.210145}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:54 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2488.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762674.962471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762673.637136}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762675.528639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762674.210145}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:55 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:55 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:55 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:55 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2475.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762676.268111, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762674.962844}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2490.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762676.268111, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762674.962844}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762676.82526, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762675.529231}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762676.82526, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762675.529231}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:56 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2477.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:57 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:57 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:57 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:57 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762677.597596, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762676.26819}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762678.080254, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762676.825754}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762677.597596, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762676.26819}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762678.080254, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762676.825754}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2498.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762678.932325, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762677.59797}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762679.4543, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762678.080792}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:58 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2498.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762678.932325, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762677.59797}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762679.4543, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762678.080792}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:57:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762680.472881, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762678.933112}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:57:59 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2478.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762680.472881, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762678.933112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762680.679668, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762679.454413}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762680.679668, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762679.454413}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:00 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:00 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:00 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:00 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2482.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:01 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:01 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:01 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:01 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2479.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762681.706302, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762680.472962}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762681.916364, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762680.680131}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:02 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762681.706302, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762680.472962}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762681.916364, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762680.680131}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2472.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:02 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2470.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762684.298184, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762682.934598}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762684.5486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762683.138626}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762684.298184, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762682.934598}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762684.5486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762683.138626}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:04 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:04 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:04 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:04 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:05 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:05 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:05 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:05 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2474.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762685.666346, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762684.298543}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762685.856698, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762684.549129}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762685.666346, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762684.298543}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762685.856698, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762684.549129}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:06 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2471.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762686.946225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762685.666709}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762687.118822, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762685.857181}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762686.946225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762685.666709}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762687.118822, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762685.857181}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2480.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762688.269561, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762686.946641}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762688.375772, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762687.119307}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:07 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762688.269561, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762686.946641}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762688.375772, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762687.119307}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:08 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:08 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:08 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:08 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:09 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:09 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:09 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:09 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2485.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762689.617833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762688.37629}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762689.729715, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762688.270019}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762689.617833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762688.37629}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762689.729715, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762688.270019}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:10 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2481.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762690.919716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762689.618357}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762690.919716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762689.618357}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762691.20369, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762689.730301}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762691.20369, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762689.730301}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2486.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762692.270262, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762690.920249}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762692.479636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762691.20405}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:11 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2483.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762692.270262, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762690.920249}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762692.479636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762691.20405}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/06/2020 10:58:13 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:13 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:13 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:13 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2476.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762693.584337, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762692.270771}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762693.76401, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762692.479718}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762693.584337, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762692.270771}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762693.76401, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762692.479718}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:14 WARNING 140544065312576] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/06/2020 10:58:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:14 INFO 140544065312576] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:14 INFO 140544065312576] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/06/2020 10:58:14 INFO 140544065312576] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2463.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762694.5951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762693.584862}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588762694.5951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588762693.584862}\n",
      "\u001b[0m\n",
      "\n",
      "CPU times: user 1.69 s, sys: 118 ms, total: 1.81 s\n",
      "Wall time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "pca_transformer.transform(np_azdias_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/azdias.csv.out to ./azdias.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/azdias.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvToDataFrame(filename):\n",
    "    df = pd.read_csv(filename, usecols = [0], header = None)\n",
    "    #df[0] = df[0].apply(lambda x: str(x)[15:])\n",
    "    #df[0] = pd.to_numeric(df[0], downcast='float')\n",
    "    \n",
    "    df = pd.read_csv(filename, nrows = 1, header = None)\n",
    "    \n",
    "    col_types = []\n",
    "    for column in range(1, df.shape[1]-1):\n",
    "        df[column] = pd.to_numeric(df[column], downcast='float')\n",
    "        \n",
    "    # create the dict of index names and optimized datatypes\n",
    "    dtypes = df.dtypes\n",
    "    colnames = dtypes.index\n",
    "    types = [i.name for i in dtypes.values]\n",
    "    column_types = dict(zip(colnames, types))\n",
    "\n",
    "    df = pd.read_csv(filename,dtype=column_types, header = None)\n",
    "\n",
    "    last_col_index = df.shape[1]-1\n",
    "\n",
    "    df[0] = df[0].apply(lambda x: str(x)[15:])\n",
    "    df[0] = pd.to_numeric(df[0], downcast='float')\n",
    "    df[last_col_index] = df[last_col_index].apply(lambda x: str(x)[:-2])\n",
    "    df[last_col_index] = pd.to_numeric(df[last_col_index], downcast='float')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 384.06 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_sub_pca = pd.DataFrame()\n",
    "\n",
    "azdias_sub_pca = csvToDataFrame('azdias.csv.out')\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 134)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_sub_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data visualization azdias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.4 Apply same transformations done on azdias to customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.dropna(thresh=290, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceForNan(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = to_category(customers_df, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 93.49 Mb\n"
     ]
    }
   ],
   "source": [
    "customers_df = to_category(customers_df, categorical_columns2)\n",
    "\n",
    "#azdias_df = to_int(azdias_df, categorical_columns)\n",
    "\n",
    "print('Memory used:', memory_usage(customers_df), 'Mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "0           0    9626        2        1.0     10.0                 1.0   \n",
       "2           2  143872        2        1.0      6.0                 1.0   \n",
       "3           3  143873        1        1.0      8.0                 0.0   \n",
       "4           4  143874        2        1.0     20.0                 7.0   \n",
       "5           5  143888        1        1.0     11.0                 1.0   \n",
       "\n",
       "   ANZ_HH_TITEL ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ...  \\\n",
       "0           0.0        0.0          2.0                        1.0  ...   \n",
       "2           0.0        0.0          1.0                        1.0  ...   \n",
       "3           NaN        0.0          0.0                        1.0  ...   \n",
       "4           0.0        0.0          4.0                        7.0  ...   \n",
       "5           0.0        0.0          2.0                        1.0  ...   \n",
       "\n",
       "   VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0      2.0            6.0            9.0      7.0        3  COSMETIC_AND_FOOD   \n",
       "2     11.0            6.0            9.0      2.0        3  COSMETIC_AND_FOOD   \n",
       "3      2.0            6.0            9.0      7.0        1           COSMETIC   \n",
       "4      4.0            2.0            9.0      3.0        1               FOOD   \n",
       "5      1.0            6.0            9.0      1.0        2  COSMETIC_AND_FOOD   \n",
       "\n",
       "  CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0    MULTI_BUYER               0         1                    4  \n",
       "2    MULTI_BUYER               0         2                    4  \n",
       "3    MULTI_BUYER               0         1                    4  \n",
       "4    MULTI_BUYER               0         1                    3  \n",
       "5    MULTI_BUYER               0         1                    3  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(customers_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "0           0    9626        2        1.0     10.0                 1.0   \n",
       "2           2  143872        2        1.0      6.0                 1.0   \n",
       "3           3  143873        1        1.0      8.0                 0.0   \n",
       "4           4  143874        2        1.0     20.0                 7.0   \n",
       "5           5  143888        1        1.0     11.0                 1.0   \n",
       "\n",
       "   ANZ_HH_TITEL ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ...  \\\n",
       "0           0.0        0.0          2.0                        1.0  ...   \n",
       "2           0.0        0.0          1.0                        1.0  ...   \n",
       "3           0.0        0.0          0.0                        1.0  ...   \n",
       "4           0.0        0.0          4.0                        7.0  ...   \n",
       "5           0.0        0.0          2.0                        1.0  ...   \n",
       "\n",
       "   VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0      2.0            6.0            9.0      7.0        3  COSMETIC_AND_FOOD   \n",
       "2     11.0            6.0            9.0      2.0        3  COSMETIC_AND_FOOD   \n",
       "3      2.0            6.0            9.0      7.0        1           COSMETIC   \n",
       "4      4.0            2.0            9.0      3.0        1               FOOD   \n",
       "5      1.0            6.0            9.0      1.0        2  COSMETIC_AND_FOOD   \n",
       "\n",
       "  CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0    MULTI_BUYER               0         1                    4  \n",
       "2    MULTI_BUYER               0         2                    4  \n",
       "3    MULTI_BUYER               0         1                    4  \n",
       "4    MULTI_BUYER               0         1                    3  \n",
       "5    MULTI_BUYER               0         1                    3  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(customers_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = pd.get_dummies(customers_df, columns =one_hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>CAMEO_DEU_2015_9B</th>\n",
       "      <th>CAMEO_DEU_2015_9C</th>\n",
       "      <th>CAMEO_DEU_2015_9D</th>\n",
       "      <th>CAMEO_DEU_2015_9E</th>\n",
       "      <th>CAMEO_DEU_2015_XX</th>\n",
       "      <th>AGER_TYP_-1</th>\n",
       "      <th>AGER_TYP_0</th>\n",
       "      <th>AGER_TYP_1</th>\n",
       "      <th>AGER_TYP_2</th>\n",
       "      <th>AGER_TYP_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>143888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\n",
       "0           0    9626        1.0     10.0                 1.0           0.0   \n",
       "2           2  143872        1.0      6.0                 1.0           0.0   \n",
       "3           3  143873        1.0      8.0                 0.0           0.0   \n",
       "4           4  143874        1.0     20.0                 7.0           0.0   \n",
       "5           5  143888        1.0     11.0                 1.0           0.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ...  \\\n",
       "0        0.0          2.0                        1.0        0.0  ...   \n",
       "2        0.0          1.0                        1.0        0.0  ...   \n",
       "3        0.0          0.0                        1.0        0.0  ...   \n",
       "4        0.0          4.0                        7.0        0.0  ...   \n",
       "5        0.0          2.0                        1.0        0.0  ...   \n",
       "\n",
       "  CAMEO_DEU_2015_9B CAMEO_DEU_2015_9C CAMEO_DEU_2015_9D CAMEO_DEU_2015_9E  \\\n",
       "0                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "5                 0                 0                 0                 0   \n",
       "\n",
       "  CAMEO_DEU_2015_XX AGER_TYP_-1 AGER_TYP_0 AGER_TYP_1 AGER_TYP_2 AGER_TYP_3  \n",
       "0                 0           0          0          0          1          0  \n",
       "2                 0           0          0          0          1          0  \n",
       "3                 0           0          0          1          0          0  \n",
       "4                 0           0          0          0          1          0  \n",
       "5                 0           0          0          1          0          0  \n",
       "\n",
       "[5 rows x 520 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_median_numerical(customers_df).head()\n",
    "impute_mode_categorical(customers_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df['OST_WEST_KZ'] = encodeColumnByLabel(customers_df, 'OST_WEST_KZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df['EINGEFUEGT_AM'] = timestampToInt(customers_df, 'EINGEFUEGT_AM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137087, 520)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that come from one hot encoding that do not exist in azdias and add with zeros the ones that exists in azdias but not in customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to add []\n",
      "Columns to drop ['AGER_TYP_-1' 'AGER_TYP_0' 'AGER_TYP_1' 'AGER_TYP_2' 'AGER_TYP_3'\n",
      " 'ANREDE_KZ' 'ANZ_HH_TITEL' 'ANZ_TITEL' 'CAMEO_DEU_2015_1A'\n",
      " 'CAMEO_DEU_2015_1B' 'CAMEO_DEU_2015_1C' 'CAMEO_DEU_2015_1D'\n",
      " 'CAMEO_DEU_2015_1E' 'CAMEO_DEU_2015_2A' 'CAMEO_DEU_2015_2B'\n",
      " 'CAMEO_DEU_2015_2C' 'CAMEO_DEU_2015_2D' 'CAMEO_DEU_2015_3A'\n",
      " 'CAMEO_DEU_2015_3B' 'CAMEO_DEU_2015_3C' 'CAMEO_DEU_2015_3D'\n",
      " 'CAMEO_DEU_2015_4A' 'CAMEO_DEU_2015_4B' 'CAMEO_DEU_2015_4C'\n",
      " 'CAMEO_DEU_2015_4D' 'CAMEO_DEU_2015_4E' 'CAMEO_DEU_2015_5A'\n",
      " 'CAMEO_DEU_2015_5B' 'CAMEO_DEU_2015_5C' 'CAMEO_DEU_2015_5D'\n",
      " 'CAMEO_DEU_2015_5E' 'CAMEO_DEU_2015_5F' 'CAMEO_DEU_2015_6A'\n",
      " 'CAMEO_DEU_2015_6B' 'CAMEO_DEU_2015_6C' 'CAMEO_DEU_2015_6D'\n",
      " 'CAMEO_DEU_2015_6E' 'CAMEO_DEU_2015_6F' 'CAMEO_DEU_2015_7A'\n",
      " 'CAMEO_DEU_2015_7B' 'CAMEO_DEU_2015_7C' 'CAMEO_DEU_2015_7D'\n",
      " 'CAMEO_DEU_2015_7E' 'CAMEO_DEU_2015_8A' 'CAMEO_DEU_2015_8B'\n",
      " 'CAMEO_DEU_2015_8C' 'CAMEO_DEU_2015_8D' 'CAMEO_DEU_2015_9A'\n",
      " 'CAMEO_DEU_2015_9B' 'CAMEO_DEU_2015_9C' 'CAMEO_DEU_2015_9D'\n",
      " 'CAMEO_DEU_2015_9E' 'CAMEO_DEU_2015_XX' 'CJT_GESAMTTYP_1.0'\n",
      " 'CJT_GESAMTTYP_2.0' 'CJT_GESAMTTYP_3.0' 'CJT_GESAMTTYP_4.0'\n",
      " 'CJT_GESAMTTYP_5.0' 'CJT_GESAMTTYP_6.0' 'CUSTOMER_GROUP'\n",
      " 'D19_KONSUMTYP_MAX_1' 'D19_KONSUMTYP_MAX_2' 'D19_KONSUMTYP_MAX_3'\n",
      " 'D19_KONSUMTYP_MAX_4' 'D19_KONSUMTYP_MAX_8' 'D19_KONSUMTYP_MAX_9'\n",
      " 'D19_TELKO_ANZ_12' 'D19_TELKO_ANZ_24' 'D19_TELKO_ONLINE_DATUM'\n",
      " 'D19_VERSI_ANZ_12' 'D19_VERSI_ONLINE_DATUM' 'DSL_FLAG' 'FINANZTYP_1'\n",
      " 'FINANZTYP_2' 'FINANZTYP_3' 'FINANZTYP_4' 'FINANZTYP_5' 'FINANZTYP_6'\n",
      " 'GEBAEUDETYP_1.0' 'GEBAEUDETYP_2.0' 'GEBAEUDETYP_3.0' 'GEBAEUDETYP_4.0'\n",
      " 'GEBAEUDETYP_6.0' 'GEBAEUDETYP_8.0' 'GFK_URLAUBERTYP_1.0'\n",
      " 'GFK_URLAUBERTYP_10.0' 'GFK_URLAUBERTYP_11.0' 'GFK_URLAUBERTYP_12.0'\n",
      " 'GFK_URLAUBERTYP_2.0' 'GFK_URLAUBERTYP_3.0' 'GFK_URLAUBERTYP_4.0'\n",
      " 'GFK_URLAUBERTYP_5.0' 'GFK_URLAUBERTYP_6.0' 'GFK_URLAUBERTYP_7.0'\n",
      " 'GFK_URLAUBERTYP_8.0' 'GFK_URLAUBERTYP_9.0' 'GREEN_AVANTGARDE'\n",
      " 'HEALTH_TYP_-1' 'HEALTH_TYP_1' 'HEALTH_TYP_2' 'HEALTH_TYP_3'\n",
      " 'HH_DELTA_FLAG' 'KBA05_HERSTTEMP_1.0' 'KBA05_HERSTTEMP_2.0'\n",
      " 'KBA05_HERSTTEMP_3.0' 'KBA05_HERSTTEMP_4.0' 'KBA05_HERSTTEMP_5.0'\n",
      " 'KBA05_HERSTTEMP_9.0' 'KBA05_MAXHERST_1.0' 'KBA05_MAXHERST_2.0'\n",
      " 'KBA05_MAXHERST_3.0' 'KBA05_MAXHERST_4.0' 'KBA05_MAXHERST_5.0'\n",
      " 'KBA05_MAXHERST_9.0' 'KBA05_MODTEMP_1.0' 'KBA05_MODTEMP_2.0'\n",
      " 'KBA05_MODTEMP_3.0' 'KBA05_MODTEMP_4.0' 'KBA05_MODTEMP_5.0'\n",
      " 'KBA05_MODTEMP_6.0' 'KBA13_KRSSEG_KLEIN' 'KONSUMZELLE'\n",
      " 'LP_FAMILIE_GROB_0.0' 'LP_FAMILIE_GROB_1.0' 'LP_FAMILIE_GROB_2.0'\n",
      " 'LP_FAMILIE_GROB_3.0' 'LP_FAMILIE_GROB_4.0' 'LP_FAMILIE_GROB_5.0'\n",
      " 'LP_LEBENSPHASE_FEIN_0.0' 'LP_LEBENSPHASE_FEIN_1.0'\n",
      " 'LP_LEBENSPHASE_FEIN_10.0' 'LP_LEBENSPHASE_FEIN_11.0'\n",
      " 'LP_LEBENSPHASE_FEIN_12.0' 'LP_LEBENSPHASE_FEIN_13.0'\n",
      " 'LP_LEBENSPHASE_FEIN_14.0' 'LP_LEBENSPHASE_FEIN_15.0'\n",
      " 'LP_LEBENSPHASE_FEIN_16.0' 'LP_LEBENSPHASE_FEIN_17.0'\n",
      " 'LP_LEBENSPHASE_FEIN_18.0' 'LP_LEBENSPHASE_FEIN_19.0'\n",
      " 'LP_LEBENSPHASE_FEIN_2.0' 'LP_LEBENSPHASE_FEIN_20.0'\n",
      " 'LP_LEBENSPHASE_FEIN_21.0' 'LP_LEBENSPHASE_FEIN_22.0'\n",
      " 'LP_LEBENSPHASE_FEIN_23.0' 'LP_LEBENSPHASE_FEIN_24.0'\n",
      " 'LP_LEBENSPHASE_FEIN_25.0' 'LP_LEBENSPHASE_FEIN_26.0'\n",
      " 'LP_LEBENSPHASE_FEIN_27.0' 'LP_LEBENSPHASE_FEIN_28.0'\n",
      " 'LP_LEBENSPHASE_FEIN_29.0' 'LP_LEBENSPHASE_FEIN_3.0'\n",
      " 'LP_LEBENSPHASE_FEIN_30.0' 'LP_LEBENSPHASE_FEIN_31.0'\n",
      " 'LP_LEBENSPHASE_FEIN_32.0' 'LP_LEBENSPHASE_FEIN_33.0'\n",
      " 'LP_LEBENSPHASE_FEIN_34.0' 'LP_LEBENSPHASE_FEIN_35.0'\n",
      " 'LP_LEBENSPHASE_FEIN_36.0' 'LP_LEBENSPHASE_FEIN_37.0'\n",
      " 'LP_LEBENSPHASE_FEIN_38.0' 'LP_LEBENSPHASE_FEIN_39.0'\n",
      " 'LP_LEBENSPHASE_FEIN_4.0' 'LP_LEBENSPHASE_FEIN_40.0'\n",
      " 'LP_LEBENSPHASE_FEIN_5.0' 'LP_LEBENSPHASE_FEIN_6.0'\n",
      " 'LP_LEBENSPHASE_FEIN_7.0' 'LP_LEBENSPHASE_FEIN_8.0'\n",
      " 'LP_LEBENSPHASE_FEIN_9.0' 'NATIONALITAET_KZ_0' 'NATIONALITAET_KZ_1'\n",
      " 'NATIONALITAET_KZ_2' 'NATIONALITAET_KZ_3' 'ONLINE_PURCHASE'\n",
      " 'PLZ8_BAUMAX_1.0' 'PLZ8_BAUMAX_2.0' 'PLZ8_BAUMAX_3.0' 'PLZ8_BAUMAX_4.0'\n",
      " 'PLZ8_BAUMAX_5.0' 'PRODUCT_GROUP' 'RETOURTYP_BK_S_1.0'\n",
      " 'RETOURTYP_BK_S_2.0' 'RETOURTYP_BK_S_3.0' 'RETOURTYP_BK_S_4.0'\n",
      " 'RETOURTYP_BK_S_5.0' 'SHOPPER_TYP_-1' 'SHOPPER_TYP_0' 'SHOPPER_TYP_1'\n",
      " 'SHOPPER_TYP_2' 'SHOPPER_TYP_3' 'SOHO_KZ' 'TITEL_KZ' 'UNGLEICHENN_FLAG'\n",
      " 'VERS_TYP_-1' 'VERS_TYP_1' 'VERS_TYP_2' 'WOHNLAGE_0.0' 'WOHNLAGE_1.0'\n",
      " 'WOHNLAGE_2.0' 'WOHNLAGE_3.0' 'WOHNLAGE_4.0' 'WOHNLAGE_5.0'\n",
      " 'WOHNLAGE_7.0' 'WOHNLAGE_8.0']\n"
     ]
    }
   ],
   "source": [
    "#Drop and add columns\n",
    "\n",
    "addColumnList = np.setdiff1d(azdias_df.columns,customers_df.columns)\n",
    "print(\"Columns to add\", addColumnList)\n",
    "\n",
    "dropColumnList = np.setdiff1d(customers_df.columns, azdias_df.columns)\n",
    "print(\"Columns to drop\", dropColumnList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.drop(list(dropColumnList), axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_customers = customers_df.values\n",
    "np_customers = scaler.transform(np_customers)\n",
    "\n",
    "customers_df = pd.DataFrame(data=np_customers,\n",
    "          index=customers_df.index,\n",
    "          columns=customers_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA transformation on customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_file = 'customers.csv'\n",
    "\n",
    "customers_dtypes = customers_df.select_dtypes(object)\n",
    "customers_df[u.columns] = customers_dtypes.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n",
    "customers_df.to_csv(customers_file,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "customers_location = session.upload_data(os.path.join(customers_file), key_prefix=prefix)\n",
    "\n",
    "#os.remove(customers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:56 INFO 140514932766528] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] nvidia-smi took: 0.0251669883728 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loading entry points\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-06 11:03:57 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-06 11:03:57 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-06 11:03:57 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-06 11:03:57 +0000] [83] [INFO] Booting worker with pid: 83\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loading model...\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-06 11:03:57 +0000] [93] [INFO] Booting worker with pid: 93\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] loading model...\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:03:57 INFO 140514932766528] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763056.647889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763037.246908}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763056.647889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763037.246908}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:04:20 ERROR 140514932766528] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[35m[05/06/2020 11:04:20 ERROR 140514932766528] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[34mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.10461, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763056.648003}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.10482, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763060.104776}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 11:04:20 ERROR 140514932766528] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[34mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.189922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763037.163819}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.190121, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763060.1901}\n",
      "\u001b[0m\n",
      "\u001b[35mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.10461, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763056.648003}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.10482, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763060.104776}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/06/2020 11:04:20 ERROR 140514932766528] Customer Error: Unable to parse payload. Some rows may have more columns than others\u001b[0m\n",
      "\u001b[35mand/or non-numeric values may be present in the csv data.\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations_error.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.189922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763037.163819}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588763060.190121, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588763060.1901}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:16.655:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.113:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: ClientError: 400\u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.113:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: \u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.113:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: Message:\u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.113:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: unable to evaluate payload provided\u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.257:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: ClientError: 400\u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.270:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: \u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.270:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: Message:\u001b[0m\n",
      "\u001b[32m2020-05-06T11:04:20.271:[sagemaker logs]: sagemaker-eu-west-1-848439228145/arvato/customers.csv: unable to evaluate payload provided\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Transform job pca-2020-05-06-11-01-19-008: Failed. Reason: ClientError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Placeholder docstring\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_last_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_transform_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TransformJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2636\u001b[0m                 ),\n\u001b[1;32m   2637\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2638\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m             )\n\u001b[1;32m   2640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Transform job pca-2020-05-06-11-01-19-008: Failed. Reason: ClientError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "pca_transformer.transform(customers_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the transformed data to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/customers.csv.out to ./customers.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/customers.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 70.07 Mb\n"
     ]
    }
   ],
   "source": [
    "customers_sub_pca = csvToDataFrame('customers.csv.out')\n",
    "\n",
    "print('Memory used:', memory_usage(customers_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137087, 134)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_sub_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data visualization PCA Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_formatted_azdias_data = pca.record_set(azdias_sub_pca.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-06 16:55:36 Starting - Starting the training job...\n",
      "2020-05-06 16:55:37 Starting - Launching requested ML instances...\n",
      "2020-05-06 16:56:36 Starting - Preparing the instances for training......\n",
      "2020-05-06 16:57:25 Downloading - Downloading input data...\n",
      "2020-05-06 16:58:01 Training - Downloading the training image..\n",
      "2020-05-06 16:58:29 Uploading - Uploading generated training model\n",
      "2020-05-06 16:58:29 Completed - Training job completed\n",
      "\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'2', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'2', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 WARNING 140536032843584] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] nvidia-smi took: 0.0251269340515 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'2', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588784299.348368, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784299.34831}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 16:58:19.356] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 52, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Iter 10: Short term msd 14.762740. Long term msd 15.499615\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:19 INFO 140536032843584] Iter 20: Short term msd 14.148256. Long term msd 14.448461\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:20 INFO 140536032843584] Iter 30: Short term msd 14.027286. Long term msd 14.158462\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:20 INFO 140536032843584] Iter 40: Short term msd 14.063868. Long term msd 14.094160\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:20 INFO 140536032843584] Iter 50: Short term msd 14.001560. Long term msd 14.033061\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:20 INFO 140536032843584] Iter 60: Short term msd 14.065946. Long term msd 14.061164\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:20 INFO 140536032843584] Iter 70: Short term msd 14.130707. Long term msd 14.109297\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:21 INFO 140536032843584] Iter 80: Short term msd 14.090654. Long term msd 14.102763\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:21 INFO 140536032843584] Iter 90: Short term msd 14.106620. Long term msd 14.100239\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:21 INFO 140536032843584] Iter 100: Short term msd 14.118859. Long term msd 14.113471\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:21 INFO 140536032843584] Iter 110: Short term msd 14.101646. Long term msd 14.112332\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:21 INFO 140536032843584] Iter 120: Short term msd 14.161888. Long term msd 14.147930\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:21 INFO 140536032843584] Iter 130: Short term msd 14.243123. Long term msd 14.210803\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] Iter 140: Short term msd 14.232370. Long term msd 14.227932\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] Iter 150: Short term msd 14.219033. Long term msd 14.218411\u001b[0m\n",
      "\u001b[34m[2020-05-06 16:58:22.127] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 2770, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588784302.127948, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588784299.356895}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] #throughput_metric: host=algo-1, train throughput=271123.909793 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 WARNING 140536032843584] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] shrinking 20 centers into 2\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #0. Current mean square distance 4.132594\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #1. Current mean square distance 4.193861\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #2. Current mean square distance 4.193861\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #3. Current mean square distance 4.179658\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #4. Current mean square distance 4.197404\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #5. Current mean square distance 4.078299\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #6. Current mean square distance 4.735617\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #7. Current mean square distance 4.797674\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #8. Current mean square distance 4.175813\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] local kmeans attempt #9. Current mean square distance 4.508935\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] finished shrinking process. Mean Square Distance = 4\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] #quality_metric: host=algo-1, train msd <loss>=4.07829856873\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] compute all data-center distances: point norm took: 46.9055%, (1.293810 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] predict compute msd took: 15.0895%, (0.416219 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] compute all data-center distances: inner product took: 11.8466%, (0.326768 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] gradient: cluster size  took: 6.9135%, (0.190697 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] gradient: cluster center took: 6.2747%, (0.173077 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] batch data loading with context took: 5.6220%, (0.155075 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] update state and report convergance took: 2.4607%, (0.067875 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] compute all data-center distances: center norm took: 1.5882%, (0.043809 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] collect from kv store took: 1.4889%, (0.041070 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] splitting centers key-value pair took: 0.9867%, (0.027218 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] gradient: one_hot took: 0.7115%, (0.019626 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] predict minus dist took: 0.1040%, (0.002870 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] update set-up time took: 0.0079%, (0.000219 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] TOTAL took: 2.75833058357\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 89.0040397644043, \"sum\": 89.0040397644043, \"min\": 89.0040397644043}, \"initialize.time\": {\"count\": 1, \"max\": 28.02896499633789, \"sum\": 28.02896499633789, \"min\": 28.02896499633789}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.1342296600341797, \"sum\": 0.1342296600341797, \"min\": 0.1342296600341797}, \"update.time\": {\"count\": 1, \"max\": 2770.820140838623, \"sum\": 2770.820140838623, \"min\": 2770.820140838623}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7510185241699219, \"sum\": 0.7510185241699219, \"min\": 0.7510185241699219}, \"_shrink.time\": {\"count\": 1, \"max\": 86.66181564331055, \"sum\": 86.66181564331055, \"min\": 86.66181564331055}}, \"EndTime\": 1588784302.218426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784299.30327}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 16:58:22 INFO 140536032843584] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 2995.1229095458984, \"sum\": 2995.1229095458984, \"min\": 2995.1229095458984}, \"setuptime\": {\"count\": 1, \"max\": 12.382030487060547, \"sum\": 12.382030487060547, \"min\": 12.382030487060547}}, \"EndTime\": 1588784302.237036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784302.218526}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 64\n",
      "Billable seconds: 64\n",
      "2020-05-06 16:58:48 Starting - Starting the training job...\n",
      "2020-05-06 16:58:49 Starting - Launching requested ML instances......\n",
      "2020-05-06 17:00:15 Starting - Preparing the instances for training......\n",
      "2020-05-06 17:00:51 Downloading - Downloading input data...\n",
      "2020-05-06 17:01:35 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'3', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'3', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 WARNING 139674809235264] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] nvidia-smi took: 0.0251250267029 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'3', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588784511.325359, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784511.325306}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:01:51.341] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 73, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:51 INFO 139674809235264] Iter 10: Short term msd 14.257905. Long term msd 14.980257\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:52 INFO 139674809235264] Iter 20: Short term msd 13.675152. Long term msd 13.968314\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:52 INFO 139674809235264] Iter 30: Short term msd 13.556550. Long term msd 13.685656\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:52 INFO 139674809235264] Iter 40: Short term msd 13.579126. Long term msd 13.613787\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:52 INFO 139674809235264] Iter 50: Short term msd 13.516036. Long term msd 13.549792\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:52 INFO 139674809235264] Iter 60: Short term msd 13.610807. Long term msd 13.597271\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:52 INFO 139674809235264] Iter 70: Short term msd 13.672900. Long term msd 13.650794\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:53 INFO 139674809235264] Iter 80: Short term msd 13.647926. Long term msd 13.655099\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:53 INFO 139674809235264] Iter 90: Short term msd 13.650882. Long term msd 13.647089\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:53 INFO 139674809235264] Iter 100: Short term msd 13.676562. Long term msd 13.666360\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:53 INFO 139674809235264] Iter 110: Short term msd 13.647411. Long term msd 13.662711\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:53 INFO 139674809235264] Iter 120: Short term msd 13.723420. Long term msd 13.705962\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] Iter 130: Short term msd 13.802482. Long term msd 13.771640\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] Iter 140: Short term msd 13.800061. Long term msd 13.794998\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] Iter 150: Short term msd 13.798618. Long term msd 13.793939\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:01:54.390] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3048, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588784514.390899, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588784511.341369}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] #throughput_metric: host=algo-1, train throughput=246363.072309 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 WARNING 139674809235264] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] shrinking 30 centers into 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #0. Current mean square distance 3.805084\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #1. Current mean square distance 3.707484\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #2. Current mean square distance 3.861160\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #3. Current mean square distance 3.972740\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #4. Current mean square distance 4.079624\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #5. Current mean square distance 3.989809\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #6. Current mean square distance 3.926588\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #7. Current mean square distance 3.856186\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #8. Current mean square distance 3.909644\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] local kmeans attempt #9. Current mean square distance 3.861755\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] finished shrinking process. Mean Square Distance = 4\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] #quality_metric: host=algo-1, train msd <loss>=3.70748400688\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] compute all data-center distances: point norm took: 40.8726%, (1.238929 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] predict compute msd took: 17.9349%, (0.543642 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] compute all data-center distances: inner product took: 13.0901%, (0.396788 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] gradient: cluster size  took: 9.1832%, (0.278361 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] gradient: cluster center took: 7.0083%, (0.212435 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] batch data loading with context took: 5.1869%, (0.157225 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] update state and report convergance took: 2.3334%, (0.070731 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] collect from kv store took: 1.4381%, (0.043592 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] gradient: one_hot took: 1.1060%, (0.033526 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] compute all data-center distances: center norm took: 0.9729%, (0.029490 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] splitting centers key-value pair took: 0.7738%, (0.023455 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] predict minus dist took: 0.0910%, (0.002759 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] update set-up time took: 0.0087%, (0.000263 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] TOTAL took: 3.03119659424\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 146.32701873779297, \"sum\": 146.32701873779297, \"min\": 146.32701873779297}, \"initialize.time\": {\"count\": 1, \"max\": 40.61293601989746, \"sum\": 40.61293601989746, \"min\": 40.61293601989746}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.1308917999267578, \"sum\": 0.1308917999267578, \"min\": 0.1308917999267578}, \"update.time\": {\"count\": 1, \"max\": 3049.298048019409, \"sum\": 3049.298048019409, \"min\": 3049.298048019409}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.6968975067138672, \"sum\": 0.6968975067138672, \"min\": 0.6968975067138672}, \"_shrink.time\": {\"count\": 1, \"max\": 143.44215393066406, \"sum\": 143.44215393066406, \"min\": 143.44215393066406}}, \"EndTime\": 1588784514.538602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784511.266852}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:01:54 INFO 139674809235264] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 3357.8150272369385, \"sum\": 3357.8150272369385, \"min\": 3357.8150272369385}, \"setuptime\": {\"count\": 1, \"max\": 12.096881866455078, \"sum\": 12.096881866455078, \"min\": 12.096881866455078}}, \"EndTime\": 1588784514.555801, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784514.5387}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 17:02:01 Uploading - Uploading generated training model\n",
      "2020-05-06 17:02:01 Completed - Training job completed\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n",
      "2020-05-06 17:02:30 Starting - Starting the training job...\n",
      "2020-05-06 17:02:31 Starting - Launching requested ML instances......\n",
      "2020-05-06 17:03:31 Starting - Preparing the instances for training...\n",
      "2020-05-06 17:04:17 Downloading - Downloading input data......\n",
      "2020-05-06 17:05:26 Training - Training image download completed. Training in progress.\n",
      "2020-05-06 17:05:26 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'4', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'4', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 WARNING 139699875751744] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] nvidia-smi took: 0.0251290798187 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'4', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588784718.216731, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784718.216681}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:05:18.231] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 60, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Iter 10: Short term msd 14.017473. Long term msd 14.707638\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:18 INFO 139699875751744] Iter 20: Short term msd 13.448159. Long term msd 13.728865\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:19 INFO 139699875751744] Iter 30: Short term msd 13.323266. Long term msd 13.449383\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:19 INFO 139699875751744] Iter 40: Short term msd 13.336153. Long term msd 13.372988\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:19 INFO 139699875751744] Iter 50: Short term msd 13.263347. Long term msd 13.301471\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:19 INFO 139699875751744] Iter 60: Short term msd 13.348651. Long term msd 13.340018\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:20 INFO 139699875751744] Iter 70: Short term msd 13.400214. Long term msd 13.382170\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:20 INFO 139699875751744] Iter 80: Short term msd 13.378109. Long term msd 13.386903\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:20 INFO 139699875751744] Iter 90: Short term msd 13.385244. Long term msd 13.380671\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:20 INFO 139699875751744] Iter 100: Short term msd 13.395239. Long term msd 13.389903\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:20 INFO 139699875751744] Iter 110: Short term msd 13.381588. Long term msd 13.392359\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] Iter 120: Short term msd 13.443236. Long term msd 13.427604\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] Iter 130: Short term msd 13.530920. Long term msd 13.497368\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] Iter 140: Short term msd 13.524589. Long term msd 13.519984\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] Iter 150: Short term msd 13.513505. Long term msd 13.510931\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:05:21.654] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3422, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588784721.654836, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588784718.231445}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] #throughput_metric: host=algo-1, train throughput=219457.645446 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 WARNING 139699875751744] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] shrinking 40 centers into 4\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #0. Current mean square distance 3.685655\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #1. Current mean square distance 3.621764\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #2. Current mean square distance 3.774812\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #3. Current mean square distance 3.549070\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #4. Current mean square distance 3.815065\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #5. Current mean square distance 3.627244\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #6. Current mean square distance 3.646489\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #7. Current mean square distance 3.635067\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #8. Current mean square distance 3.468940\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] local kmeans attempt #9. Current mean square distance 3.511108\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] #quality_metric: host=algo-1, train msd <loss>=3.46894025803\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] compute all data-center distances: point norm took: 35.9241%, (1.226194 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] predict compute msd took: 20.8168%, (0.710539 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] compute all data-center distances: inner product took: 14.0300%, (0.478885 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] gradient: cluster size  took: 10.2930%, (0.351330 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] gradient: cluster center took: 7.3057%, (0.249365 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] batch data loading with context took: 4.9244%, (0.168083 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] update state and report convergance took: 2.1169%, (0.072258 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] collect from kv store took: 1.3337%, (0.045522 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] compute all data-center distances: center norm took: 1.2807%, (0.043713 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] gradient: one_hot took: 1.1782%, (0.040215 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] splitting centers key-value pair took: 0.7025%, (0.023979 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] predict minus dist took: 0.0853%, (0.002912 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] update set-up time took: 0.0088%, (0.000300 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] TOTAL took: 3.41329479218\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 136.1391544342041, \"sum\": 136.1391544342041, \"min\": 136.1391544342041}, \"initialize.time\": {\"count\": 1, \"max\": 29.81400489807129, \"sum\": 29.81400489807129, \"min\": 29.81400489807129}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.12302398681640625, \"sum\": 0.12302398681640625, \"min\": 0.12302398681640625}, \"update.time\": {\"count\": 1, \"max\": 3423.2099056243896, \"sum\": 3423.2099056243896, \"min\": 3423.2099056243896}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7190704345703125, \"sum\": 0.7190704345703125, \"min\": 0.7190704345703125}, \"_shrink.time\": {\"count\": 1, \"max\": 133.94403457641602, \"sum\": 133.94403457641602, \"min\": 133.94403457641602}}, \"EndTime\": 1588784721.79241, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784718.16982}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:05:21 INFO 139699875751744] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 3696.8979835510254, \"sum\": 3696.8979835510254, \"min\": 3696.8979835510254}, \"setuptime\": {\"count\": 1, \"max\": 11.73090934753418, \"sum\": 11.73090934753418, \"min\": 11.73090934753418}}, \"EndTime\": 1588784721.80681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784721.792523}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 17:05:33 Completed - Training job completed\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n",
      "2020-05-06 17:06:12 Starting - Starting the training job...\n",
      "2020-05-06 17:06:13 Starting - Launching requested ML instances......\n",
      "2020-05-06 17:07:13 Starting - Preparing the instances for training...\n",
      "2020-05-06 17:07:52 Downloading - Downloading input data...\n",
      "2020-05-06 17:08:39 Training - Downloading the training image...\n",
      "2020-05-06 17:09:13 Uploading - Uploading generated training model\n",
      "2020-05-06 17:09:13 Completed - Training job completed\n",
      "\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'5', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 WARNING 140327030462272] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] nvidia-smi took: 0.0251381397247 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:57 INFO 140327030462272] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588784937.672565, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784937.672506}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:08:57.684] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 76, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:58 INFO 140327030462272] Iter 10: Short term msd 13.800860. Long term msd 14.528999\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:58 INFO 140327030462272] Iter 20: Short term msd 13.195283. Long term msd 13.492582\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:58 INFO 140327030462272] Iter 30: Short term msd 13.088316. Long term msd 13.213443\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:58 INFO 140327030462272] Iter 40: Short term msd 13.105934. Long term msd 13.140087\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:59 INFO 140327030462272] Iter 50: Short term msd 13.049292. Long term msd 13.080047\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:59 INFO 140327030462272] Iter 60: Short term msd 13.116113. Long term msd 13.108345\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:59 INFO 140327030462272] Iter 70: Short term msd 13.147294. Long term msd 13.136291\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:08:59 INFO 140327030462272] Iter 80: Short term msd 13.131207. Long term msd 13.140383\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:00 INFO 140327030462272] Iter 90: Short term msd 13.147455. Long term msd 13.140047\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:00 INFO 140327030462272] Iter 100: Short term msd 13.166046. Long term msd 13.157272\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:00 INFO 140327030462272] Iter 110: Short term msd 13.150456. Long term msd 13.159522\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:00 INFO 140327030462272] Iter 120: Short term msd 13.200942. Long term msd 13.189736\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] Iter 130: Short term msd 13.281316. Long term msd 13.251772\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] Iter 140: Short term msd 13.284661. Long term msd 13.276108\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] Iter 150: Short term msd 13.289893. Long term msd 13.282113\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:09:01.407] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3722, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588784941.408234, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588784937.684773}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] #throughput_metric: host=algo-1, train throughput=201768.809733 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 WARNING 140327030462272] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] shrinking 50 centers into 5\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #0. Current mean square distance 3.651449\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #1. Current mean square distance 3.450888\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #2. Current mean square distance 3.585699\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #3. Current mean square distance 3.342096\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #4. Current mean square distance 3.544566\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #5. Current mean square distance 3.481320\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #6. Current mean square distance 3.585003\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #7. Current mean square distance 3.575641\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #8. Current mean square distance 3.311955\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] local kmeans attempt #9. Current mean square distance 3.658237\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] #quality_metric: host=algo-1, train msd <loss>=3.31195521355\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] compute all data-center distances: point norm took: 33.1220%, (1.231365 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] predict compute msd took: 21.3677%, (0.794380 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] compute all data-center distances: inner product took: 15.8538%, (0.589391 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] gradient: cluster size  took: 11.8133%, (0.439178 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] gradient: cluster center took: 7.7249%, (0.287185 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] batch data loading with context took: 4.1271%, (0.153433 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] update state and report convergance took: 1.9609%, (0.072901 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] collect from kv store took: 1.1247%, (0.041811 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] gradient: one_hot took: 1.0770%, (0.040038 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] compute all data-center distances: center norm took: 1.0005%, (0.037197 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] splitting centers key-value pair took: 0.7308%, (0.027168 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] predict minus dist took: 0.0901%, (0.003351 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] update set-up time took: 0.0071%, (0.000264 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] TOTAL took: 3.7176630497\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 179.7797679901123, \"sum\": 179.7797679901123, \"min\": 179.7797679901123}, \"initialize.time\": {\"count\": 1, \"max\": 46.72694206237793, \"sum\": 46.72694206237793, \"min\": 46.72694206237793}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.16689300537109375, \"sum\": 0.16689300537109375, \"min\": 0.16689300537109375}, \"update.time\": {\"count\": 1, \"max\": 3723.271131515503, \"sum\": 3723.271131515503, \"min\": 3723.271131515503}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.8141994476318359, \"sum\": 0.8141994476318359, \"min\": 0.8141994476318359}, \"_shrink.time\": {\"count\": 1, \"max\": 177.22105979919434, \"sum\": 177.22105979919434, \"min\": 177.22105979919434}}, \"EndTime\": 1588784941.589711, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784937.607125}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:09:01 INFO 140327030462272] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4073.904037475586, \"sum\": 4073.904037475586, \"min\": 4073.904037475586}, \"setuptime\": {\"count\": 1, \"max\": 12.354135513305664, \"sum\": 12.354135513305664, \"min\": 12.354135513305664}}, \"EndTime\": 1588784941.615562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588784941.58985}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 81\n",
      "Billable seconds: 81\n",
      "2020-05-06 17:09:23 Starting - Starting the training job...\n",
      "2020-05-06 17:09:25 Starting - Launching requested ML instances...\n",
      "2020-05-06 17:10:21 Starting - Preparing the instances for training......\n",
      "2020-05-06 17:11:01 Downloading - Downloading input data...\n",
      "2020-05-06 17:11:43 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'6', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'6', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 WARNING 140132372399936] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] nvidia-smi took: 0.0251560211182 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'6', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588785123.29448, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785123.294428}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:12:03.306] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 61, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:03 INFO 140132372399936] Iter 10: Short term msd 13.605867. Long term msd 14.288174\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:04 INFO 140132372399936] Iter 20: Short term msd 13.031435. Long term msd 13.311743\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:04 INFO 140132372399936] Iter 30: Short term msd 12.930813. Long term msd 13.048274\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:04 INFO 140132372399936] Iter 40: Short term msd 12.950435. Long term msd 12.980831\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:04 INFO 140132372399936] Iter 50: Short term msd 12.905958. Long term msd 12.931788\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:05 INFO 140132372399936] Iter 60: Short term msd 12.969873. Long term msd 12.962464\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:05 INFO 140132372399936] Iter 70: Short term msd 12.994536. Long term msd 12.985994\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:05 INFO 140132372399936] Iter 80: Short term msd 12.975623. Long term msd 12.986823\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:05 INFO 140132372399936] Iter 90: Short term msd 12.984892. Long term msd 12.979792\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:06 INFO 140132372399936] Iter 100: Short term msd 12.999412. Long term msd 12.994674\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:06 INFO 140132372399936] Iter 110: Short term msd 12.987445. Long term msd 12.996223\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:06 INFO 140132372399936] Iter 120: Short term msd 13.043314. Long term msd 13.030396\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:06 INFO 140132372399936] Iter 130: Short term msd 13.121599. Long term msd 13.091617\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] Iter 140: Short term msd 13.126980. Long term msd 13.118856\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] Iter 150: Short term msd 13.121335. Long term msd 13.119323\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:12:07.387] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4080, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588785127.388269, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588785123.306387}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] #throughput_metric: host=algo-1, train throughput=184055.927548 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 WARNING 140132372399936] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] shrinking 60 centers into 6\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #0. Current mean square distance 3.566780\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #1. Current mean square distance 3.209211\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #2. Current mean square distance 3.450600\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #3. Current mean square distance 3.469128\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #4. Current mean square distance 3.233192\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #5. Current mean square distance 3.678496\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #6. Current mean square distance 3.172987\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #7. Current mean square distance 3.173405\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #8. Current mean square distance 3.444790\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] local kmeans attempt #9. Current mean square distance 3.593643\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] #quality_metric: host=algo-1, train msd <loss>=3.17298650742\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] compute all data-center distances: point norm took: 30.3479%, (1.240114 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] predict compute msd took: 22.3650%, (0.913907 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] compute all data-center distances: inner product took: 15.9012%, (0.649774 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] gradient: cluster size  took: 12.9656%, (0.529818 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] gradient: cluster center took: 7.8313%, (0.320014 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] batch data loading with context took: 4.5866%, (0.187425 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] update state and report convergance took: 1.8629%, (0.076122 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] collect from kv store took: 1.2760%, (0.052141 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] compute all data-center distances: center norm took: 1.2192%, (0.049822 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] gradient: one_hot took: 0.7825%, (0.031975 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] splitting centers key-value pair took: 0.7749%, (0.031663 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] predict minus dist took: 0.0782%, (0.003197 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] update set-up time took: 0.0086%, (0.000352 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] TOTAL took: 4.08632659912\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 213.6540412902832, \"sum\": 213.6540412902832, \"min\": 213.6540412902832}, \"initialize.time\": {\"count\": 1, \"max\": 32.35507011413574, \"sum\": 32.35507011413574, \"min\": 32.35507011413574}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.17905235290527344, \"sum\": 0.17905235290527344, \"min\": 0.17905235290527344}, \"update.time\": {\"count\": 1, \"max\": 4081.6409587860107, \"sum\": 4081.6409587860107, \"min\": 4081.6409587860107}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.6990432739257812, \"sum\": 0.6990432739257812, \"min\": 0.6990432739257812}, \"_shrink.time\": {\"count\": 1, \"max\": 210.97588539123535, \"sum\": 210.97588539123535, \"min\": 210.97588539123535}}, \"EndTime\": 1588785127.60341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785123.243984}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:12:07 INFO 140132372399936] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4450.304985046387, \"sum\": 4450.304985046387, \"min\": 4450.304985046387}, \"setuptime\": {\"count\": 1, \"max\": 13.432979583740234, \"sum\": 13.432979583740234, \"min\": 13.432979583740234}}, \"EndTime\": 1588785127.629896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785127.60358}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 17:12:18 Uploading - Uploading generated training model\n",
      "2020-05-06 17:12:18 Completed - Training job completed\n",
      "Training seconds: 77\n",
      "Billable seconds: 77\n",
      "2020-05-06 17:12:35 Starting - Starting the training job...\n",
      "2020-05-06 17:12:36 Starting - Launching requested ML instances...\n",
      "2020-05-06 17:13:33 Starting - Preparing the instances for training......\n",
      "2020-05-06 17:14:24 Downloading - Downloading input data.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'7', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 WARNING 140327097136960] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] nvidia-smi took: 0.0251469612122 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588785323.365894, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785323.365843}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:15:23.373] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 89, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:23 INFO 140327097136960] Iter 10: Short term msd 13.459113. Long term msd 14.130954\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:24 INFO 140327097136960] Iter 20: Short term msd 12.895405. Long term msd 13.171924\u001b[0m\n",
      "\n",
      "2020-05-06 17:15:31 Training - Training image download completed. Training in progress.\n",
      "2020-05-06 17:15:31 Uploading - Uploading generated training model\u001b[34m[05/06/2020 17:15:24 INFO 140327097136960] Iter 30: Short term msd 12.788946. Long term msd 12.907452\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:24 INFO 140327097136960] Iter 40: Short term msd 12.816111. Long term msd 12.846005\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:24 INFO 140327097136960] Iter 50: Short term msd 12.764970. Long term msd 12.792809\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:25 INFO 140327097136960] Iter 60: Short term msd 12.818219. Long term msd 12.813898\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:25 INFO 140327097136960] Iter 70: Short term msd 12.841703. Long term msd 12.833707\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:25 INFO 140327097136960] Iter 80: Short term msd 12.828501. Long term msd 12.837426\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:26 INFO 140327097136960] Iter 90: Short term msd 12.847356. Long term msd 12.839201\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:26 INFO 140327097136960] Iter 100: Short term msd 12.859240. Long term msd 12.854690\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:26 INFO 140327097136960] Iter 110: Short term msd 12.859212. Long term msd 12.862250\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:26 INFO 140327097136960] Iter 120: Short term msd 12.906388. Long term msd 12.895647\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] Iter 130: Short term msd 12.989060. Long term msd 12.958244\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] Iter 140: Short term msd 12.985788. Long term msd 12.977388\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] Iter 150: Short term msd 12.993418. Long term msd 12.986274\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:15:27.492] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4118, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588785327.492605, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588785323.3735}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] #throughput_metric: host=algo-1, train throughput=182392.528294 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 WARNING 140327097136960] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] shrinking 70 centers into 7\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #0. Current mean square distance 3.319963\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #1. Current mean square distance 2.884962\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #2. Current mean square distance 2.890618\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #3. Current mean square distance 2.884838\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #4. Current mean square distance 3.104784\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #5. Current mean square distance 2.943204\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #6. Current mean square distance 2.879879\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #7. Current mean square distance 3.047561\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #8. Current mean square distance 3.021384\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] local kmeans attempt #9. Current mean square distance 2.907995\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] #quality_metric: host=algo-1, train msd <loss>=2.87987923622\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] compute all data-center distances: point norm took: 28.0626%, (1.151988 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] predict compute msd took: 23.8961%, (0.980953 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] compute all data-center distances: inner product took: 17.1176%, (0.702690 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] gradient: cluster size  took: 14.2040%, (0.583085 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] gradient: cluster center took: 7.5610%, (0.310384 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] batch data loading with context took: 3.8668%, (0.158736 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] update state and report convergance took: 1.9094%, (0.078383 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] collect from kv store took: 1.0134%, (0.041602 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] compute all data-center distances: center norm took: 0.9205%, (0.037787 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] gradient: one_hot took: 0.7507%, (0.030818 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] splitting centers key-value pair took: 0.6211%, (0.025495 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] predict minus dist took: 0.0703%, (0.002884 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] update set-up time took: 0.0065%, (0.000267 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] TOTAL took: 4.10507178307\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 243.12186241149902, \"sum\": 243.12186241149902, \"min\": 243.12186241149902}, \"initialize.time\": {\"count\": 1, \"max\": 63.88497352600098, \"sum\": 63.88497352600098, \"min\": 63.88497352600098}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.15497207641601562, \"sum\": 0.15497207641601562, \"min\": 0.15497207641601562}, \"update.time\": {\"count\": 1, \"max\": 4118.920087814331, \"sum\": 4118.920087814331, \"min\": 4118.920087814331}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7219314575195312, \"sum\": 0.7219314575195312, \"min\": 0.7219314575195312}, \"_shrink.time\": {\"count\": 1, \"max\": 240.49901962280273, \"sum\": 240.49901962280273, \"min\": 240.49901962280273}}, \"EndTime\": 1588785327.737264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785323.283363}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:15:27 INFO 140327097136960] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4534.962892532349, \"sum\": 4534.962892532349, \"min\": 4534.962892532349}, \"setuptime\": {\"count\": 1, \"max\": 12.04991340637207, \"sum\": 12.04991340637207, \"min\": 12.04991340637207}}, \"EndTime\": 1588785327.757945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785327.737405}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 17:15:37 Completed - Training job completed\n",
      "Training seconds: 73\n",
      "Billable seconds: 73\n",
      "2020-05-06 17:16:17 Starting - Starting the training job...\n",
      "2020-05-06 17:16:19 Starting - Launching requested ML instances...\n",
      "2020-05-06 17:17:14 Starting - Preparing the instances for training......\n",
      "2020-05-06 17:18:07 Downloading - Downloading input data......\n",
      "2020-05-06 17:19:18 Training - Training image download completed. Training in progress.\n",
      "2020-05-06 17:19:18 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'8', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'8', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 WARNING 140432125736768] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] nvidia-smi took: 0.0251660346985 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'8', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:09 INFO 140432125736768] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588785549.831707, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785549.831654}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:19:09.845] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 122, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:10 INFO 140432125736768] Iter 10: Short term msd 13.404689. Long term msd 14.074420\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:10 INFO 140432125736768] Iter 20: Short term msd 12.826432. Long term msd 13.104863\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:11 INFO 140432125736768] Iter 30: Short term msd 12.710936. Long term msd 12.832009\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:11 INFO 140432125736768] Iter 40: Short term msd 12.730547. Long term msd 12.764483\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:11 INFO 140432125736768] Iter 50: Short term msd 12.672025. Long term msd 12.703057\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:11 INFO 140432125736768] Iter 60: Short term msd 12.737688. Long term msd 12.729922\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:12 INFO 140432125736768] Iter 70: Short term msd 12.765346. Long term msd 12.754872\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:12 INFO 140432125736768] Iter 80: Short term msd 12.749802. Long term msd 12.757710\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:12 INFO 140432125736768] Iter 90: Short term msd 12.763258. Long term msd 12.756879\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:13 INFO 140432125736768] Iter 100: Short term msd 12.784092. Long term msd 12.775922\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:13 INFO 140432125736768] Iter 110: Short term msd 12.776147. Long term msd 12.781201\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:13 INFO 140432125736768] Iter 120: Short term msd 12.823004. Long term msd 12.812747\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:13 INFO 140432125736768] Iter 130: Short term msd 12.894538. Long term msd 12.867867\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] Iter 140: Short term msd 12.898594. Long term msd 12.889745\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] Iter 150: Short term msd 12.897865. Long term msd 12.893362\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:19:14.247] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4401, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588785554.247942, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588785549.845442}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] #throughput_metric: host=algo-1, train throughput=170654.186544 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 WARNING 140432125736768] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] shrinking 80 centers into 8\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #0. Current mean square distance 2.804449\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #1. Current mean square distance 2.907057\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #2. Current mean square distance 2.819429\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #3. Current mean square distance 2.978382\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #4. Current mean square distance 2.859156\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #5. Current mean square distance 2.881796\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #6. Current mean square distance 3.281821\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #7. Current mean square distance 2.892002\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #8. Current mean square distance 2.894015\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] local kmeans attempt #9. Current mean square distance 2.881410\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] #quality_metric: host=algo-1, train msd <loss>=2.80444860458\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] compute all data-center distances: point norm took: 26.1397%, (1.148356 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] predict compute msd took: 23.8201%, (1.046452 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] compute all data-center distances: inner product took: 18.3833%, (0.807607 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] gradient: cluster size  took: 14.7022%, (0.645891 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] gradient: cluster center took: 7.6129%, (0.334448 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] batch data loading with context took: 3.8709%, (0.170053 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] update state and report convergance took: 1.6357%, (0.071860 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] compute all data-center distances: center norm took: 1.1405%, (0.050102 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] collect from kv store took: 1.0967%, (0.048181 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] gradient: one_hot took: 0.8288%, (0.036412 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] splitting centers key-value pair took: 0.6973%, (0.030632 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] predict minus dist took: 0.0655%, (0.002875 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] update set-up time took: 0.0064%, (0.000282 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] TOTAL took: 4.3931517601\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 252.4721622467041, \"sum\": 252.4721622467041, \"min\": 252.4721622467041}, \"initialize.time\": {\"count\": 1, \"max\": 91.42398834228516, \"sum\": 91.42398834228516, \"min\": 91.42398834228516}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.1609325408935547, \"sum\": 0.1609325408935547, \"min\": 0.1609325408935547}, \"update.time\": {\"count\": 1, \"max\": 4402.220964431763, \"sum\": 4402.220964431763, \"min\": 4402.220964431763}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 1.4348030090332031, \"sum\": 1.4348030090332031, \"min\": 1.4348030090332031}, \"_shrink.time\": {\"count\": 1, \"max\": 250.86188316345215, \"sum\": 250.86188316345215, \"min\": 250.86188316345215}}, \"EndTime\": 1588785554.502578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785549.722447}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:19:14 INFO 140432125736768] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4865.415811538696, \"sum\": 4865.415811538696, \"min\": 4865.415811538696}, \"setuptime\": {\"count\": 1, \"max\": 16.18194580078125, \"sum\": 16.18194580078125, \"min\": 16.18194580078125}}, \"EndTime\": 1588785554.520392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785554.50268}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 17:19:24 Completed - Training job completed\n",
      "Training seconds: 77\n",
      "Billable seconds: 77\n",
      "2020-05-06 17:19:59 Starting - Starting the training job...\n",
      "2020-05-06 17:20:01 Starting - Launching requested ML instances......\n",
      "2020-05-06 17:21:02 Starting - Preparing the instances for training...\n",
      "2020-05-06 17:21:55 Downloading - Downloading input data......\n",
      "2020-05-06 17:22:54 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'9', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'9', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 WARNING 140500454938432] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] nvidia-smi took: 0.0251259803772 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'9', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:56 INFO 140500454938432] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588785776.656899, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785776.655773}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:22:56.670] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 120, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:57 INFO 140500454938432] Iter 10: Short term msd 13.272947. Long term msd 13.938927\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:57 INFO 140500454938432] Iter 20: Short term msd 12.710301. Long term msd 12.985414\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:57 INFO 140500454938432] Iter 30: Short term msd 12.604754. Long term msd 12.722138\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:58 INFO 140500454938432] Iter 40: Short term msd 12.631589. Long term msd 12.662458\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:58 INFO 140500454938432] Iter 50: Short term msd 12.579696. Long term msd 12.607651\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:58 INFO 140500454938432] Iter 60: Short term msd 12.639434. Long term msd 12.633265\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:59 INFO 140500454938432] Iter 70: Short term msd 12.671380. Long term msd 12.659424\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:59 INFO 140500454938432] Iter 80: Short term msd 12.648750. Long term msd 12.658097\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:59 INFO 140500454938432] Iter 90: Short term msd 12.664054. Long term msd 12.658511\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:22:59 INFO 140500454938432] Iter 100: Short term msd 12.688853. Long term msd 12.680860\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:00 INFO 140500454938432] Iter 110: Short term msd 12.674635. Long term msd 12.681763\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:00 INFO 140500454938432] Iter 120: Short term msd 12.719165. Long term msd 12.709656\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:00 INFO 140500454938432] Iter 130: Short term msd 12.793755. Long term msd 12.767038\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] Iter 140: Short term msd 12.792472. Long term msd 12.785246\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] Iter 150: Short term msd 12.798782. Long term msd 12.792564\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:23:01.319] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4648, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588785781.320045, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588785776.671175}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] #throughput_metric: host=algo-1, train throughput=161610.653673 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 WARNING 140500454938432] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] shrinking 90 centers into 9\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #0. Current mean square distance 2.716318\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #1. Current mean square distance 2.698776\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #2. Current mean square distance 2.790508\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #3. Current mean square distance 2.812480\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #4. Current mean square distance 2.910883\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #5. Current mean square distance 2.714066\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #6. Current mean square distance 2.757403\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #7. Current mean square distance 2.778687\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #8. Current mean square distance 2.744043\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] local kmeans attempt #9. Current mean square distance 2.731875\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] #quality_metric: host=algo-1, train msd <loss>=2.69877552986\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] predict compute msd took: 26.0220%, (1.204972 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] compute all data-center distances: point norm took: 24.1270%, (1.117220 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] compute all data-center distances: inner product took: 17.6827%, (0.818813 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] gradient: cluster size  took: 15.5722%, (0.721087 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] gradient: cluster center took: 7.7236%, (0.357650 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] batch data loading with context took: 3.4334%, (0.158988 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] update state and report convergance took: 1.5418%, (0.071396 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] compute all data-center distances: center norm took: 1.4014%, (0.064891 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] collect from kv store took: 1.0524%, (0.048732 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] gradient: one_hot took: 0.8623%, (0.039927 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] splitting centers key-value pair took: 0.5118%, (0.023698 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] predict minus dist took: 0.0641%, (0.002968 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] update set-up time took: 0.0053%, (0.000247 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] TOTAL took: 4.63058876991\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 253.4031867980957, \"sum\": 253.4031867980957, \"min\": 253.4031867980957}, \"initialize.time\": {\"count\": 1, \"max\": 88.70196342468262, \"sum\": 88.70196342468262, \"min\": 88.70196342468262}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.12803077697753906, \"sum\": 0.12803077697753906, \"min\": 0.12803077697753906}, \"update.time\": {\"count\": 1, \"max\": 4648.683071136475, \"sum\": 4648.683071136475, \"min\": 4648.683071136475}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 1.1739730834960938, \"sum\": 1.1739730834960938, \"min\": 1.1739730834960938}, \"_shrink.time\": {\"count\": 1, \"max\": 251.2381076812744, \"sum\": 251.2381076812744, \"min\": 251.2381076812744}}, \"EndTime\": 1588785781.575335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785776.54945}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:23:01 INFO 140500454938432] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5105.376958847046, \"sum\": 5105.376958847046, \"min\": 5105.376958847046}, \"setuptime\": {\"count\": 1, \"max\": 13.005971908569336, \"sum\": 13.005971908569336, \"min\": 13.005971908569336}}, \"EndTime\": 1588785781.590301, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785781.575427}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 17:23:11 Uploading - Uploading generated training model\n",
      "2020-05-06 17:23:11 Completed - Training job completed\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n",
      "2020-05-06 17:23:42 Starting - Starting the training job...\n",
      "2020-05-06 17:23:43 Starting - Launching requested ML instances......\n",
      "2020-05-06 17:24:46 Starting - Preparing the instances for training...\n",
      "2020-05-06 17:25:25 Downloading - Downloading input data...\n",
      "2020-05-06 17:26:09 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'10', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 WARNING 140452107892544] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] nvidia-smi took: 0.0251240730286 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:25 INFO 140452107892544] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588785986.017784, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785986.017731}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:26:26.039] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 136, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:26 INFO 140452107892544] Iter 10: Short term msd 13.202068. Long term msd 13.855332\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:27 INFO 140452107892544] Iter 20: Short term msd 12.647000. Long term msd 12.915975\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:27 INFO 140452107892544] Iter 30: Short term msd 12.540014. Long term msd 12.655906\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:27 INFO 140452107892544] Iter 40: Short term msd 12.563356. Long term msd 12.593098\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:28 INFO 140452107892544] Iter 50: Short term msd 12.510390. Long term msd 12.538352\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:28 INFO 140452107892544] Iter 60: Short term msd 12.568382. Long term msd 12.562807\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:28 INFO 140452107892544] Iter 70: Short term msd 12.614752. Long term msd 12.598562\u001b[0m\n",
      "\n",
      "2020-05-06 17:26:40 Uploading - Uploading generated training model\n",
      "2020-05-06 17:26:40 Completed - Training job completed\n",
      "\u001b[34m[05/06/2020 17:26:29 INFO 140452107892544] Iter 80: Short term msd 12.589445. Long term msd 12.599206\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:29 INFO 140452107892544] Iter 90: Short term msd 12.604011. Long term msd 12.597457\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:29 INFO 140452107892544] Iter 100: Short term msd 12.612977. Long term msd 12.607839\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:29 INFO 140452107892544] Iter 110: Short term msd 12.600509. Long term msd 12.610485\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:30 INFO 140452107892544] Iter 120: Short term msd 12.655848. Long term msd 12.642671\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:30 INFO 140452107892544] Iter 130: Short term msd 12.732138. Long term msd 12.703565\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:30 INFO 140452107892544] Iter 140: Short term msd 12.739292. Long term msd 12.729771\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] Iter 150: Short term msd 12.720559. Long term msd 12.722103\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:26:31.048] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 5008, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588785991.049152, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588785986.03925}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] #throughput_metric: host=algo-1, train throughput=149964.440784 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 WARNING 140452107892544] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] shrinking 100 centers into 10\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #0. Current mean square distance 2.635093\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #1. Current mean square distance 2.818008\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #2. Current mean square distance 2.821874\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #3. Current mean square distance 2.735099\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #4. Current mean square distance 2.686427\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #5. Current mean square distance 2.666028\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #6. Current mean square distance 2.643703\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #7. Current mean square distance 2.676352\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #8. Current mean square distance 2.811081\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] local kmeans attempt #9. Current mean square distance 2.649019\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] #quality_metric: host=algo-1, train msd <loss>=2.63509345055\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] predict compute msd took: 25.6475%, (1.282340 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] compute all data-center distances: point norm took: 22.6321%, (1.131574 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] compute all data-center distances: inner product took: 18.6641%, (0.933179 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] gradient: cluster size  took: 16.5485%, (0.827403 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] gradient: cluster center took: 8.2660%, (0.413288 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] batch data loading with context took: 3.4071%, (0.170351 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] update state and report convergance took: 1.4145%, (0.070721 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] compute all data-center distances: center norm took: 1.1286%, (0.056430 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] collect from kv store took: 0.8852%, (0.044260 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] gradient: one_hot took: 0.8005%, (0.040025 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] splitting centers key-value pair took: 0.5092%, (0.025458 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] predict minus dist took: 0.0907%, (0.004535 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] update set-up time took: 0.0060%, (0.000302 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] TOTAL took: 4.99986505508\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 307.6958656311035, \"sum\": 307.6958656311035, \"min\": 307.6958656311035}, \"initialize.time\": {\"count\": 1, \"max\": 98.47092628479004, \"sum\": 98.47092628479004, \"min\": 98.47092628479004}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.16689300537109375, \"sum\": 0.16689300537109375, \"min\": 0.16689300537109375}, \"update.time\": {\"count\": 1, \"max\": 5009.64093208313, \"sum\": 5009.64093208313, \"min\": 5009.64093208313}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 1.627206802368164, \"sum\": 1.627206802368164, \"min\": 1.627206802368164}, \"_shrink.time\": {\"count\": 1, \"max\": 306.1079978942871, \"sum\": 306.1079978942871, \"min\": 306.1079978942871}}, \"EndTime\": 1588785991.359119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785985.901434}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:26:31 INFO 140452107892544] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5541.136980056763, \"sum\": 5541.136980056763, \"min\": 5541.136980056763}, \"setuptime\": {\"count\": 1, \"max\": 13.760089874267578, \"sum\": 13.760089874267578, \"min\": 13.760089874267578}}, \"EndTime\": 1588785991.378385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588785991.359236}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 75\n",
      "Billable seconds: 75\n",
      "2020-05-06 17:26:54 Starting - Starting the training job...\n",
      "2020-05-06 17:26:57 Starting - Launching requested ML instances......\n",
      "2020-05-06 17:27:57 Starting - Preparing the instances for training...\n",
      "2020-05-06 17:28:32 Downloading - Downloading input data...\n",
      "2020-05-06 17:29:17 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'11', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'11', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 WARNING 140041683601216] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] nvidia-smi took: 0.0251679420471 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'11', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:33 INFO 140041683601216] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588786173.394733, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588786173.394314}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:29:33.401] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 156, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:34 INFO 140041683601216] Iter 10: Short term msd 13.158351. Long term msd 13.809245\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:34 INFO 140041683601216] Iter 20: Short term msd 12.595415. Long term msd 12.867252\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:34 INFO 140041683601216] Iter 30: Short term msd 12.493735. Long term msd 12.607860\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:35 INFO 140041683601216] Iter 40: Short term msd 12.514074. Long term msd 12.542856\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:35 INFO 140041683601216] Iter 50: Short term msd 12.446556. Long term msd 12.478809\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:35 INFO 140041683601216] Iter 60: Short term msd 12.520740. Long term msd 12.511328\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:36 INFO 140041683601216] Iter 70: Short term msd 12.554316. Long term msd 12.539953\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:36 INFO 140041683601216] Iter 80: Short term msd 12.531690. Long term msd 12.541046\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:36 INFO 140041683601216] Iter 90: Short term msd 12.536827. Long term msd 12.534531\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:37 INFO 140041683601216] Iter 100: Short term msd 12.558162. Long term msd 12.551607\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:37 INFO 140041683601216] Iter 110: Short term msd 12.547417. Long term msd 12.555782\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:37 INFO 140041683601216] Iter 120: Short term msd 12.601798. Long term msd 12.589270\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] Iter 130: Short term msd 12.677423. Long term msd 12.649219\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] Iter 140: Short term msd 12.673396. Long term msd 12.668432\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] Iter 150: Short term msd 12.669786. Long term msd 12.667349\u001b[0m\n",
      "\u001b[34m[2020-05-06 17:29:38.745] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 5344, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588786178.746515, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588786173.401381}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] #throughput_metric: host=algo-1, train throughput=140559.472301 records/second\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 WARNING 140041683601216] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] shrinking 110 centers into 11\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #0. Current mean square distance 2.638716\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #1. Current mean square distance 2.615052\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #2. Current mean square distance 2.603812\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #3. Current mean square distance 2.751400\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #4. Current mean square distance 2.660625\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #5. Current mean square distance 2.618917\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #6. Current mean square distance 2.672873\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:38 INFO 140041683601216] local kmeans attempt #7. Current mean square distance 2.769841\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] local kmeans attempt #8. Current mean square distance 2.704918\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] local kmeans attempt #9. Current mean square distance 2.707762\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] #quality_metric: host=algo-1, train msd <loss>=2.60381150246\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] predict compute msd took: 26.2228%, (1.396045 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] compute all data-center distances: point norm took: 21.8634%, (1.163960 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] compute all data-center distances: inner product took: 17.5238%, (0.932931 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] gradient: cluster size  took: 17.4660%, (0.929852 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] gradient: cluster center took: 8.1515%, (0.433968 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] batch data loading with context took: 3.7443%, (0.199336 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] update state and report convergance took: 1.5321%, (0.081567 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] compute all data-center distances: center norm took: 1.2510%, (0.066603 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] gradient: one_hot took: 0.8634%, (0.045964 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] collect from kv store took: 0.8326%, (0.044328 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] splitting centers key-value pair took: 0.4890%, (0.026031 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] predict minus dist took: 0.0550%, (0.002928 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] update set-up time took: 0.0052%, (0.000275 secs)\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] TOTAL took: 5.32378768921\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 302.73985862731934, \"sum\": 302.73985862731934, \"min\": 302.73985862731934}, \"initialize.time\": {\"count\": 1, \"max\": 133.07619094848633, \"sum\": 133.07619094848633, \"min\": 133.07619094848633}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.1418590545654297, \"sum\": 0.1418590545654297, \"min\": 0.1418590545654297}, \"update.time\": {\"count\": 1, \"max\": 5344.92301940918, \"sum\": 5344.92301940918, \"min\": 5344.92301940918}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7510185241699219, \"sum\": 0.7510185241699219, \"min\": 0.7510185241699219}, \"_shrink.time\": {\"count\": 1, \"max\": 300.23813247680664, \"sum\": 300.23813247680664, \"min\": 300.23813247680664}}, \"EndTime\": 1588786179.050781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588786173.243667}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/06/2020 17:29:39 INFO 140041683601216] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5891.487121582031, \"sum\": 5891.487121582031, \"min\": 5891.487121582031}, \"setuptime\": {\"count\": 1, \"max\": 12.540102005004883, \"sum\": 12.540102005004883, \"min\": 12.540102005004883}}, \"EndTime\": 1588786179.069534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588786179.050885}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-06 17:29:48 Uploading - Uploading generated training model\n",
      "2020-05-06 17:29:48 Completed - Training job completed\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n"
     ]
    }
   ],
   "source": [
    "##Launch different jobs\n",
    "K = range(2, 12) # change the range to be used for k\n",
    "\n",
    "output_path = 's3://{}/kmeans/output/'.format(bucket_name)\n",
    "job_names = {}\n",
    "# launching jobs for all k\n",
    "for k in K:\n",
    "    k_estimator = sagemaker.KMeans(role,\n",
    "                               train_instance_count = 1,\n",
    "                               train_instance_type = 'ml.m5.large',\n",
    "                               k = k,\n",
    "                               output_path = output_path\n",
    "                              )\n",
    "\n",
    "    k_estimator.fit(k_formatted_azdias_data)\n",
    "    job_names[k] = k_estimator._current_job_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'kmeans-2020-05-06-16-55-36-157', 3: 'kmeans-2020-05-06-16-58-47-893', 4: 'kmeans-2020-05-06-17-02-29-834', 5: 'kmeans-2020-05-06-17-06-12-021', 6: 'kmeans-2020-05-06-17-09-23-773', 7: 'kmeans-2020-05-06-17-12-35-565', 8: 'kmeans-2020-05-06-17-16-17-762', 9: 'kmeans-2020-05-06-17-19-59-806', 10: 'kmeans-2020-05-06-17-23-42-010', 11: 'kmeans-2020-05-06-17-26-54-111'}\n"
     ]
    }
   ],
   "source": [
    "print(job_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names = {2: 'kmeans-2020-05-06-16-55-36-157', 3: 'kmeans-2020-05-06-16-58-47-893', 4: 'kmeans-2020-05-06-17-02-29-834', 5: 'kmeans-2020-05-06-17-06-12-021', 6: 'kmeans-2020-05-06-17-09-23-773', 7: 'kmeans-2020-05-06-17-12-35-565', 8: 'kmeans-2020-05-06-17-16-17-762', 9: 'kmeans-2020-05-06-17-19-59-806', 10: 'kmeans-2020-05-06-17-23-42-010', 11: 'kmeans-2020-05-06-17-26-54-111'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the most appropiate number of groups using the elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModelByGroupNumber(k):\n",
    "    model_key = os.path.join('kmeans/output/',job_names[k], 'output/model.tar.gz')\n",
    "    \n",
    "    # download and unzip model\n",
    "    boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "    \n",
    "    \n",
    "    #print(\"Model for k={} ({})\".format(k, key))\n",
    "    !tar -xvf model.tar.gz                       \n",
    "    return mx.ndarray.load('model_algo-1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_algo-1\n",
      "state_2068f41b-dedd-4469-9d15-f2e2722ffc69\n",
      "state_a6368ea2-da3f-4a19-ae86-1a767664706e\n",
      "model_algo-1\n",
      "state_ef55b82d-47be-4ff8-9b9b-cca053bc70ca\n",
      "model_algo-1\n",
      "model_algo-1\n",
      "state_9b608f10-3568-41fd-9240-751d4d520c21\n",
      "model_algo-1\n",
      "state_efe7261a-06ac-44f3-a93f-989129fd8408\n",
      "model_algo-1\n",
      "state_1caa963d-70b3-488d-8aa6-d71e80d111c4\n",
      "model_algo-1\n",
      "state_5a8ec6f1-1f02-44b0-9c2b-00039dde588d\n",
      "state_2374ed2c-7cc9-432c-8607-6a68ca3d5f80\n",
      "model_algo-1\n",
      "state_5d43275c-9176-4c3f-a7fd-9d6ada42f205\n",
      "model_algo-1\n",
      "state_0f653a81-c3b1-48f6-add0-519b329f308d\n",
      "model_algo-1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#chunk based on https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "K = range(2, 12) # change the range to be used for k\n",
    "\n",
    "plt.plot()\n",
    "colors = ['b', 'g', 'r']\n",
    "markers = ['o', 'v', 's']\n",
    "models = {}\n",
    "distortions = []\n",
    "for k in K:\n",
    "    kmeans_model = loadModelByGroupNumber(k)\n",
    "    kmeans_numpy = kmeans_model[0].asnumpy()\n",
    "    distortions.append(sum(np.min(cdist(azdias_sub_pca.values, kmeans_numpy, 'euclidean'), axis=1)) / azdias_sub_pca.values.shape[0])\n",
    "    models[k] = kmeans_numpy\n",
    " \n",
    "#plot\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('distortion')\n",
    "plt.title('Elbow graph')\n",
    "plt.show()\n",
    "\n",
    "#s3://sagemaker-eu-west-1-848439228145/kmeans/output/kmeans-2020-05-06-16-55-36-157/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the elbow graph it seems that 7 groups are the best option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_algo-1\r\n",
      "state_1caa963d-70b3-488d-8aa6-d71e80d111c4\r\n"
     ]
    }
   ],
   "source": [
    "kmeans_7 = loadModelByGroupNumber(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit with 7 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_formatted_customers_data = pca.record_set(customers_sub_pca.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 16:31:38 Starting - Starting the training job...\n",
      "2020-05-07 16:31:39 Starting - Launching requested ML instances...\n",
      "2020-05-07 16:32:37 Starting - Preparing the instances for training......\n",
      "2020-05-07 16:33:12 Downloading - Downloading input data...\n",
      "2020-05-07 16:34:09 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'134', u'k': u'7', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 WARNING 139866441905984] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] nvidia-smi took: 0.0251429080963 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'134', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'7', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:11 INFO 139866441905984] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588869252.010666, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588869252.010611}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-07 16:34:12.022] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 100, \"num_examples\": 1, \"num_bytes\": 2820000}\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:12 INFO 139866441905984] Iter 10: Short term msd 13.682465. Long term msd 14.408378\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:12 INFO 139866441905984] Iter 20: Short term msd 13.003200. Long term msd 13.315103\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:13 INFO 139866441905984] Iter 30: Short term msd 12.861533. Long term msd 13.002303\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:13 INFO 139866441905984] Iter 40: Short term msd 12.873427. Long term msd 12.914677\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:13 INFO 139866441905984] Iter 50: Short term msd 12.810616. Long term msd 12.845559\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:13 INFO 139866441905984] Iter 60: Short term msd 12.889524. Long term msd 12.879900\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:14 INFO 139866441905984] Iter 70: Short term msd 12.932549. Long term msd 12.914749\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:14 INFO 139866441905984] Iter 80: Short term msd 12.902783. Long term msd 12.914213\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:14 INFO 139866441905984] Iter 90: Short term msd 12.916804. Long term msd 12.911260\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:14 INFO 139866441905984] Iter 100: Short term msd 12.937696. Long term msd 12.927783\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:15 INFO 139866441905984] Iter 110: Short term msd 12.916294. Long term msd 12.927433\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:15 INFO 139866441905984] Iter 120: Short term msd 12.975756. Long term msd 12.961692\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:15 INFO 139866441905984] Iter 130: Short term msd 13.055382. Long term msd 13.025826\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:15 INFO 139866441905984] Iter 140: Short term msd 13.050713. Long term msd 13.045715\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] Iter 150: Short term msd 13.048823. Long term msd 13.045108\u001b[0m\n",
      "\u001b[34m[2020-05-07 16:34:16.083] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 4060, \"num_examples\": 151, \"num_bytes\": 423750684}\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] processed a total of 751331 examples\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}, \"Total Records Seen\": {\"count\": 1, \"max\": 756331, \"sum\": 756331.0, \"min\": 756331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588869256.083869, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1588869252.022183}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] #throughput_metric: host=algo-1, train throughput=184973.020351 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 WARNING 139866441905984] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] shrinking 70 centers into 7\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #0. Current mean square distance 3.021975\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #1. Current mean square distance 3.020439\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #2. Current mean square distance 2.991682\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #3. Current mean square distance 3.000541\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #4. Current mean square distance 2.932885\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #5. Current mean square distance 3.357774\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #6. Current mean square distance 2.850080\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #7. Current mean square distance 3.020625\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #8. Current mean square distance 3.403172\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] local kmeans attempt #9. Current mean square distance 2.975302\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] #quality_metric: host=algo-1, train msd <loss>=2.85008049011\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] compute all data-center distances: point norm took: 28.7517%, (1.166202 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] predict compute msd took: 22.9584%, (0.931221 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] compute all data-center distances: inner product took: 17.2284%, (0.698805 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] gradient: cluster size  took: 14.4530%, (0.586232 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] gradient: cluster center took: 7.8249%, (0.317389 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] batch data loading with context took: 3.5088%, (0.142322 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] update state and report convergance took: 1.6415%, (0.066581 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] compute all data-center distances: center norm took: 1.0696%, (0.043383 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] collect from kv store took: 1.0420%, (0.042264 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] gradient: one_hot took: 0.7615%, (0.030888 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] splitting centers key-value pair took: 0.6873%, (0.027878 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] predict minus dist took: 0.0661%, (0.002681 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] update set-up time took: 0.0067%, (0.000273 secs)\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] TOTAL took: 4.05611872673\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 201.43485069274902, \"sum\": 201.43485069274902, \"min\": 201.43485069274902}, \"initialize.time\": {\"count\": 1, \"max\": 70.35088539123535, \"sum\": 70.35088539123535, \"min\": 70.35088539123535}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.12111663818359375, \"sum\": 0.12111663818359375, \"min\": 0.12111663818359375}, \"update.time\": {\"count\": 1, \"max\": 4061.455011367798, \"sum\": 4061.455011367798, \"min\": 4061.455011367798}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7500648498535156, \"sum\": 0.7500648498535156, \"min\": 0.7500648498535156}, \"_shrink.time\": {\"count\": 1, \"max\": 199.32103157043457, \"sum\": 199.32103157043457, \"min\": 199.32103157043457}}, \"EndTime\": 1588869256.286696, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588869251.920522}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 16:34:16 INFO 139866441905984] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4442.98791885376, \"sum\": 4442.98791885376, \"min\": 4442.98791885376}, \"setuptime\": {\"count\": 1, \"max\": 12.158870697021484, \"sum\": 12.158870697021484, \"min\": 12.158870697021484}}, \"EndTime\": 1588869256.302942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1588869256.286794}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-07 16:34:27 Uploading - Uploading generated training model\n",
      "2020-05-07 16:34:27 Completed - Training job completed\n",
      "Training seconds: 75\n",
      "Billable seconds: 75\n"
     ]
    }
   ],
   "source": [
    "output_path = 's3://{}/kmeans/output/'.format(bucket_name)\n",
    "\n",
    "k_estimator = sagemaker.KMeans(role,\n",
    "                               train_instance_count = 1,\n",
    "                               train_instance_type = 'ml.m5.large',\n",
    "                               output_path = output_path,\n",
    "                               k = 7                           \n",
    "                              )\n",
    "\n",
    "k_estimator.fit(k_formatted_azdias_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Using already existing model: kmeans-2020-05-07-16-31-38-807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 ms, sys: 0 ns, total: 29 ms\n",
      "Wall time: 388 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "kmeans_transformer = k_estimator.transformer(instance_count = 1, \n",
    "                                  instance_type = 'ml.m5.large',\n",
    "                                  output_path='s3://{}/{}/kmeans/transform/test'.format(bucket_name, prefix+\"/transform\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform azdias to 7 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_sub_pca.to_csv('azdias_sub_pca',header = False,index=False, encoding=\"utf-8\")\n",
    "azdias_pca_location = session.upload_data(os.path.join('azdias_sub_pca'), key_prefix='test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loading entry points\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:35:58 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:35:58 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:35:58 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:35:58 +0000] [67] [INFO] Booting worker with pid: 67\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loading model...\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 WARNING 139779487721280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] nvidia-smi took: 0.0252180099487 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:35:58 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] loading model...\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 WARNING 139779487721280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] nvidia-smi took: 0.0251619815826 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:35:58 INFO 139779487721280] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872962.669955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872958.881036}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872962.669955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872958.881036}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-05-07T17:36:02.681:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872966.215059, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872958.789151}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872966.255083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872962.670164}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872966.816542, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872966.255247}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872967.027992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872966.215156}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872966.215059, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872958.789151}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872966.255083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872962.670164}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872966.816542, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872966.255247}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872967.027992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872966.215156}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872967.573511, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872966.816614}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872967.721168, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872967.028144}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872967.573511, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872966.816614}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015020370483398438, \"sum\": 0.015020370483398438, \"min\": 0.015020370483398438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872967.721168, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872967.028144}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872968.298867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872967.573999}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872968.539042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872967.721242}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872968.876615, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872968.298939}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872968.298867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872967.573999}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872968.539042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872967.721242}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872968.876615, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872968.298939}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872969.321989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872968.539589}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872969.598936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872968.876689}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.016093, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872969.322479}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872969.321989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872968.539589}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872969.598936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872968.876689}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.016093, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872969.322479}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.247917, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872969.59901}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.713654, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.016584}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.989125, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.248008}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.247917, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872969.59901}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.713654, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.016584}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872970.989125, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.248008}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872971.27959, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.713726}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872971.665099, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.989526}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872971.965473, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872971.279669}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872971.27959, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.713726}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872971.665099, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872970.989526}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872971.965473, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872971.279669}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872973.264673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872972.671203}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872973.264673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872972.671203}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872973.766538, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872972.959634}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872973.873266, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872973.264753}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872973.766538, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872972.959634}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872973.873266, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872973.264753}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872974.326515, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872973.767037}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872974.48612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872973.873339}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872974.934356, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872974.327034}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872974.326515, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872973.767037}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872974.48612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872973.873339}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872974.934356, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872974.327034}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872975.245392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872974.486196}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872975.245392, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872974.486196}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872975.680927, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872974.93443}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872975.856428, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872975.245497}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872975.680927, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872974.93443}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872975.856428, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872975.245497}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872976.34789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872975.6814}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872976.413969, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872975.856502}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872976.946466, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872976.348439}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872977.098889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872976.414042}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872976.34789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872975.6814}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872976.413969, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872975.856502}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872976.946466, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872976.348439}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872977.098889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872976.414042}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872977.553138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872976.947062}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872977.665383, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872977.098963}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872977.553138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872976.947062}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872977.665383, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872977.098963}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.303752, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872977.553647}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.317768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872977.66546}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.303752, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872977.553647}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.317768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872977.66546}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.870109, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.304313}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.966316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.317842}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.870109, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.304313}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872978.966316, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.317842}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872979.496378, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.966395}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872979.656765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.870262}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872979.496378, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.966395}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872979.656765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872978.870262}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872980.242676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872979.657065}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872980.264007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872979.496449}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872980.822648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872980.264087}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872981.004499, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872980.242858}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872980.242676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872979.657065}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872980.264007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872979.496449}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872980.822648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872980.264087}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872981.004499, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872980.242858}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872981.469042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872980.82272}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872981.752447, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872981.004653}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872981.469042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872980.82272}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872981.752447, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872981.004653}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872982.100794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872981.469149}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872982.100794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872981.469149}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872982.739293, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872982.100868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872983.094873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872982.474673}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872982.739293, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872982.100868}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872983.094873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872982.474673}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872983.437826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872982.739369}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872983.437826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872982.739369}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872983.704322, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872983.095364}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872984.117922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872983.437899}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872983.704322, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872983.095364}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872984.117922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872983.437899}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872984.392108, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872983.704816}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872984.744114, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872984.117995}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872985.057458, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872984.392264}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872984.392108, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872983.704816}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872984.744114, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872984.117995}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872985.057458, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872984.392264}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872985.45766, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872984.744185}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872985.698936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872985.057532}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.076242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872985.457841}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872985.45766, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872984.744185}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872985.698936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872985.057532}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.076242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872985.457841}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.332537, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872985.699013}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.694478, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.076396}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.332537, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872985.699013}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.694478, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.076396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.978048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.332606}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872986.978048, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.332606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872987.360541, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.694634}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872987.689675, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.978122}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872988.009223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872987.36069}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872987.360541, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.694634}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872987.689675, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872986.978122}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872988.009223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872987.36069}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872988.395417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872987.689748}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872988.395417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872987.689748}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872988.627273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872988.009389}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872988.627273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872988.009389}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.145701, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872988.395511}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.265274, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872988.627688}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.852195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.145851}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.955211, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.265795}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.145701, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872988.395511}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.265274, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872988.627688}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.852195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.145851}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872989.955211, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.265795}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872990.457393, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.955384}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872990.596573, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.852269}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.115822, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872990.457468}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872990.457393, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.955384}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872990.596573, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872989.852269}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.115822, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872990.457468}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.20027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872990.59695}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.742808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872991.115897}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.76189, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872991.20064}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.20027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872990.59695}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.742808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872991.115897}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872991.76189, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872991.20064}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872993.231852, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872992.37648}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872993.702456, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872992.944573}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872993.970152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872993.232028}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872993.231852, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872992.37648}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872993.702456, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872992.944573}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872993.970152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872993.232028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872994.302451, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872993.702527}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872994.302451, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872993.702527}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872994.622283, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872993.970229}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872994.936824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872994.302963}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872994.622283, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872993.970229}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872994.936824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872994.302963}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872995.289251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872994.622369}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872995.724232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872994.937336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872995.937307, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872995.289326}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872995.289251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872994.622369}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872995.724232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872994.937336}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872995.937307, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872995.289326}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872996.362026, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872995.724717}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872996.611077, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872995.937378}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.012488, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872996.36253}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872996.362026, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872995.724717}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872996.611077, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872995.937378}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.012488, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872996.36253}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.280405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872996.611151}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.621802, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.01298}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.858378, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.280481}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.280405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872996.611151}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.621802, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.01298}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872997.858378, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.280481}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872998.279039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.62228}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872998.552494, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.858451}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.013983, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872998.279522}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872998.279039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.62228}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872998.552494, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872997.858451}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.013983, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872998.279522}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.221374, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872998.552608}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.711217, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.014486}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.955796, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.221449}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.221374, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872998.552608}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.711217, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.014486}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588872999.955796, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.221449}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873000.295479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.711709}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873000.551628, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.955871}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873000.947862, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873000.295981}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873000.295479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.711709}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873000.551628, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588872999.955871}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873000.947862, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873000.295981}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873001.252694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873000.551705}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873001.652314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873000.947936}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873001.820574, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873001.253202}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873001.252694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873000.551705}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873001.652314, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873000.947936}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873001.820574, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873001.253202}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873003.191304, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873002.506435}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873003.557261, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873002.854296}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873003.808068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873003.191379}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873003.191304, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873002.506435}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873003.557261, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873002.854296}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873003.808068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873003.191379}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873004.297087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873003.55777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873004.362264, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873003.808138}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873004.866903, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873004.362345}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873005.058832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873004.297576}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873004.297087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873003.55777}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873004.362264, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873003.808138}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873004.866903, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873004.362345}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873005.058832, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873004.297576}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873005.590956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873004.867425}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873005.590956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873004.867425}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873005.629709, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873005.058908}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873005.629709, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873005.058908}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873006.179357, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873005.629791}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873006.397643, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873005.591487}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873006.854049, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873006.179431}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873007.067639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873006.39805}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873006.179357, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873005.629791}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873006.397643, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873005.591487}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873006.854049, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873006.179431}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873007.067639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873006.39805}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873007.484932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873006.854124}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873007.76746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873007.068165}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873007.484932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873006.854124}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873007.76746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873007.068165}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873008.138674, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873007.485003}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873008.422227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873007.767947}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873008.840472, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873008.13917}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873009.102434, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873008.4223}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873008.138674, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873007.485003}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873008.422227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873007.767947}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873008.840472, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873008.13917}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873009.102434, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873008.4223}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873009.516157, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873008.840551}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873009.74055, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873009.102973}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.094595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873009.516226}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873009.516157, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873008.840551}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02193450927734375, \"sum\": 0.02193450927734375, \"min\": 0.02193450927734375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873009.74055, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873009.102973}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.094595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873009.516226}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.354273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873009.741047}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019788742065429688, \"sum\": 0.019788742065429688, \"min\": 0.019788742065429688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.354273, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873009.741047}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.806112, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.09467}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.976809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.354783}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.806112, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.09467}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873010.976809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.354783}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873011.505552, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.806186}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873011.576992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.977287}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873012.112638, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873011.505627}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873011.505552, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.806186}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873011.576992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873010.977287}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873012.112638, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873011.505627}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873013.266733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873012.703924}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873013.528646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873012.963068}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873013.812469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873013.266808}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.083534, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873013.529134}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873013.266733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873012.703924}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873013.528646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873012.963068}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873013.812469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873013.266808}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.083534, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873013.529134}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.367648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873013.812542}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.637671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.084028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.914632, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.367722}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.367648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873013.812542}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.637671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.084028}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873014.914632, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.367722}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873015.199251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.638173}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873015.465722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.914704}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873015.761052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873015.199746}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.012116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873015.465795}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873015.199251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.638173}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873015.465722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873014.914704}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873015.761052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873015.199746}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.012116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873015.465795}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.316893, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873015.76154}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.560544, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.012196}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.878527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.317381}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873017.104669, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.560618}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.316893, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873015.76154}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.560544, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.012196}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01621246337890625, \"sum\": 0.01621246337890625, \"min\": 0.01621246337890625}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873016.878527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.317381}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873017.104669, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.560618}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873017.441681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.879034}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873017.441681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873016.879034}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873017.67523, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873017.104744}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.053377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873017.442165}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873017.67523, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873017.104744}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.053377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873017.442165}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.260891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873017.67532}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.657922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.053861}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.815573, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.260998}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.260891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873017.67532}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.657922, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.053861}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873018.815573, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.260998}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.217927, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.658776}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.217927, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.658776}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.3777, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.815648}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.76225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.218009}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.937928, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.3782}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.02002716064453125, \"sum\": 0.02002716064453125, \"min\": 0.02002716064453125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.3777, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873018.815648}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.76225, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.218009}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873019.937928, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.3782}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873020.323794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.762326}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873020.492296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.938432}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873020.874257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873020.323865}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.052272, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873020.492776}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873020.323794, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.762326}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873020.492296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873019.938432}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873020.874257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873020.323865}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.052272, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873020.492776}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.440857, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873020.874329}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.638562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873021.052774}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.996464, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873021.44093}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.440857, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873020.874329}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.638562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873021.052774}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873021.996464, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873021.44093}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.108514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873022.553217}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.108514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873022.553217}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.362198, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873022.769056}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04601478576660156, \"sum\": 0.04601478576660156, \"min\": 0.04601478576660156}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.665012, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.10903}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.917859, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.362274}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.362198, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873022.769056}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04601478576660156, \"sum\": 0.04601478576660156, \"min\": 0.04601478576660156}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.665012, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.10903}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873023.917859, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.362274}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873024.265743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.66553}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873024.265743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.66553}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873024.27688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.917936}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873024.27688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873023.917936}\n",
      "\u001b[0m\n",
      "CPU times: user 651 ms, sys: 43.7 ms, total: 695 ms\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_transformer.transform(azdias_pca_location, \n",
    "                             content_type=CONTENT_TYPE_CSV,                               \n",
    "                             split_type='Line')\n",
    "kmeans_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to local the result of the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/kmeans/transform/test/azdias_sub_pca.out to ./azdias_sub_pca.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://{}/{}/kmeans/transform/test/'.format(bucket_name, prefix+\"/transform\") + 'azdias_sub_pca.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def readKmeanResultToCSV(filename):\n",
    "    file = open(filename, \"r\")\n",
    "\n",
    "    Lines = file.readlines() \n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    content_list = []\n",
    "\n",
    "    for line in Lines: \n",
    "        # Strips the newline character \n",
    "        contents = line.strip()\n",
    "        \n",
    "        content_dict = ast.literal_eval(contents)\n",
    "        content_list.append(content_dict)\n",
    "    \n",
    "    return pd.DataFrame(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closest_cluster</th>\n",
       "      <th>distance_to_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.558292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.480638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.517870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.480166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.350770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closest_cluster  distance_to_cluster\n",
       "0              5.0             3.558292\n",
       "1              5.0             3.480638\n",
       "2              6.0             3.517870\n",
       "3              4.0             4.480166\n",
       "4              6.0             3.350770"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_kmeans_csv = readKmeanResultToCSV(\"azdias_sub_pca.out\")\n",
    "azdias_kmeans_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform customers to 7 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_sub_pca.to_csv('customers_sub_pca',header = False,index=False, encoding=\"utf-8\")\n",
    "customers_pca_location = session.upload_data(os.path.join('customers_sub_pca'), key_prefix='test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loading entry points\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:45:42 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:45:42 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:45:42 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:45:42 +0000] [71] [INFO] Booting worker with pid: 71\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loading model...\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 WARNING 140090257639232] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] nvidia-smi took: 0.0254518985748 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-07 17:45:42 +0000] [92] [INFO] Booting worker with pid: 92\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] loading model...\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 WARNING 140090257639232] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] nvidia-smi took: 0.0253789424896 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/07/2020 17:45:42 INFO 140090257639232] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873563.376531, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873542.880833}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0209808349609375, \"sum\": 0.0209808349609375, \"min\": 0.0209808349609375}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873566.406506, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873542.944221}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873566.407148, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873563.376661}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873567.113126, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873566.407421}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873567.120535, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873566.406612}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873567.644689, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873567.120594}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873567.771235, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873567.113486}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873568.267652, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873567.644763}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[32m2020-05-07T17:46:03.386:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873568.579184, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873567.771369}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873568.929301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873568.267821}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873569.173255, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873568.579268}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873568.579184, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873567.771369}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873568.929301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873568.267821}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873569.173255, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873568.579268}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873569.51673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873568.929762}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873569.779856, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873569.17333}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873570.132989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873569.516875}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873569.51673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873568.929762}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873569.779856, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873569.17333}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873570.132989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873569.516875}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873570.410097, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873569.780271}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873570.735035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873570.133067}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.011601, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873570.41042}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.321452, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873570.735112}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873570.410097, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873569.780271}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0171661376953125, \"sum\": 0.0171661376953125, \"min\": 0.0171661376953125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873570.735035, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873570.133067}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.011601, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873570.41042}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.321452, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873570.735112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0591278076171875, \"sum\": 0.0591278076171875, \"min\": 0.0591278076171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.600563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.012193}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.903854, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.321545}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873572.195289, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.600718}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0591278076171875, \"sum\": 0.0591278076171875, \"min\": 0.0591278076171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.600563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.012193}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873571.903854, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.321545}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873572.195289, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.600718}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873572.517094, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.903934}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873572.780096, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873572.195445}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873572.517094, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873571.903934}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873572.780096, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873572.195445}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873573.110988, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873572.51717}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873573.378323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873572.780251}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.016927719116210938, \"sum\": 0.016927719116210938, \"min\": 0.016927719116210938}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873573.110988, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873572.51717}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873573.378323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873572.780251}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873573.706079, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873573.111068}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.017215, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873573.378465}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.298424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873573.706231}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873573.706079, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873573.111068}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.017215, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873573.378465}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.298424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873573.706231}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.599397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.017292}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.903371, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.298573}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873575.174741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.599475}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873575.280876, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.903519}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.017881393432617188, \"sum\": 0.017881393432617188, \"min\": 0.017881393432617188}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.599397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.017292}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.01811981201171875, \"sum\": 0.01811981201171875, \"min\": 0.01811981201171875}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873574.903371, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.298573}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.018835067749023438, \"sum\": 0.018835067749023438, \"min\": 0.018835067749023438}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873575.174741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.599475}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.015974044799804688, \"sum\": 0.015974044799804688, \"min\": 0.015974044799804688}, \"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588873575.280876, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"KMeansModel\"}, \"StartTime\": 1588873574.903519}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 518 ms, sys: 13.3 ms, total: 531 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_transformer.transform(customers_pca_location, \n",
    "                             content_type=CONTENT_TYPE_CSV,                               \n",
    "                             split_type='Line')\n",
    "kmeans_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/kmeans/transform/test/customers_sub_pca.out to ./customers_sub_pca.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://{}/{}/kmeans/transform/test/'.format(bucket_name, prefix+\"/transform\") + 'customers_sub_pca.out'\n",
    "!aws s3 cp  $s3file_uri ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closest_cluster</th>\n",
       "      <th>distance_to_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.492790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.369774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.342125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.463631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.497910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closest_cluster  distance_to_cluster\n",
       "0              0.0            98.492790\n",
       "1              0.0            98.369774\n",
       "2              0.0            98.342125\n",
       "3              0.0            98.463631\n",
       "4              0.0            98.497910"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_kmeans_csv = readKmeanResultToCSV(\"customers_sub_pca.out\")\n",
    "customers_kmeans_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closest_cluster        0\n",
       "distance_to_cluster    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_kmeans_csv.loc[customers_kmeans_csv['closest_cluster'] == 7].count()\n",
    "\n",
    "#TODO Plot a bar graph with number of samples in each group for azdias and customers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
