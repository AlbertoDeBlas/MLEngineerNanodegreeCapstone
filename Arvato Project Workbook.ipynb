{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3 client to get S3 data\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name='sagemaker-eu-west-1-848439228145'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list withe files in the bucket and print the file names to be sure that we will be retrieving from the correct location and obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Capstone/Udacity_AZDIAS_052018.csv', 'Capstone/Udacity_CUSTOMERS_052018.csv', 'Capstone/Udacity_MAILOUT_052018_TEST.csv', 'Capstone/Udacity_MAILOUT_052018_TRAIN.csv', 'arvato/azdias.csv', 'arvato/transform/pca/transform/test/azdias.csv.out']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "# get a list of objects in the bucket\n",
    "obj_list=s3_client.list_objects(Bucket=bucket_name)\n",
    "\n",
    "def filter_csv(string):\n",
    "    return re.search(r'.csv', string)\n",
    "\n",
    "\n",
    "files=[]\n",
    "for contents in obj_list['Contents']:\n",
    "    files.append(contents['Key'])\n",
    "    \n",
    "filtered_list = list(filter(filter_csv, files))\n",
    "    \n",
    "    \n",
    "# print csv objects in in S3 bucket  \n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_from_s3(s3_client, bucket, name):\n",
    "    data_object = s3_client.get_object(Bucket=bucket, Key=name)\n",
    "    data_body = data_object[\"Body\"].read()\n",
    "    data_stream = io.BytesIO(data_body)\n",
    "    \n",
    "    return pd.read_csv(data_stream, header=0, delimiter=\",\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9628</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0    9626         2         1.0      10.0          NaN   \n",
       "1           1    9628        -1         9.0      11.0          NaN   \n",
       "2           2  143872        -1         1.0       6.0          NaN   \n",
       "3           3  143873         1         1.0       8.0          NaN   \n",
       "4           4  143874        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VK_ZG11  \\\n",
       "0          NaN          NaN          NaN                  10.0  ...      2.0   \n",
       "1          NaN          NaN          NaN                   NaN  ...      3.0   \n",
       "2          NaN          NaN          NaN                   0.0  ...     11.0   \n",
       "3          NaN          NaN          NaN                   8.0  ...      2.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...      4.0   \n",
       "\n",
       "   W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0             6.0             9.0       7.0         3  COSMETIC_AND_FOOD   \n",
       "1             0.0             9.0       NaN         3               FOOD   \n",
       "2             6.0             9.0       2.0         3  COSMETIC_AND_FOOD   \n",
       "3             NaN             9.0       7.0         1           COSMETIC   \n",
       "4             2.0             9.0       3.0         1               FOOD   \n",
       "\n",
       "   CUSTOMER_GROUP  ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0     MULTI_BUYER                0         1                    4  \n",
       "1    SINGLE_BUYER                0         1                    4  \n",
       "2     MULTI_BUYER                0         2                    4  \n",
       "3     MULTI_BUYER                0         1                    4  \n",
       "4     MULTI_BUYER                0         1                    3  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df = None\n",
    "customers_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[1])\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0  910215        -1         NaN       NaN          NaN   \n",
       "1           1  910220        -1         9.0       0.0          NaN   \n",
       "2           2  910225        -1         9.0      17.0          NaN   \n",
       "3           3  910226         2         1.0      13.0          NaN   \n",
       "4           4  910241        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VHN  \\\n",
       "0          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "1          NaN          NaN          NaN                  21.0  ...  4.0   \n",
       "2          NaN          NaN          NaN                  17.0  ...  2.0   \n",
       "3          NaN          NaN          NaN                  13.0  ...  0.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...  2.0   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1       8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2       9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3       7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4       3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3         1                    2  \n",
       "1         5         2                    1  \n",
       "2         5         2                    3  \n",
       "3         3         2                    4  \n",
       "4         4         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df = None\n",
    "azdias_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[0])\n",
    "azdias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>11766.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>139810.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>137910.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>141725.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>1.747525</td>\n",
       "      <td>11.352009</td>\n",
       "      <td>12.337243</td>\n",
       "      <td>13.672353</td>\n",
       "      <td>14.647059</td>\n",
       "      <td>15.377119</td>\n",
       "      <td>10.331579</td>\n",
       "      <td>...</td>\n",
       "      <td>4.374417</td>\n",
       "      <td>4.564769</td>\n",
       "      <td>3.168868</td>\n",
       "      <td>4.152716</td>\n",
       "      <td>8.646371</td>\n",
       "      <td>3.723133</td>\n",
       "      <td>2.576806</td>\n",
       "      <td>0.090247</td>\n",
       "      <td>1.376432</td>\n",
       "      <td>3.060907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55325.311233</td>\n",
       "      <td>55325.311233</td>\n",
       "      <td>1.391672</td>\n",
       "      <td>1.966334</td>\n",
       "      <td>6.275026</td>\n",
       "      <td>4.006050</td>\n",
       "      <td>3.243335</td>\n",
       "      <td>2.753787</td>\n",
       "      <td>2.307653</td>\n",
       "      <td>4.134828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.924355</td>\n",
       "      <td>2.887035</td>\n",
       "      <td>2.233516</td>\n",
       "      <td>1.974375</td>\n",
       "      <td>1.154001</td>\n",
       "      <td>2.095540</td>\n",
       "      <td>1.168486</td>\n",
       "      <td>0.286536</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>1.086254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47912.750000</td>\n",
       "      <td>47913.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>143738.250000</td>\n",
       "      <td>143739.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191651.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0            LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  191652.000000  191652.000000  191652.000000  145056.000000   \n",
       "mean    95825.500000   95826.500000       0.344359       1.747525   \n",
       "std     55325.311233   55325.311233       1.391672       1.966334   \n",
       "min         0.000000       1.000000      -1.000000       1.000000   \n",
       "25%     47912.750000   47913.750000      -1.000000       1.000000   \n",
       "50%     95825.500000   95826.500000       0.000000       1.000000   \n",
       "75%    143738.250000  143739.250000       2.000000       1.000000   \n",
       "max    191651.000000  191652.000000       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  145056.000000  11766.000000  5100.000000  1275.000000   236.000000   \n",
       "mean       11.352009     12.337243    13.672353    14.647059    15.377119   \n",
       "std         6.275026      4.006050     3.243335     2.753787     2.307653   \n",
       "min         0.000000      2.000000     2.000000     5.000000     8.000000   \n",
       "25%         8.000000      9.000000    11.000000    13.000000    14.000000   \n",
       "50%        11.000000     13.000000    14.000000    15.000000    16.000000   \n",
       "75%        16.000000     16.000000    16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000    18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...       VK_DHT4A     VK_DISTANZ        VK_ZG11  \\\n",
       "count         139810.000000  ...  143781.000000  143781.000000  143781.000000   \n",
       "mean              10.331579  ...       4.374417       4.564769       3.168868   \n",
       "std                4.134828  ...       2.924355       2.887035       2.233516   \n",
       "min                0.000000  ...       1.000000       1.000000       1.000000   \n",
       "25%                9.000000  ...       2.000000       2.000000       1.000000   \n",
       "50%               10.000000  ...       4.000000       4.000000       3.000000   \n",
       "75%               13.000000  ...       7.000000       7.000000       4.000000   \n",
       "max               25.000000  ...      11.000000      13.000000      11.000000   \n",
       "\n",
       "       W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE       ZABEOTYP  \\\n",
       "count   137910.000000   145056.000000  141725.000000  191652.000000   \n",
       "mean         4.152716        8.646371       3.723133       2.576806   \n",
       "std          1.974375        1.154001       2.095540       1.168486   \n",
       "min          0.000000        1.000000       0.000000       1.000000   \n",
       "25%          2.000000        9.000000       2.000000       1.000000   \n",
       "50%          5.000000        9.000000       3.000000       3.000000   \n",
       "75%          6.000000        9.000000       5.000000       3.000000   \n",
       "max          6.000000        9.000000       8.000000       6.000000   \n",
       "\n",
       "       ONLINE_PURCHASE      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count    191652.000000  191652.000000         191652.000000  \n",
       "mean          0.090247       1.376432              3.060907  \n",
       "std           0.286536       0.484492              1.086254  \n",
       "min           0.000000       1.000000              1.000000  \n",
       "25%           0.000000       1.000000              3.000000  \n",
       "50%           0.000000       1.000000              3.000000  \n",
       "75%           0.000000       2.000000              4.000000  \n",
       "max           1.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(customers_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891221.000000</td>\n",
       "      <td>8.912210e+05</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>81058.000000</td>\n",
       "      <td>29499.000000</td>\n",
       "      <td>6170.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>628274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>770025.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>783619.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>798073.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-0.358435</td>\n",
       "      <td>4.421928</td>\n",
       "      <td>10.864126</td>\n",
       "      <td>11.745392</td>\n",
       "      <td>13.402658</td>\n",
       "      <td>14.476013</td>\n",
       "      <td>15.089627</td>\n",
       "      <td>13.700717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417322</td>\n",
       "      <td>6.001214</td>\n",
       "      <td>7.532130</td>\n",
       "      <td>5.945972</td>\n",
       "      <td>3.933406</td>\n",
       "      <td>7.908791</td>\n",
       "      <td>4.052836</td>\n",
       "      <td>3.362438</td>\n",
       "      <td>1.522098</td>\n",
       "      <td>2.777398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257273.486465</td>\n",
       "      <td>2.572735e+05</td>\n",
       "      <td>1.198724</td>\n",
       "      <td>3.638805</td>\n",
       "      <td>7.639683</td>\n",
       "      <td>4.097660</td>\n",
       "      <td>3.243300</td>\n",
       "      <td>2.712427</td>\n",
       "      <td>2.452932</td>\n",
       "      <td>5.079849</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166572</td>\n",
       "      <td>2.856091</td>\n",
       "      <td>3.247789</td>\n",
       "      <td>2.771464</td>\n",
       "      <td>1.964701</td>\n",
       "      <td>1.923137</td>\n",
       "      <td>1.949539</td>\n",
       "      <td>1.352704</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>1.068775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916530e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222805.000000</td>\n",
       "      <td>4.144580e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668415.000000</td>\n",
       "      <td>8.600680e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891220.000000</td>\n",
       "      <td>1.082873e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0           LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  891221.000000  8.912210e+05  891221.000000  817722.000000   \n",
       "mean   445610.000000  6.372630e+05      -0.358435       4.421928   \n",
       "std    257273.486465  2.572735e+05       1.198724       3.638805   \n",
       "min         0.000000  1.916530e+05      -1.000000       1.000000   \n",
       "25%    222805.000000  4.144580e+05      -1.000000       1.000000   \n",
       "50%    445610.000000  6.372630e+05      -1.000000       3.000000   \n",
       "75%    668415.000000  8.600680e+05      -1.000000       9.000000   \n",
       "max    891220.000000  1.082873e+06       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  817722.000000  81058.000000  29499.000000  6170.000000  1205.000000   \n",
       "mean       10.864126     11.745392     13.402658    14.476013    15.089627   \n",
       "std         7.639683      4.097660      3.243300     2.712427     2.452932   \n",
       "min         0.000000      2.000000      2.000000     4.000000     7.000000   \n",
       "25%         0.000000      8.000000     11.000000    13.000000    14.000000   \n",
       "50%        13.000000     12.000000     14.000000    15.000000    15.000000   \n",
       "75%        17.000000     15.000000     16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000     18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...            VHN       VK_DHT4A     VK_DISTANZ  \\\n",
       "count         628274.000000  ...  770025.000000  815304.000000  815304.000000   \n",
       "mean              13.700717  ...       2.417322       6.001214       7.532130   \n",
       "std                5.079849  ...       1.166572       2.856091       3.247789   \n",
       "min                0.000000  ...       0.000000       1.000000       1.000000   \n",
       "25%               11.000000  ...       2.000000       3.000000       5.000000   \n",
       "50%               14.000000  ...       2.000000       6.000000       8.000000   \n",
       "75%               17.000000  ...       3.000000       9.000000      10.000000   \n",
       "max               25.000000  ...       4.000000      11.000000      13.000000   \n",
       "\n",
       "             VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE  \\\n",
       "count  815304.000000   783619.000000   817722.000000  798073.000000   \n",
       "mean        5.945972        3.933406        7.908791       4.052836   \n",
       "std         2.771464        1.964701        1.923137       1.949539   \n",
       "min         1.000000        0.000000        1.000000       0.000000   \n",
       "25%         4.000000        2.000000        8.000000       3.000000   \n",
       "50%         6.000000        4.000000        9.000000       3.000000   \n",
       "75%         8.000000        6.000000        9.000000       5.000000   \n",
       "max        11.000000        6.000000        9.000000       8.000000   \n",
       "\n",
       "            ZABEOTYP      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count  891221.000000  891221.000000         891221.000000  \n",
       "mean        3.362438       1.522098              2.777398  \n",
       "std         1.352704       0.499512              1.068775  \n",
       "min         1.000000       1.000000              1.000000  \n",
       "25%         3.000000       1.000000              2.000000  \n",
       "50%         3.000000       2.000000              3.000000  \n",
       "75%         4.000000       2.000000              4.000000  \n",
       "max         6.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 361 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(azdias_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTER_KIND4                    99.864792\n",
       "ALTER_KIND3                    99.307691\n",
       "ALTER_KIND2                    96.690047\n",
       "ALTER_KIND1                    90.904837\n",
       "EXTSEL992                      73.399639\n",
       "KK_KUNDENTYP                   65.596749\n",
       "ALTERSKATEGORIE_FEIN           29.504130\n",
       "D19_VERSI_ONLINE_QUOTE_12      28.849522\n",
       "D19_LETZTER_KAUF_BRANCHE       28.849522\n",
       "D19_BANKEN_ONLINE_QUOTE_12     28.849522\n",
       "D19_TELKO_ONLINE_QUOTE_12      28.849522\n",
       "D19_VERSAND_ONLINE_QUOTE_12    28.849522\n",
       "D19_KONSUMTYP                  28.849522\n",
       "D19_SOZIALES                   28.849522\n",
       "D19_GESAMT_ONLINE_QUOTE_12     28.849522\n",
       "D19_LOTTO                      28.849522\n",
       "KBA05_SEG8                     14.959701\n",
       "KBA05_SEG7                     14.959701\n",
       "KBA05_KW2                      14.959701\n",
       "KBA05_KW3                      14.959701\n",
       "KBA05_MAXAH                    14.959701\n",
       "KBA05_MAXBJ                    14.959701\n",
       "KBA05_MAXHERST                 14.959701\n",
       "KBA05_MAXSEG                   14.959701\n",
       "KBA05_MAXVORB                  14.959701\n",
       "KBA05_MOD1                     14.959701\n",
       "KBA05_MOD2                     14.959701\n",
       "KBA05_MOD3                     14.959701\n",
       "KBA05_MOD4                     14.959701\n",
       "KBA05_MOD8                     14.959701\n",
       "                                 ...    \n",
       "D19_RATGEBER                    0.000000\n",
       "FINANZ_ANLEGER                  0.000000\n",
       "D19_REISEN                      0.000000\n",
       "D19_SAMMELARTIKEL               0.000000\n",
       "D19_SCHUHE                      0.000000\n",
       "D19_SONSTIGE                    0.000000\n",
       "D19_TECHNIK                     0.000000\n",
       "D19_TELKO_ANZ_12                0.000000\n",
       "D19_TELKO_ANZ_24                0.000000\n",
       "D19_TELKO_DATUM                 0.000000\n",
       "D19_TELKO_MOBILE                0.000000\n",
       "D19_TELKO_OFFLINE_DATUM         0.000000\n",
       "D19_TELKO_ONLINE_DATUM          0.000000\n",
       "D19_TELKO_REST                  0.000000\n",
       "D19_TIERARTIKEL                 0.000000\n",
       "D19_VERSAND_ANZ_12              0.000000\n",
       "D19_VERSAND_ANZ_24              0.000000\n",
       "D19_VERSAND_DATUM               0.000000\n",
       "D19_VERSAND_OFFLINE_DATUM       0.000000\n",
       "D19_VERSAND_ONLINE_DATUM        0.000000\n",
       "D19_VERSAND_REST                0.000000\n",
       "D19_VERSI_ANZ_12                0.000000\n",
       "D19_VERSI_ANZ_24                0.000000\n",
       "D19_VERSI_DATUM                 0.000000\n",
       "D19_VERSI_OFFLINE_DATUM         0.000000\n",
       "D19_VERSI_ONLINE_DATUM          0.000000\n",
       "D19_VERSICHERUNGEN              0.000000\n",
       "D19_VOLLSORTIMENT               0.000000\n",
       "D19_WEIN_FEINKOST               0.000000\n",
       "Unnamed: 0                      0.000000\n",
       "Length: 367, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = azdias_df.shape[0]\n",
    "missing_values_azdias = azdias_df.isnull().sum().sort_values(ascending = False).divide(other = (rows/100))\n",
    "\n",
    "display(missing_values_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have more than 28% of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 351)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a dict with the names of the columns and then drop this columns from dataframe\n",
    "drop_columns = missing_values_azdias[missing_values_azdias > 28]\n",
    "\n",
    "azdias_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)\n",
    "\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have less than 0.5 variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_description = azdias_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = azdias_description.loc[['std']].values.reshape(346,)\n",
    "std_serie = pd.Series(std_df, index =azdias_description.columns) \n",
    "\n",
    "drop_lowdispersion_cols = std_serie[std_serie < 0.5]\n",
    "\n",
    "azdias_df.drop(columns = list(drop_lowdispersion_cols.index), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 2486.31 Mb\n"
     ]
    }
   ],
   "source": [
    "def memory_usage(df):\n",
    "    return(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2))\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'LNR', 'AGER_TYP', 'AKT_DAT_KL', 'ALTER_HH', 'ANZ_HAUSHALTE_AKTIV', 'ANZ_KINDER', 'ANZ_PERSONEN', 'ANZ_STATISTISCHE_HAUSHALTE', 'ARBEIT', 'BALLRAUM', 'CAMEO_DEU_2015', 'CAMEO_DEUG_2015', 'CAMEO_INTL_2015', 'CJT_GESAMTTYP', 'CJT_KATALOGNUTZER', 'CJT_TYP_1', 'CJT_TYP_2', 'CJT_TYP_3', 'CJT_TYP_4', 'CJT_TYP_5', 'CJT_TYP_6', 'D19_BANKEN_ANZ_12', 'D19_BANKEN_ANZ_24', 'D19_BANKEN_DATUM', 'D19_BANKEN_DIREKT', 'D19_BANKEN_GROSS', 'D19_BANKEN_LOKAL', 'D19_BANKEN_OFFLINE_DATUM', 'D19_BANKEN_ONLINE_DATUM', 'D19_BANKEN_REST', 'D19_BEKLEIDUNG_GEH', 'D19_BEKLEIDUNG_REST', 'D19_BILDUNG', 'D19_BIO_OEKO', 'D19_BUCH_CD', 'D19_DIGIT_SERV', 'D19_DROGERIEARTIKEL', 'D19_ENERGIE', 'D19_FREIZEIT', 'D19_GARTEN', 'D19_GESAMT_ANZ_12', 'D19_GESAMT_ANZ_24', 'D19_GESAMT_DATUM', 'D19_GESAMT_OFFLINE_DATUM', 'D19_GESAMT_ONLINE_DATUM', 'D19_HANDWERK', 'D19_HAUS_DEKO', 'D19_KINDERARTIKEL', 'D19_KONSUMTYP_MAX', 'D19_KOSMETIK', 'D19_LEBENSMITTEL', 'D19_NAHRUNGSERGAENZUNG', 'D19_RATGEBER', 'D19_REISEN', 'D19_SAMMELARTIKEL', 'D19_SCHUHE', 'D19_SONSTIGE', 'D19_TECHNIK', 'D19_TELKO_DATUM', 'D19_TELKO_MOBILE', 'D19_TELKO_OFFLINE_DATUM', 'D19_TELKO_REST', 'D19_TIERARTIKEL', 'D19_VERSAND_ANZ_12', 'D19_VERSAND_ANZ_24', 'D19_VERSAND_DATUM', 'D19_VERSAND_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM', 'D19_VERSAND_REST', 'D19_VERSI_ANZ_24', 'D19_VERSI_DATUM', 'D19_VERSI_OFFLINE_DATUM', 'D19_VERSICHERUNGEN', 'D19_VOLLSORTIMENT', 'D19_WEIN_FEINKOST', 'EINGEFUEGT_AM', 'EINGEZOGENAM_HH_JAHR', 'EWDICHTE', 'FINANZ_ANLEGER', 'FINANZ_HAUSBAUER', 'FINANZ_MINIMALIST', 'FINANZ_SPARER', 'FINANZ_UNAUFFAELLIGER', 'FINANZ_VORSORGER', 'FINANZTYP', 'FIRMENDICHTE', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GEBURTSJAHR', 'GEMEINDETYP', 'GFK_URLAUBERTYP', 'HEALTH_TYP', 'HH_EINKOMMEN_SCORE', 'INNENSTADT', 'KBA05_ALTER1', 'KBA05_ALTER2', 'KBA05_ALTER3', 'KBA05_ALTER4', 'KBA05_ANHANG', 'KBA05_ANTG1', 'KBA05_ANTG2', 'KBA05_ANTG3', 'KBA05_ANTG4', 'KBA05_AUTOQUOT', 'KBA05_BAUMAX', 'KBA05_CCM1', 'KBA05_CCM2', 'KBA05_CCM3', 'KBA05_CCM4', 'KBA05_DIESEL', 'KBA05_FRAU', 'KBA05_GBZ', 'KBA05_HERST1', 'KBA05_HERST2', 'KBA05_HERST3', 'KBA05_HERST4', 'KBA05_HERST5', 'KBA05_HERSTTEMP', 'KBA05_KRSAQUOT', 'KBA05_KRSHERST1', 'KBA05_KRSHERST2', 'KBA05_KRSHERST3', 'KBA05_KRSKLEIN', 'KBA05_KRSOBER', 'KBA05_KRSVAN', 'KBA05_KRSZUL', 'KBA05_KW1', 'KBA05_KW2', 'KBA05_KW3', 'KBA05_MAXAH', 'KBA05_MAXBJ', 'KBA05_MAXHERST', 'KBA05_MAXSEG', 'KBA05_MAXVORB', 'KBA05_MOD1', 'KBA05_MOD2', 'KBA05_MOD3', 'KBA05_MOD4', 'KBA05_MOD8', 'KBA05_MODTEMP', 'KBA05_MOTOR', 'KBA05_MOTRAD', 'KBA05_SEG1', 'KBA05_SEG10', 'KBA05_SEG2', 'KBA05_SEG3', 'KBA05_SEG4', 'KBA05_SEG5', 'KBA05_SEG6', 'KBA05_SEG7', 'KBA05_SEG8', 'KBA05_SEG9', 'KBA05_VORB0', 'KBA05_VORB1', 'KBA05_VORB2', 'KBA05_ZUL1', 'KBA05_ZUL2', 'KBA05_ZUL3', 'KBA05_ZUL4', 'KBA13_ALTERHALTER_30', 'KBA13_ALTERHALTER_45', 'KBA13_ALTERHALTER_60', 'KBA13_ALTERHALTER_61', 'KBA13_ANTG1', 'KBA13_ANTG2', 'KBA13_ANTG3', 'KBA13_ANTG4', 'KBA13_ANZAHL_PKW', 'KBA13_AUDI', 'KBA13_AUTOQUOTE', 'KBA13_BAUMAX', 'KBA13_BJ_1999', 'KBA13_BJ_2000', 'KBA13_BJ_2004', 'KBA13_BJ_2006', 'KBA13_BJ_2008', 'KBA13_BJ_2009', 'KBA13_BMW', 'KBA13_CCM_0_1400', 'KBA13_CCM_1000', 'KBA13_CCM_1200', 'KBA13_CCM_1400', 'KBA13_CCM_1401_2500', 'KBA13_CCM_1500', 'KBA13_CCM_1600', 'KBA13_CCM_1800', 'KBA13_CCM_2000', 'KBA13_CCM_2500', 'KBA13_CCM_2501', 'KBA13_CCM_3000', 'KBA13_CCM_3001', 'KBA13_FAB_ASIEN', 'KBA13_FAB_SONSTIGE', 'KBA13_FIAT', 'KBA13_FORD', 'KBA13_GBZ', 'KBA13_HALTER_20', 'KBA13_HALTER_25', 'KBA13_HALTER_30', 'KBA13_HALTER_35', 'KBA13_HALTER_40', 'KBA13_HALTER_45', 'KBA13_HALTER_50', 'KBA13_HALTER_55', 'KBA13_HALTER_60', 'KBA13_HALTER_65', 'KBA13_HALTER_66', 'KBA13_HERST_ASIEN', 'KBA13_HERST_AUDI_VW', 'KBA13_HERST_BMW_BENZ', 'KBA13_HERST_EUROPA', 'KBA13_HERST_FORD_OPEL', 'KBA13_HERST_SONST', 'KBA13_HHZ', 'KBA13_KMH_0_140', 'KBA13_KMH_110', 'KBA13_KMH_140', 'KBA13_KMH_140_210', 'KBA13_KMH_180', 'KBA13_KMH_210', 'KBA13_KMH_211', 'KBA13_KMH_250', 'KBA13_KMH_251', 'KBA13_KRSAQUOT', 'KBA13_KRSHERST_AUDI_VW', 'KBA13_KRSHERST_BMW_BENZ', 'KBA13_KRSHERST_FORD_OPEL', 'KBA13_KRSSEG_OBER', 'KBA13_KRSSEG_VAN', 'KBA13_KRSZUL_NEU', 'KBA13_KW_0_60', 'KBA13_KW_110', 'KBA13_KW_120', 'KBA13_KW_121', 'KBA13_KW_30', 'KBA13_KW_40', 'KBA13_KW_50', 'KBA13_KW_60', 'KBA13_KW_61_120', 'KBA13_KW_70', 'KBA13_KW_80', 'KBA13_KW_90', 'KBA13_MAZDA', 'KBA13_MERCEDES', 'KBA13_MOTOR', 'KBA13_NISSAN', 'KBA13_OPEL', 'KBA13_PEUGEOT', 'KBA13_RENAULT', 'KBA13_SEG_GELAENDEWAGEN', 'KBA13_SEG_GROSSRAUMVANS', 'KBA13_SEG_KLEINST', 'KBA13_SEG_KLEINWAGEN', 'KBA13_SEG_KOMPAKTKLASSE', 'KBA13_SEG_MINIVANS', 'KBA13_SEG_MINIWAGEN', 'KBA13_SEG_MITTELKLASSE', 'KBA13_SEG_OBEREMITTELKLASSE', 'KBA13_SEG_OBERKLASSE', 'KBA13_SEG_SONSTIGE', 'KBA13_SEG_SPORTWAGEN', 'KBA13_SEG_UTILITIES', 'KBA13_SEG_VAN', 'KBA13_SEG_WOHNMOBILE', 'KBA13_SITZE_4', 'KBA13_SITZE_5', 'KBA13_SITZE_6', 'KBA13_TOYOTA', 'KBA13_VORB_0', 'KBA13_VORB_1', 'KBA13_VORB_1_2', 'KBA13_VORB_2', 'KBA13_VORB_3', 'KBA13_VW', 'KKK', 'KOMBIALTER', 'KONSUMNAEHE', 'LP_FAMILIE_FEIN', 'LP_FAMILIE_GROB', 'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'LP_STATUS_FEIN', 'LP_STATUS_GROB', 'MIN_GEBAEUDEJAHR', 'MOBI_RASTER', 'MOBI_REGIO', 'NATIONALITAET_KZ', 'ONLINE_AFFINITAET', 'ORTSGR_KLS9', 'OST_WEST_KZ', 'PLZ8_ANTG1', 'PLZ8_ANTG2', 'PLZ8_ANTG3', 'PLZ8_ANTG4', 'PLZ8_BAUMAX', 'PLZ8_GBZ', 'PLZ8_HHZ', 'PRAEGENDE_JUGENDJAHRE', 'REGIOTYP', 'RELAT_AB', 'RETOURTYP_BK_S', 'RT_KEIN_ANREIZ', 'RT_SCHNAEPPCHEN', 'RT_UEBERGROESSE', 'SEMIO_DOM', 'SEMIO_ERL', 'SEMIO_FAM', 'SEMIO_KAEM', 'SEMIO_KRIT', 'SEMIO_KULT', 'SEMIO_LUST', 'SEMIO_MAT', 'SEMIO_PFLICHT', 'SEMIO_RAT', 'SEMIO_REL', 'SEMIO_SOZ', 'SEMIO_TRADV', 'SEMIO_VERT', 'SHOPPER_TYP', 'STRUKTURTYP', 'UMFELD_ALT', 'UMFELD_JUNG', 'VERDICHTUNGSRAUM', 'VERS_TYP', 'VHA', 'VHN', 'VK_DHT4A', 'VK_DISTANZ', 'VK_ZG11', 'W_KEIT_KIND_HH', 'WOHNDAUER_2008', 'WOHNLAGE', 'ZABEOTYP', 'ALTERSKATEGORIE_GROB']\n"
     ]
    }
   ],
   "source": [
    "print(list(azdias_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['CAMEO_INTL_2015'].replace('XX',np.nan, inplace = True)\n",
    "azdias_df['CAMEO_DEUG_2015'].replace('X',np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 650.54 Mb\n"
     ]
    }
   ],
   "source": [
    "#It is necessary to reduce the size of the dataframe in order to optimize the memory usage\n",
    "\n",
    "def to_category(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('category', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def to_int(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('uint8', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "categorical_columns = [\n",
    "                        'ALTERSKATEGORIE_GROB','AGER_TYP','ALTER_HH',\n",
    "                      'BALLRAUM','CAMEO_DEUG_2015','CAMEO_DEU_2015','D19_BANKEN_ANZ_24',\n",
    "                      'CJT_GESAMTTYP','D19_BANKEN_ANZ_12','D19_BANKEN_DATUM',\n",
    "                      'D19_BANKEN_OFFLINE_DATUM',\n",
    "                      'D19_BANKEN_ONLINE_DATUM','D19_BANKEN_DIREKT','D19_BANKEN_GROSS',\n",
    "                      'D19_BANKEN_LOKAL','D19_BANKEN_REST',\n",
    "                      'D19_BEKLEIDUNG_GEH','D19_BEKLEIDUNG_REST','D19_BILDUNG',\n",
    "                      'D19_BIO_OEKO','D19_BUCH_CD','D19_DIGIT_SERV','D19_DROGERIEARTIKEL',\n",
    "                      'D19_ENERGIE','D19_FREIZEIT','D19_GARTEN','D19_GESAMT_ANZ_12',\n",
    "                      'D19_GESAMT_ANZ_24','D19_GESAMT_DATUM','D19_GESAMT_OFFLINE_DATUM','D19_GESAMT_ONLINE_DATUM',\n",
    "                      'D19_HANDWERK','D19_HAUS_DEKO','D19_KINDERARTIKEL',\n",
    "                      'D19_KONSUMTYP_MAX','D19_KOSMETIK','D19_LEBENSMITTEL','D19_NAHRUNGSERGAENZUNG',\n",
    "                      'D19_RATGEBER','D19_REISEN','D19_SAMMELARTIKEL','D19_SCHUHE','D19_SONSTIGE',\n",
    "                      'D19_TECHNIK','D19_TELKO_DATUM',\n",
    "                      'D19_TELKO_MOBILE','D19_TELKO_OFFLINE_DATUM',\n",
    "                       'D19_TELKO_REST','D19_TIERARTIKEL','D19_VERSAND_ANZ_12',\n",
    "                      'D19_VERSAND_ANZ_24','D19_VERSAND_DATUM','D19_VERSAND_DATUM',\n",
    "                      'D19_VERSAND_ONLINE_DATUM','D19_VERSAND_REST','D19_VERSICHERUNGEN',\n",
    "                      'D19_VERSI_ANZ_24','D19_VOLLSORTIMENT','D19_WEIN_FEINKOST','EWDICHTE',\n",
    "                      'FINANZTYP','FINANZ_ANLEGER','FINANZ_HAUSBAUER','FINANZ_MINIMALIST',\n",
    "                      'FINANZ_SPARER','FINANZ_UNAUFFAELLIGER','FINANZ_VORSORGER',\n",
    "                      'GEBAEUDETYP','GEBAEUDETYP_RASTER','GFK_URLAUBERTYP',\n",
    "                      'STRUKTURTYP','HEALTH_TYP',\n",
    "                      'HH_EINKOMMEN_SCORE','INNENSTADT','KBA05_ALTER1','KBA05_ALTER2',\n",
    "                      'KBA05_ALTER3','KBA05_ALTER4','KBA05_ANHANG','KBA05_ANTG1','KBA05_ANTG2',\n",
    "                      'KBA05_ANTG3','KBA05_ANTG4','KBA05_AUTOQUOT','KBA05_BAUMAX','KBA05_CCM1',\n",
    "                    'KBA05_CCM2','KBA05_CCM3','KBA05_CCM4','KBA05_DIESEL','KBA05_FRAU','KBA05_GBZ',\n",
    "                    'KBA05_HERST1','KBA05_HERST2','KBA05_HERST3','KBA05_HERST4','KBA05_HERST5',\n",
    "                    'KBA05_HERSTTEMP','KBA05_KRSAQUOT','KBA05_KRSHERST1','KBA05_KRSHERST2',\n",
    "                    'KBA05_KRSHERST3','KBA05_KRSKLEIN','KBA05_KRSOBER','KBA05_KRSVAN',\n",
    "                    'KBA05_KRSZUL','KBA05_KW1','KBA05_KW2','KBA05_KW3','KBA05_MAXAH','KBA05_MAXBJ',\n",
    "                    'KBA05_MAXHERST','KBA05_MAXSEG','KBA05_MAXVORB','KBA05_MOD1','KBA05_MOD2',\n",
    "                    'KBA05_MOD3','KBA05_MOD4','KBA05_MOD8','KBA05_MODTEMP','KBA05_MOTOR',\n",
    "                    'KBA05_MOTRAD','KBA05_SEG1','KBA05_SEG10','KBA05_SEG2','KBA05_SEG3',\n",
    "                    'KBA05_SEG4','KBA05_SEG5','KBA05_SEG6','KBA05_SEG7','KBA05_SEG8','KBA05_SEG9',\n",
    "                    'KBA05_VORB0','KBA05_VORB1','KBA05_VORB2','KBA05_ZUL1','KBA05_ZUL2',\n",
    "                    'KBA05_ZUL3','KBA05_ZUL4','KBA13_ALTERHALTER_30','KBA13_ALTERHALTER_45',\n",
    "                    'KBA13_ALTERHALTER_60','KBA13_ALTERHALTER_61','KBA13_AUDI','KBA13_AUTOQUOTE',\n",
    "                    'KBA13_BJ_1999','KBA13_BJ_2000','KBA13_BJ_2004','KBA13_BJ_2006',\n",
    "                    'KBA13_BJ_2008','KBA13_BJ_2009','KBA13_BMW','KBA13_CCM_1000','KBA13_CCM_1200',\n",
    "                    'KBA13_CCM_1400','KBA13_CCM_0_1400','KBA13_CCM_1500','KBA13_CCM_1401_2500',\n",
    "                    'KBA13_CCM_1600','KBA13_CCM_1800','KBA13_CCM_2000','KBA13_CCM_2500',\n",
    "                    'KBA13_CCM_2501','KBA13_CCM_3000','KBA13_CCM_3001','KBA13_FAB_ASIEN',\n",
    "                    'KBA13_FAB_SONSTIGE','KBA13_FIAT','KBA13_FORD','KBA13_HALTER_20',\n",
    "                    'KBA13_HALTER_25','KBA13_HALTER_30','KBA13_HALTER_35','KBA13_HALTER_40',\n",
    "                    'KBA13_HALTER_45','KBA13_HALTER_50','KBA13_HALTER_55','KBA13_HALTER_60',\n",
    "                    'KBA13_HALTER_65','KBA13_HALTER_66','KBA13_HERST_ASIEN','KBA13_HERST_AUDI_VW',\n",
    "                    'KBA13_HERST_BMW_BENZ','KBA13_HERST_EUROPA','KBA13_HERST_FORD_OPEL',\n",
    "                    'KBA13_HERST_SONST','KBA13_KMH_110','KBA13_KMH_140','KBA13_KMH_180',\n",
    "                    'KBA13_KMH_0_140','KBA13_KMH_140_210','KBA13_KMH_211','KBA13_KMH_250',\n",
    "                    'KBA13_KMH_251','KBA13_KRSAQUOT','KBA13_KRSHERST_AUDI_VW',\n",
    "                    'KBA13_KRSHERST_BMW_BENZ','KBA13_KRSHERST_FORD_OPEL',\n",
    "                    'KBA13_KRSSEG_OBER','KBA13_KRSSEG_VAN','KBA13_KRSZUL_NEU','KBA13_KW_30',\n",
    "                    'KBA13_KW_40','KBA13_KW_50','KBA13_KW_60','KBA13_KW_0_60','KBA13_KW_70',\n",
    "                    'KBA13_KW_61_120','KBA13_KW_80','KBA13_KW_90','KBA13_KW_110','KBA13_KW_120',\n",
    "                    'KBA13_KW_121','KBA13_MAZDA','KBA13_MERCEDES','KBA13_MOTOR','KBA13_NISSAN',\n",
    "                    'KBA13_OPEL','KBA13_PEUGEOT','KBA13_RENAULT','KBA13_SEG_GELAENDEWAGEN',\n",
    "                    'KBA13_SEG_GROSSRAUMVANS','KBA13_SEG_KLEINST','KBA13_SEG_KLEINWAGEN',\n",
    "                    'KBA13_SEG_KOMPAKTKLASSE','KBA13_SEG_MINIVANS','KBA13_SEG_MINIWAGEN',\n",
    "                    'KBA13_SEG_MITTELKLASSE','KBA13_SEG_OBEREMITTELKLASSE','KBA13_SEG_OBERKLASSE',\n",
    "                    'KBA13_SEG_SONSTIGE','KBA13_SEG_SPORTWAGEN','KBA13_SEG_UTILITIES',\n",
    "                    'KBA13_SEG_VAN','KBA13_SEG_WOHNMOBILE','KBA13_SITZE_4','KBA13_SITZE_5',\n",
    "                    'KBA13_SITZE_6','KBA13_TOYOTA','KBA13_VORB_0','KBA13_VORB_1','KBA13_VORB_1_2',\n",
    "                    'KBA13_VORB_2','KBA13_VORB_3','KBA13_VW','KKK','KONSUMNAEHE','LP_FAMILIE_FEIN',\n",
    "                    'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','LP_LEBENSPHASE_GROB','LP_STATUS_FEIN',\n",
    "                    'LP_STATUS_GROB','MOBI_REGIO','NATIONALITAET_KZ','ONLINE_AFFINITAET','ORTSGR_KLS9',\n",
    "                    'OST_WEST_KZ','PLZ8_ANTG1','PLZ8_ANTG2','PLZ8_ANTG3','PLZ8_ANTG4','PLZ8_BAUMAX',\n",
    "                    'PLZ8_GBZ','PLZ8_HHZ','PRAEGENDE_JUGENDJAHRE','REGIOTYP','RELAT_AB',\n",
    "                    'RETOURTYP_BK_S','SEMIO_DOM','SEMIO_ERL','SEMIO_FAM','SEMIO_KAEM','SEMIO_KRIT',\n",
    "                    'SEMIO_KULT','SEMIO_LUST','SEMIO_MAT','SEMIO_PFLICHT','SEMIO_RAT','SEMIO_REL',\n",
    "                    'SEMIO_SOZ','SEMIO_TRADV','SEMIO_VERT','SHOPPER_TYP',\n",
    "                    'VERS_TYP','WOHNDAUER_2008','WOHNLAGE','W_KEIT_KIND_HH','ZABEOTYP']\n",
    "\n",
    "#GEBURTSJAHR year of birth, to int or to date\n",
    "#GREEN_AVANTGARDE maybe can be a bool\n",
    "azdias_df = to_category(azdias_df, categorical_columns)\n",
    "#azdias_df = to_int(azdias_df, categorical_columns)\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging for more space it can be seen that there are columns that are not listed in the csv description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EINGEFUEGT_AM                 60.686382\n",
       "CAMEO_INTL_2015               39.016406\n",
       "ANZ_STATISTISCHE_HAUSHALTE     6.799477\n",
       "KBA13_GBZ                      6.799477\n",
       "CJT_KATALOGNUTZER              6.799477\n",
       "RT_SCHNAEPPCHEN                6.799477\n",
       "RT_KEIN_ANREIZ                 6.799477\n",
       "AKT_DAT_KL                     6.799477\n",
       "KBA13_HHZ                      6.799477\n",
       "ANZ_HAUSHALTE_AKTIV            6.799477\n",
       "ANZ_KINDER                     6.799477\n",
       "ANZ_PERSONEN                   6.799477\n",
       "ARBEIT                         6.799477\n",
       "D19_VERSI_OFFLINE_DATUM        6.799477\n",
       "D19_VERSAND_OFFLINE_DATUM      6.799477\n",
       "CJT_TYP_6                      6.799477\n",
       "CJT_TYP_5                      6.799477\n",
       "CJT_TYP_4                      6.799477\n",
       "MOBI_RASTER                    6.799477\n",
       "MIN_GEBAEUDEJAHR               6.799477\n",
       "CJT_TYP_3                      6.799477\n",
       "CJT_TYP_2                      6.799477\n",
       "CJT_TYP_1                      6.799477\n",
       "KOMBIALTER                     6.799477\n",
       "D19_VERSI_DATUM                6.799477\n",
       "KBA13_ANTG3                    6.799477\n",
       "VERDICHTUNGSRAUM               6.799477\n",
       "LNR                            6.799477\n",
       "FIRMENDICHTE                   6.799477\n",
       "KBA13_ANTG1                    6.799477\n",
       "                                ...    \n",
       "KBA13_CCM_3001                 0.850125\n",
       "KBA13_HALTER_35                0.850125\n",
       "KBA13_HALTER_30                0.850125\n",
       "KBA13_FIAT                     0.850125\n",
       "KBA13_HALTER_20                0.850125\n",
       "KBA13_FAB_ASIEN                0.850125\n",
       "KBA13_FORD                     0.850125\n",
       "KBA13_FAB_SONSTIGE             0.850125\n",
       "KBA13_KRSZUL_NEU               0.850118\n",
       "KBA05_KRSVAN                   0.850118\n",
       "PLZ8_ANTG3                     0.850118\n",
       "KBA13_MOTOR                    0.850118\n",
       "NATIONALITAET_KZ               0.850118\n",
       "KBA05_MAXVORB                  0.850118\n",
       "KBA05_KRSKLEIN                 0.850118\n",
       "KBA13_KRSSEG_VAN               0.850118\n",
       "KBA05_KRSOBER                  0.850118\n",
       "HEALTH_TYP                     0.850118\n",
       "KBA05_KRSZUL                   0.850118\n",
       "KBA13_KRSSEG_OBER              0.850118\n",
       "KBA05_ANTG3                    0.850118\n",
       "VERS_TYP                       0.850034\n",
       "STRUKTURTYP                    0.850034\n",
       "KBA13_KMH_110                  0.850034\n",
       "KBA05_ANTG4                    0.850034\n",
       "PLZ8_ANTG4                     0.850034\n",
       "KBA05_SEG6                     0.850034\n",
       "KBA13_KMH_251                  0.850034\n",
       "KBA13_KW_30                    0.850034\n",
       "Index                          0.000076\n",
       "Length: 336, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(azdias_df.memory_usage(deep=True) / 1024 ** 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 364.24 Mb\n"
     ]
    }
   ],
   "source": [
    "categorical_columns2 = ['CAMEO_INTL_2015','KBA13_ANTG1','KBA13_GBZ','D19_VERSI_DATUM','RT_UEBERGROESSE',\n",
    "                       'RT_SCHNAEPPCHEN','RT_KEIN_ANREIZ','ANZ_HAUSHALTE_AKTIV','ANZ_KINDER',\n",
    "                       'ANZ_PERSONEN','ANZ_STATISTISCHE_HAUSHALTE','ARBEIT','MOBI_RASTER',\n",
    "                       'D19_VERSI_OFFLINE_DATUM','MIN_GEBAEUDEJAHR','KOMBIALTER',\n",
    "                       'CJT_KATALOGNUTZER','CJT_TYP_1','CJT_TYP_2','CJT_TYP_3','CJT_TYP_4','CJT_TYP_5',\n",
    "                        'CJT_TYP_6','KBA13_HHZ','KBA13_KMH_210','KBA13_BAUMAX',\n",
    "                       'UMFELD_JUNG','EINGEZOGENAM_HH_JAHR','GEMEINDETYP',\n",
    "                       'GEBURTSJAHR','AKT_DAT_KL','KBA13_ANTG2','D19_VERSAND_OFFLINE_DATUM','UMFELD_ALT',\n",
    "                       'KBA13_ANTG3','VK_DISTANZ','FIRMENDICHTE','VERDICHTUNGSRAUM',\n",
    "                       'VK_ZG11','KBA13_ANTG4','VK_DHT4A','VHN','VHA']\n",
    "\n",
    "azdias_df = to_category(azdias_df, categorical_columns2)\n",
    "#KBA13_ANZAHL_PKW to int\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows that not have at least 270 (80%) non null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired in https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4\n",
    "\n",
    "def impute_mode_categorical(df):\n",
    "    categorical_columns= df.select_dtypes(include=['category'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in categorical_columns: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        #col_data.replace('XX',np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        mode = col_data.mode()[0]\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(mode, inplace=True)\n",
    "            \n",
    "    return df\n",
    "    \n",
    "def impute_median_numerical(df):\n",
    "    numeric_cols = df.select_dtypes(include=['int','float'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in numeric_cols: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        median = col_data.median()\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(median, inplace=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 316.11 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_df.dropna(thresh=290, inplace = True)\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace nulls and unknown (-1) values with mode or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 335)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of the non ordinal categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 435.76 Mb\n"
     ]
    }
   ],
   "source": [
    "one_hot_list = ['WOHNLAGE','VERS_TYP','SHOPPER_TYP','RETOURTYP_BK_S','PLZ8_BAUMAX','NATIONALITAET_KZ',\n",
    "                'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','KBA05_MODTEMP','KBA05_MAXHERST','KBA05_HERSTTEMP',\n",
    "                'HEALTH_TYP','GFK_URLAUBERTYP','GEBAEUDETYP','FINANZTYP','D19_KONSUMTYP_MAX',\n",
    "                'CJT_GESAMTTYP','CAMEO_DEU_2015','AGER_TYP']\n",
    "azdias_df = pd.get_dummies(azdias_df, columns =one_hot_list)\n",
    "\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode into numerical values binary feature OST_WEST_KZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_ost_west = LabelEncoder()\n",
    "label_ost_west.fit(azdias_df['OST_WEST_KZ'])\n",
    "azdias_df['OST_WEST_KZ'] = label_ost_west.transform(azdias_df['OST_WEST_KZ'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp into an integer formed by year month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp =  pd.to_datetime(azdias_df['EINGEFUEGT_AM']) ## pandas recognizes your format\n",
    "\n",
    "azdias_df['EINGEFUEGT_AM'] = timestamp.dt.strftime('%Y%m%d')\n",
    "azdias_df['EINGEFUEGT_AM'] = azdias_df['EINGEFUEGT_AM'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize values before aplying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "np_azdias = azdias_df.values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np_azdias)\n",
    "np_azdias = scaler.transform(np_azdias)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in the dataframe the normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df = pd.DataFrame(data=np_azdias,\n",
    "          index=azdias_df.index,\n",
    "          columns=azdias_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "session = sagemaker.Session()\n",
    "# get IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'arvato'\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix+\"/train\")\n",
    "num_components = 400\n",
    "\n",
    "\n",
    "\n",
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to recordset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_azdias_data = pca.record_set(np_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit data to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 16:09:21 Starting - Starting the training job...\n",
      "2020-05-03 16:09:22 Starting - Launching requested ML instances...\n",
      "2020-05-03 16:10:21 Starting - Preparing the instances for training......\n",
      "2020-05-03 16:10:56 Downloading - Downloading input data......\n",
      "2020-05-03 16:12:18 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'502', u'mini_batch_size': u'500', u'num_components': u'400'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Final configuration: {u'num_components': u'400', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'502', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 WARNING 139907838519104] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7450fb77-2918-4c71-8e4c-dc9a0eff1906', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-09-21-047', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-76-145.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/fedd427b-220b-43a1-9e17-60a96e616679', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-09-21-047', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7450fb77-2918-4c71-8e4c-dc9a0eff1906', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.76.145', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-09-21-047', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-76-145.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/fedd427b-220b-43a1-9e17-60a96e616679', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-09-21-047', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7450fb77-2918-4c71-8e4c-dc9a0eff1906', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-09-21-047', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-76-145.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/fedd427b-220b-43a1-9e17-60a96e616679', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-09-21-047', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7450fb77-2918-4c71-8e4c-dc9a0eff1906', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.76.145', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-09-21-047', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-76-145.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/fedd427b-220b-43a1-9e17-60a96e616679', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-09-21-047', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7450fb77-2918-4c71-8e4c-dc9a0eff1906', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.76.145', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-09-21-047', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-76-145.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/fedd427b-220b-43a1-9e17-60a96e616679', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-09-21-047', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 58 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 68 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:20 INFO 139907838519104] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:21 INFO 139907838519104] nvidia-smi took: 0.0251469612122 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:21 INFO 139907838519104] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:21 INFO 139907838519104] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:21 INFO 139907838519104] 502 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:21 INFO 139907838519104] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1059.6439838409424, \"sum\": 1059.6439838409424, \"min\": 1059.6439838409424}}, \"EndTime\": 1588522341.668998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588522340.57948}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588522341.669499, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588522341.669171}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-03 16:12:21.675] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1094, \"num_examples\": 1, \"num_bytes\": 2022000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-03 16:12:50 Uploading - Uploading generated training model\n",
      "2020-05-03 16:12:50 Completed - Training job completed\n",
      "\u001b[34m[2020-05-03 16:12:40.862] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 19179, \"num_examples\": 1503, \"num_bytes\": 3038382564}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 19187.885999679565, \"sum\": 19187.885999679565, \"min\": 19187.885999679565}}, \"EndTime\": 1588522360.863234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588522341.669096}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:40 INFO 139907838519104] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588522360.863918, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1588522341.675309}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:40 INFO 139907838519104] #throughput_metric: host=algo-1, train throughput=39154.2795879 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 95.89099884033203, \"sum\": 95.89099884033203, \"min\": 95.89099884033203}}, \"EndTime\": 1588522360.960514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588522360.863358}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:12:40 INFO 139907838519104] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 20586.055040359497, \"sum\": 20586.055040359497, \"min\": 20586.055040359497}, \"setuptime\": {\"count\": 1, \"max\": 42.64998435974121, \"sum\": 42.64998435974121, \"min\": 42.64998435974121}}, \"EndTime\": 1588522360.97883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588522360.960579}\n",
      "\u001b[0m\n",
      "Training seconds: 114\n",
      "Billable seconds: 114\n"
     ]
    }
   ],
   "source": [
    "#train_inputs = sagemaker.s3_input(train_s3, content_type='text/csv;label_size=0')\n",
    "\n",
    "pca.fit(formatted_azdias_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arvato/train/pca-2020-05-03-16-09-21-047/output/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the training job, it's suggested that you copy-paste\n",
    "# from the notebook or from a specific job in the AWS console\n",
    "\n",
    "training_job_name=pca._current_job_name\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix+\"/train\", training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as model_algo-1\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# loading the unzipped artifacts\n",
    "pca_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selected params\n",
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the explained variance for the top n principal components\n",
    "# you may assume you have access to the global var N_COMPONENTS\n",
    "def explained_variance(s, n_top_components):\n",
    "    '''Calculates the approx. data variance that n_top_components captures.\n",
    "       :param s: A dataframe of singular values for top components; \n",
    "           the top value is in the last row.\n",
    "       :param n_top_components: An integer, the number of top components to use.\n",
    "       :return: The expected data variance covered by the n_top_components.'''\n",
    "    \n",
    "    n_components = len(s) - n_top_components\n",
    "    partial = s[n_components:].pow(2).sum(axis=0)\n",
    "    total = s.pow(2).sum(axis=0)\n",
    "\n",
    "    return partial/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0    0.923581\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "n_top_components = 220 # select a value for the number of top components\n",
    "\n",
    "# calculate the explained variance\n",
    "exp_variance = explained_variance(s, n_top_components)\n",
    "print('Explained variance: ', exp_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for x in range(400):\n",
    "    y.append(explained_variance(s, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y)\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how many components are needed for 90% of explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n"
     ]
    }
   ],
   "source": [
    "#convert list of series to list of floats\n",
    "floats_y = [float(i) for i in y]\n",
    "#construct an comprehension to locate the index of the first element with more than 0.9 explained variance\n",
    "components = (i for i,v in enumerate(floats_y) if (v > 0.9))\n",
    "x1 = next(components)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-fit PCA with the number of components obtained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 16:33:02 Starting - Starting the training job...\n",
      "2020-05-03 16:33:03 Starting - Launching requested ML instances......\n",
      "2020-05-03 16:34:02 Starting - Preparing the instances for training...\n",
      "2020-05-03 16:34:38 Downloading - Downloading input data......\n",
      "2020-05-03 16:35:50 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:06 INFO 140549059913536] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:06 INFO 140549059913536] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'502', u'mini_batch_size': u'500', u'num_components': u'194'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:06 INFO 140549059913536] Final configuration: {u'num_components': u'194', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'502', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:06 WARNING 140549059913536] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/ec5dfdc8-e602-463a-b764-2a6a3b461486', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-33-02-030', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-100-86.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/db63e5ee-28a7-4716-a268-1bc7e75444ec', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-33-02-030', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/ec5dfdc8-e602-463a-b764-2a6a3b461486', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.100.86', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-33-02-030', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-100-86.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/db63e5ee-28a7-4716-a268-1bc7e75444ec', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-33-02-030', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/ec5dfdc8-e602-463a-b764-2a6a3b461486', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-33-02-030', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-100-86.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/db63e5ee-28a7-4716-a268-1bc7e75444ec', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-33-02-030', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/ec5dfdc8-e602-463a-b764-2a6a3b461486', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.100.86', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-33-02-030', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-100-86.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/db63e5ee-28a7-4716-a268-1bc7e75444ec', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-33-02-030', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/ec5dfdc8-e602-463a-b764-2a6a3b461486', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.100.86', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-03-16-33-02-030', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-100-86.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/db63e5ee-28a7-4716-a268-1bc7e75444ec', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-03-16-33-02-030', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 58 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 67 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:07 INFO 140549059913536] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:09 INFO 140549059913536] nvidia-smi took: 0.0251359939575 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:09 INFO 140549059913536] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:09 INFO 140549059913536] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:09 INFO 140549059913536] 502 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:09 INFO 140549059913536] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1304.3978214263916, \"sum\": 1304.3978214263916, \"min\": 1304.3978214263916}}, \"EndTime\": 1588523769.282073, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588523767.957519}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588523769.282314, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588523769.282261}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-03 16:36:09.289] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1331, \"num_examples\": 1, \"num_bytes\": 2022000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-03 16:36:30 Uploading - Uploading generated training model\u001b[34m[2020-05-03 16:36:28.117] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 18821, \"num_examples\": 1503, \"num_bytes\": 3038382564}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 18828.539848327637, \"sum\": 18828.539848327637, \"min\": 18828.539848327637}}, \"EndTime\": 1588523788.118513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588523769.282168}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:28 INFO 140549059913536] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588523788.118878, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1588523769.28962}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:28 INFO 140549059913536] #throughput_metric: host=algo-1, train throughput=39899.7413473 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 87.39805221557617, \"sum\": 87.39805221557617, \"min\": 87.39805221557617}}, \"EndTime\": 1588523788.20875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588523788.118612}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:36:28 INFO 140549059913536] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 21996.00100517273, \"sum\": 21996.00100517273, \"min\": 21996.00100517273}, \"setuptime\": {\"count\": 1, \"max\": 1599.841833114624, \"sum\": 1599.841833114624, \"min\": 1599.841833114624}}, \"EndTime\": 1588523788.229441, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588523788.208809}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-03 16:36:36 Completed - Training job completed\n",
      "Training seconds: 118\n",
      "Billable seconds: 118\n"
     ]
    }
   ],
   "source": [
    "num_components = 194\n",
    "\n",
    "\n",
    "\n",
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)\n",
    "\n",
    "pca.fit(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 ms, sys: 5 µs, total: 24.8 ms\n",
      "Wall time: 373 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pca_transformer = pca.transformer(instance_count = 1, \n",
    "                                  instance_type = 'ml.m5.large',\n",
    "                                  output_path='s3://{}/{}/pca/transform/test'.format(bucket_name, prefix+\"/transform\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'azdias.csv'\n",
    "\n",
    "\n",
    "u = azdias_df.select_dtypes(object)\n",
    "azdias_df[u.columns] = u.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into local notebook storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df.to_csv(filename,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "np_azdias_location = session.upload_data(os.path.join(filename), key_prefix=prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print dataset location in order to avoid previous computation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-848439228145/arvato/azdias.csv\n"
     ]
    }
   ],
   "source": [
    "print(np_azdias_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete temp file from sagemaker notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:14 INFO 140529370249024] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] nvidia-smi took: 0.0251111984253 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loading entry points\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-03 16:54:15 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-03 16:54:15 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-03 16:54:15 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-03 16:54:15 +0000] [84] [INFO] Booting worker with pid: 84\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loading model...\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-03 16:54:15 +0000] [94] [INFO] Booting worker with pid: 94\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] loading model...\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:15 INFO 140529370249024] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524871.267403, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524855.10384}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524871.267403, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524855.10384}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-05-03T16:54:31.277:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524875.631077, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524855.162425}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524875.635567, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524871.267516}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524875.631077, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524855.162425}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524875.635567, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524871.267516}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524877.105949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524875.631176}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524877.282658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524875.636891}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524877.105949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524875.631176}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524877.282658, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524875.636891}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524878.645826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524877.106315}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524878.713845, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524877.28274}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524878.645826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524877.106315}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524878.713845, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524877.28274}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524880.082025, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524878.646179}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524880.430047, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524878.713927}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524880.082025, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524878.646179}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524880.430047, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524878.713927}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:54:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524882.952493, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524881.551622}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524882.952493, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524881.551622}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524883.359959, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524881.852537}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524883.359959, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524881.852537}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524884.332358, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524882.95257}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524884.748191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524883.360483}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524884.332358, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524882.95257}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524884.748191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524883.360483}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524885.759301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524884.332434}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524885.759301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524884.332434}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524886.302887, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524884.748735}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524886.302887, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524884.748735}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524887.194484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524885.75983}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524887.734989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524886.302969}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:47 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:47 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:47 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524887.194484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524885.75983}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524887.734989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524886.302969}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:47 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:47 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:47 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524888.562098, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524887.19499}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524888.562098, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524887.19499}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524889.124286, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524887.735068}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524889.124286, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524887.735068}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524889.93386, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524888.562601}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524889.93386, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524888.562601}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524890.795877, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524889.124364}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524890.795877, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524889.124364}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:54:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524892.279295, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524890.795951}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524892.866666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524891.392433}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524892.279295, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524890.795951}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524892.866666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524891.392433}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524893.969001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524892.279374}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524893.969001, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524892.279374}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524894.491828, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524892.867164}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524894.491828, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524892.867164}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524895.637333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524893.969473}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524895.637333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524893.969473}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524896.072893, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524894.491906}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524896.072893, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524894.491906}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524897.028358, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524895.637828}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524897.519889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524896.072995}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524897.028358, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524895.637828}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524897.519889, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524896.072995}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524898.440491, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524897.028837}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524898.440491, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524897.028837}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524899.136372, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524897.519967}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:54:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524899.999455, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524898.44098}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524899.136372, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524897.519967}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:54:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524899.999455, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524898.44098}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524900.550251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524899.136449}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524900.550251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524899.136449}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:55:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524902.146886, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524900.550335}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524902.88056, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524901.402624}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524902.146886, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524900.550335}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524902.88056, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524901.402624}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524903.707737, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524902.146963}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524903.707737, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524902.146963}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524904.307019, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524902.881071}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524904.307019, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524902.881071}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1907.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1907.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524905.117849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524903.70781}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524905.979717, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524904.307558}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524905.117849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524903.70781}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524905.979717, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524904.307558}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524906.628003, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524905.117928}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524906.628003, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524905.117928}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524907.47409, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524905.9802}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524907.47409, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524905.9802}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524908.097327, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524906.628084}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524908.097327, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524906.628084}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524909.085692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524907.474166}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524909.615997, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524908.097823}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524909.085692, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524907.474166}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524909.615997, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524908.097823}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524910.848879, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524909.085768}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524910.848879, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524909.085768}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:55:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524912.341548, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524910.848958}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524912.341548, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524910.848958}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524912.82105, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524911.266367}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524912.82105, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524911.266367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524913.917561, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524912.341623}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524913.917561, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524912.341623}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524914.406703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524912.82156}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524914.406703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524912.82156}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524915.345281, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524913.91806}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524915.930102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524914.406782}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524915.345281, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524913.91806}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524915.930102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524914.406782}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524916.852004, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524915.345356}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524916.852004, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524915.345356}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524917.421813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524915.930578}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:17 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:17 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524917.421813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524915.930578}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:17 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:17 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524918.555667, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524916.852346}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524918.555667, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524916.852346}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524919.056274, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524917.421898}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524919.956542, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524918.555739}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524919.056274, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524917.421898}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524919.956542, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524918.555739}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524920.515, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524919.056487}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524920.515, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524919.056487}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524922.161674, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524920.515076}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524922.161674, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524920.515076}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524923.120603, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524921.506559}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524923.726377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524922.161755}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524923.120603, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524921.506559}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524923.726377, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524922.161755}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524924.595122, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524923.121076}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524924.595122, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524923.121076}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524925.24562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524923.726455}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524925.24562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524923.726455}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524926.144413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524924.595631}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524926.727136, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524925.2457}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:26 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:26 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:26 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:26 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524926.144413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524924.595631}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524926.727136, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524925.2457}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:26 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:26 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:26 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:26 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524927.751892, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524926.14449}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524927.751892, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524926.14449}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524928.357646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524926.727653}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524928.357646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524926.727653}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524929.339268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524927.751972}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524929.892524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524928.358136}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524929.339268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524927.751972}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524929.892524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524928.358136}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524930.760799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524929.339829}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524930.760799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524929.339829}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524931.4594, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524929.892603}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524931.4594, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524929.892603}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524932.135347, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524930.761303}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524932.951032, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524931.459478}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524932.135347, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524930.761303}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524932.951032, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524931.459478}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524933.630287, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524932.135851}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1905.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524933.630287, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524932.135851}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1905.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524934.465507, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524932.951106}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524934.947018, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524933.630776}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524934.465507, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524932.951106}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524934.947018, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524933.630776}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524935.880558, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524934.465582}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524935.880558, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524934.465582}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524936.395468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524934.947542}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524936.395468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524934.947542}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524937.38974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524935.880634}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524937.778577, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524936.396021}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524937.38974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524935.880634}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524937.778577, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524936.396021}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524938.938636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524937.389817}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524938.938636, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524937.389817}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524939.231056, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524937.779136}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524939.231056, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524937.779136}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524940.335851, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524938.939145}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524940.682685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524939.231135}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524940.335851, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524938.939145}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524940.682685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524939.231135}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:55:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524943.258768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524941.723682}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524943.697799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524942.207823}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524943.258768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524941.723682}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524943.697799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524942.207823}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524944.616957, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524943.259264}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524944.616957, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524943.259264}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524945.222075, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524943.69788}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524945.222075, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524943.69788}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524946.126476, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524944.617463}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524946.732249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524945.222153}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524946.126476, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524944.617463}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524946.732249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524945.222153}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:47 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:47 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:47 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524947.630311, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524946.126975}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:47 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:47 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:47 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524947.630311, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524946.126975}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524948.372553, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524946.732332}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524948.372553, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524946.732332}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524949.107296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524947.63082}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524949.107296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524947.63082}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524949.966407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524948.372629}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524949.966407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524948.372629}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524950.665663, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524949.107834}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524950.665663, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524949.107834}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524952.069875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524950.666167}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524952.069875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524950.666167}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524952.95788, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524951.413517}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524952.95788, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524951.413517}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524953.545182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524952.070375}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524953.545182, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524952.070375}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524954.618479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524952.957956}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524955.049326, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524953.545734}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524954.618479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524952.957956}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524955.049326, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524953.545734}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524956.204019, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524954.618554}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524956.463396, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524955.051844}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524956.204019, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524954.618554}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524956.463396, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524955.051844}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524957.735514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524956.204096}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524957.892802, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524956.463938}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524957.735514, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524956.204096}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524957.892802, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524956.463938}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524959.13605, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524957.735606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524959.356853, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524957.893327}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:55:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524959.13605, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524957.735606}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524959.356853, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524957.893327}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:55:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524960.685631, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524959.136126}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524960.925116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524959.357395}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524960.685631, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524959.136126}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524960.925116, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524959.357395}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:56:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524962.141101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524960.685704}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524962.386173, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524960.925634}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524962.141101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524960.685704}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524962.386173, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524960.925634}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524963.697276, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524962.141173}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524963.763574, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524962.386701}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524963.697276, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524962.141173}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524963.763574, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524962.386701}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524965.147337, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524963.764116}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524965.452955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524963.697359}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524965.147337, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524963.764116}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524965.452955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524963.697359}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524966.680421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524965.147852}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524967.046951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524965.453036}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524966.680421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524965.147852}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524967.046951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524965.453036}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524968.301263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524966.68096}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524968.677873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524967.04703}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524968.301263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524966.68096}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524968.677873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524967.04703}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524969.833486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524968.301768}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524969.833486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524968.301768}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524970.117874, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524968.677951}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524970.117874, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524968.677951}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524971.789685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524970.117951}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524971.789685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524970.117951}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1906.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524972.616405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524971.128947}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1906.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524972.616405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524971.128947}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524973.410245, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524971.789761}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524973.410245, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524971.789761}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524974.110811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524972.616954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524974.855673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524973.410744}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524974.110811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524972.616954}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524974.855673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524973.410744}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524975.703102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524974.11089}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524975.703102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524974.11089}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524976.389941, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524974.85617}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524976.389941, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524974.85617}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524977.212023, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524975.703181}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524977.899748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524976.390593}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524977.212023, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524975.703181}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524977.899748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524976.390593}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524978.640662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524977.212554}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524978.640662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524977.212554}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524979.448676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524977.899823}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524980.050556, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524978.641274}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524979.448676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524977.899823}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524980.050556, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524978.641274}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524981.003893, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524979.448751}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524981.003893, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524979.448751}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524981.631733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524980.05105}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524981.631733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524980.05105}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524982.515016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524981.004}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524982.515016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524981.004}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524983.089418, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524981.632246}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524984.004379, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524982.515127}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524983.089418, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524981.632246}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524984.004379, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524982.515127}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524984.629604, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524983.089938}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524984.629604, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524983.089938}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524985.595288, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524984.007866}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524985.595288, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524984.007866}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:56:26 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:26 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:26 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:26 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1905.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:26 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:26 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:26 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:26 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1905.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524987.1143, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524985.595811}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524987.626846, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524986.152573}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524987.1143, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524985.595811}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524987.626846, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524986.152573}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524988.596761, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524987.114786}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524988.596761, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524987.114786}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524989.177907, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524987.626928}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524989.177907, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524987.626928}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524990.175833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524988.597258}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524990.65612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524989.177989}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524990.175833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524988.597258}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524990.65612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524989.177989}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:31 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:31 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:31 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524991.74072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524990.176355}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:31 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:31 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:31 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524991.74072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524990.176355}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524992.160615, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524990.656201}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524992.160615, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524990.656201}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524993.260723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524991.741216}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524993.638367, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524992.160702}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524993.260723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524991.741216}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524993.638367, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524992.160702}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524994.823823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524993.261258}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524994.823823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524993.261258}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524995.097879, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524993.638444}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524995.097879, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524993.638444}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524996.283703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524994.824303}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524996.633395, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524995.097953}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524996.283703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524994.824303}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524996.633395, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524995.097953}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524997.75872, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524996.284202}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524997.75872, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524996.284202}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524998.215268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524996.633473}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524998.215268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524996.633473}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524999.184187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524997.759231}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524999.660341, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524998.21535}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524999.184187, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524997.759231}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588524999.660341, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524998.21535}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525000.701505, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524999.184261}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525000.701505, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588524999.184261}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:56:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525002.27811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525000.701582}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525002.914722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525001.268243}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525002.27811, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525000.701582}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525002.914722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525001.268243}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525003.915974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525002.278191}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525003.915974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525002.278191}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525004.303163, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525002.915244}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525004.303163, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525002.915244}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525005.467348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525003.916047}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525005.723113, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525004.303961}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525005.467348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525003.916047}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525005.723113, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525004.303961}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1931.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525007.001145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525005.467426}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1931.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525007.001145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525005.467426}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525007.246716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525005.723639}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525007.246716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525005.723639}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:47 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:47 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:47 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:47 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:47 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:47 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525008.571303, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525007.00122}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525008.825589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525007.247312}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525008.571303, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525007.00122}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525008.825589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525007.247312}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525010.056221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525008.571376}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525010.056221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525008.571376}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525010.227355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525008.826156}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525010.227355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525008.826156}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525011.589547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525010.056295}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525011.744486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525010.227989}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525011.589547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525010.056295}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525011.744486, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525010.227989}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525013.058593, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525011.589629}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525013.058593, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525011.589629}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525013.230829, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525011.745039}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525013.230829, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525011.745039}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525014.62686, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525013.058667}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525014.925547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525013.231539}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525014.62686, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525013.058667}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525014.925547, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525013.231539}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525016.359618, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525014.926055}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525016.359618, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525014.926055}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525017.673016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525016.109395}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525017.787333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525016.360127}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525017.673016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525016.109395}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525017.787333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525016.360127}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525019.013919, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525017.78794}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525019.013919, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525017.78794}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525019.276221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525017.673096}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:56:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525019.276221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525017.673096}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:56:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525020.480164, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525019.014426}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525020.754874, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525019.276301}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525020.480164, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525019.014426}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525020.754874, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525019.276301}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:57:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525023.434992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525021.954436}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525023.935087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525022.301373}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525023.434992, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525021.954436}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525023.935087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525022.301373}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525025.02762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525023.435759}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525025.02762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525023.435759}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525025.315697, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525023.935654}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525025.315697, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525023.935654}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525026.519215, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525025.027697}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525026.733042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525025.31621}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525026.519215, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525025.027697}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525026.733042, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525025.31621}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525028.017007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525026.519294}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525028.017007, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525026.519294}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525028.24257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525026.733614}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525028.24257, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525026.733614}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525029.579287, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525028.017081}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525029.813525, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525028.243078}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525029.579287, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525028.017081}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525029.813525, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525028.243078}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525031.028524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525029.579365}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:10 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525031.028524, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525029.579365}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525032.607939, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525031.028599}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525032.937955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525031.427901}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525032.607939, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525031.028599}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525032.937955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525031.427901}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525034.217588, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525032.608017}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525034.217588, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525032.608017}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525034.432741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525032.938485}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525034.432741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525032.938485}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525035.77101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525034.217661}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525035.934748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525034.433458}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525035.77101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525034.217661}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525035.934748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525034.433458}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:16 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525037.323109, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525035.771089}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525037.633891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525035.935375}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525037.323109, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525035.771089}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525037.633891, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525035.935375}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525038.908659, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525037.323184}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525038.942296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525037.634458}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525038.908659, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525037.323184}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525038.942296, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525037.634458}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1906.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1906.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525040.314892, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525038.908737}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525040.473362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525038.942897}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525040.314892, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525038.908737}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525040.473362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525038.942897}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525041.941867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525040.314969}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525042.112083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525040.474027}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525041.941867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525040.314969}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525042.112083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525040.474027}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525043.384521, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525041.941983}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525043.643027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525042.112605}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525043.384521, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525041.941983}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525043.643027, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525042.112605}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525044.902982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525043.384599}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525044.902982, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525043.384599}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525045.202552, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525043.643536}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525045.202552, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525043.643536}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:57:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525047.834634, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525046.556194}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525048.077593, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525046.403588}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525047.834634, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525046.556194}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525048.077593, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525046.403588}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525049.302405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525047.835114}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525049.518648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525048.078091}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525049.302405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525047.835114}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525049.518648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525048.078091}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525050.763039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525049.302478}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525051.108437, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525049.519191}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525050.763039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525049.302478}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525051.108437, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525049.519191}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:31 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:31 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:31 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:31 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525052.251849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525050.763116}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525052.636205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525051.108964}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525052.251849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525050.763116}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525052.636205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525051.108964}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525053.695557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525052.251924}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525054.083354, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525052.636716}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525053.695557, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525052.251924}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525054.083354, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525052.636716}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:34 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525055.162732, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525053.695643}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525055.619576, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525054.083871}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525055.162732, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525053.695643}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525055.619576, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525054.083871}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525056.55925, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525055.162809}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525056.55925, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525055.162809}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525057.299293, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525055.620174}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525058.094139, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525056.559325}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:37 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:37 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525057.299293, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525055.620174}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:37 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:37 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525058.094139, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525056.559325}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525058.902156, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525057.299363}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525058.902156, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525057.299363}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525059.678259, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525058.094696}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525059.678259, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525058.094696}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525060.428929, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525058.902237}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525060.428929, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525058.902237}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:40 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:40 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:40 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:40 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525061.242805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525059.678335}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525061.903622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525060.429024}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525061.242805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525059.678335}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525061.903622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525060.429024}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525062.792871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525061.24332}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525062.792871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525061.24332}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525063.39791, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525061.903719}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525063.39791, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525061.903719}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:43 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:43 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:43 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:43 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525064.511685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525062.793373}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525064.511685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525062.793373}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525065.147353, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525063.39799}\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:45 INFO 140529370249024] Number of GPUs being used: 0\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525065.908354, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525064.51176}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525065.147353, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525063.39799}\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:45 INFO 140529370249024] Number of GPUs being used: 0\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525065.908354, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525064.51176}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:46 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:46 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:46 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:46 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:57:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525068.257254, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525066.786794}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525068.95094, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525067.421931}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525068.257254, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525066.786794}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525068.95094, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525067.421931}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525069.751039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525068.25733}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525069.751039, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525068.25733}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525070.341882, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525068.951466}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525070.341882, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525068.951466}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525071.204844, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525069.751118}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:51 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525071.938024, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525070.342404}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525071.204844, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525069.751118}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:51 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525071.938024, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525070.342404}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525072.559413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525071.204921}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525072.559413, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525071.204921}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525073.475526, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525071.938531}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525073.941335, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525072.559498}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525073.475526, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525071.938531}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525073.941335, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525072.559498}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1925.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525075.005582, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525073.476033}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1925.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525075.005582, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525073.476033}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525075.309693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525073.941414}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525075.309693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525073.941414}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:55 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:55 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:55 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:55 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:57:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525077.895806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525076.471498}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525077.895806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525076.471498}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525078.238516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525076.820127}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525078.238516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525076.820127}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:57:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:57:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525079.366397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525077.896289}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525079.750551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525078.238596}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525079.366397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525077.896289}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525079.750551, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525078.238596}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525080.857357, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525079.366908}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525080.857357, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525079.366908}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525081.181118, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525079.750631}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525081.181118, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525079.750631}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525082.364928, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525080.857883}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525082.92397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525081.181195}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525082.364928, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525080.857883}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525082.92397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525081.181195}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525083.954871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525082.365003}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525083.954871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525082.365003}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525084.568806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525082.92451}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525084.568806, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525082.92451}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525085.645931, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525083.954948}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525086.031578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525084.569356}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525085.645931, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525083.954948}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525086.031578, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525084.569356}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:58:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525087.13449, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525085.646008}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525087.13449, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525085.646008}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525087.811835, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525086.032095}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525087.811835, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525086.032095}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:07 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:07 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:07 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:07 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525088.75209, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525087.137206}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525088.75209, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525087.137206}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525089.32647, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525087.811916}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525089.32647, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525087.811916}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525090.259323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525088.752585}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525090.766438, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525089.32655}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525090.259323, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525088.752585}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525090.766438, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525089.32655}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525091.788606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525090.259814}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525091.788606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525090.259814}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525092.181016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525090.766519}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525092.181016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525090.766519}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525093.362188, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525091.78912}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525093.672848, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525092.181736}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525093.362188, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525091.78912}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525093.672848, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525092.181736}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525094.874157, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525093.362264}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525095.127445, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525093.673463}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525094.874157, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525093.362264}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525095.127445, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525093.673463}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:58:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:17 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525097.777113, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525096.346196}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525098.05684, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525096.541924}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:17 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525097.777113, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525096.346196}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525098.05684, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525096.541924}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525099.305223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525097.777192}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525099.562249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525098.057385}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525099.305223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525097.777192}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525099.562249, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525098.057385}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525100.789376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525099.305297}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525101.12462, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525099.562826}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525100.789376, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525099.305297}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525101.12462, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525099.562826}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525102.214564, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525100.789451}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525102.727567, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525101.124699}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525102.214564, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525100.789451}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525102.727567, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525101.124699}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525103.622049, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525102.21464}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525103.622049, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525102.21464}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525104.257743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525102.728092}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525105.164869, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525103.62212}\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525104.257743, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525102.728092}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525105.164869, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525103.62212}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525105.795287, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525104.257822}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525105.795287, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525104.257822}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525107.261439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525105.79537}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525107.261439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525105.79537}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525108.344464, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525106.73874}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525108.791754, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525107.261949}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525108.344464, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525106.73874}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525108.791754, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525107.261949}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525109.801646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525108.344968}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:29 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525109.801646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525108.344968}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525110.247917, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525108.791833}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525110.247917, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525108.791833}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:30 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525111.307074, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525109.802145}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525111.307074, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525109.802145}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525111.753347, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525110.247996}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:31 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:31 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:31 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:31 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525111.753347, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525110.247996}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:31 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:31 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:31 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:31 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525112.754989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525111.307581}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:32 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:32 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:32 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:32 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525112.754989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525111.307581}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525113.184211, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525111.753426}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525113.184211, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525111.753426}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:33 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525114.269556, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525112.755475}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525114.661229, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525113.184296}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525114.269556, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525112.755475}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525114.661229, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525113.184296}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525115.916683, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525114.270055}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:35 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525115.916683, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525114.270055}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:58:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:36 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:36 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:36 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:36 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525117.589602, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525115.917172}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525117.589602, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525115.917172}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525117.740454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525116.292788}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525117.740454, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525116.292788}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:38 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525119.056195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525117.590108}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525119.056195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525117.590108}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525119.194797, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525117.740548}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525119.194797, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525117.740548}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:39 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525120.507342, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525119.056755}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525120.711942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525119.194884}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525120.507342, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525119.056755}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525120.711942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525119.194884}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525121.966102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525120.507866}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:41 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525121.966102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525120.507866}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525122.286659, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525120.712022}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525122.286659, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525120.712022}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:42 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525123.472284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525121.966591}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525123.751071, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525122.286738}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525123.472284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525121.966591}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525123.751071, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525122.286738}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525125.094338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525123.472357}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:44 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525125.094338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525123.472357}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525125.264145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525123.752057}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525125.264145, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525123.752057}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:45 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:58:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:47 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525128.104261, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525126.562645}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525128.104261, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525126.562645}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525128.340139, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525126.691052}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525128.340139, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525126.691052}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:48 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:48 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:48 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:48 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:49 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:49 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:49 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:49 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525129.581465, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525128.104772}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525129.792071, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525128.340219}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525129.581465, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525128.104772}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525129.792071, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525128.340219}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:50 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525131.261833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525129.581966}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525131.471589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525129.79215}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:51 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:51 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:51 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:51 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525131.261833, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525129.581966}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525131.471589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525129.79215}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:51 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:51 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:51 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:51 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:52 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:52 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:52 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:52 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525132.722348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525131.262352}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525132.917585, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525131.471678}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525132.722348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525131.262352}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525132.917585, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525131.471678}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525134.174152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525132.722853}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:53 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525134.174152, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525132.722853}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525134.386318, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525132.917664}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525134.386318, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525132.917664}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:54 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525135.704041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525134.17466}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525135.814447, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525134.386401}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525135.704041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525134.17466}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525135.814447, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525134.386401}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:58:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:56 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:56 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:56 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:56 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525137.231639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525135.814535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525137.369646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525135.704586}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525137.231639, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525135.814535}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525137.369646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525135.704586}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:57 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:57 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:57 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:57 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:58 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:58 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:58 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:58 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525138.662349, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525137.231721}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525138.862813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525137.370406}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525138.662349, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525137.231721}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525138.862813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525137.370406}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:58:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525140.081295, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525138.662424}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:58:59 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525140.081295, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525138.662424}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525140.395516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525138.864198}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525140.395516, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525138.864198}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:00 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:00 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:00 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:00 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:01 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:01 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:01 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:01 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525141.555096, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525140.081371}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525141.88906, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525140.396038}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525141.555096, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525140.081371}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525141.88906, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525140.396038}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525143.133276, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525141.555173}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:02 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525143.133276, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525141.555173}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525143.386653, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525141.889473}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525143.386653, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525141.889473}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:03 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:03 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:03 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:03 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:04 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:04 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:04 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:04 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525144.672768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525143.133354}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525144.795968, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525143.387163}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525144.672768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525143.133354}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525144.795968, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525143.387163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:05 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525146.004431, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525144.672844}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525146.004431, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525144.672844}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/03/2020 16:59:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1928.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:06 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1928.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525147.40424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525146.004506}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525147.744391, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525146.261121}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525147.40424, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525146.004506}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525147.744391, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525146.261121}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525148.917232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525147.404317}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:08 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525148.917232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525147.404317}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525149.140546, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525147.745082}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525149.140546, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525147.745082}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:09 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525150.344081, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525148.917307}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525150.344081, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525148.917307}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525150.648453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525149.141266}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525150.648453, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525149.141266}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525151.822504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525150.344569}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525152.153627, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525150.648743}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:11 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525151.822504, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525150.344569}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525152.153627, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525150.648743}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:12 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525153.278307, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525151.822581}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525153.278307, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525151.822581}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525153.66512, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525152.15464}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525153.66512, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525152.15464}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:13 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:13 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:13 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:13 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:14 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:14 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:14 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:14 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525154.704164, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525153.27838}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525154.955045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525153.665813}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525154.704164, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525153.27838}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525154.955045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525153.665813}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525156.001277, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525154.704238}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:15 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525156.001277, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525154.704238}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525157.427301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525156.001761}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525157.785193, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525156.340635}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525157.427301, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525156.001761}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525157.785193, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525156.340635}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525158.835142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525157.427821}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:18 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525158.835142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525157.427821}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525159.241596, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525157.785456}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525159.241596, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525157.785456}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:19 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525160.205193, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525158.835638}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525160.719128, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525159.241875}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525160.205193, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525158.835638}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525160.719128, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525159.241875}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:20 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:20 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:20 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:20 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:21 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525161.591362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525160.205696}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525162.092938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525160.719369}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:21 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:21 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:21 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525161.591362, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525160.205696}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525162.092938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525160.719369}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525163.014089, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525161.591887}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:22 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525163.014089, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525161.591887}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525163.655041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525162.093259}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:23 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:23 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:23 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:23 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525163.655041, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525162.093259}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525164.460043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525163.014164}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:24 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:24 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:24 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:24 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525164.460043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525163.014164}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525165.296716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525163.655873}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525165.916777, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525164.460125}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525165.296716, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525163.655873}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525165.916777, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525164.460125}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:25 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m[05/03/2020 16:59:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:27 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525168.246998, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525166.859904}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525168.713746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525167.40982}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/03/2020 16:59:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1701.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525168.246998, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525166.859904}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525168.713746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525167.40982}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:28 WARNING 140529370249024] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:28 INFO 140529370249024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:28 INFO 140529370249024] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/03/2020 16:59:28 INFO 140529370249024] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1701.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525169.46898, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525168.247076}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588525169.46898, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588525168.247076}\n",
      "\u001b[0m\n",
      "CPU times: user 1.8 s, sys: 131 ms, total: 1.94 s\n",
      "Wall time: 8min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "\n",
    "pca_transformer.transform(np_azdias_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/azdias.csv.out to ./azdias.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/azdias.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 53.3 Mb\n"
     ]
    }
   ],
   "source": [
    "transformed_filename = 'azdias.csv.out'\n",
    "\n",
    "azdias_sub_pca = pd.read_csv(transformed_filename, usecols = [0], header = None)\n",
    "azdias_sub_pca[0] = azdias_sub_pca[0].apply(lambda x: str(x)[15:])\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 2.87 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_sub_pca[0] = pd.to_numeric(azdias_sub_pca[0], downcast='float')\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"projection\":[0.134954333305358</td>\n",
       "      <td>0.022095</td>\n",
       "      <td>0.135128</td>\n",
       "      <td>0.111898</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>-0.035284</td>\n",
       "      <td>0.180991</td>\n",
       "      <td>0.171228</td>\n",
       "      <td>-0.113437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077222</td>\n",
       "      <td>-0.780036</td>\n",
       "      <td>0.240591</td>\n",
       "      <td>0.277516</td>\n",
       "      <td>-0.712171</td>\n",
       "      <td>0.049081</td>\n",
       "      <td>0.840891</td>\n",
       "      <td>-1.507357</td>\n",
       "      <td>1.447555</td>\n",
       "      <td>1.698855757713317]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0         1         2         3         4    \\\n",
       "0  {\"projection\":[0.134954333305358  0.022095  0.135128  0.111898  0.060468   \n",
       "\n",
       "        5         6         7         8         9    ...       184       185  \\\n",
       "0  0.068402 -0.035284  0.180991  0.171228 -0.113437  ... -0.077222 -0.780036   \n",
       "\n",
       "        186       187       188       189       190       191       192  \\\n",
       "0  0.240591  0.277516 -0.712171  0.049081  0.840891 -1.507357  1.447555   \n",
       "\n",
       "                   193  \n",
       "0  1.698855757713317]}  \n",
       "\n",
       "[1 rows x 194 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(transformed_filename, nrows = 1, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendColumns(df, number):\n",
    "    for column in range(1,number-1):\n",
    "        data_col = pd.read_csv(transformed_filename, usecols = [column], header = None)\n",
    "        df[column] = pd.to_numeric(\n",
    "                        #pd.read_csv(transformed_filename, usecols = [column], header = None),\n",
    "                        data_col[column],\n",
    "                        downcast='float'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 553.16 Mb\n",
      "CPU times: user 36min 18s, sys: 1min 32s, total: 37min 50s\n",
      "Wall time: 37min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "appendColumns(azdias_sub_pca, num_components)\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a KMeans estimator\n",
    "k_estimator = sagemaker.KMeans(role,\n",
    "                               train_instance_count = 1,\n",
    "                               train_instance_type = 'ml.m5.large',\n",
    "                               k = 8\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
