{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3 client to get S3 data\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name='sagemaker-eu-west-1-848439228145'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list withe files in the bucket and print the file names to be sure that we will be retrieving from the correct location and obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Capstone/Udacity_AZDIAS_052018.csv', 'Capstone/Udacity_CUSTOMERS_052018.csv', 'Capstone/Udacity_MAILOUT_052018_TEST.csv', 'Capstone/Udacity_MAILOUT_052018_TRAIN.csv', 'arvato/azdias.csv']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "# get a list of objects in the bucket\n",
    "obj_list=s3_client.list_objects(Bucket=bucket_name)\n",
    "\n",
    "def filter_csv(string):\n",
    "    return re.search(r'.csv', string)\n",
    "\n",
    "\n",
    "files=[]\n",
    "for contents in obj_list['Contents']:\n",
    "    files.append(contents['Key'])\n",
    "    \n",
    "filtered_list = list(filter(filter_csv, files))\n",
    "    \n",
    "    \n",
    "# print csv objects in in S3 bucket  \n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_from_s3(s3_client, bucket, name):\n",
    "    data_object = s3_client.get_object(Bucket=bucket, Key=name)\n",
    "    data_body = data_object[\"Body\"].read()\n",
    "    data_stream = io.BytesIO(data_body)\n",
    "    \n",
    "    return pd.read_csv(data_stream, header=0, delimiter=\",\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9628</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>143872</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>143874</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0    9626         2         1.0      10.0          NaN   \n",
       "1           1    9628        -1         9.0      11.0          NaN   \n",
       "2           2  143872        -1         1.0       6.0          NaN   \n",
       "3           3  143873         1         1.0       8.0          NaN   \n",
       "4           4  143874        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VK_ZG11  \\\n",
       "0          NaN          NaN          NaN                  10.0  ...      2.0   \n",
       "1          NaN          NaN          NaN                   NaN  ...      3.0   \n",
       "2          NaN          NaN          NaN                   0.0  ...     11.0   \n",
       "3          NaN          NaN          NaN                   8.0  ...      2.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...      4.0   \n",
       "\n",
       "   W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0             6.0             9.0       7.0         3  COSMETIC_AND_FOOD   \n",
       "1             0.0             9.0       NaN         3               FOOD   \n",
       "2             6.0             9.0       2.0         3  COSMETIC_AND_FOOD   \n",
       "3             NaN             9.0       7.0         1           COSMETIC   \n",
       "4             2.0             9.0       3.0         1               FOOD   \n",
       "\n",
       "   CUSTOMER_GROUP  ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0     MULTI_BUYER                0         1                    4  \n",
       "1    SINGLE_BUYER                0         1                    4  \n",
       "2     MULTI_BUYER                0         2                    4  \n",
       "3     MULTI_BUYER                0         1                    4  \n",
       "4     MULTI_BUYER                0         1                    3  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df = None\n",
    "customers_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[1])\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0           0  910215        -1         NaN       NaN          NaN   \n",
       "1           1  910220        -1         9.0       0.0          NaN   \n",
       "2           2  910225        -1         9.0      17.0          NaN   \n",
       "3           3  910226         2         1.0      13.0          NaN   \n",
       "4           4  910241        -1         1.0      20.0          NaN   \n",
       "\n",
       "   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VHN  \\\n",
       "0          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "1          NaN          NaN          NaN                  21.0  ...  4.0   \n",
       "2          NaN          NaN          NaN                  17.0  ...  2.0   \n",
       "3          NaN          NaN          NaN                  13.0  ...  0.0   \n",
       "4          NaN          NaN          NaN                  14.0  ...  2.0   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1       8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2       9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3       7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4       3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3         1                    2  \n",
       "1         5         2                    1  \n",
       "2         5         2                    3  \n",
       "3         3         2                    4  \n",
       "4         4         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df = None\n",
    "azdias_df = load_dataframe_from_s3(s3_client, bucket_name, filtered_list[0])\n",
    "azdias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>11766.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>139810.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>143781.000000</td>\n",
       "      <td>137910.000000</td>\n",
       "      <td>145056.000000</td>\n",
       "      <td>141725.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>1.747525</td>\n",
       "      <td>11.352009</td>\n",
       "      <td>12.337243</td>\n",
       "      <td>13.672353</td>\n",
       "      <td>14.647059</td>\n",
       "      <td>15.377119</td>\n",
       "      <td>10.331579</td>\n",
       "      <td>...</td>\n",
       "      <td>4.374417</td>\n",
       "      <td>4.564769</td>\n",
       "      <td>3.168868</td>\n",
       "      <td>4.152716</td>\n",
       "      <td>8.646371</td>\n",
       "      <td>3.723133</td>\n",
       "      <td>2.576806</td>\n",
       "      <td>0.090247</td>\n",
       "      <td>1.376432</td>\n",
       "      <td>3.060907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55325.311233</td>\n",
       "      <td>55325.311233</td>\n",
       "      <td>1.391672</td>\n",
       "      <td>1.966334</td>\n",
       "      <td>6.275026</td>\n",
       "      <td>4.006050</td>\n",
       "      <td>3.243335</td>\n",
       "      <td>2.753787</td>\n",
       "      <td>2.307653</td>\n",
       "      <td>4.134828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.924355</td>\n",
       "      <td>2.887035</td>\n",
       "      <td>2.233516</td>\n",
       "      <td>1.974375</td>\n",
       "      <td>1.154001</td>\n",
       "      <td>2.095540</td>\n",
       "      <td>1.168486</td>\n",
       "      <td>0.286536</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>1.086254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47912.750000</td>\n",
       "      <td>47913.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95825.500000</td>\n",
       "      <td>95826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>143738.250000</td>\n",
       "      <td>143739.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191651.000000</td>\n",
       "      <td>191652.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0            LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  191652.000000  191652.000000  191652.000000  145056.000000   \n",
       "mean    95825.500000   95826.500000       0.344359       1.747525   \n",
       "std     55325.311233   55325.311233       1.391672       1.966334   \n",
       "min         0.000000       1.000000      -1.000000       1.000000   \n",
       "25%     47912.750000   47913.750000      -1.000000       1.000000   \n",
       "50%     95825.500000   95826.500000       0.000000       1.000000   \n",
       "75%    143738.250000  143739.250000       2.000000       1.000000   \n",
       "max    191651.000000  191652.000000       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  145056.000000  11766.000000  5100.000000  1275.000000   236.000000   \n",
       "mean       11.352009     12.337243    13.672353    14.647059    15.377119   \n",
       "std         6.275026      4.006050     3.243335     2.753787     2.307653   \n",
       "min         0.000000      2.000000     2.000000     5.000000     8.000000   \n",
       "25%         8.000000      9.000000    11.000000    13.000000    14.000000   \n",
       "50%        11.000000     13.000000    14.000000    15.000000    16.000000   \n",
       "75%        16.000000     16.000000    16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000    18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...       VK_DHT4A     VK_DISTANZ        VK_ZG11  \\\n",
       "count         139810.000000  ...  143781.000000  143781.000000  143781.000000   \n",
       "mean              10.331579  ...       4.374417       4.564769       3.168868   \n",
       "std                4.134828  ...       2.924355       2.887035       2.233516   \n",
       "min                0.000000  ...       1.000000       1.000000       1.000000   \n",
       "25%                9.000000  ...       2.000000       2.000000       1.000000   \n",
       "50%               10.000000  ...       4.000000       4.000000       3.000000   \n",
       "75%               13.000000  ...       7.000000       7.000000       4.000000   \n",
       "max               25.000000  ...      11.000000      13.000000      11.000000   \n",
       "\n",
       "       W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE       ZABEOTYP  \\\n",
       "count   137910.000000   145056.000000  141725.000000  191652.000000   \n",
       "mean         4.152716        8.646371       3.723133       2.576806   \n",
       "std          1.974375        1.154001       2.095540       1.168486   \n",
       "min          0.000000        1.000000       0.000000       1.000000   \n",
       "25%          2.000000        9.000000       2.000000       1.000000   \n",
       "50%          5.000000        9.000000       3.000000       3.000000   \n",
       "75%          6.000000        9.000000       5.000000       3.000000   \n",
       "max          6.000000        9.000000       8.000000       6.000000   \n",
       "\n",
       "       ONLINE_PURCHASE      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count    191652.000000  191652.000000         191652.000000  \n",
       "mean          0.090247       1.376432              3.060907  \n",
       "std           0.286536       0.484492              1.086254  \n",
       "min           0.000000       1.000000              1.000000  \n",
       "25%           0.000000       1.000000              3.000000  \n",
       "50%           0.000000       1.000000              3.000000  \n",
       "75%           0.000000       2.000000              4.000000  \n",
       "max           1.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(customers_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891221.000000</td>\n",
       "      <td>8.912210e+05</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>81058.000000</td>\n",
       "      <td>29499.000000</td>\n",
       "      <td>6170.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>628274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>770025.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>815304.000000</td>\n",
       "      <td>783619.000000</td>\n",
       "      <td>817722.000000</td>\n",
       "      <td>798073.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "      <td>891221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-0.358435</td>\n",
       "      <td>4.421928</td>\n",
       "      <td>10.864126</td>\n",
       "      <td>11.745392</td>\n",
       "      <td>13.402658</td>\n",
       "      <td>14.476013</td>\n",
       "      <td>15.089627</td>\n",
       "      <td>13.700717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417322</td>\n",
       "      <td>6.001214</td>\n",
       "      <td>7.532130</td>\n",
       "      <td>5.945972</td>\n",
       "      <td>3.933406</td>\n",
       "      <td>7.908791</td>\n",
       "      <td>4.052836</td>\n",
       "      <td>3.362438</td>\n",
       "      <td>1.522098</td>\n",
       "      <td>2.777398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257273.486465</td>\n",
       "      <td>2.572735e+05</td>\n",
       "      <td>1.198724</td>\n",
       "      <td>3.638805</td>\n",
       "      <td>7.639683</td>\n",
       "      <td>4.097660</td>\n",
       "      <td>3.243300</td>\n",
       "      <td>2.712427</td>\n",
       "      <td>2.452932</td>\n",
       "      <td>5.079849</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166572</td>\n",
       "      <td>2.856091</td>\n",
       "      <td>3.247789</td>\n",
       "      <td>2.771464</td>\n",
       "      <td>1.964701</td>\n",
       "      <td>1.923137</td>\n",
       "      <td>1.949539</td>\n",
       "      <td>1.352704</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>1.068775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916530e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222805.000000</td>\n",
       "      <td>4.144580e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445610.000000</td>\n",
       "      <td>6.372630e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668415.000000</td>\n",
       "      <td>8.600680e+05</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891220.000000</td>\n",
       "      <td>1.082873e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0           LNR       AGER_TYP     AKT_DAT_KL  \\\n",
       "count  891221.000000  8.912210e+05  891221.000000  817722.000000   \n",
       "mean   445610.000000  6.372630e+05      -0.358435       4.421928   \n",
       "std    257273.486465  2.572735e+05       1.198724       3.638805   \n",
       "min         0.000000  1.916530e+05      -1.000000       1.000000   \n",
       "25%    222805.000000  4.144580e+05      -1.000000       1.000000   \n",
       "50%    445610.000000  6.372630e+05      -1.000000       3.000000   \n",
       "75%    668415.000000  8.600680e+05      -1.000000       9.000000   \n",
       "max    891220.000000  1.082873e+06       3.000000       9.000000   \n",
       "\n",
       "            ALTER_HH   ALTER_KIND1   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
       "count  817722.000000  81058.000000  29499.000000  6170.000000  1205.000000   \n",
       "mean       10.864126     11.745392     13.402658    14.476013    15.089627   \n",
       "std         7.639683      4.097660      3.243300     2.712427     2.452932   \n",
       "min         0.000000      2.000000      2.000000     4.000000     7.000000   \n",
       "25%         0.000000      8.000000     11.000000    13.000000    14.000000   \n",
       "50%        13.000000     12.000000     14.000000    15.000000    15.000000   \n",
       "75%        17.000000     15.000000     16.000000    17.000000    17.000000   \n",
       "max        21.000000     18.000000     18.000000    18.000000    18.000000   \n",
       "\n",
       "       ALTERSKATEGORIE_FEIN  ...            VHN       VK_DHT4A     VK_DISTANZ  \\\n",
       "count         628274.000000  ...  770025.000000  815304.000000  815304.000000   \n",
       "mean              13.700717  ...       2.417322       6.001214       7.532130   \n",
       "std                5.079849  ...       1.166572       2.856091       3.247789   \n",
       "min                0.000000  ...       0.000000       1.000000       1.000000   \n",
       "25%               11.000000  ...       2.000000       3.000000       5.000000   \n",
       "50%               14.000000  ...       2.000000       6.000000       8.000000   \n",
       "75%               17.000000  ...       3.000000       9.000000      10.000000   \n",
       "max               25.000000  ...       4.000000      11.000000      13.000000   \n",
       "\n",
       "             VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008       WOHNLAGE  \\\n",
       "count  815304.000000   783619.000000   817722.000000  798073.000000   \n",
       "mean        5.945972        3.933406        7.908791       4.052836   \n",
       "std         2.771464        1.964701        1.923137       1.949539   \n",
       "min         1.000000        0.000000        1.000000       0.000000   \n",
       "25%         4.000000        2.000000        8.000000       3.000000   \n",
       "50%         6.000000        4.000000        9.000000       3.000000   \n",
       "75%         8.000000        6.000000        9.000000       5.000000   \n",
       "max        11.000000        6.000000        9.000000       8.000000   \n",
       "\n",
       "            ZABEOTYP      ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "count  891221.000000  891221.000000         891221.000000  \n",
       "mean        3.362438       1.522098              2.777398  \n",
       "std         1.352704       0.499512              1.068775  \n",
       "min         1.000000       1.000000              1.000000  \n",
       "25%         3.000000       1.000000              2.000000  \n",
       "50%         3.000000       2.000000              3.000000  \n",
       "75%         4.000000       2.000000              4.000000  \n",
       "max         6.000000       2.000000              9.000000  \n",
       "\n",
       "[8 rows x 361 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(azdias_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTER_KIND4                    99.864792\n",
       "ALTER_KIND3                    99.307691\n",
       "ALTER_KIND2                    96.690047\n",
       "ALTER_KIND1                    90.904837\n",
       "EXTSEL992                      73.399639\n",
       "KK_KUNDENTYP                   65.596749\n",
       "ALTERSKATEGORIE_FEIN           29.504130\n",
       "D19_VERSI_ONLINE_QUOTE_12      28.849522\n",
       "D19_LETZTER_KAUF_BRANCHE       28.849522\n",
       "D19_BANKEN_ONLINE_QUOTE_12     28.849522\n",
       "D19_TELKO_ONLINE_QUOTE_12      28.849522\n",
       "D19_VERSAND_ONLINE_QUOTE_12    28.849522\n",
       "D19_KONSUMTYP                  28.849522\n",
       "D19_SOZIALES                   28.849522\n",
       "D19_GESAMT_ONLINE_QUOTE_12     28.849522\n",
       "D19_LOTTO                      28.849522\n",
       "KBA05_SEG8                     14.959701\n",
       "KBA05_SEG7                     14.959701\n",
       "KBA05_KW2                      14.959701\n",
       "KBA05_KW3                      14.959701\n",
       "KBA05_MAXAH                    14.959701\n",
       "KBA05_MAXBJ                    14.959701\n",
       "KBA05_MAXHERST                 14.959701\n",
       "KBA05_MAXSEG                   14.959701\n",
       "KBA05_MAXVORB                  14.959701\n",
       "KBA05_MOD1                     14.959701\n",
       "KBA05_MOD2                     14.959701\n",
       "KBA05_MOD3                     14.959701\n",
       "KBA05_MOD4                     14.959701\n",
       "KBA05_MOD8                     14.959701\n",
       "                                 ...    \n",
       "D19_RATGEBER                    0.000000\n",
       "FINANZ_ANLEGER                  0.000000\n",
       "D19_REISEN                      0.000000\n",
       "D19_SAMMELARTIKEL               0.000000\n",
       "D19_SCHUHE                      0.000000\n",
       "D19_SONSTIGE                    0.000000\n",
       "D19_TECHNIK                     0.000000\n",
       "D19_TELKO_ANZ_12                0.000000\n",
       "D19_TELKO_ANZ_24                0.000000\n",
       "D19_TELKO_DATUM                 0.000000\n",
       "D19_TELKO_MOBILE                0.000000\n",
       "D19_TELKO_OFFLINE_DATUM         0.000000\n",
       "D19_TELKO_ONLINE_DATUM          0.000000\n",
       "D19_TELKO_REST                  0.000000\n",
       "D19_TIERARTIKEL                 0.000000\n",
       "D19_VERSAND_ANZ_12              0.000000\n",
       "D19_VERSAND_ANZ_24              0.000000\n",
       "D19_VERSAND_DATUM               0.000000\n",
       "D19_VERSAND_OFFLINE_DATUM       0.000000\n",
       "D19_VERSAND_ONLINE_DATUM        0.000000\n",
       "D19_VERSAND_REST                0.000000\n",
       "D19_VERSI_ANZ_12                0.000000\n",
       "D19_VERSI_ANZ_24                0.000000\n",
       "D19_VERSI_DATUM                 0.000000\n",
       "D19_VERSI_OFFLINE_DATUM         0.000000\n",
       "D19_VERSI_ONLINE_DATUM          0.000000\n",
       "D19_VERSICHERUNGEN              0.000000\n",
       "D19_VOLLSORTIMENT               0.000000\n",
       "D19_WEIN_FEINKOST               0.000000\n",
       "Unnamed: 0                      0.000000\n",
       "Length: 367, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = azdias_df.shape[0]\n",
    "missing_values_azdias = azdias_df.isnull().sum().sort_values(ascending = False).divide(other = (rows/100))\n",
    "\n",
    "display(missing_values_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have more than 28% of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891221, 351)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a dict with the names of the columns and then drop this columns from dataframe\n",
    "drop_columns = missing_values_azdias[missing_values_azdias > 28]\n",
    "\n",
    "azdias_df.drop(columns = list(drop_columns.index), axis = 1, inplace = True)\n",
    "\n",
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the columns that have less than 0.5 variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_description = azdias_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = azdias_description.loc[['std']].values.reshape(346,)\n",
    "std_serie = pd.Series(std_df, index =azdias_description.columns) \n",
    "\n",
    "drop_lowdispersion_cols = std_serie[std_serie < 0.5]\n",
    "\n",
    "azdias_df.drop(columns = list(drop_lowdispersion_cols.index), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 2486.31 Mb\n"
     ]
    }
   ],
   "source": [
    "def memory_usage(df):\n",
    "    return(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2))\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'LNR', 'AGER_TYP', 'AKT_DAT_KL', 'ALTER_HH', 'ANZ_HAUSHALTE_AKTIV', 'ANZ_KINDER', 'ANZ_PERSONEN', 'ANZ_STATISTISCHE_HAUSHALTE', 'ARBEIT', 'BALLRAUM', 'CAMEO_DEU_2015', 'CAMEO_DEUG_2015', 'CAMEO_INTL_2015', 'CJT_GESAMTTYP', 'CJT_KATALOGNUTZER', 'CJT_TYP_1', 'CJT_TYP_2', 'CJT_TYP_3', 'CJT_TYP_4', 'CJT_TYP_5', 'CJT_TYP_6', 'D19_BANKEN_ANZ_12', 'D19_BANKEN_ANZ_24', 'D19_BANKEN_DATUM', 'D19_BANKEN_DIREKT', 'D19_BANKEN_GROSS', 'D19_BANKEN_LOKAL', 'D19_BANKEN_OFFLINE_DATUM', 'D19_BANKEN_ONLINE_DATUM', 'D19_BANKEN_REST', 'D19_BEKLEIDUNG_GEH', 'D19_BEKLEIDUNG_REST', 'D19_BILDUNG', 'D19_BIO_OEKO', 'D19_BUCH_CD', 'D19_DIGIT_SERV', 'D19_DROGERIEARTIKEL', 'D19_ENERGIE', 'D19_FREIZEIT', 'D19_GARTEN', 'D19_GESAMT_ANZ_12', 'D19_GESAMT_ANZ_24', 'D19_GESAMT_DATUM', 'D19_GESAMT_OFFLINE_DATUM', 'D19_GESAMT_ONLINE_DATUM', 'D19_HANDWERK', 'D19_HAUS_DEKO', 'D19_KINDERARTIKEL', 'D19_KONSUMTYP_MAX', 'D19_KOSMETIK', 'D19_LEBENSMITTEL', 'D19_NAHRUNGSERGAENZUNG', 'D19_RATGEBER', 'D19_REISEN', 'D19_SAMMELARTIKEL', 'D19_SCHUHE', 'D19_SONSTIGE', 'D19_TECHNIK', 'D19_TELKO_DATUM', 'D19_TELKO_MOBILE', 'D19_TELKO_OFFLINE_DATUM', 'D19_TELKO_REST', 'D19_TIERARTIKEL', 'D19_VERSAND_ANZ_12', 'D19_VERSAND_ANZ_24', 'D19_VERSAND_DATUM', 'D19_VERSAND_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM', 'D19_VERSAND_REST', 'D19_VERSI_ANZ_24', 'D19_VERSI_DATUM', 'D19_VERSI_OFFLINE_DATUM', 'D19_VERSICHERUNGEN', 'D19_VOLLSORTIMENT', 'D19_WEIN_FEINKOST', 'EINGEFUEGT_AM', 'EINGEZOGENAM_HH_JAHR', 'EWDICHTE', 'FINANZ_ANLEGER', 'FINANZ_HAUSBAUER', 'FINANZ_MINIMALIST', 'FINANZ_SPARER', 'FINANZ_UNAUFFAELLIGER', 'FINANZ_VORSORGER', 'FINANZTYP', 'FIRMENDICHTE', 'GEBAEUDETYP', 'GEBAEUDETYP_RASTER', 'GEBURTSJAHR', 'GEMEINDETYP', 'GFK_URLAUBERTYP', 'HEALTH_TYP', 'HH_EINKOMMEN_SCORE', 'INNENSTADT', 'KBA05_ALTER1', 'KBA05_ALTER2', 'KBA05_ALTER3', 'KBA05_ALTER4', 'KBA05_ANHANG', 'KBA05_ANTG1', 'KBA05_ANTG2', 'KBA05_ANTG3', 'KBA05_ANTG4', 'KBA05_AUTOQUOT', 'KBA05_BAUMAX', 'KBA05_CCM1', 'KBA05_CCM2', 'KBA05_CCM3', 'KBA05_CCM4', 'KBA05_DIESEL', 'KBA05_FRAU', 'KBA05_GBZ', 'KBA05_HERST1', 'KBA05_HERST2', 'KBA05_HERST3', 'KBA05_HERST4', 'KBA05_HERST5', 'KBA05_HERSTTEMP', 'KBA05_KRSAQUOT', 'KBA05_KRSHERST1', 'KBA05_KRSHERST2', 'KBA05_KRSHERST3', 'KBA05_KRSKLEIN', 'KBA05_KRSOBER', 'KBA05_KRSVAN', 'KBA05_KRSZUL', 'KBA05_KW1', 'KBA05_KW2', 'KBA05_KW3', 'KBA05_MAXAH', 'KBA05_MAXBJ', 'KBA05_MAXHERST', 'KBA05_MAXSEG', 'KBA05_MAXVORB', 'KBA05_MOD1', 'KBA05_MOD2', 'KBA05_MOD3', 'KBA05_MOD4', 'KBA05_MOD8', 'KBA05_MODTEMP', 'KBA05_MOTOR', 'KBA05_MOTRAD', 'KBA05_SEG1', 'KBA05_SEG10', 'KBA05_SEG2', 'KBA05_SEG3', 'KBA05_SEG4', 'KBA05_SEG5', 'KBA05_SEG6', 'KBA05_SEG7', 'KBA05_SEG8', 'KBA05_SEG9', 'KBA05_VORB0', 'KBA05_VORB1', 'KBA05_VORB2', 'KBA05_ZUL1', 'KBA05_ZUL2', 'KBA05_ZUL3', 'KBA05_ZUL4', 'KBA13_ALTERHALTER_30', 'KBA13_ALTERHALTER_45', 'KBA13_ALTERHALTER_60', 'KBA13_ALTERHALTER_61', 'KBA13_ANTG1', 'KBA13_ANTG2', 'KBA13_ANTG3', 'KBA13_ANTG4', 'KBA13_ANZAHL_PKW', 'KBA13_AUDI', 'KBA13_AUTOQUOTE', 'KBA13_BAUMAX', 'KBA13_BJ_1999', 'KBA13_BJ_2000', 'KBA13_BJ_2004', 'KBA13_BJ_2006', 'KBA13_BJ_2008', 'KBA13_BJ_2009', 'KBA13_BMW', 'KBA13_CCM_0_1400', 'KBA13_CCM_1000', 'KBA13_CCM_1200', 'KBA13_CCM_1400', 'KBA13_CCM_1401_2500', 'KBA13_CCM_1500', 'KBA13_CCM_1600', 'KBA13_CCM_1800', 'KBA13_CCM_2000', 'KBA13_CCM_2500', 'KBA13_CCM_2501', 'KBA13_CCM_3000', 'KBA13_CCM_3001', 'KBA13_FAB_ASIEN', 'KBA13_FAB_SONSTIGE', 'KBA13_FIAT', 'KBA13_FORD', 'KBA13_GBZ', 'KBA13_HALTER_20', 'KBA13_HALTER_25', 'KBA13_HALTER_30', 'KBA13_HALTER_35', 'KBA13_HALTER_40', 'KBA13_HALTER_45', 'KBA13_HALTER_50', 'KBA13_HALTER_55', 'KBA13_HALTER_60', 'KBA13_HALTER_65', 'KBA13_HALTER_66', 'KBA13_HERST_ASIEN', 'KBA13_HERST_AUDI_VW', 'KBA13_HERST_BMW_BENZ', 'KBA13_HERST_EUROPA', 'KBA13_HERST_FORD_OPEL', 'KBA13_HERST_SONST', 'KBA13_HHZ', 'KBA13_KMH_0_140', 'KBA13_KMH_110', 'KBA13_KMH_140', 'KBA13_KMH_140_210', 'KBA13_KMH_180', 'KBA13_KMH_210', 'KBA13_KMH_211', 'KBA13_KMH_250', 'KBA13_KMH_251', 'KBA13_KRSAQUOT', 'KBA13_KRSHERST_AUDI_VW', 'KBA13_KRSHERST_BMW_BENZ', 'KBA13_KRSHERST_FORD_OPEL', 'KBA13_KRSSEG_OBER', 'KBA13_KRSSEG_VAN', 'KBA13_KRSZUL_NEU', 'KBA13_KW_0_60', 'KBA13_KW_110', 'KBA13_KW_120', 'KBA13_KW_121', 'KBA13_KW_30', 'KBA13_KW_40', 'KBA13_KW_50', 'KBA13_KW_60', 'KBA13_KW_61_120', 'KBA13_KW_70', 'KBA13_KW_80', 'KBA13_KW_90', 'KBA13_MAZDA', 'KBA13_MERCEDES', 'KBA13_MOTOR', 'KBA13_NISSAN', 'KBA13_OPEL', 'KBA13_PEUGEOT', 'KBA13_RENAULT', 'KBA13_SEG_GELAENDEWAGEN', 'KBA13_SEG_GROSSRAUMVANS', 'KBA13_SEG_KLEINST', 'KBA13_SEG_KLEINWAGEN', 'KBA13_SEG_KOMPAKTKLASSE', 'KBA13_SEG_MINIVANS', 'KBA13_SEG_MINIWAGEN', 'KBA13_SEG_MITTELKLASSE', 'KBA13_SEG_OBEREMITTELKLASSE', 'KBA13_SEG_OBERKLASSE', 'KBA13_SEG_SONSTIGE', 'KBA13_SEG_SPORTWAGEN', 'KBA13_SEG_UTILITIES', 'KBA13_SEG_VAN', 'KBA13_SEG_WOHNMOBILE', 'KBA13_SITZE_4', 'KBA13_SITZE_5', 'KBA13_SITZE_6', 'KBA13_TOYOTA', 'KBA13_VORB_0', 'KBA13_VORB_1', 'KBA13_VORB_1_2', 'KBA13_VORB_2', 'KBA13_VORB_3', 'KBA13_VW', 'KKK', 'KOMBIALTER', 'KONSUMNAEHE', 'LP_FAMILIE_FEIN', 'LP_FAMILIE_GROB', 'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'LP_STATUS_FEIN', 'LP_STATUS_GROB', 'MIN_GEBAEUDEJAHR', 'MOBI_RASTER', 'MOBI_REGIO', 'NATIONALITAET_KZ', 'ONLINE_AFFINITAET', 'ORTSGR_KLS9', 'OST_WEST_KZ', 'PLZ8_ANTG1', 'PLZ8_ANTG2', 'PLZ8_ANTG3', 'PLZ8_ANTG4', 'PLZ8_BAUMAX', 'PLZ8_GBZ', 'PLZ8_HHZ', 'PRAEGENDE_JUGENDJAHRE', 'REGIOTYP', 'RELAT_AB', 'RETOURTYP_BK_S', 'RT_KEIN_ANREIZ', 'RT_SCHNAEPPCHEN', 'RT_UEBERGROESSE', 'SEMIO_DOM', 'SEMIO_ERL', 'SEMIO_FAM', 'SEMIO_KAEM', 'SEMIO_KRIT', 'SEMIO_KULT', 'SEMIO_LUST', 'SEMIO_MAT', 'SEMIO_PFLICHT', 'SEMIO_RAT', 'SEMIO_REL', 'SEMIO_SOZ', 'SEMIO_TRADV', 'SEMIO_VERT', 'SHOPPER_TYP', 'STRUKTURTYP', 'UMFELD_ALT', 'UMFELD_JUNG', 'VERDICHTUNGSRAUM', 'VERS_TYP', 'VHA', 'VHN', 'VK_DHT4A', 'VK_DISTANZ', 'VK_ZG11', 'W_KEIT_KIND_HH', 'WOHNDAUER_2008', 'WOHNLAGE', 'ZABEOTYP', 'ALTERSKATEGORIE_GROB']\n"
     ]
    }
   ],
   "source": [
    "print(list(azdias_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df['CAMEO_INTL_2015'].replace('XX',np.nan, inplace = True)\n",
    "azdias_df['CAMEO_DEUG_2015'].replace('X',np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 650.54 Mb\n"
     ]
    }
   ],
   "source": [
    "#It is necessary to reduce the size of the dataframe in order to optimize the memory usage\n",
    "\n",
    "def to_category(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('category', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def to_int(df, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].astype('uint8', inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "categorical_columns = [\n",
    "                        'ALTERSKATEGORIE_GROB','AGER_TYP','ALTER_HH',\n",
    "                      'BALLRAUM','CAMEO_DEUG_2015','CAMEO_DEU_2015','D19_BANKEN_ANZ_24',\n",
    "                      'CJT_GESAMTTYP','D19_BANKEN_ANZ_12','D19_BANKEN_DATUM',\n",
    "                      'D19_BANKEN_OFFLINE_DATUM',\n",
    "                      'D19_BANKEN_ONLINE_DATUM','D19_BANKEN_DIREKT','D19_BANKEN_GROSS',\n",
    "                      'D19_BANKEN_LOKAL','D19_BANKEN_REST',\n",
    "                      'D19_BEKLEIDUNG_GEH','D19_BEKLEIDUNG_REST','D19_BILDUNG',\n",
    "                      'D19_BIO_OEKO','D19_BUCH_CD','D19_DIGIT_SERV','D19_DROGERIEARTIKEL',\n",
    "                      'D19_ENERGIE','D19_FREIZEIT','D19_GARTEN','D19_GESAMT_ANZ_12',\n",
    "                      'D19_GESAMT_ANZ_24','D19_GESAMT_DATUM','D19_GESAMT_OFFLINE_DATUM','D19_GESAMT_ONLINE_DATUM',\n",
    "                      'D19_HANDWERK','D19_HAUS_DEKO','D19_KINDERARTIKEL',\n",
    "                      'D19_KONSUMTYP_MAX','D19_KOSMETIK','D19_LEBENSMITTEL','D19_NAHRUNGSERGAENZUNG',\n",
    "                      'D19_RATGEBER','D19_REISEN','D19_SAMMELARTIKEL','D19_SCHUHE','D19_SONSTIGE',\n",
    "                      'D19_TECHNIK','D19_TELKO_DATUM',\n",
    "                      'D19_TELKO_MOBILE','D19_TELKO_OFFLINE_DATUM',\n",
    "                       'D19_TELKO_REST','D19_TIERARTIKEL','D19_VERSAND_ANZ_12',\n",
    "                      'D19_VERSAND_ANZ_24','D19_VERSAND_DATUM','D19_VERSAND_DATUM',\n",
    "                      'D19_VERSAND_ONLINE_DATUM','D19_VERSAND_REST','D19_VERSICHERUNGEN',\n",
    "                      'D19_VERSI_ANZ_24','D19_VOLLSORTIMENT','D19_WEIN_FEINKOST','EWDICHTE',\n",
    "                      'FINANZTYP','FINANZ_ANLEGER','FINANZ_HAUSBAUER','FINANZ_MINIMALIST',\n",
    "                      'FINANZ_SPARER','FINANZ_UNAUFFAELLIGER','FINANZ_VORSORGER',\n",
    "                      'GEBAEUDETYP','GEBAEUDETYP_RASTER','GFK_URLAUBERTYP',\n",
    "                      'STRUKTURTYP','HEALTH_TYP',\n",
    "                      'HH_EINKOMMEN_SCORE','INNENSTADT','KBA05_ALTER1','KBA05_ALTER2',\n",
    "                      'KBA05_ALTER3','KBA05_ALTER4','KBA05_ANHANG','KBA05_ANTG1','KBA05_ANTG2',\n",
    "                      'KBA05_ANTG3','KBA05_ANTG4','KBA05_AUTOQUOT','KBA05_BAUMAX','KBA05_CCM1',\n",
    "                    'KBA05_CCM2','KBA05_CCM3','KBA05_CCM4','KBA05_DIESEL','KBA05_FRAU','KBA05_GBZ',\n",
    "                    'KBA05_HERST1','KBA05_HERST2','KBA05_HERST3','KBA05_HERST4','KBA05_HERST5',\n",
    "                    'KBA05_HERSTTEMP','KBA05_KRSAQUOT','KBA05_KRSHERST1','KBA05_KRSHERST2',\n",
    "                    'KBA05_KRSHERST3','KBA05_KRSKLEIN','KBA05_KRSOBER','KBA05_KRSVAN',\n",
    "                    'KBA05_KRSZUL','KBA05_KW1','KBA05_KW2','KBA05_KW3','KBA05_MAXAH','KBA05_MAXBJ',\n",
    "                    'KBA05_MAXHERST','KBA05_MAXSEG','KBA05_MAXVORB','KBA05_MOD1','KBA05_MOD2',\n",
    "                    'KBA05_MOD3','KBA05_MOD4','KBA05_MOD8','KBA05_MODTEMP','KBA05_MOTOR',\n",
    "                    'KBA05_MOTRAD','KBA05_SEG1','KBA05_SEG10','KBA05_SEG2','KBA05_SEG3',\n",
    "                    'KBA05_SEG4','KBA05_SEG5','KBA05_SEG6','KBA05_SEG7','KBA05_SEG8','KBA05_SEG9',\n",
    "                    'KBA05_VORB0','KBA05_VORB1','KBA05_VORB2','KBA05_ZUL1','KBA05_ZUL2',\n",
    "                    'KBA05_ZUL3','KBA05_ZUL4','KBA13_ALTERHALTER_30','KBA13_ALTERHALTER_45',\n",
    "                    'KBA13_ALTERHALTER_60','KBA13_ALTERHALTER_61','KBA13_AUDI','KBA13_AUTOQUOTE',\n",
    "                    'KBA13_BJ_1999','KBA13_BJ_2000','KBA13_BJ_2004','KBA13_BJ_2006',\n",
    "                    'KBA13_BJ_2008','KBA13_BJ_2009','KBA13_BMW','KBA13_CCM_1000','KBA13_CCM_1200',\n",
    "                    'KBA13_CCM_1400','KBA13_CCM_0_1400','KBA13_CCM_1500','KBA13_CCM_1401_2500',\n",
    "                    'KBA13_CCM_1600','KBA13_CCM_1800','KBA13_CCM_2000','KBA13_CCM_2500',\n",
    "                    'KBA13_CCM_2501','KBA13_CCM_3000','KBA13_CCM_3001','KBA13_FAB_ASIEN',\n",
    "                    'KBA13_FAB_SONSTIGE','KBA13_FIAT','KBA13_FORD','KBA13_HALTER_20',\n",
    "                    'KBA13_HALTER_25','KBA13_HALTER_30','KBA13_HALTER_35','KBA13_HALTER_40',\n",
    "                    'KBA13_HALTER_45','KBA13_HALTER_50','KBA13_HALTER_55','KBA13_HALTER_60',\n",
    "                    'KBA13_HALTER_65','KBA13_HALTER_66','KBA13_HERST_ASIEN','KBA13_HERST_AUDI_VW',\n",
    "                    'KBA13_HERST_BMW_BENZ','KBA13_HERST_EUROPA','KBA13_HERST_FORD_OPEL',\n",
    "                    'KBA13_HERST_SONST','KBA13_KMH_110','KBA13_KMH_140','KBA13_KMH_180',\n",
    "                    'KBA13_KMH_0_140','KBA13_KMH_140_210','KBA13_KMH_211','KBA13_KMH_250',\n",
    "                    'KBA13_KMH_251','KBA13_KRSAQUOT','KBA13_KRSHERST_AUDI_VW',\n",
    "                    'KBA13_KRSHERST_BMW_BENZ','KBA13_KRSHERST_FORD_OPEL',\n",
    "                    'KBA13_KRSSEG_OBER','KBA13_KRSSEG_VAN','KBA13_KRSZUL_NEU','KBA13_KW_30',\n",
    "                    'KBA13_KW_40','KBA13_KW_50','KBA13_KW_60','KBA13_KW_0_60','KBA13_KW_70',\n",
    "                    'KBA13_KW_61_120','KBA13_KW_80','KBA13_KW_90','KBA13_KW_110','KBA13_KW_120',\n",
    "                    'KBA13_KW_121','KBA13_MAZDA','KBA13_MERCEDES','KBA13_MOTOR','KBA13_NISSAN',\n",
    "                    'KBA13_OPEL','KBA13_PEUGEOT','KBA13_RENAULT','KBA13_SEG_GELAENDEWAGEN',\n",
    "                    'KBA13_SEG_GROSSRAUMVANS','KBA13_SEG_KLEINST','KBA13_SEG_KLEINWAGEN',\n",
    "                    'KBA13_SEG_KOMPAKTKLASSE','KBA13_SEG_MINIVANS','KBA13_SEG_MINIWAGEN',\n",
    "                    'KBA13_SEG_MITTELKLASSE','KBA13_SEG_OBEREMITTELKLASSE','KBA13_SEG_OBERKLASSE',\n",
    "                    'KBA13_SEG_SONSTIGE','KBA13_SEG_SPORTWAGEN','KBA13_SEG_UTILITIES',\n",
    "                    'KBA13_SEG_VAN','KBA13_SEG_WOHNMOBILE','KBA13_SITZE_4','KBA13_SITZE_5',\n",
    "                    'KBA13_SITZE_6','KBA13_TOYOTA','KBA13_VORB_0','KBA13_VORB_1','KBA13_VORB_1_2',\n",
    "                    'KBA13_VORB_2','KBA13_VORB_3','KBA13_VW','KKK','KONSUMNAEHE','LP_FAMILIE_FEIN',\n",
    "                    'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','LP_LEBENSPHASE_GROB','LP_STATUS_FEIN',\n",
    "                    'LP_STATUS_GROB','MOBI_REGIO','NATIONALITAET_KZ','ONLINE_AFFINITAET','ORTSGR_KLS9',\n",
    "                    'OST_WEST_KZ','PLZ8_ANTG1','PLZ8_ANTG2','PLZ8_ANTG3','PLZ8_ANTG4','PLZ8_BAUMAX',\n",
    "                    'PLZ8_GBZ','PLZ8_HHZ','PRAEGENDE_JUGENDJAHRE','REGIOTYP','RELAT_AB',\n",
    "                    'RETOURTYP_BK_S','SEMIO_DOM','SEMIO_ERL','SEMIO_FAM','SEMIO_KAEM','SEMIO_KRIT',\n",
    "                    'SEMIO_KULT','SEMIO_LUST','SEMIO_MAT','SEMIO_PFLICHT','SEMIO_RAT','SEMIO_REL',\n",
    "                    'SEMIO_SOZ','SEMIO_TRADV','SEMIO_VERT','SHOPPER_TYP',\n",
    "                    'VERS_TYP','WOHNDAUER_2008','WOHNLAGE','W_KEIT_KIND_HH','ZABEOTYP']\n",
    "\n",
    "#GEBURTSJAHR year of birth, to int or to date\n",
    "#GREEN_AVANTGARDE maybe can be a bool\n",
    "azdias_df = to_category(azdias_df, categorical_columns)\n",
    "#azdias_df = to_int(azdias_df, categorical_columns)\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging for more space it can be seen that there are columns that are not listed in the csv description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EINGEFUEGT_AM                 60.686382\n",
       "CAMEO_INTL_2015               39.016406\n",
       "ANZ_STATISTISCHE_HAUSHALTE     6.799477\n",
       "KBA13_GBZ                      6.799477\n",
       "CJT_KATALOGNUTZER              6.799477\n",
       "RT_SCHNAEPPCHEN                6.799477\n",
       "RT_KEIN_ANREIZ                 6.799477\n",
       "AKT_DAT_KL                     6.799477\n",
       "KBA13_HHZ                      6.799477\n",
       "ANZ_HAUSHALTE_AKTIV            6.799477\n",
       "ANZ_KINDER                     6.799477\n",
       "ANZ_PERSONEN                   6.799477\n",
       "ARBEIT                         6.799477\n",
       "D19_VERSI_OFFLINE_DATUM        6.799477\n",
       "D19_VERSAND_OFFLINE_DATUM      6.799477\n",
       "CJT_TYP_6                      6.799477\n",
       "CJT_TYP_5                      6.799477\n",
       "CJT_TYP_4                      6.799477\n",
       "MOBI_RASTER                    6.799477\n",
       "MIN_GEBAEUDEJAHR               6.799477\n",
       "CJT_TYP_3                      6.799477\n",
       "CJT_TYP_2                      6.799477\n",
       "CJT_TYP_1                      6.799477\n",
       "KOMBIALTER                     6.799477\n",
       "D19_VERSI_DATUM                6.799477\n",
       "KBA13_ANTG3                    6.799477\n",
       "VERDICHTUNGSRAUM               6.799477\n",
       "LNR                            6.799477\n",
       "FIRMENDICHTE                   6.799477\n",
       "KBA13_ANTG1                    6.799477\n",
       "                                ...    \n",
       "KBA13_CCM_3001                 0.850125\n",
       "KBA13_HALTER_35                0.850125\n",
       "KBA13_HALTER_30                0.850125\n",
       "KBA13_FIAT                     0.850125\n",
       "KBA13_HALTER_20                0.850125\n",
       "KBA13_FAB_ASIEN                0.850125\n",
       "KBA13_FORD                     0.850125\n",
       "KBA13_FAB_SONSTIGE             0.850125\n",
       "KBA13_KRSZUL_NEU               0.850118\n",
       "KBA05_KRSVAN                   0.850118\n",
       "PLZ8_ANTG3                     0.850118\n",
       "KBA13_MOTOR                    0.850118\n",
       "NATIONALITAET_KZ               0.850118\n",
       "KBA05_MAXVORB                  0.850118\n",
       "KBA05_KRSKLEIN                 0.850118\n",
       "KBA13_KRSSEG_VAN               0.850118\n",
       "KBA05_KRSOBER                  0.850118\n",
       "HEALTH_TYP                     0.850118\n",
       "KBA05_KRSZUL                   0.850118\n",
       "KBA13_KRSSEG_OBER              0.850118\n",
       "KBA05_ANTG3                    0.850118\n",
       "VERS_TYP                       0.850034\n",
       "STRUKTURTYP                    0.850034\n",
       "KBA13_KMH_110                  0.850034\n",
       "KBA05_ANTG4                    0.850034\n",
       "PLZ8_ANTG4                     0.850034\n",
       "KBA05_SEG6                     0.850034\n",
       "KBA13_KMH_251                  0.850034\n",
       "KBA13_KW_30                    0.850034\n",
       "Index                          0.000076\n",
       "Length: 336, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(azdias_df.memory_usage(deep=True) / 1024 ** 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 364.24 Mb\n"
     ]
    }
   ],
   "source": [
    "categorical_columns2 = ['CAMEO_INTL_2015','KBA13_ANTG1','KBA13_GBZ','D19_VERSI_DATUM','RT_UEBERGROESSE',\n",
    "                       'RT_SCHNAEPPCHEN','RT_KEIN_ANREIZ','ANZ_HAUSHALTE_AKTIV','ANZ_KINDER',\n",
    "                       'ANZ_PERSONEN','ANZ_STATISTISCHE_HAUSHALTE','ARBEIT','MOBI_RASTER',\n",
    "                       'D19_VERSI_OFFLINE_DATUM','MIN_GEBAEUDEJAHR','KOMBIALTER',\n",
    "                       'CJT_KATALOGNUTZER','CJT_TYP_1','CJT_TYP_2','CJT_TYP_3','CJT_TYP_4','CJT_TYP_5',\n",
    "                        'CJT_TYP_6','KBA13_HHZ','KBA13_KMH_210','KBA13_BAUMAX',\n",
    "                       'UMFELD_JUNG','EINGEZOGENAM_HH_JAHR','GEMEINDETYP',\n",
    "                       'GEBURTSJAHR','AKT_DAT_KL','KBA13_ANTG2','D19_VERSAND_OFFLINE_DATUM','UMFELD_ALT',\n",
    "                       'KBA13_ANTG3','VK_DISTANZ','FIRMENDICHTE','VERDICHTUNGSRAUM',\n",
    "                       'VK_ZG11','KBA13_ANTG4','VK_DHT4A','VHN','VHA']\n",
    "\n",
    "azdias_df = to_category(azdias_df, categorical_columns2)\n",
    "#KBA13_ANZAHL_PKW to int\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows that not have at least 270 (80%) non null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired in https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4\n",
    "\n",
    "def impute_mode_categorical(df):\n",
    "    categorical_columns= df.select_dtypes(include=['category'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in categorical_columns: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        #col_data.replace('XX',np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        mode = col_data.mode()[0]\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(mode, inplace=True)\n",
    "            \n",
    "    return df\n",
    "    \n",
    "def impute_median_numerical(df):\n",
    "    numeric_cols = df.select_dtypes(include=['int','float'])\n",
    "    cols = list(df)\n",
    "    \n",
    "    for column in numeric_cols: \n",
    "        col_data = df[column]\n",
    "        \n",
    "        col_data.replace(-1,np.nan, inplace = True)\n",
    "        null_data = sum(col_data.isna())\n",
    "        median = col_data.median()\n",
    "        if null_data > 0:\n",
    "            col_data.fillna(median, inplace=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 316.11 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_df.dropna(thresh=290, inplace = True)\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace nulls and unknown (-1) values with mode or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_mode_categorical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>...</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>910220</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>910225</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>910241</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>910244</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     LNR AGER_TYP AKT_DAT_KL ALTER_HH ANZ_HAUSHALTE_AKTIV  \\\n",
       "1           1  910220        2        9.0      0.0                11.0   \n",
       "2           2  910225        2        9.0     17.0                10.0   \n",
       "3           3  910226        2        1.0     13.0                 1.0   \n",
       "4           4  910241        2        1.0     20.0                 3.0   \n",
       "5           5  910244        3        1.0     10.0                 5.0   \n",
       "\n",
       "  ANZ_KINDER ANZ_PERSONEN ANZ_STATISTISCHE_HAUSHALTE ARBEIT  ...  VHA  VHN  \\\n",
       "1        0.0          2.0                       12.0    3.0  ...  0.0  4.0   \n",
       "2        0.0          1.0                        7.0    3.0  ...  0.0  2.0   \n",
       "3        0.0          0.0                        2.0    2.0  ...  1.0  0.0   \n",
       "4        0.0          4.0                        3.0    4.0  ...  0.0  2.0   \n",
       "5        0.0          1.0                        2.0    2.0  ...  0.0  2.0   \n",
       "\n",
       "  VK_DHT4A VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "1      8.0       11.0    10.0            3.0            9.0      4.0        5   \n",
       "2      9.0        9.0     6.0            3.0            9.0      2.0        5   \n",
       "3      7.0       10.0    11.0            6.0            9.0      7.0        3   \n",
       "4      3.0        5.0     4.0            2.0            9.0      3.0        4   \n",
       "5     10.0        7.0     4.0            6.0            9.0      7.0        4   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(impute_median_numerical(azdias_df).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751331, 335)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of the non ordinal categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 435.76 Mb\n"
     ]
    }
   ],
   "source": [
    "one_hot_list = ['WOHNLAGE','VERS_TYP','SHOPPER_TYP','RETOURTYP_BK_S','PLZ8_BAUMAX','NATIONALITAET_KZ',\n",
    "                'LP_FAMILIE_GROB','LP_LEBENSPHASE_FEIN','KBA05_MODTEMP','KBA05_MAXHERST','KBA05_HERSTTEMP',\n",
    "                'HEALTH_TYP','GFK_URLAUBERTYP','GEBAEUDETYP','FINANZTYP','D19_KONSUMTYP_MAX',\n",
    "                'CJT_GESAMTTYP','CAMEO_DEU_2015','AGER_TYP']\n",
    "azdias_df = pd.get_dummies(azdias_df, columns =one_hot_list)\n",
    "\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_df), 'Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode into numerical values binary feature OST_WEST_KZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_ost_west = LabelEncoder()\n",
    "label_ost_west.fit(azdias_df['OST_WEST_KZ'])\n",
    "azdias_df['OST_WEST_KZ'] = label_ost_west.transform(azdias_df['OST_WEST_KZ'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp into an integer formed by year month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp =  pd.to_datetime(azdias_df['EINGEFUEGT_AM']) ## pandas recognizes your format\n",
    "\n",
    "azdias_df['EINGEFUEGT_AM'] = timestamp.dt.strftime('%Y%m%d')\n",
    "azdias_df['EINGEFUEGT_AM'] = azdias_df['EINGEFUEGT_AM'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize values before aplying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "np_azdias = azdias_df.values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np_azdias)\n",
    "np_azdias = scaler.transform(np_azdias)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in the dataframe the normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df = pd.DataFrame(data=np_azdias,\n",
    "          index=azdias_df.index,\n",
    "          columns=azdias_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "session = sagemaker.Session()\n",
    "# get IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'arvato'\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix+\"/train\")\n",
    "num_components = 400\n",
    "\n",
    "\n",
    "\n",
    "pca = sagemaker.PCA(  role = role,\n",
    "                      train_instance_count = 1,\n",
    "                      train_instance_type = 'ml.m5.large', \n",
    "                      num_components = num_components,\n",
    "                      sagemaker_session=session,\n",
    "                      output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to recordset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_azdias_data = pca.record_set(np_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit data to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 15:40:24 Starting - Starting the training job...\n",
      "2020-05-01 15:40:25 Starting - Launching requested ML instances......\n",
      "2020-05-01 15:41:54 Starting - Preparing the instances for training...\n",
      "2020-05-01 15:42:23 Downloading - Downloading input data.........\n",
      "2020-05-01 15:43:50 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'502', u'mini_batch_size': u'500', u'num_components': u'400'}\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Final configuration: {u'num_components': u'400', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'502', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 WARNING 140455081604928] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/5953775c-38c9-487f-9574-eb91470c808f', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-01-15-40-24-085', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-245-8.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/899368c1-1c5f-4a3f-b999-32caf248673c', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-01-15-40-24-085', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/5953775c-38c9-487f-9574-eb91470c808f', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.245.8', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-01-15-40-24-085', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-245-8.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/899368c1-1c5f-4a3f-b999-32caf248673c', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-01-15-40-24-085', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/5953775c-38c9-487f-9574-eb91470c808f', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-01-15-40-24-085', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-245-8.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/899368c1-1c5f-4a3f-b999-32caf248673c', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-01-15-40-24-085', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/5953775c-38c9-487f-9574-eb91470c808f', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.245.8', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-01-15-40-24-085', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-245-8.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/899368c1-1c5f-4a3f-b999-32caf248673c', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-01-15-40-24-085', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/5953775c-38c9-487f-9574-eb91470c808f', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.245.8', 'AWS_REGION': 'eu-west-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-05-01-15-40-24-085', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-245-8.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/899368c1-1c5f-4a3f-b999-32caf248673c', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:848439228145:training-job/pca-2020-05-01-15-40-24-085', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 60 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 69 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:55 INFO 140455081604928] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:56 INFO 140455081604928] nvidia-smi took: 0.0252611637115 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:56 INFO 140455081604928] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:56 INFO 140455081604928] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:56 INFO 140455081604928] 502 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:43:56 INFO 140455081604928] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1073.0619430541992, \"sum\": 1073.0619430541992, \"min\": 1073.0619430541992}}, \"EndTime\": 1588347836.283591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588347835.181784}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1588347836.284219, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588347836.284165}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-01 15:43:56.290] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1107, \"num_examples\": 1, \"num_bytes\": 2022000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-01 15:44:23 Uploading - Uploading generated training model\n",
      "2020-05-01 15:44:23 Completed - Training job completed\n",
      "\u001b[34m[2020-05-01 15:44:15.236] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 18901, \"num_examples\": 1503, \"num_bytes\": 3038382564}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 18945.493936538696, \"sum\": 18945.493936538696, \"min\": 18945.493936538696}}, \"EndTime\": 1588347855.236465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588347836.284064}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:44:15 INFO 140455081604928] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1503, \"sum\": 1503.0, \"min\": 1503}, \"Total Records Seen\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 751331, \"sum\": 751331.0, \"min\": 751331}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588347855.237147, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1588347836.290928}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:44:15 INFO 140455081604928] #throughput_metric: host=algo-1, train throughput=39655.7268164 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 107.93113708496094, \"sum\": 107.93113708496094, \"min\": 107.93113708496094}}, \"EndTime\": 1588347855.345386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588347855.236876}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 15:44:15 INFO 140455081604928] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 20410.696029663086, \"sum\": 20410.696029663086, \"min\": 20410.696029663086}, \"setuptime\": {\"count\": 1, \"max\": 62.96896934509277, \"sum\": 62.96896934509277, \"min\": 62.96896934509277}}, \"EndTime\": 1588347855.375323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1588347855.345449}\n",
      "\u001b[0m\n",
      "Training seconds: 120\n",
      "Billable seconds: 120\n"
     ]
    }
   ],
   "source": [
    "#train_inputs = sagemaker.s3_input(train_s3, content_type='text/csv;label_size=0')\n",
    "\n",
    "pca.fit(formatted_azdias_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arvato/train/pca-2020-05-01-15-40-24-085/output/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the training job, it's suggested that you copy-paste\n",
    "# from the notebook or from a specific job in the AWS console\n",
    "\n",
    "training_job_name=pca._current_job_name\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix+\"/train\", training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as model_algo-1\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# loading the unzipped artifacts\n",
    "pca_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selected params\n",
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[  64.041176   64.28302    64.72615    64.96312    65.14543    66.50293\n",
       "   66.81868    66.87259    68.13239    68.98486    69.03504    70.19039\n",
       "   70.464905   70.72362    70.752655   70.99339    71.22265    71.31992\n",
       "   71.70301    71.81789    72.54359    72.63774    72.9882     73.442726\n",
       "   73.88662    74.057014   74.92334    75.01181    75.086044   75.580414\n",
       "   75.62884    75.761375   76.63863    76.73813    77.409195   77.55518\n",
       "   77.614914   78.25904    78.7608     78.96526    79.58971    79.712685\n",
       "   80.04612    80.549774   81.315956   81.94433    82.31471    82.88931\n",
       "   83.10964    83.91693    85.03807    85.46076    86.37928    86.468\n",
       "   87.162476   87.73943    88.0198     88.20649    88.83095    89.50008\n",
       "   89.65988    89.88306    90.298744   90.969086   91.63041    92.39185\n",
       "   92.91409    93.216415   93.476425   93.89461    94.061066   94.37686\n",
       "   95.071075   95.486145   96.091705   96.43826    96.50029    96.937744\n",
       "   97.79459    97.92416    98.40093    98.75659    98.98326    99.460655\n",
       "   99.68439    99.8764    100.51172   100.622025  100.98229   101.213745\n",
       "  101.83463   102.093216  102.48854   102.816635  103.09386   103.29491\n",
       "  103.473946  104.02833   104.22494   104.72688   104.93021   105.96768\n",
       "  106.210754  106.749916  107.520905  107.76745   108.094025  108.535736\n",
       "  108.64307   109.63687   110.3629    111.49265   111.62157   112.40975\n",
       "  112.48941   113.21458   113.279945  113.81157   114.63968   115.45147\n",
       "  116.087875  116.43378   117.08814   117.39372   117.98615   118.82683\n",
       "  119.0814    119.44722   120.103676  120.869064  121.24304   122.0131\n",
       "  122.18428   122.765785  122.989555  123.32855   123.54312   123.7102\n",
       "  124.082565  124.730194  125.43594   125.50193   126.119194  127.01189\n",
       "  127.54554   127.74286   128.70743   128.98956   129.3243    129.66942\n",
       "  130.33195   130.99608   131.21825   131.42809   132.19121   132.41028\n",
       "  132.81073   133.25896   133.68224   133.96858   134.78519   135.41245\n",
       "  136.213     136.78769   137.12466   137.46027   137.79408   138.99141\n",
       "  139.6225    139.90747   140.21939   140.4572    140.7342    142.04477\n",
       "  142.43492   142.71829   144.3521    145.00662   145.16302   145.67418\n",
       "  146.25012   146.5487    146.92433   147.7632    147.97906   148.16734\n",
       "  149.48488   149.9875    150.35345   150.79633   151.11617   151.75583\n",
       "  152.69743   153.51955   154.4289    155.2043    155.66931   155.9639\n",
       "  156.72363   157.62872   158.31032   159.59886   159.99931   161.28888\n",
       "  162.38644   163.1995    164.13869   164.3684    164.96428   165.38443\n",
       "  165.96123   167.05635   167.57121   168.9483    168.99046   169.80037\n",
       "  170.26003   171.85304   172.63223   173.66139   174.42488   174.98944\n",
       "  175.40875   175.78284   176.83148   177.2614    177.36206   177.85947\n",
       "  178.7421    179.08759   179.96947   180.81288   182.17894   182.18712\n",
       "  182.61356   183.84015   183.96863   185.5466    186.01842   187.2966\n",
       "  187.75288   187.96733   188.4381    189.1136    189.54785   190.0254\n",
       "  191.32693   191.69409   192.56194   193.46262   194.19073   194.37973\n",
       "  195.06113   196.28683   196.68121   197.16528   198.63306   199.2906\n",
       "  199.43886   201.92963   203.0214    203.77975   204.47977   204.51512\n",
       "  205.59232   207.18619   207.81604   209.71732   210.46777   210.50172\n",
       "  212.49759   213.18277   214.04477   215.05093   215.7555    217.86552\n",
       "  219.15034   219.80891   220.11417   221.93146   223.49878   225.44131\n",
       "  226.39223   227.11687   227.99081   228.40349   228.99919   229.88698\n",
       "  231.33673   232.41072   233.83357   234.41193   236.27332   237.13126\n",
       "  239.35698   240.75906   242.64423   243.16154   244.50319   245.45184\n",
       "  246.9081    247.38213   248.65602   250.23755   250.7464    252.49147\n",
       "  254.43727   255.44818   257.52963   259.09488   261.38324   263.10522\n",
       "  263.5377    267.22986   268.42697   270.32635   270.81876   271.83466\n",
       "  272.9639    274.69235   277.4038    278.74417   279.68958   281.93762\n",
       "  283.13095   283.5866    286.2063    286.5463    290.04468   292.02585\n",
       "  293.48938   294.67593   297.26596   299.1729    299.29126   301.8865\n",
       "  304.65347   307.9394    311.5526    312.29245   313.12274   314.96832\n",
       "  318.59982   319.12796   321.38696   323.85196   324.00735   327.131\n",
       "  329.58392   330.00412   331.3796    336.57245   339.69214   340.35553\n",
       "  343.68964   350.51846   353.40048   354.03076   358.57538   362.7714\n",
       "  368.26236   368.78586   375.6947    379.2791    381.81165   384.63565\n",
       "  393.18457   400.0817    400.99814   403.57227   407.15997   414.08762\n",
       "  415.07492   416.60327   422.3149    427.67856   434.04114   438.51758\n",
       "  447.02722   461.2349    462.07718   482.41174   487.67105   493.12335\n",
       "  508.22787   516.47345   534.65955   554.74634   568.82874   584.407\n",
       "  616.4234    653.3704    677.761     696.6082    719.29865   740.6566\n",
       "  992.99054  1008.35144  1193.3284   1467.2262  ]\n",
       "<NDArray 400 @cpu(0)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_model_params['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the explained variance for the top n principal components\n",
    "# you may assume you have access to the global var N_COMPONENTS\n",
    "def explained_variance(s, n_top_components):\n",
    "    '''Calculates the approx. data variance that n_top_components captures.\n",
    "       :param s: A dataframe of singular values for top components; \n",
    "           the top value is in the last row.\n",
    "       :param n_top_components: An integer, the number of top components to use.\n",
    "       :return: The expected data variance covered by the n_top_components.'''\n",
    "    \n",
    "    n_components = len(s) - n_top_components\n",
    "    partial = s[n_components:].pow(2).sum(axis=0)\n",
    "    total = s.pow(2).sum(axis=0)\n",
    "\n",
    "    return partial/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0    0.923581\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "n_top_components = 220 # select a value for the number of top components\n",
    "\n",
    "# calculate the explained variance\n",
    "exp_variance = explained_variance(s, n_top_components)\n",
    "print('Explained variance: ', exp_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for x in range(400):\n",
    "    y.append(explained_variance(s, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y)\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 ms, sys: 2.36 ms, total: 24.8 ms\n",
      "Wall time: 398 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pca_transformer = pca.transformer(instance_count = 1, \n",
    "                                  instance_type = 'ml.m5.large',\n",
    "                                  output_path='s3://{}/{}/pca/transform/test'.format(bucket_name, prefix+\"/transform\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(formatted_azdias_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "filename = 'azdias.csv'\n",
    "\n",
    "\n",
    "u = azdias_df.select_dtypes(object)\n",
    "azdias_df[u.columns] = u.apply(\n",
    "    lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into local notebook storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df.to_csv(filename,header = False,index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv into S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "\n",
    "np_azdias_location = session.upload_data(os.path.join(filename), key_prefix=prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete temp file from sagemaker notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] nvidia-smi took: 0.0251898765564 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loading entry points\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] Number of server workers: 2\u001b[0m\n",
      "\u001b[34m[2020-05-01 16:10:26 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-05-01 16:10:26 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-05-01 16:10:26 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-05-01 16:10:26 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loading model...\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2020-05-01 16:10:26 +0000] [90] [INFO] Booting worker with pid: 90\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] loading model...\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:26 INFO 140572090439488] ...model loaded.\u001b[0m\n",
      "\u001b[32m2020-05-01T16:10:45.815:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349445.797934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349426.87702}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349445.797934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349426.87702}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349452.254034, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349445.798038}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349452.254034, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349445.798038}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349452.686508, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349426.96379}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349452.686508, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349426.96379}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349454.722705, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349452.254158}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349454.722705, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349452.254158}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349455.092224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349452.686606}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349455.092224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349452.686606}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:10:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349457.263938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349454.722792}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349457.263938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349454.722792}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349457.755703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349455.092728}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349457.755703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349455.092728}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:10:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:10:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349459.788812, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349457.264026}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349460.150718, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349457.756223}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349459.788812, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349457.264026}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349460.150718, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349457.756223}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349462.019091, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349459.788899}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349462.019091, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349459.788899}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349462.563624, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349460.151217}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349462.563624, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349460.151217}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349464.471496, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349462.019169}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349465.326284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349462.56416}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349464.471496, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349462.019169}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349465.326284, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349462.56416}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:11:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349469.404227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349466.959163}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349469.404227, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349466.959163}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349470.193951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349467.72899}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349470.193951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349467.72899}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349471.95589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349469.404748}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349471.95589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349469.404748}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349472.566378, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349470.194036}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349472.566378, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349470.194036}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349474.230218, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349471.956396}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349474.230218, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349471.956396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349474.882926, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349472.566464}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349474.882926, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349472.566464}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349477.09191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349474.23073}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349477.243374, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349474.883118}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349477.09191, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349474.23073}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349477.243374, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349474.883118}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349479.470901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349477.091993}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349479.731778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349477.243529}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349479.470901, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349477.091993}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349479.731778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349477.243529}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349481.912067, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349479.471425}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349482.290285, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349479.731863}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349481.912067, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349479.471425}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349482.290285, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349479.731863}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:22 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:22 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:22 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:22 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349484.417135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349481.912586}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349484.417135, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349481.912586}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349484.638979, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349482.290367}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349484.638979, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349482.290367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349486.872949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349484.417651}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349487.067212, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349484.639065}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349486.872949, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349484.417651}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349487.067212, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349484.639065}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349489.46779, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349487.067292}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349489.619244, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349486.87354}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349489.46779, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349487.067292}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349489.619244, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349486.87354}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349491.842993, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349489.619364}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349492.100351, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349489.468342}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349491.842993, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349489.619364}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349492.100351, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349489.468342}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349494.326165, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349491.84308}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349494.326165, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349491.84308}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349494.736251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349492.101034}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349494.736251, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349492.101034}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349497.28466, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349494.736349}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349497.28466, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349494.736349}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349499.400767, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349496.809632}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349499.400767, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349496.809632}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1907.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349500.427888, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349497.285185}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1907.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349500.427888, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349497.285185}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349501.8682, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349499.40122}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349501.8682, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349499.40122}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349503.093197, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349500.427965}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349503.093197, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349500.427965}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:43 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:43 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349504.201814, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349501.869127}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:43 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:43 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349504.201814, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349501.869127}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349505.564149, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349503.093277}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349505.564149, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349503.093277}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349507.999967, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349505.564661}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349507.999967, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349505.564661}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349509.054562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349506.586397}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349509.054562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349506.586397}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349510.552845, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349508.000549}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349510.552845, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349508.000549}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349511.58462, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349509.054638}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349511.58462, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349509.054638}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349513.12012, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349510.553378}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349513.12012, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349510.553378}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349514.014971, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349511.585519}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349514.014971, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349511.585519}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349515.52962, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349513.12065}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349515.52962, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349513.12065}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:11:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349516.504476, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349514.01539}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349516.504476, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349514.01539}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349518.123434, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349515.530146}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349518.123434, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349515.530146}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349518.907072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349516.504939}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349518.907072, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349516.504939}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:11:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:11:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349520.688275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349518.123967}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349521.331756, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349518.907556}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349520.688275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349518.123967}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349521.331756, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349518.907556}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349523.285733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349520.688777}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349523.285733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349520.688777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349523.896518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349521.332263}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349523.896518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349521.332263}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349525.717397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349523.285815}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349526.404529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349523.897361}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349525.717397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349523.285815}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349526.404529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349523.897361}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:12:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349528.115215, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349525.717482}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349528.115215, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349525.717482}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349528.83994, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349526.405499}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349528.83994, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349526.405499}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349530.582934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349528.115295}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349531.28491, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349528.84049}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:11 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349530.582934, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349528.115295}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349531.28491, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349528.84049}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:11 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349533.040103, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349530.583012}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349533.040103, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349530.583012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349533.70873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349531.284991}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349533.70873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349531.284991}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349535.412723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349533.040604}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349535.412723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349533.040604}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349536.092808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349533.708816}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349536.092808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349533.708816}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:12:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349537.866022, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349535.413239}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349537.866022, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349535.413239}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349538.502465, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349536.092893}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349538.502465, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349536.092893}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349540.288809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349537.8661}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349540.288809, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349537.8661}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349541.012053, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349538.50255}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349541.012053, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349538.50255}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349542.759621, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349540.289318}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349543.343483, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349541.012143}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349542.759621, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349540.289318}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349543.343483, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349541.012143}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349545.142851, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349542.760132}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349545.142851, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349542.760132}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349545.767799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349543.34357}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349545.767799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349543.34357}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:12:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349548.41485, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349545.768379}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349548.41485, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349545.768379}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349550.191512, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349547.776602}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349550.191512, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349547.776602}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349551.017671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349548.414934}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349551.017671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349548.414934}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349552.64083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349550.191592}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349552.64083, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349550.191592}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349553.492194, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349551.017765}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349553.492194, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349551.017765}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349554.983297, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349552.641358}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349554.983297, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349552.641358}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349555.832475, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349553.49228}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349555.832475, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349553.49228}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:12:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349558.270749, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349555.832552}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349558.270749, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349555.832552}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349559.906275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349557.342741}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349559.906275, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349557.342741}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349560.95101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349558.27124}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349560.95101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349558.27124}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349562.23648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349559.906756}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349562.23648, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349559.906756}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:43 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:43 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:43 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:43 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349563.487936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349560.951089}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349563.487936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349560.951089}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349564.806167, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349562.236983}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349564.806167, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349562.236983}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349566.051397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349563.488266}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349566.051397, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349563.488266}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:12:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349567.200346, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349564.806248}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349567.200346, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349564.806248}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349568.544051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349566.052225}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349568.544051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349566.052225}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349569.618646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349567.200455}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349569.618646, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349567.200455}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349570.932216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349568.544888}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349570.932216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349568.544888}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349572.178348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349569.618726}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349572.178348, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349569.618726}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349573.416745, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349570.933028}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349573.416745, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349570.933028}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349574.739021, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349572.178857}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349574.739021, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349572.178857}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349575.81068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349573.417131}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349575.81068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349573.417131}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:12:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349578.389216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349575.811082}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349578.389216, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349575.811082}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:12:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:12:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349579.662768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349577.286449}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349579.662768, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349577.286449}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349580.894961, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349578.389635}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349580.894961, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349578.389635}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349582.185407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349579.663267}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349582.185407, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349579.663267}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349583.423964, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349580.895439}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349583.423964, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349580.895439}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349584.740717, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349582.185915}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349584.740717, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349582.185915}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349585.866338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349583.424765}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349585.866338, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349583.424765}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:13:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349588.359765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349585.866802}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349588.359765, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349585.866802}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349589.788205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349587.218408}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349589.788205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349587.218408}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349590.735272, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349588.360203}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349590.735272, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349588.360203}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:11 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349592.278119, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349589.7887}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:11 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349592.278119, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349589.7887}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349593.144583, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349590.735749}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349593.144583, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349590.735749}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349594.711469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349592.278622}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349594.711469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349592.278622}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349595.847471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349593.145026}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349595.847471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349593.145026}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:13:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349597.307864, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349594.71155}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349597.307864, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349594.71155}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349598.389119, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349595.848403}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349598.389119, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349595.848403}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349599.677534, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349597.307949}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349599.677534, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349597.307949}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349600.871799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349598.389622}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349600.871799, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349598.389622}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349602.16772, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349599.677614}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349602.16772, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349599.677614}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349603.470274, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349600.872293}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349603.470274, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349600.872293}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349604.670641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349602.168223}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349604.670641, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349602.168223}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349605.900349, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349603.470346}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349605.900349, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349603.470346}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:13:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349608.423916, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349605.900428}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349608.423916, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349605.900428}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349609.788936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349607.217703}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349609.788936, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349607.217703}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349610.929836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349608.424409}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349610.929836, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349608.424409}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1906.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349612.245789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349609.789016}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1906.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349612.245789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349609.789016}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349613.596609, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349610.93035}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349613.596609, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349610.93035}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349614.657059, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349612.24587}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349614.657059, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349612.24587}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349615.966353, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349613.596694}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349615.966353, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349613.596694}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:13:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349617.087254, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349614.65755}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349617.087254, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349614.65755}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349618.311045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349615.966431}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349618.311045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349615.966431}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349619.440526, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349617.087752}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349619.440526, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349617.087752}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349620.763142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349618.31112}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349620.763142, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349618.31112}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349621.993146, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349619.440602}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349621.993146, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349619.440602}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349623.362681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349620.763652}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349623.362681, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349620.763652}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349624.540932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349621.998885}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349624.540932, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349621.998885}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349625.844045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349623.362765}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349625.844045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349623.362765}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349626.846416, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349624.541444}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349626.846416, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349624.541444}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349628.40622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349625.844126}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349628.40622, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349625.844126}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349629.382691, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349626.846902}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349629.382691, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349626.846902}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349630.828662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349628.406722}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349630.828662, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349628.406722}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:13:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349631.894466, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349629.382774}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349631.894466, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349629.382774}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349633.260924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349630.829167}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349633.260924, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349630.829167}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349634.464987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349631.894552}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349634.464987, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349631.894552}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1905.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1905.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349635.786199, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349633.261432}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349635.786199, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349633.261432}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349637.028666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349634.465074}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349637.028666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349634.465074}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349638.085393, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349635.786697}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349638.085393, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349635.786697}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:13:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:13:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349639.560974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349637.028747}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349639.560974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349637.028747}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349640.792583, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349638.085902}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349640.792583, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349638.085902}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:14:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349642.14908, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349639.561059}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349642.14908, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349639.561059}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349643.382912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349640.792663}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349643.382912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349640.792663}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349644.887762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349642.149586}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349644.887762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349642.149586}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349645.989502, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349643.383362}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349645.989502, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349643.383362}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349647.359398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349644.888268}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349647.359398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349644.888268}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349648.425971, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349645.99001}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349648.425971, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349645.99001}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349649.877748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349647.359478}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349649.877748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349647.359478}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349650.974242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349648.426487}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349650.974242, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349648.426487}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:14:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349653.560673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349650.974739}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349653.560673, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349650.974739}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349654.800241, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349652.343368}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349654.800241, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349652.343368}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349656.025676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349653.561178}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349656.025676, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349653.561178}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349657.336625, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349654.800736}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349657.336625, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349654.800736}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349658.501746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349656.025755}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349658.501746, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349656.025755}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349659.716997, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349657.336706}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349659.716997, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349657.336706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349660.917567, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349658.502286}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349660.917567, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349658.502286}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:14:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349662.36073, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349659.717467}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349662.36073, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349659.717467}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349663.452663, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349660.917655}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349663.452663, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349660.917655}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349664.990549, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349662.361257}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349664.990549, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349662.361257}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349665.84688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349663.453334}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349665.84688, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349663.453334}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349667.445728, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349664.990626}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349667.445728, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349664.990626}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1931.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349668.378638, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349665.847659}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1931.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349668.378638, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349665.847659}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349670.040826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349667.445807}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349670.040826, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349667.445807}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349671.012224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349668.37956}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349671.012224, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349668.37956}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349672.551469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349670.041336}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349673.444957, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349671.012307}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349672.551469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349670.041336}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349673.444957, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349671.012307}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349675.030582, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349672.551877}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349675.030582, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349672.551877}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349675.761162, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349673.445037}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349675.761162, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349673.445037}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349677.464589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349675.03109}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349677.464589, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349675.03109}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349678.305244, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349675.761253}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349678.305244, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349675.761253}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349679.789087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349677.465122}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349679.789087, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349677.465122}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349680.723263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349678.305687}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349680.723263, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349678.305687}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:14:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349684.87541, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349682.261718}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349684.87541, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349682.261718}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349685.621088, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349683.103067}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349685.621088, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349683.103067}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349687.364612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349684.875497}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349687.364612, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349684.875497}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349688.043741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349685.621529}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349688.043741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349685.621529}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349689.763023, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349687.365125}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349689.763023, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349687.365125}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349690.547734, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349688.04388}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349690.547734, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349688.04388}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:14:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349694.892025, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349692.175893}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349694.892025, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349692.175893}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349695.898741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349693.016142}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349695.898741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349693.016142}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349697.483723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349694.892565}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349697.483723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349694.892565}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349698.406268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349695.898822}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349698.406268, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349695.898822}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:14:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:14:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349699.952877, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349697.484241}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349699.952877, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349697.484241}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349700.887597, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349698.406346}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349700.887597, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349698.406346}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:15:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349703.330138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349700.887676}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349703.330138, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349700.887676}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349704.850694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349702.409871}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349704.850694, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349702.409871}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349705.715051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349703.330217}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349705.715051, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349703.330217}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349707.337725, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349704.851201}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349707.337725, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349704.851201}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349708.209068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349705.71513}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349708.209068, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349705.71513}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349709.756262, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349707.338263}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349709.756262, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349707.338263}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349710.800595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349708.209147}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349710.800595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349708.209147}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:15:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349712.189805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349709.756336}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349712.189805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349709.756336}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349713.245821, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349710.801107}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349713.245821, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349710.801107}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349714.580045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349712.189885}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349714.580045, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349712.189885}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349715.67101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349713.246347}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349715.67101, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349713.246347}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349717.104553, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349714.580157}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349717.104553, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349714.580157}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349718.097955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349715.671118}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349718.097955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349715.671118}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349719.584779, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349717.105089}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349719.584779, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349717.105089}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349720.644808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349718.098035}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349720.644808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349718.098035}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349723.127709, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349720.64489}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349723.127709, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349720.64489}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349724.498441, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349721.986332}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349724.498441, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349721.986332}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349725.763819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349723.12779}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349725.763819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349723.12779}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349726.982823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349724.498956}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349726.982823, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349724.498956}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349728.52775, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349725.763902}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349728.52775, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349725.763902}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349729.627381, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349726.982905}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349729.627381, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349726.982905}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349731.021149, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349728.527832}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349731.021149, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349728.527832}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:15:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349731.993332, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349729.627884}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349731.993332, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349729.627884}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349733.543843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349731.021232}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349733.543843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349731.021232}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349734.469383, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349731.99341}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349734.469383, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349731.99341}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349735.928425, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349733.544312}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349735.928425, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349733.544312}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349737.039562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349734.469464}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349737.039562, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349734.469464}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349738.45985, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349735.928508}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349738.45985, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349735.928508}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349739.559838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349737.040069}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349739.559838, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349737.040069}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349740.991194, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349738.45993}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349740.991194, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349738.45993}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:15:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349742.084029, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349739.559923}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349742.084029, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349739.559923}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349743.44873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349740.991273}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349743.44873, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349740.991273}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349744.567171, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349742.084561}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349744.567171, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349742.084561}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349745.878898, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349743.449263}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349745.878898, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349743.449263}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349746.985775, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349744.567672}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349746.985775, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349744.567672}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349748.316679, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349745.87941}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349748.316679, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349745.87941}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349749.419105, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349746.986304}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349749.419105, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349746.986304}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349750.681693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349748.316759}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349750.681693, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349748.316759}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349753.140468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349750.682223}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349753.140468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349750.682223}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349754.48814, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349751.957398}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349754.48814, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349751.957398}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349755.698956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349753.140959}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349755.698956, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349753.140959}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349756.992954, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349754.488647}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349756.992954, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349754.488647}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349758.054205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349755.699041}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349758.054205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349755.699041}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:15:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349759.387638, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349756.993464}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:15:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349759.387638, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349756.993464}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349760.736093, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349758.054282}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349760.736093, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349758.054282}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349763.133719, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349760.736173}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349763.133719, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349760.736173}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349764.440685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349762.032675}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:03 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:03 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:03 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:03 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349764.440685, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349762.032675}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349765.494102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349763.134305}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349765.494102, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349763.134305}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349766.948546, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349764.440769}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349766.948546, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349764.440769}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349767.998675, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349765.494197}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349767.998675, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349765.494197}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349769.486285, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349766.949071}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:08 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:08 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:08 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:08 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349769.486285, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349766.949071}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349770.480285, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349767.998753}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349770.480285, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349767.998753}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:11 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:11 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:11 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:16:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349773.027852, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349770.480367}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349773.027852, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349770.480367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:13 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:13 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349774.344158, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349771.928471}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:13 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:13 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349774.344158, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349771.928471}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349775.515849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349773.027931}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349775.515849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349773.027931}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349776.874683, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349774.344662}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349776.874683, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349774.344662}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349777.906479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349775.516363}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349777.906479, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349775.516363}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:18 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:18 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:18 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:18 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349779.382913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349776.875203}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349779.382913, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349776.875203}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1925.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349780.347697, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349777.906561}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1925.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349780.347697, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349777.906561}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:16:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:23 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:23 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:23 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:23 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349784.619733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349781.911637}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349785.337974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349782.755651}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349784.619733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349781.911637}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349785.337974, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349782.755651}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349786.960861, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349784.620247}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349786.960861, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349784.620247}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349787.913951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349785.338179}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349787.913951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349785.338179}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349789.456789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349786.961383}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349789.456789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349786.961383}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349790.24563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349787.914596}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349790.24563, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349787.914596}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:16:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349794.570469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349791.985421}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349794.570469, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349791.985421}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349795.218791, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349792.690989}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349795.218791, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349792.690989}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349797.172133, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349794.57098}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349797.172133, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349794.57098}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349797.662417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349795.218877}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349797.662417, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349795.218877}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:38 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349799.670398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349797.184954}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349799.670398, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349797.184954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349800.121467, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349797.662501}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349800.121467, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349797.662501}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:16:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:43 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:43 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:43 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:43 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:43 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:43 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349804.479468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349802.028356}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349804.479468, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349802.028356}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349805.012016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349802.581447}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349805.012016, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349802.581447}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349806.90818, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349804.479556}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349807.490355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349805.01253}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349806.90818, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349804.479556}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349807.490355, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349805.01253}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349809.482852, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349806.90826}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349809.482852, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349806.90826}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349809.882405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349807.490438}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349809.882405, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349807.490438}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:16:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:53 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:53 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:53 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349814.283583, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349811.910659}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349814.283583, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349811.910659}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349814.817518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349812.3799}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349814.817518, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349812.3799}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1925.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1925.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349816.799449, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349814.283667}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349817.244741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349814.817604}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349816.799449, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349814.283667}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349817.244741, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349814.817604}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:58 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:58 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:58 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:58 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1909.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349819.147938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349816.799527}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349819.147938, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349816.799527}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349819.64052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349817.245295}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:16:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349819.64052, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349817.245295}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:16:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349821.484843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349819.148049}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349821.484843, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349819.148049}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:17:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349823.885492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349821.484929}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349824.482916, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349822.01858}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349823.885492, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349821.484929}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349824.482916, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349822.01858}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:05 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:05 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:05 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:05 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349826.380808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349823.885573}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349826.380808, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349823.885573}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349827.026912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349824.483439}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349827.026912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349824.483439}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1910.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349828.884824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349826.38089}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349829.419813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349827.026998}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349828.884824, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349826.38089}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349829.419813, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349827.026998}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:10 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:10 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:10 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:10 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349831.335431, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349828.885342}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349831.335431, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349828.885342}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:17:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1930.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1930.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349833.811718, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349831.335965}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349834.388942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349832.015582}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349833.811718, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349831.335965}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349834.388942, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349832.015582}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:15 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:15 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:15 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:15 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349836.251503, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349833.8118}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349836.251503, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349833.8118}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349836.860076, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349834.389025}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349836.860076, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349834.389025}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349838.826062, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349836.251993}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349839.197545, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349836.860161}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349838.826062, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349836.251993}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349839.197545, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349836.860161}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:20 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:20 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:20 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:20 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349841.294643, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349838.826597}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349841.294643, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349838.826597}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:17:22 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:22 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:22 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:22 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:22 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349843.936525, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349841.295172}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349844.412644, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349841.726765}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349843.936525, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349841.295172}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349844.412644, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349841.726765}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:25 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:25 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:25 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:25 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349846.504912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349843.937031}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349846.504912, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349843.937031}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349847.007511, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349844.412726}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349847.007511, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349844.412726}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:27 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349849.022629, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349846.504996}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349849.606723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349847.008047}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349849.022629, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349846.504996}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349849.606723, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349847.008047}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:30 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:30 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:30 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:30 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349851.386004, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349849.02271}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349851.386004, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349849.02271}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:17:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:32 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349853.722351, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349851.386083}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349854.559978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349852.033042}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349853.722351, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349851.386083}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349854.559978, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349852.033042}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:35 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:35 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:35 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:35 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349856.201176, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349853.722429}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349856.201176, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349853.722429}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349857.046955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349854.560796}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349857.046955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349854.560796}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:37 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349858.664043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349856.201256}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349859.581687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349857.047049}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349858.664043, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349856.201256}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:39 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:39 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:39 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349859.581687, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349857.047049}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:40 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:40 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:40 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:40 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349861.179703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349858.664129}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349861.179703, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349858.664129}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:17:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:42 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1927.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349863.774998, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349861.179786}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349864.461778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349862.031766}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349863.774998, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349861.179786}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349864.461778, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349862.031766}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:45 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:45 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:45 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:45 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349866.254595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349863.775078}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349866.254595, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349863.775078}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349867.095689, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349864.461865}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349867.095689, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349864.461865}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:47 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349868.688495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349866.254675}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349868.688495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349866.254675}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349869.518605, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349867.096224}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349869.518605, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349867.096224}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:50 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:50 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:50 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:50 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349871.154244, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349868.688576}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349871.154244, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349868.688576}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:17:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349871.996911, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349869.518687}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349871.996911, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349869.518687}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349873.624885, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349871.154748}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:52 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:52 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:52 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:52 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1920.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349873.624885, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349871.154748}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349874.479221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349871.996988}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349874.479221, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349871.996988}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:54 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:54 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:54 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:54 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349876.185485, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349873.625438}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349876.185485, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349873.625438}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349876.881671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349874.479309}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349876.881671, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349874.479309}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:56 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:56 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:56 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:56 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1926.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349878.600214, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349876.185976}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:57 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:57 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:57 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:57 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349878.600214, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349876.185976}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349879.357495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349876.882202}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:17:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349879.357495, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349876.882202}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:59 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:59 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:59 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:17:59 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1922.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:00 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:00 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:00 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:00 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349881.108602, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349878.600293}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349881.108602, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349878.600293}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:18:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:01 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:01 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:01 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:01 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:02 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:02 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349883.575598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349881.108684}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:02 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:02 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1924.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349883.575598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349881.108684}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349884.293634, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349881.886049}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349884.293634, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349881.886049}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:04 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349886.08127, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349883.575706}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349886.08127, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349883.575706}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349886.709867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349884.294157}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349886.709867, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349884.294157}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:06 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:06 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:06 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:06 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:07 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:07 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:07 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:07 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349888.592033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349886.081349}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349888.592033, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349886.081349}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349889.200446, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349886.710405}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349889.200446, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349886.710405}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:09 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349890.984748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349888.592114}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349891.546762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349889.200964}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349890.984748, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349888.592114}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349891.546762, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349889.200964}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:18:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:11 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:11 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:12 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:12 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:12 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:12 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349893.470371, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349890.984831}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349893.470371, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349890.984831}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349894.086772, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349891.547255}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349894.086772, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349891.547255}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:14 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349896.049123, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349893.470452}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349896.637906, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349894.087706}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349896.049123, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349893.470452}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349896.637906, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349894.087706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:16 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:16 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:16 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:16 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1908.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:17 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:17 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:17 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:17 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349898.484381, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349896.049206}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349898.484381, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349896.049206}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349898.957575, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349896.638412}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1928.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349898.957575, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349896.638412}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1928.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:19 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349900.917849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349898.48499}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349901.303733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349898.958004}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349900.917849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349898.48499}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349901.303733, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349898.958004}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:21 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:21 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:21 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:21 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:18:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:24 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1919.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349905.699849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349903.295445}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349905.699849, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349903.295445}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349906.117232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349903.734452}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349906.117232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349903.734452}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1913.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:26 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1911.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349908.097172, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349905.700379}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349908.542484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349906.11749}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349908.097172, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349905.700379}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349908.542484, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349906.11749}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:28 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:28 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:28 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:28 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1912.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:29 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:29 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:29 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:29 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349910.491805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349908.09769}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349910.491805, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349908.09769}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349910.960061, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349908.542887}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349910.960061, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349908.542887}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:31 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349912.893527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349910.492318}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349913.344195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349910.96067}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349912.893527, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349910.492318}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349913.344195, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349910.96067}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:33 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:33 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:33 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:33 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:34 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:34 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:34 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:34 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349915.344752, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349912.894063}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349915.344752, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349912.894063}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349915.869104, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349913.344637}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349915.869104, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349913.344637}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:36 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:18:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:39 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349920.529509, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349917.880195}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349920.529509, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349917.880195}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349920.988846, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349918.276983}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349920.988846, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349918.276983}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:41 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:44 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:44 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:44 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:44 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1921.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349925.649009, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349923.332135}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349925.649009, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349923.332135}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349925.827819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349923.428129}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349925.827819, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349923.428129}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1915.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:46 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1917.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349927.977003, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349925.828384}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349928.3626, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349925.649094}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349927.977003, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349925.828384}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349928.3626, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349925.649094}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:48 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:48 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:48 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:48 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1923.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:49 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:49 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:49 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:49 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349930.422063, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349927.977538}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349930.422063, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349927.977538}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349930.753267, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349928.362686}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349930.753267, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349928.362686}\n",
      "\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1918.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:51 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/01/2020 16:18:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:53 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1914.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349935.170984, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349932.796868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349935.514548, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349933.213344}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349935.170984, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349932.796868}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349935.514548, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349933.213344}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/01/2020 16:18:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1701.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:55 WARNING 140572090439488] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:55 INFO 140572090439488] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:55 INFO 140572090439488] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[05/01/2020 16:18:55 INFO 140572090439488] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1701.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349937.562624, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349935.171566}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588349937.562624, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"AlgorithmModel\"}, \"StartTime\": 1588349935.171566}\n",
      "\u001b[0m\n",
      "\n",
      "CPU times: user 2.5 s, sys: 132 ms, total: 2.63 s\n",
      "Wall time: 11min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "\n",
    "pca_transformer.transform(np_azdias_location, content_type=CONTENT_TYPE_CSV, split_type='Line')\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-848439228145/arvato/transform/pca/transform/test/azdias.csv.out to ./azdias.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3file_uri = 's3://'+bucket_name+'/arvato/transform/pca/transform/test/azdias.csv.out'\n",
    "!aws s3 cp  $s3file_uri ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 53.32 Mb\n"
     ]
    }
   ],
   "source": [
    "transformed_filename = 'azdias.csv.out'\n",
    "\n",
    "azdias_sub_pca = pd.read_csv(transformed_filename, usecols = [0], header = None)\n",
    "azdias_sub_pca[0] = azdias_sub_pca[0].apply(lambda x: str(x)[15:])\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 2.87 Mb\n"
     ]
    }
   ],
   "source": [
    "azdias_sub_pca[0] = pd.to_numeric(azdias_sub_pca[0], downcast='float')\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendColumns(df, number):\n",
    "    for column in range(1,number):\n",
    "        data_col = pd.read_csv(transformed_filename, usecols = [column], header = None)\n",
    "        df[column] = pd.to_numeric(\n",
    "                        #pd.read_csv(transformed_filename, usecols = [column], header = None),\n",
    "                        data_col[column],\n",
    "                        downcast='float'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 630.54 Mb\n"
     ]
    }
   ],
   "source": [
    "appendColumns(azdias_sub_pca, 220)\n",
    "\n",
    "print('Memory used:', memory_usage(azdias_sub_pca), 'Mb') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a KMeans estimator\n",
    "k_estimator = sagemaker.KMeans(role,\n",
    "                               train_instance_count = 1,\n",
    "                               train_instance_type = 'ml.m5.large',\n",
    "                               k = 8\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
